import os
import sys
import json
import asyncio
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from typing import Dict, List, Optional, Any, Tuple
import time
from datetime import datetime
import random

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from utils.data_loader import DataLoader
from utils.cache_manager import CacheManager
from utils.llm_processor import LLMProcessor, get_keywords

# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œé…ç½®
st.set_page_config(
    page_title="è®ºæ–‡å…³é”®è¯åŒ¹é…",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨ã€ç¼“å­˜ç®¡ç†å™¨å’ŒLLMå¤„ç†å™¨
@st.cache_resource
def get_data_loader():
    return DataLoader()

@st.cache_resource
def get_cache_manager():
    return CacheManager()

def get_llm_processor():
    api_key = st.session_state.get("api_key", "")
    processor = LLMProcessor(api_key=api_key)
    return processor

# åˆå§‹åŒ–SessionçŠ¶æ€
def init_session_state():
    if "api_key" not in st.session_state:
        st.session_state.api_key = ""
    if "loaded_data" not in st.session_state:
        st.session_state.loaded_data = None
    if "selected_keywords" not in st.session_state:
        st.session_state.selected_keywords = []
    if "system_prompt" not in st.session_state:
        st.session_state.system_prompt = ""
    if "user_prompt_template" not in st.session_state:
        st.session_state.user_prompt_template = ""
    if "processing_results" not in st.session_state:
        st.session_state.processing_results = []
    if "current_tab" not in st.session_state:
        st.session_state.current_tab = "æ•°æ®åŠ è½½"
    if "annotation_results" not in st.session_state:
        st.session_state.annotation_results = {}
    # æ·»åŠ è§†å›¾æ§åˆ¶çŠ¶æ€
    if "show_detail_view" not in st.session_state:
        st.session_state.show_detail_view = False
    if "selected_result" not in st.session_state:
        st.session_state.selected_result = None
    # æ·»åŠ å…³é”®è¯ç®¡ç†çŠ¶æ€
    if "keyword_lists" not in st.session_state:
        st.session_state.keyword_lists = {}  # ä¿å­˜çš„å…³é”®è¯åˆ—è¡¨é›†åˆ
    if "to_select_keywords" not in st.session_state:
        st.session_state.to_select_keywords = []  # æ‰¹é‡é€‰æ‹©ä¸´æ—¶å­˜å‚¨
    if "to_delete_keywords" not in st.session_state:
        st.session_state.to_delete_keywords = []  # æ‰¹é‡åˆ é™¤ä¸´æ—¶å­˜å‚¨
    # æ·»åŠ å¤„ç†çŠ¶æ€æ§åˆ¶
    if "is_processing" not in st.session_state:
        st.session_state.is_processing = False  # æ˜¯å¦æ­£åœ¨å¤„ç†æ•°æ®
    if "current_processing" not in st.session_state:
        st.session_state.current_processing = None  # å½“å‰æ­£åœ¨å¤„ç†çš„æ•°æ®
    if "processed_items" not in st.session_state:
        st.session_state.processed_items = []  # æœ¬æ¬¡ä¼šè¯å·²å¤„ç†çš„æ•°æ®åˆ—è¡¨
    if "processing_queue" not in st.session_state:
        st.session_state.processing_queue = []  # å¾…å¤„ç†é˜Ÿåˆ—
    if "display_page" not in st.session_state:
        st.session_state.display_page = {
            "unprocessed": 0,  # æœªå¤„ç†æ•°æ®å½“å‰é¡µç 
            "processed": 0,    # å·²å¤„ç†æ•°æ®å½“å‰é¡µç 
            "processing": 0,   # æ­£åœ¨å¤„ç†æ•°æ®å½“å‰é¡µç 
            "results_list": 0, # ç»“æœåˆ—è¡¨å½“å‰é¡µç 
            "cached": 0,       # ç¼“å­˜æ•°æ®å½“å‰é¡µç 
            "page_size": 10    # æ¯é¡µæ˜¾ç¤ºæ•°é‡
        }
    # æ·»åŠ æ•°æ®åŠ è½½ç¼“å­˜çŠ¶æ€
    if "last_loaded_files" not in st.session_state:
        st.session_state.last_loaded_files = []  # ä¸Šæ¬¡åŠ è½½çš„æ–‡ä»¶åˆ—è¡¨
    if "last_loaded_source" not in st.session_state:
        st.session_state.last_loaded_source = ""  # ä¸Šæ¬¡åŠ è½½çš„æ•°æ®æº
    if "last_session_time" not in st.session_state:
        st.session_state.last_session_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")  # ä¸Šæ¬¡ä¼šè¯æ—¶é—´
    if "to_delete_results" not in st.session_state:
        st.session_state.to_delete_results = []  # å¾…åˆ é™¤ç»“æœåˆ—è¡¨
    if "prompt_examples" not in st.session_state:
        st.session_state.prompt_examples = []  # æç¤ºè¯ç¤ºä¾‹
    if "confirm_clear_cache" not in st.session_state:
        st.session_state.confirm_clear_cache = False  # ç¡®è®¤æ¸…ç©ºç¼“å­˜çš„çŠ¶æ€

# åŠ è½½é»˜è®¤æç¤ºè¯
def load_default_prompts():
    prompts_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "prompts")
    default_prompts = os.path.join(prompts_dir, "default.json")
    if os.path.exists(default_prompts):
        try:
            with open(default_prompts, 'r', encoding='utf-8') as f:
                prompts = json.load(f)
                st.session_state.system_prompt = prompts.get('system_prompt', '')
                st.session_state.user_prompt_template = prompts.get('user_prompt_template', '')
                st.session_state.prompt_examples = prompts.get('examples', [])
        except Exception as e:
            st.error(f"åŠ è½½é»˜è®¤æç¤ºè¯æ—¶å‡ºé”™: {str(e)}")

# å¢åŠ ç¼“å­˜ç®¡ç†å™¨ä¸­çš„æ•°æ®åŠ è½½ç¼“å­˜æ–¹æ³•
def add_data_cache_methods():
    cache_manager = get_cache_manager()
    
    # ä¿å­˜åŠ è½½çš„æ•°æ®
    def save_loaded_data(df, source, file_paths):
        """ä¿å­˜åŠ è½½çš„æ•°æ®åˆ°ç¼“å­˜"""
        if df is None or df.empty:
            return False
        
        try:
            # åˆ›å»ºç¼“å­˜ç›®å½•
            data_cache_dir = os.path.join(cache_manager.cache_dir, "data_cache")
            os.makedirs(data_cache_dir, exist_ok=True)
            
            # ä¿å­˜æ•°æ®
            cache_path = os.path.join(data_cache_dir, "last_loaded_data.pkl")
            df.to_pickle(cache_path)
            
            # ä¿å­˜å…ƒæ•°æ®
            metadata = {
                "source": source,
                "file_paths": file_paths,
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "rows": len(df)
            }
            with open(os.path.join(data_cache_dir, "last_loaded_metadata.json"), "w", encoding="utf-8") as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            return True
        except Exception as e:
            print(f"ä¿å­˜åŠ è½½æ•°æ®åˆ°ç¼“å­˜æ—¶å‡ºé”™: {str(e)}")
            return False
    
    # åŠ è½½ä¸Šæ¬¡åŠ è½½çš„æ•°æ®
    def load_last_data():
        """ä»ç¼“å­˜åŠ è½½ä¸Šæ¬¡åŠ è½½çš„æ•°æ®"""
        try:
            # æ£€æŸ¥ç¼“å­˜æ–‡ä»¶
            data_cache_dir = os.path.join(cache_manager.cache_dir, "data_cache")
            cache_path = os.path.join(data_cache_dir, "last_loaded_data.pkl")
            metadata_path = os.path.join(data_cache_dir, "last_loaded_metadata.json")
            
            if not os.path.exists(cache_path) or not os.path.exists(metadata_path):
                return None, None
            
            # åŠ è½½å…ƒæ•°æ®
            with open(metadata_path, "r", encoding="utf-8") as f:
                metadata = json.load(f)
            
            # åŠ è½½æ•°æ®
            df = pd.read_pickle(cache_path)
            
            return df, metadata
        except Exception as e:
            print(f"ä»ç¼“å­˜åŠ è½½æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return None, None
    
    # APIå¯†é’¥ç¼“å­˜åŠŸèƒ½
    def save_api_key(api_key):
        """ä¿å­˜APIå¯†é’¥åˆ°ç¼“å­˜"""
        if not api_key:
            return False
            
        try:
            # åˆ›å»ºç¼“å­˜ç›®å½•
            api_cache_dir = os.path.join(cache_manager.cache_dir, "api_cache")
            os.makedirs(api_cache_dir, exist_ok=True)
            
            # ä¿å­˜APIå¯†é’¥
            with open(os.path.join(api_cache_dir, "api_key.txt"), "w", encoding="utf-8") as f:
                f.write(api_key)
                
            return True
        except Exception as e:
            print(f"ä¿å­˜APIå¯†é’¥åˆ°ç¼“å­˜æ—¶å‡ºé”™: {str(e)}")
            return False
    
    def load_api_key():
        """ä»ç¼“å­˜åŠ è½½APIå¯†é’¥"""
        try:
            # æ£€æŸ¥ç¼“å­˜æ–‡ä»¶
            api_cache_dir = os.path.join(cache_manager.cache_dir, "api_cache")
            cache_path = os.path.join(api_cache_dir, "api_key.txt")
            
            if not os.path.exists(cache_path):
                return ""
                
            # åŠ è½½APIå¯†é’¥
            with open(cache_path, "r", encoding="utf-8") as f:
                api_key = f.read().strip()
                
            return api_key
        except Exception as e:
            print(f"ä»ç¼“å­˜åŠ è½½APIå¯†é’¥æ—¶å‡ºé”™: {str(e)}")
            return ""
    
    # ä¿å­˜å½“å‰é€‰æ‹©çš„å…³é”®è¯
    def save_current_keywords(keywords):
        """ä¿å­˜å½“å‰é€‰æ‹©çš„å…³é”®è¯åˆ°ç¼“å­˜"""
        if not keywords:
            return False
        
        try:
            # åˆ›å»ºç¼“å­˜ç›®å½•
            keywords_cache_dir = os.path.join(cache_manager.cache_dir, "keywords_cache")
            os.makedirs(keywords_cache_dir, exist_ok=True)
            
            # ä¿å­˜å½“å‰å…³é”®è¯
            with open(os.path.join(keywords_cache_dir, "current_keywords.json"), "w", encoding="utf-8") as f:
                json.dump({
                    "keywords": keywords,
                    "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                }, f, ensure_ascii=False, indent=2)
            
            return True
        except Exception as e:
            print(f"ä¿å­˜å½“å‰å…³é”®è¯åˆ°ç¼“å­˜æ—¶å‡ºé”™: {str(e)}")
            return False
    
    # åŠ è½½ä¸Šæ¬¡é€‰æ‹©çš„å…³é”®è¯
    def load_last_keywords():
        """ä»ç¼“å­˜åŠ è½½ä¸Šæ¬¡é€‰æ‹©çš„å…³é”®è¯"""
        try:
            # æ£€æŸ¥ç¼“å­˜æ–‡ä»¶
            keywords_cache_dir = os.path.join(cache_manager.cache_dir, "keywords_cache")
            cache_path = os.path.join(keywords_cache_dir, "current_keywords.json")
            
            if not os.path.exists(cache_path):
                return []
            
            # åŠ è½½å…³é”®è¯
            with open(cache_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            return data.get("keywords", [])
        except Exception as e:
            print(f"ä»ç¼“å­˜åŠ è½½å…³é”®è¯æ—¶å‡ºé”™: {str(e)}")
            return []
    
    # æ·»åŠ æ–¹æ³•åˆ°cache_manager
    cache_manager.save_loaded_data = save_loaded_data
    cache_manager.load_last_data = load_last_data
    cache_manager.save_api_key = save_api_key
    cache_manager.load_api_key = load_api_key
    cache_manager.save_current_keywords = save_current_keywords
    cache_manager.load_last_keywords = load_last_keywords
    
    return cache_manager

# ä¿®æ”¹æ•°æ®åŠ è½½é¡µé¢
def render_data_loading_page():
    st.header("ğŸ“Š æ•°æ®åŠ è½½")
    
    # åˆå§‹åŒ–å¢å¼ºç‰ˆç¼“å­˜ç®¡ç†å™¨
    cache_manager = add_data_cache_methods()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("é€‰æ‹©æ•°æ®æ¥æºå’Œæ–‡ä»¶")
        data_loader = get_data_loader()
        available_files = data_loader.get_available_data_files()
        
        # æ£€æŸ¥ç¼“å­˜ä¸­çš„ä¸Šä¸€æ¬¡åŠ è½½çš„æ•°æ®
        cached_data, metadata = cache_manager.load_last_data()
        if cached_data is not None and metadata is not None:
            st.info(f"å‘ç°ä¸Šæ¬¡åŠ è½½çš„æ•°æ®: {metadata['rows']}æ¡è®°å½•ï¼Œæ¥æº: {metadata['source']}ï¼ŒåŠ è½½æ—¶é—´: {metadata['timestamp']}")
            
            if st.button("æ¢å¤ä¸Šæ¬¡åŠ è½½çš„æ•°æ®"):
                st.session_state.loaded_data = cached_data
                st.session_state.last_loaded_source = metadata['source']
                st.session_state.last_loaded_files = metadata['file_paths']
                st.success(f"å·²æ¢å¤ä¸Šæ¬¡åŠ è½½çš„æ•°æ®ï¼Œå…±{len(cached_data)}æ¡è®°å½•")
                # é‡æ–°åŠ è½½é¡µé¢ä»¥æ›´æ–°UI
                st.rerun()
        
        # é€‰æ‹©æ•°æ®æº
        data_source = st.radio("é€‰æ‹©æ•°æ®æ¥æº:", ["CNKI", "WOS"])
        
        # æ˜¾ç¤ºå¯ç”¨æ–‡ä»¶
        available_file_types = available_files[data_source]
        file_type = st.radio("é€‰æ‹©æ–‡ä»¶ç±»å‹:", ["xls", "csv"])
        
        if available_file_types[file_type]:
            selected_files = st.multiselect(
                "é€‰æ‹©è¦åŠ è½½çš„æ–‡ä»¶:",
                [os.path.basename(f) for f in available_file_types[file_type]],
                key=f"{data_source}_{file_type}_selection"
            )
            
            selected_file_paths = [
                os.path.join(os.path.dirname(f), s) 
                for f in available_file_types[file_type] 
                for s in selected_files 
                if os.path.basename(f) == s
            ]
            
            if selected_file_paths and st.button("åŠ è½½é€‰ä¸­çš„æ–‡ä»¶"):
                try:
                    with st.spinner("æ­£åœ¨åŠ è½½æ•°æ®..."):
                        df = data_loader.load_multiple_files(selected_file_paths, data_source)
                        if not df.empty:
                            st.session_state.loaded_data = df
                            st.session_state.last_loaded_source = data_source
                            st.session_state.last_loaded_files = selected_file_paths
                            
                            # ä¿å­˜åˆ°ç¼“å­˜
                            cache_manager.save_loaded_data(df, data_source, selected_file_paths)
                            
                            st.success(f"æˆåŠŸåŠ è½½ {len(df)} æ¡æ•°æ®ï¼")
                            time.sleep(1)  # ç»™ç”¨æˆ·æ—¶é—´çœ‹åˆ°æˆåŠŸæ¶ˆæ¯
                            st.rerun()  # é‡æ–°åŠ è½½é¡µé¢ä»¥æ›´æ–°å…¶ä»–ç»„ä»¶
                        else:
                            st.error("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ•°æ®ã€‚")
                except Exception as e:
                    st.error(f"åŠ è½½æ•°æ®æ—¶å‡ºé”™: {str(e)}")
        else:
            st.info(f"æ²¡æœ‰æ‰¾åˆ° {data_source} çš„ {file_type} æ–‡ä»¶ã€‚")

    with col2:
        st.subheader("å·²åŠ è½½çš„æ•°æ®é¢„è§ˆ")
        if st.session_state.loaded_data is not None:
            df = st.session_state.loaded_data
            st.write(f"æ•°æ®å½¢çŠ¶: {df.shape}")
            
            # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡ä¿¡æ¯
            stats_tab1, stats_tab2 = st.tabs(["æ•°æ®åˆ†å¸ƒ", "æ•°æ®é¢„è§ˆ"])
            
            with stats_tab1:
                # æŒ‰é¢†åŸŸå’Œæ–¹æ³•æ˜¾ç¤ºæ•°æ®åˆ†å¸ƒ
                if 'area' in df.columns and 'method' in df.columns:
                    area_counts = df['area'].value_counts().reset_index()
                    area_counts.columns = ['area', 'count']
                    
                    method_counts = df['method'].value_counts().reset_index()
                    method_counts.columns = ['method', 'count']
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.subheader("æŒ‰é¢†åŸŸåˆ†å¸ƒ")
                        fig = px.pie(area_counts, values='count', names='area', title='æŒ‰é¢†åŸŸåˆ†å¸ƒ')
                        st.plotly_chart(fig, use_container_width=True)
                    
                    with col2:
                        st.subheader("æŒ‰æ–¹æ³•åˆ†å¸ƒ")
                        fig = px.pie(method_counts, values='count', names='method', title='æŒ‰æ–¹æ³•åˆ†å¸ƒ')
                        st.plotly_chart(fig, use_container_width=True)
                    
                # æŒ‰å¹´ä»½æ˜¾ç¤ºæ•°æ®åˆ†å¸ƒ
                if 'year' in df.columns:
                    year_counts = df['year'].value_counts().reset_index()
                    year_counts.columns = ['year', 'count']
                    year_counts = year_counts.sort_values('year')
                    
                    st.subheader("æŒ‰å¹´ä»½åˆ†å¸ƒ")
                    fig = px.bar(year_counts, x='year', y='count', title='æŒ‰å¹´ä»½åˆ†å¸ƒ')
                    st.plotly_chart(fig, use_container_width=True)
            
            with stats_tab2:
                st.dataframe(df.head(10))
                
                # éšæœºå±•ç¤ºä¸€æ¡æ•°æ®
                if st.button("éšæœºå±•ç¤ºä¸€æ¡æ•°æ®"):
                    if len(df) > 0:  # ç¡®ä¿æœ‰æ•°æ®å¯ä»¥å±•ç¤º
                        random_idx = random.randint(0, len(df) - 1)
                        random_row = df.iloc[random_idx]
                        
                        st.subheader("éšæœºæ•°æ®æ ·ä¾‹")
                        st.markdown(f"**æ ‡é¢˜**: {random_row['title']}")
                        st.markdown(f"**æ‘˜è¦**: {random_row['abstract']}")
                        st.markdown(f"**å¹´ä»½**: {random_row['year']}")
                        st.markdown(f"**é¢†åŸŸ**: {random_row['area']}")
                        st.markdown(f"**æ–¹æ³•**: {random_row['method']}")
                    else:
                        st.error("æ•°æ®é›†ä¸ºç©ºï¼Œæ— æ³•å±•ç¤ºéšæœºæ•°æ®ã€‚")
        else:
            st.info("è¯·å…ˆåŠ è½½æ•°æ®ã€‚")

# ä¿®æ”¹å…³é”®è¯ç®¡ç†é¡µé¢
def render_keywords_management_page():
    st.header("ğŸ”‘ å…³é”®è¯ç®¡ç†")
    
    # åˆå§‹åŒ–å¢å¼ºç‰ˆç¼“å­˜ç®¡ç†å™¨
    cache_manager = add_data_cache_methods()
    
    # å¦‚æœè¿˜æ²¡æœ‰é€‰æ‹©å…³é”®è¯ï¼Œå°è¯•ä»ç¼“å­˜æ¢å¤ä¸Šæ¬¡é€‰æ‹©çš„å…³é”®è¯
    if not st.session_state.selected_keywords:
        last_keywords = cache_manager.load_last_keywords()
        if last_keywords:
            st.info(f"å‘ç°ä¸Šæ¬¡é€‰æ‹©çš„{len(last_keywords)}ä¸ªå…³é”®è¯")
            if st.button("æ¢å¤ä¸Šæ¬¡é€‰æ‹©çš„å…³é”®è¯"):
                st.session_state.selected_keywords = last_keywords
                st.success(f"å·²æ¢å¤ä¸Šæ¬¡é€‰æ‹©çš„{len(last_keywords)}ä¸ªå…³é”®è¯")
                st.rerun()  # ç«‹å³åˆ·æ–°é¡µé¢æ˜¾ç¤ºæ¢å¤çš„å…³é”®è¯
    
    # è·å–å…³é”®è¯
    keywords_dict = get_keywords()
    
    if not keywords_dict:
        st.error("æ— æ³•åŠ è½½å…³é”®è¯ï¼Œè¯·æ£€æŸ¥keywords.pyæ–‡ä»¶æ˜¯å¦å­˜åœ¨ã€‚")
        return
    
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("å…³é”®è¯é€‰æ‹©")
        
        # é€‰æ‹©å…³é”®è¯ç±»åˆ«çš„é€‰é¡¹å¡
        categories = list(keywords_dict.keys())
        category = st.selectbox("é€‰æ‹©å…³é”®è¯ç±»åˆ«:", categories)
        
        # ç¡®ä¿é€‰æ‹©çš„ç±»åˆ«å­˜åœ¨äºå­—å…¸ä¸­
        if category in keywords_dict:
            keywords = keywords_dict[category]
            st.write(f"å…± {len(keywords)} ä¸ªå…³é”®è¯")
            
            # æ‰¹é‡é€‰æ‹©æ§åˆ¶
            st.subheader("æ‰¹é‡é€‰æ‹©")
            batch_col1, batch_col2 = st.columns(2)
            
            with batch_col1:
                select_all = st.checkbox("å…¨é€‰", key=f"select_all_{category}")
            
            with batch_col2:
                if select_all:
                    st.session_state.to_select_keywords = keywords.copy()
                
                if st.button("æ‰¹é‡æ·»åŠ ", key=f"batch_add_{category}"):
                    # å°†æ‰¹é‡é€‰æ‹©çš„å…³é”®è¯æ·»åŠ åˆ°å·²é€‰åˆ—è¡¨
                    added_count = 0
                    for kw in st.session_state.to_select_keywords:
                        if kw not in st.session_state.selected_keywords:
                            st.session_state.selected_keywords.append(kw)
                            added_count += 1
                    
                    st.session_state.to_select_keywords = []  # æ¸…ç©ºä¸´æ—¶åˆ—è¡¨
                    
                    # ä¿å­˜å½“å‰é€‰æ‹©çš„å…³é”®è¯åˆ°ç¼“å­˜
                    cache_manager.save_current_keywords(st.session_state.selected_keywords)
                    
                    if added_count > 0:
                        st.success(f"å·²æ·»åŠ {added_count}ä¸ªå…³é”®è¯")
                        st.rerun()  # ç«‹å³åˆ·æ–°ä»¥æ›´æ–°ç•Œé¢
            
            # æ˜¾ç¤ºå…³é”®è¯åˆ—è¡¨å¹¶æä¾›å•ç‹¬é€‰æ‹©åŠŸèƒ½
            st.subheader("å…³é”®è¯åˆ—è¡¨")
            
            # ä½¿ç”¨å®¹å™¨æ˜¾ç¤ºå…³é”®è¯åˆ—è¡¨
            keyword_container = st.container()
            
            # è®¡ç®—è¡Œæ•°å’Œåˆ—æ•°
            keywords_count = len(keywords)
            num_columns = 4
            rows_per_column = (keywords_count + num_columns - 1) // num_columns  # å‘ä¸Šå–æ•´
            
            # åˆ›å»ºå…³é”®è¯æ§ä»¶åˆ—è¡¨
            keyword_controls = []
            
            # ä¸ºæ¯ä¸ªå…³é”®è¯åˆ›å»ºæ§ä»¶é›†åˆ
            for keyword_idx, keyword in enumerate(keywords):
                # è®¡ç®—åˆ—ç´¢å¼• - ä¿®æ”¹ä¸ºåˆ—ä¼˜å…ˆé¡ºåºï¼ˆå…ˆå¡«æ»¡ç¬¬ä¸€åˆ—å†å¡«ç¬¬äºŒåˆ—ï¼‰
                col_idx = keyword_idx // rows_per_column
                
                # è®¡ç®—è¡Œç´¢å¼•
                row_idx = keyword_idx % rows_per_column
                
                # æ£€æŸ¥æ˜¯å¦å·²åœ¨å·²é€‰åˆ—è¡¨ä¸­
                is_selected = keyword in st.session_state.selected_keywords
                is_in_batch = keyword in st.session_state.to_select_keywords
                
                # æ·»åŠ åˆ°æ§ä»¶åˆ—è¡¨
                keyword_controls.append((row_idx, col_idx, keyword, is_selected, is_in_batch))
            
            # æŒ‰è¡Œæ’åºæ§ä»¶
            keyword_controls.sort()
            
            # åˆ›å»º4ä¸ªåˆ—æ¥æ˜¾ç¤ºå…³é”®è¯
            cols = st.columns(4)
            
            # åˆ†é…å…³é”®è¯åˆ°åˆ—
            for row_idx in range(rows_per_column):
                for col_idx in range(num_columns):
                    # æŸ¥æ‰¾å½“å‰è¡Œåˆ—ä½ç½®çš„å…³é”®è¯
                    current_controls = [
                        control for control in keyword_controls 
                        if control[0] == row_idx and control[1] == col_idx
                    ]
                    
                    if current_controls:
                        _, _, keyword, is_selected, is_in_batch = current_controls[0]
                        
                        # åœ¨å¯¹åº”åˆ—ä¸­æ˜¾ç¤ºå…³é”®è¯
                        with cols[col_idx]:
                            # æ˜¾ç¤ºå…³é”®è¯å’Œæ·»åŠ æŒ‰é’®
                            batch_select = st.checkbox(
                                keyword, 
                                value=select_all or is_in_batch,
                                key=f"kw_{category}_{keyword}"
                            )
                            
                            add_disabled = is_selected
                            if st.button(
                                "â•", 
                                key=f"add_{category}_{keyword}", 
                                disabled=add_disabled
                            ):
                                st.session_state.selected_keywords.append(keyword)
                                # ä¿å­˜å½“å‰é€‰æ‹©çš„å…³é”®è¯åˆ°ç¼“å­˜
                                cache_manager.save_current_keywords(st.session_state.selected_keywords)
                                st.rerun()  # ç«‹å³åˆ·æ–°ç•Œé¢
                            
                            # æ›´æ–°æ‰¹é‡é€‰æ‹©åˆ—è¡¨
                            if batch_select and keyword not in st.session_state.to_select_keywords:
                                st.session_state.to_select_keywords.append(keyword)
                            elif not batch_select and keyword in st.session_state.to_select_keywords:
                                st.session_state.to_select_keywords.remove(keyword)
        else:
            st.error(f"æ‰¾ä¸åˆ°ç±»åˆ«'{category}'çš„å…³é”®è¯ã€‚")
    
    with col2:
        st.subheader("å·²é€‰å…³é”®è¯")
        
        # æ˜¾ç¤ºå·²é€‰å…³é”®è¯æ•°é‡
        num_selected = len(st.session_state.selected_keywords)
        st.write(f"å·²é€‰æ‹© {num_selected} ä¸ªå…³é”®è¯")
        
        # ä¿å­˜å…³é”®è¯åˆ—è¡¨åŠŸèƒ½
        st.subheader("ä¿å­˜å…³é”®è¯åˆ—è¡¨")
        
        # ä½¿ç”¨containerä»£æ›¿åµŒå¥—åˆ—
        save_container = st.container()
        list_name = save_container.text_input("å…³é”®è¯åˆ—è¡¨åç§°:", placeholder="è¾“å…¥åç§°...")
        
        save_disabled = not list_name or num_selected == 0
        if save_container.button("ä¿å­˜å…³é”®è¯åˆ—è¡¨", disabled=save_disabled):
            try:
                # ä¿å­˜åˆ°session_state
                st.session_state.keyword_lists[list_name] = st.session_state.selected_keywords.copy()
                # æŒä¹…åŒ–ä¿å­˜
                if cache_manager.save_keyword_list(list_name, st.session_state.selected_keywords):
                    st.success(f"å·²ä¿å­˜å…³é”®è¯åˆ—è¡¨ï¼š{list_name}")
                    # åŒæ—¶ä¿å­˜å½“å‰é€‰æ‹©çš„å…³é”®è¯
                    cache_manager.save_current_keywords(st.session_state.selected_keywords)
                else:
                    st.error("ä¿å­˜å…³é”®è¯åˆ—è¡¨å¤±è´¥")
            except Exception as e:
                st.error(f"ä¿å­˜å…³é”®è¯åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")
        
        # åŠ è½½å·²ä¿å­˜çš„å…³é”®è¯åˆ—è¡¨
        saved_lists_from_cache = cache_manager.get_all_keyword_lists()
        
        # åˆå¹¶å†…å­˜ä¸­å’Œç¼“å­˜ä¸­çš„å…³é”®è¯åˆ—è¡¨
        for name, keywords in saved_lists_from_cache.items():
            if name not in st.session_state.keyword_lists:
                st.session_state.keyword_lists[name] = keywords
        
        if st.session_state.keyword_lists:
            saved_lists = list(st.session_state.keyword_lists.keys())
            selected_list = st.selectbox("åŠ è½½å·²ä¿å­˜çš„åˆ—è¡¨:", [""] + saved_lists)
            
            if selected_list and st.button("åŠ è½½åˆ—è¡¨"):
                try:
                    st.session_state.selected_keywords = st.session_state.keyword_lists[selected_list].copy()
                    # ä¿å­˜å½“å‰é€‰æ‹©çš„å…³é”®è¯åˆ°ç¼“å­˜
                    cache_manager.save_current_keywords(st.session_state.selected_keywords)
                    st.success(f"å·²åŠ è½½å…³é”®è¯åˆ—è¡¨ï¼š{selected_list}")
                    st.rerun()  # ç«‹å³åˆ·æ–°ç•Œé¢
                except Exception as e:
                    st.error(f"åŠ è½½å…³é”®è¯åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")
        
        # æ‰¹é‡åˆ é™¤åŠŸèƒ½
        st.subheader("å…³é”®è¯ç®¡ç†")
        
        # æ‰¹é‡æ“ä½œåŠŸèƒ½ - ä½¿ç”¨containerä»£æ›¿åµŒå¥—åˆ—
        delete_container = st.container()
        delete_all = delete_container.checkbox("å…¨é€‰åˆ é™¤")
        
        if delete_all:
            st.session_state.to_delete_keywords = st.session_state.selected_keywords.copy()
        
        delete_disabled = len(st.session_state.to_delete_keywords) == 0
        if delete_container.button("æ‰¹é‡åˆ é™¤", disabled=delete_disabled):
            try:
                removed_count = 0
                for kw in st.session_state.to_delete_keywords:
                    if kw in st.session_state.selected_keywords:
                        st.session_state.selected_keywords.remove(kw)
                        removed_count += 1
                
                st.session_state.to_delete_keywords = []  # æ¸…ç©ºä¸´æ—¶åˆ—è¡¨
                # ä¿å­˜å½“å‰é€‰æ‹©çš„å…³é”®è¯åˆ°ç¼“å­˜
                cache_manager.save_current_keywords(st.session_state.selected_keywords)
                
                if removed_count > 0:
                    st.success(f"å·²åˆ é™¤{removed_count}ä¸ªå…³é”®è¯")
                    st.rerun()  # ç«‹å³åˆ·æ–°ç•Œé¢
            except Exception as e:
                st.error(f"åˆ é™¤å…³é”®è¯æ—¶å‡ºé”™: {str(e)}")
        
        # æ˜¾ç¤ºå·²é€‰å…³é”®è¯
        st.subheader("å·²é€‰å…³é”®è¯åˆ—è¡¨")
        
        if st.session_state.selected_keywords:
            # ä½¿ç”¨å®¹å™¨è€Œä¸æ˜¯åµŒå¥—åˆ—
            selected_keywords_container = st.container()
            
            # è®¡ç®—æ¯ç»„åº”æ˜¾ç¤ºçš„å…³é”®è¯æ•°é‡
            num_selected = len(st.session_state.selected_keywords)
            num_columns = 4
            rows_per_column = (num_selected + num_columns - 1) // num_columns  # å‘ä¸Šå–æ•´
            
            # åˆ›å»ºå…³é”®è¯æ§ä»¶åˆ—è¡¨ - ä¿®æ”¹ä¸ºåˆ—ä¼˜å…ˆé¡ºåº
            keyword_controls = []
            
            # ä¸ºæ¯ä¸ªå…³é”®è¯åˆ›å»ºä¸€ä¸ªæ§ä»¶é›†åˆ
            for keyword_idx, keyword in enumerate(st.session_state.selected_keywords):
                # è®¡ç®—åˆ—ç´¢å¼• - åˆ—ä¼˜å…ˆé¡ºåº
                col_idx = keyword_idx // rows_per_column
                
                # è®¡ç®—è¡Œç´¢å¼•
                row_idx = keyword_idx % rows_per_column
                
                # æ·»åŠ åˆ°æ§ä»¶åˆ—è¡¨
                keyword_controls.append((row_idx, col_idx, keyword))
            
            # æŒ‰è¡Œåˆ—é¡ºåºæ’åºæ§ä»¶
            keyword_controls.sort()
            
            # åˆ›å»º4ä¸ªåˆ—æ¥æ˜¾ç¤ºå…³é”®è¯
            selected_cols = st.columns(4)
            
            # æ˜¾ç¤ºæ§ä»¶
            for row_idx, col_idx, keyword in keyword_controls:
                with selected_cols[col_idx]:
                    # æ˜¾ç¤ºå¤é€‰æ¡†å’Œåˆ é™¤æŒ‰é’®
                    is_in_delete_batch = keyword in st.session_state.to_delete_keywords
                    delete_select = st.checkbox(
                        keyword, 
                        value=delete_all or is_in_delete_batch,
                        key=f"del_{keyword}"
                    )
                    
                    if st.button("åˆ é™¤", key=f"remove_{keyword}"):
                        st.session_state.selected_keywords.remove(keyword)
                        # ä¿å­˜å½“å‰é€‰æ‹©çš„å…³é”®è¯åˆ°ç¼“å­˜
                        cache_manager.save_current_keywords(st.session_state.selected_keywords)
                        st.rerun()  # ç«‹å³åˆ·æ–°ç•Œé¢
                    
                    # æ›´æ–°æ‰¹é‡åˆ é™¤åˆ—è¡¨
                    if delete_select and keyword not in st.session_state.to_delete_keywords:
                        st.session_state.to_delete_keywords.append(keyword)
                    elif not delete_select and keyword in st.session_state.to_delete_keywords:
                        st.session_state.to_delete_keywords.remove(keyword)
        else:
            st.info("è¯·å…ˆä»å·¦ä¾§é€‰æ‹©å…³é”®è¯ã€‚")
        
        # æ·»åŠ è‡ªå®šä¹‰å…³é”®è¯
        st.subheader("æ·»åŠ è‡ªå®šä¹‰å…³é”®è¯")
        
        # ä½¿ç”¨å®¹å™¨è€ŒéåµŒå¥—åˆ—
        custom_container = st.container()
        new_keyword = custom_container.text_input("è¾“å…¥å…³é”®è¯:")
        
        add_disabled = not new_keyword or new_keyword in st.session_state.selected_keywords
        if custom_container.button("æ·»åŠ è‡ªå®šä¹‰å…³é”®è¯", disabled=add_disabled, key="add_custom"):
            if new_keyword and new_keyword not in st.session_state.selected_keywords:
                st.session_state.selected_keywords.append(new_keyword)
                # ä¿å­˜å½“å‰é€‰æ‹©çš„å…³é”®è¯åˆ°ç¼“å­˜
                cache_manager.save_current_keywords(st.session_state.selected_keywords)
                st.success(f"å·²æ·»åŠ å…³é”®è¯ï¼š{new_keyword}")
                st.rerun()  # ç«‹å³åˆ·æ–°ç•Œé¢

# æç¤ºè¯ç®¡ç†é¡µé¢
def render_prompts_management_page():
    st.header("ğŸ’¬ æç¤ºè¯ç®¡ç†")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ç¼–è¾‘ç³»ç»Ÿæç¤ºè¯")
        system_prompt = st.text_area("ç³»ç»Ÿæç¤ºè¯:", st.session_state.system_prompt, height=300)
        
        st.subheader("ç¼–è¾‘ç”¨æˆ·æç¤ºè¯æ¨¡æ¿")
        user_prompt_template = st.text_area("ç”¨æˆ·æç¤ºè¯æ¨¡æ¿:", st.session_state.user_prompt_template, height=200)
        
        if st.button("ä¿å­˜æç¤ºè¯"):
            st.session_state.system_prompt = system_prompt
            st.session_state.user_prompt_template = user_prompt_template
            st.success("æç¤ºè¯å·²æ›´æ–°ã€‚")
    
    with col2:
        st.subheader("æç¤ºè¯æ¨¡æ¿ç¤ºä¾‹")
        if hasattr(st.session_state, 'prompt_examples'):
            examples = st.session_state.prompt_examples
            selected_example = st.selectbox("é€‰æ‹©ç¤ºä¾‹:", [""] + [ex['name'] for ex in examples])
            
            if selected_example:
                example = next((ex for ex in examples if ex['name'] == selected_example), None)
                if example:
                    st.text_area("ç¤ºä¾‹ç³»ç»Ÿæç¤ºè¯:", example['system_prompt'], height=200, disabled=True)
                    st.text_area("ç¤ºä¾‹ç”¨æˆ·æç¤ºè¯æ¨¡æ¿:", example['user_prompt_template'], height=100, disabled=True)
                    
                    if st.button("ä½¿ç”¨æ­¤ç¤ºä¾‹"):
                        st.session_state.system_prompt = example['system_prompt']
                        st.session_state.user_prompt_template = example['user_prompt_template']
        
        st.subheader("é¢„è§ˆæ ¼å¼åŒ–åçš„ç”¨æˆ·æç¤ºè¯")
        if st.session_state.loaded_data is not None and not st.session_state.loaded_data.empty and st.session_state.selected_keywords:
            df = st.session_state.loaded_data
            random_idx = random.randint(0, len(df) - 1)
            random_row = df.iloc[random_idx]
            
            processor = get_llm_processor()
            processor.set_prompts(st.session_state.system_prompt, st.session_state.user_prompt_template)
            
            formatted_prompt = processor.format_user_prompt(
                random_row['title'],
                random_row['abstract'],
                st.session_state.selected_keywords
            )
            
            st.text_area("é¢„è§ˆ:", formatted_prompt, height=300, disabled=True)
        else:
            st.info("è¯·å…ˆåŠ è½½æ•°æ®å¹¶é€‰æ‹©å…³é”®è¯ã€‚")

# æ•°æ®åˆ†é¡µå‡½æ•°
def paginate_dataframe(df, page_key, page_size_key=None):
    """
    å°†æ•°æ®æ¡†åˆ†é¡µæ˜¾ç¤º
    
    å‚æ•°:
        df: è¦åˆ†é¡µçš„æ•°æ®æ¡†
        page_key: é¡µç åœ¨session_stateä¸­çš„é”®å
        page_size_key: æ¯é¡µå¤§å°åœ¨session_stateä¸­çš„é”®åï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼
    
    è¿”å›:
        å½“å‰é¡µçš„æ•°æ®æ¡†
    """
    if df.empty:
        return df
    
    page = st.session_state.display_page.get(page_key, 0)
    page_size = st.session_state.display_page.get("page_size", 10)
    
    # è®¡ç®—æ€»é¡µæ•°
    total_pages = (len(df) + page_size - 1) // page_size
    
    # ç¡®ä¿é¡µç åœ¨æœ‰æ•ˆèŒƒå›´å†…
    page = max(0, min(page, total_pages - 1))
    
    # è®¡ç®—å½“å‰é¡µçš„èµ·å§‹å’Œç»“æŸç´¢å¼•
    start_idx = page * page_size
    end_idx = min(start_idx + page_size, len(df))
    
    # è¿”å›å½“å‰é¡µçš„æ•°æ®
    return df.iloc[start_idx:end_idx], page, total_pages, start_idx, end_idx

# é¡µé¢å¯¼èˆªæ§ä»¶
def render_pagination_controls(page_key, total_pages, current_page):
    """
    æ¸²æŸ“åˆ†é¡µæ§ä»¶
    
    å‚æ•°:
        page_key: é¡µç åœ¨session_stateä¸­çš„é”®å
        total_pages: æ€»é¡µæ•°
        current_page: å½“å‰é¡µç 
    """
    if total_pages <= 1:
        return
    
    col1, col2, col3, col4, col5 = st.columns([1, 1, 3, 1, 1])
    
    with col1:
        if st.button("é¦–é¡µ", key=f"first_{page_key}", disabled=current_page == 0):
            st.session_state.display_page[page_key] = 0
            st.rerun()
    
    with col2:
        if st.button("ä¸Šä¸€é¡µ", key=f"prev_{page_key}", disabled=current_page == 0):
            st.session_state.display_page[page_key] = max(0, current_page - 1)
            st.rerun()
    
    with col3:
        st.write(f"ç¬¬ {current_page + 1} é¡µï¼Œå…± {total_pages} é¡µ")
    
    with col4:
        if st.button("ä¸‹ä¸€é¡µ", key=f"next_{page_key}", disabled=current_page >= total_pages - 1):
            st.session_state.display_page[page_key] = min(total_pages - 1, current_page + 1)
            st.rerun()
    
    with col5:
        if st.button("æœ«é¡µ", key=f"last_{page_key}", disabled=current_page >= total_pages - 1):
            st.session_state.display_page[page_key] = total_pages - 1
            st.rerun()
    
    # å…è®¸ç›´æ¥è·³è½¬åˆ°æŒ‡å®šé¡µé¢
    jump_col1, jump_col2 = st.columns([3, 1])
    with jump_col1:
        jump_page = st.number_input(
            "è·³è½¬åˆ°é¡µç :", 
            min_value=1, 
            max_value=total_pages,
            value=current_page + 1,
            key=f"jump_input_{page_key}"
        )
    
    with jump_col2:
        if st.button("è·³è½¬", key=f"jump_{page_key}"):
            st.session_state.display_page[page_key] = jump_page - 1
            st.rerun()

# æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
def render_data_table(df, show_columns=None, title="æ•°æ®åˆ—è¡¨", page_key=None):
    """
    æ¸²æŸ“æ•°æ®è¡¨æ ¼å¹¶æä¾›åˆ†é¡µåŠŸèƒ½
    
    å‚æ•°:
        df: è¦æ˜¾ç¤ºçš„æ•°æ®æ¡†
        show_columns: è¦æ˜¾ç¤ºçš„åˆ—
        title: è¡¨æ ¼æ ‡é¢˜
        page_key: é¡µç åœ¨session_stateä¸­çš„é”®å
    """
    if df.empty:
        st.info(f"æ²¡æœ‰{title}æ•°æ®")
        return
    
    # è®¾ç½®è¦æ˜¾ç¤ºçš„åˆ—
    if show_columns is None:
        show_columns = ['title', 'year', 'area', 'method']
    
    # ç¡®ä¿æ‰€æœ‰æŒ‡å®šçš„åˆ—éƒ½å­˜åœ¨
    valid_columns = [col for col in show_columns if col in df.columns]
    
    if not valid_columns:
        st.error(f"æ•°æ®ä¸­æ²¡æœ‰å¯æ˜¾ç¤ºçš„åˆ—")
        return
    
    # å¦‚æœæœ‰é¡µç é”®ï¼Œåˆ™ä½¿ç”¨åˆ†é¡µæ˜¾ç¤º
    if page_key is not None:
        current_df, current_page, total_pages, start_idx, end_idx = paginate_dataframe(df, page_key)
        st.write(f"{title} ({len(df)}æ¡ï¼Œæ˜¾ç¤ºç¬¬ {start_idx+1}-{end_idx} æ¡):")
        st.dataframe(current_df[valid_columns], use_container_width=True)
        
        # æ¸²æŸ“åˆ†é¡µæ§ä»¶
        render_pagination_controls(page_key, total_pages, current_page)
    else:
        # å¦åˆ™ç›´æ¥æ˜¾ç¤ºæ‰€æœ‰æ•°æ®
        st.write(f"{title} ({len(df)}æ¡):")
        st.dataframe(df[valid_columns], use_container_width=True)

# æ£€æŸ¥æ–‡çŒ®æ˜¯å¦å·²è¢«å¤„ç†
def is_paper_processed(title, abstract, cache_manager, selected_keywords):
    """
    æ£€æŸ¥æ–‡çŒ®æ˜¯å¦å·²ç»è¢«å¤„ç†è¿‡
    
    å‚æ•°:
        title: æ–‡çŒ®æ ‡é¢˜
        abstract: æ–‡çŒ®æ‘˜è¦
        cache_manager: ç¼“å­˜ç®¡ç†å™¨
        selected_keywords: é€‰ä¸­çš„å…³é”®è¯åˆ—è¡¨
    
    è¿”å›:
        å¸ƒå°”å€¼ï¼Œè¡¨ç¤ºæ˜¯å¦å·²å¤„ç†
    """
    try:
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = cache_manager.generate_cache_key(title, abstract, selected_keywords)
        
        # ç›´æ¥æ£€æŸ¥ç»“æœæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        result_file = os.path.join(cache_manager.results_dir, f"{cache_key}.json")
        return os.path.exists(result_file)
    except Exception as e:
        print(f"æ£€æŸ¥æ–‡çŒ®æ˜¯å¦å·²å¤„ç†æ—¶å‡ºé”™: {str(e)}")
        return False

# æ”¹è¿›ç¼“å­˜æ•°æ®è·å–å‡½æ•°
def get_processed_papers(cache_manager, selected_keywords=None, filter_criteria=None):
    """
    è·å–å·²å¤„ç†çš„æ–‡çŒ®åˆ—è¡¨ï¼Œæ”¯æŒå…³é”®è¯å’Œå…¶ä»–æ¡ä»¶ç­›é€‰
    
    å‚æ•°:
        cache_manager: ç¼“å­˜ç®¡ç†å™¨
        selected_keywords: é€‰ä¸­çš„å…³é”®è¯åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä¸æŒ‰å…³é”®è¯ç­›é€‰
        filter_criteria: å…¶ä»–ç­›é€‰æ¡ä»¶ï¼Œä¾‹å¦‚é¢†åŸŸã€æ–¹æ³•ç­‰
    
    è¿”å›:
        å·²å¤„ç†æ–‡çŒ®çš„DataFrame
    """
    # è·å–æ‰€æœ‰å·²å¤„ç†é¡¹ç›®
    all_processed_items = cache_manager.get_all_processed_items()
    
    # å‡†å¤‡æ•°æ®
    processed_data = []
    for item in all_processed_items:
        metadata = item
        
        # åº”ç”¨ç­›é€‰æ¡ä»¶
        skip_item = False
        if filter_criteria:
            for key, value in filter_criteria.items():
                if metadata.get(key) != value:
                    skip_item = True
                    break
        
        if skip_item:
            continue
        
        # å¦‚æœæŒ‡å®šäº†å…³é”®è¯ï¼Œåˆ™åªè¿”å›ä½¿ç”¨è¿™äº›å…³é”®è¯å¤„ç†çš„æ–‡çŒ®
        if selected_keywords is not None:
            # è·å–å¤„ç†è¯¥æ–‡çŒ®æ—¶ä½¿ç”¨çš„å…³é”®è¯
            used_keywords = metadata.get('keywords', [])
            # å¦‚æœæ²¡æœ‰å…³é”®è¯ä¿¡æ¯ï¼Œåˆ™è·³è¿‡
            if not used_keywords:
                continue
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç›¸åŒçš„å…³é”®è¯é›†åˆ (å®½æ¾åŒ¹é…ï¼Œåªè¦æœ‰ä¸€ä¸ªå…³é”®è¯ç›¸åŒå°±è¿”å›)
            if not set(used_keywords).intersection(set(selected_keywords)):
                continue
        
        # è·å–å…³é”®ç»“æœä¿¡æ¯
        cache_key = metadata.get('cache_key', '')
        result = cache_manager.get_cached_result(cache_key) if cache_key else {}
        
        # æå–å…³é”®ä¿¡æ¯
        processed_item = {
            'title': metadata.get('title', ''),
            'abstract': metadata.get('abstract', ''),
            'year': metadata.get('year', ''),
            'area': metadata.get('area', ''),
            'method': metadata.get('method', ''),
            'source': metadata.get('source', ''),
            'success': result.get('success', False) if result else False,
            'relevant_keywords': result.get('relevant_keywords', []) if result else [],
            'cache_key': cache_key
        }
        
        processed_data.append(processed_item)
    
    # è½¬æ¢ä¸ºDataFrame
    if processed_data:
        return pd.DataFrame(processed_data)
    else:
        return pd.DataFrame()

# LLMå¤„ç†é¡µé¢
def render_llm_processing_page():
    st.header("ğŸ¤– LLMå¤„ç†")
    
    # åˆ›å»ºä¸»è¦çš„åˆ—å¸ƒå±€
    main_col1, main_col2 = st.columns([2, 1])
    
    with main_col1:
        st.subheader("APIè®¾ç½®")
        
        # è·å–ç¼“å­˜ç®¡ç†å™¨
        cache_manager = get_cache_manager()
        cache_manager = add_data_cache_methods()
        
        # å°è¯•ä»ç¼“å­˜åŠ è½½APIå¯†é’¥
        if not st.session_state.api_key:
            cached_api_key = cache_manager.load_api_key()
            if cached_api_key:
                st.session_state.api_key = cached_api_key
                
        api_key = st.text_input("DeepSeek APIå¯†é’¥:", st.session_state.api_key, type="password")
        if api_key != st.session_state.api_key:
            st.session_state.api_key = api_key
            # ä¿å­˜APIå¯†é’¥åˆ°ç¼“å­˜
            if api_key:
                cache_manager.save_api_key(api_key)
        
        if not st.session_state.api_key:
            st.warning("è¯·è¾“å…¥DeepSeek APIå¯†é’¥ã€‚")
        
        # æ£€æŸ¥æ˜¯å¦å¤„äºå¤„ç†çŠ¶æ€
        is_processing = st.session_state.is_processing
        
        # å¤„ç†è®¾ç½®éƒ¨åˆ†
        st.subheader("å¤„ç†è®¾ç½®")
        if st.session_state.loaded_data is not None and not st.session_state.loaded_data.empty:
            # è·å–ç¼“å­˜ç®¡ç†å™¨
            cache_manager = get_cache_manager()
            # å¢å¼ºç‰ˆç¼“å­˜ç®¡ç†å™¨
            cache_manager = add_data_cache_methods()
            # æ·»åŠ åˆ é™¤ç»“æœæ–¹æ³•
            cache_manager = add_delete_result_method()
            
            # æå–æ ‡é¢˜å’Œæ‘˜è¦ä»¥ä¾¿ç­›é€‰
            df = st.session_state.loaded_data
            
            # ç­›é€‰è¦å¤„ç†çš„æ•°æ®
            filter_section = st.container()
            
            with filter_section:
                if not is_processing:  # åªæœ‰åœ¨éå¤„ç†çŠ¶æ€æ‰å…è®¸ä¿®æ”¹ç­›é€‰æ¡ä»¶
                    filter_col, process_col = st.columns(2)
                    
                    with filter_col:
                        # æŒ‰é¢†åŸŸç­›é€‰
                        if 'area' in df.columns:
                            areas = ['å…¨éƒ¨'] + sorted(df['area'].unique().tolist())
                            selected_area = st.selectbox("æŒ‰é¢†åŸŸç­›é€‰:", areas, disabled=is_processing)
                        
                        # æŒ‰æ–¹æ³•ç­›é€‰
                        if 'method' in df.columns:
                            methods = ['å…¨éƒ¨'] + sorted(df['method'].unique().tolist())
                            selected_method = st.selectbox("æŒ‰æ–¹æ³•ç­›é€‰:", methods, disabled=is_processing)
                        
                        # æŒ‰å¹´ä»½ç­›é€‰
                        if 'year' in df.columns:
                            years = sorted(df['year'].unique().tolist())
                            min_year, max_year = min(years), max(years)
                            # æ£€æŸ¥æœ€å°å€¼å’Œæœ€å¤§å€¼æ˜¯å¦ç›¸åŒ
                            if min_year == max_year:
                                st.write(f"å¹´ä»½: {min_year}ï¼ˆæ‰€æœ‰æ–‡æ¡£å¹´ä»½ç›¸åŒï¼‰")
                                year_range = (min_year, min_year)
                            else:
                                year_range = st.slider(
                                    "æŒ‰å¹´ä»½ç­›é€‰:", 
                                    min_value=min_year, 
                                    max_value=max_year, 
                                    value=(min_year, max_year), 
                                    disabled=is_processing
                                )
                        
                        # æ·»åŠ æ˜¯å¦æ’é™¤å·²å¤„ç†æ•°æ®çš„é€‰é¡¹
                        exclude_processed = st.checkbox("æ’é™¤å·²å¤„ç†æ•°æ®", value=True, disabled=is_processing)
                    
                    # åº”ç”¨ç­›é€‰
                    filtered_df = df.copy()
                    
                    if 'area' in df.columns and selected_area != 'å…¨éƒ¨':
                        filtered_df = filtered_df[filtered_df['area'] == selected_area]
                    
                    if 'method' in df.columns and selected_method != 'å…¨éƒ¨':
                        filtered_df = filtered_df[filtered_df['method'] == selected_method]
                    
                    # åº”ç”¨å¹´ä»½ç­›é€‰
                    if 'year' in df.columns and min_year != max_year:
                        # ç¡®ä¿yearåˆ—æ˜¯æ•°å€¼ç±»å‹
                        filtered_df['year'] = pd.to_numeric(filtered_df['year'], errors='coerce')
                        # ä½¿ç”¨æœ‰æ•ˆçš„å¹´ä»½æ•°æ®è¿›è¡Œç­›é€‰
                        filtered_df = filtered_df.dropna(subset=['year'])
                        filtered_df = filtered_df[(filtered_df['year'] >= year_range[0]) & (filtered_df['year'] <= year_range[1])]
                    
                    # æ’é™¤å·²å¤„ç†çš„æ•°æ® - ä¿®å¤ç‰ˆæœ¬
                    if exclude_processed:
                        # è·å–æ‰€æœ‰å·²å¤„ç†ç»“æœ
                        processed_results = cache_manager.get_results_by_filter({})
                        processed_titles_set = set()
                        
                        # æ”¶é›†æ‰€æœ‰å·²å¤„ç†çš„æ ‡é¢˜ï¼Œç”¨é›†åˆæé«˜æŸ¥æ‰¾æ•ˆç‡
                        for item in processed_results:
                            title = item['metadata'].get('title', '')
                            if title:
                                processed_titles_set.add(title)
                        
                        # è¿‡æ»¤æ‰å·²å¤„ç†çš„æ•°æ®
                        if processed_titles_set:
                            filtered_df = filtered_df[~filtered_df['title'].isin(processed_titles_set)]
                    
                    with process_col:
                        st.write(f"ç­›é€‰åæ•°æ®æ¡æ•°: {len(filtered_df)}")
                        
                        # è®¾ç½®å¤„ç†å‚æ•°
                        batch_size = st.slider("æ‰¹æ¬¡å¤§å°:", min_value=1, max_value=50, value=10, disabled=is_processing)
                        max_concurrent = st.slider("æœ€å¤§å¹¶å‘è¯·æ±‚æ•°:", min_value=1, max_value=50, value=5, disabled=is_processing)
                        
                        # ä¿å­˜å¤„ç†å‚æ•°åˆ°ä¼šè¯çŠ¶æ€
                        st.session_state.batch_size = batch_size
                        st.session_state.max_concurrent = max_concurrent
                        
                        # éšæœºæŠ½æ ·
                        sample_size = st.number_input("éšæœºæŠ½æ ·æ•°é‡ (0è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨æ•°æ®):", min_value=0, max_value=len(filtered_df), value=min(20, len(filtered_df)), disabled=is_processing)
                        
                        if sample_size > 0 and sample_size < len(filtered_df) and not is_processing:
                            filtered_df = filtered_df.sample(sample_size, random_state=42)
                            st.write(f"å·²éšæœºæŠ½å– {len(filtered_df)} æ¡æ•°æ®ã€‚")
                
                # æ˜¾ç¤ºå¤„ç†çŠ¶æ€
                status_container = st.container()
                
                # æ£€æŸ¥æ˜¯å¦å·²é€‰æ‹©å…³é”®è¯
                error_msgs = []
                if not st.session_state.selected_keywords:
                    error_msgs.append("è¯·å…ˆåœ¨å…³é”®è¯ç®¡ç†é¡µé¢é€‰æ‹©å…³é”®è¯ã€‚")
                # æ£€æŸ¥æç¤ºè¯æ˜¯å¦å·²è®¾ç½®
                if not st.session_state.system_prompt or not st.session_state.user_prompt_template:
                    error_msgs.append("è¯·å…ˆåœ¨æç¤ºè¯ç®¡ç†é¡µé¢è®¾ç½®æç¤ºè¯ã€‚")
                # æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å·²è®¾ç½®
                if not st.session_state.api_key:
                    error_msgs.append("è¯·å…ˆè®¾ç½®DeepSeek APIå¯†é’¥ã€‚")
                
                if error_msgs:
                    for msg in error_msgs:
                        st.warning(msg)
                elif not is_processing:
                    # åˆ›å»ºå¤„ç†é˜Ÿåˆ—å¹¶å­˜å‚¨åœ¨ä¼šè¯çŠ¶æ€ä¸­
                    if st.button("å¼€å§‹å¤„ç†", disabled=is_processing or filtered_df.empty):
                        # å°†ç­›é€‰åçš„æ•°æ®è½¬æ¢ä¸ºè®°å½•åˆ—è¡¨
                        st.session_state.processing_queue = filtered_df.to_dict('records')
                        st.session_state.is_processing = True
                        st.session_state.processed_items = []  # æ¸…ç©ºå·²å¤„ç†åˆ—è¡¨
                        # é‡æ–°åŠ è½½é¡µé¢ä»¥å¼€å§‹å¤„ç†
                        st.rerun()
                else:
                    # æ˜¾ç¤ºæ­£åœ¨å¤„ç†çš„çŠ¶æ€
                    with status_container:
                        st.info(f"æ­£åœ¨å¤„ç†æ•°æ®ï¼Œé˜Ÿåˆ—ä¸­è¿˜æœ‰ {len(st.session_state.processing_queue)} æ¡æ•°æ®å¾…å¤„ç†")
                        
                        if st.button("åœæ­¢å¤„ç†", key="stop_processing_btn"):
                            st.session_state.is_processing = False
                            st.success("å·²åœæ­¢å¤„ç†")
                            st.rerun()
            
            # æ˜¾ç¤ºæ•°æ®åˆ—è¡¨
            data_tabs = st.tabs(["å¾…å¤„ç†æ•°æ®", "æ­£åœ¨å¤„ç†", "æœ¬æ¬¡å·²å¤„ç†æ•°æ®", "ç¼“å­˜ä¸­çš„å·²å¤„ç†æ•°æ®"])
            
            with data_tabs[0]:
                # å¾…å¤„ç†æ•°æ®åˆ—è¡¨
                if is_processing:
                    # å¦‚æœæ­£åœ¨å¤„ç†ï¼Œæ˜¾ç¤ºå¤„ç†é˜Ÿåˆ—ä¸­çš„æ•°æ®
                    queue_df = pd.DataFrame(st.session_state.processing_queue)
                    if not queue_df.empty:
                        render_data_table(queue_df, title="å¾…å¤„ç†æ•°æ®", page_key="unprocessed")
                    else:
                        st.info("é˜Ÿåˆ—ä¸­æ²¡æœ‰å¾…å¤„ç†æ•°æ®")
                else:
                    # å¦åˆ™æ˜¾ç¤ºç­›é€‰åçš„æ•°æ®
                    if not filtered_df.empty:
                        render_data_table(filtered_df, title="å¾…å¤„ç†æ•°æ®", page_key="unprocessed")
                    else:
                        st.info("æ²¡æœ‰å¾…å¤„ç†æ•°æ®")
            
            with data_tabs[1]:
                # æ­£åœ¨å¤„ç†çš„æ•°æ®
                if is_processing and st.session_state.processing_queue:
                    # æ˜¾ç¤ºå½“å‰æ­£åœ¨å¤„ç†çš„æ‰¹æ¬¡
                    current_batch_size = min(st.session_state.batch_size, len(st.session_state.processing_queue))
                    batch_items = st.session_state.processing_queue[:current_batch_size]
                    current_df = pd.DataFrame(batch_items)
                    st.write(f"å½“å‰æ‰¹å¤„ç† ({current_batch_size}æ¡ï¼Œæœ€å¤§å¹¶å‘: {st.session_state.max_concurrent})")
                    render_data_table(current_df, title="å½“å‰æ‰¹æ¬¡æ•°æ®", page_key="processing")
                else:
                    st.info("æ²¡æœ‰æ­£åœ¨å¤„ç†çš„æ•°æ®")
            
            with data_tabs[2]:
                # æœ¬æ¬¡å·²å¤„ç†æ•°æ®åˆ—è¡¨
                processed_df = pd.DataFrame(st.session_state.processed_items)
                if not processed_df.empty:
                    render_data_table(processed_df, title="æœ¬æ¬¡å·²å¤„ç†æ•°æ®", page_key="processed")
                else:
                    st.info("æœ¬æ¬¡ä¼šè¯å°šæœªå¤„ç†ä»»ä½•æ•°æ®")
            
            with data_tabs[3]:
                # è·å–æ‰€æœ‰å¤„ç†ç»“æœï¼Œä½¿ç”¨ä¸ç»“æœæŸ¥çœ‹é¡µé¢ä¸€è‡´çš„æ–¹æ³•
                all_results = cache_manager.get_results_by_filter({})
                
                # å‡†å¤‡æ•°æ®æ¡†
                if all_results:
                    cached_data = []
                    for item in all_results:
                        metadata = item['metadata']
                        result = item['result']
                        
                        relevant_keywords = result.get('relevant_keywords', [])
                        
                        cached_item = {
                            'title': metadata.get('title', ''),
                            'abstract': metadata.get('abstract', ''),
                            'year': metadata.get('year', ''),
                            'area': metadata.get('area', ''),
                            'method': metadata.get('method', ''),
                            'source': metadata.get('source', ''),
                            'success': result.get('success', False),
                            'relevant_keywords': relevant_keywords,
                            'num_keywords': len(relevant_keywords),
                            'cache_key': metadata.get('cache_key', '')
                        }
                        
                        cached_data.append(cached_item)
                    
                    cached_processed_df = pd.DataFrame(cached_data)
                    
                    # æ·»åŠ ç¼“å­˜æ•°æ®çš„ç­›é€‰æ§ä»¶
                    cache_filter_col1, cache_filter_col2 = st.columns(2)
                    
                    with cache_filter_col1:
                        if 'area' in cached_processed_df.columns and not cached_processed_df['area'].empty:
                            cache_areas = ['å…¨éƒ¨'] + sorted(cached_processed_df['area'].unique().tolist())
                            cache_selected_area = st.selectbox("æŒ‰é¢†åŸŸç­›é€‰ç¼“å­˜:", cache_areas, key="cache_area_filter")
                        
                        if 'method' in cached_processed_df.columns and not cached_processed_df['method'].empty:
                            cache_methods = ['å…¨éƒ¨'] + sorted(cached_processed_df['method'].unique().tolist())
                            cache_selected_method = st.selectbox("æŒ‰æ–¹æ³•ç­›é€‰ç¼“å­˜:", cache_methods, key="cache_method_filter")
                    
                    with cache_filter_col2:
                        if 'year' in cached_processed_df.columns and not cached_processed_df['year'].empty:
                            cache_years = sorted(cached_processed_df['year'].unique().tolist())
                            if cache_years:
                                cache_min_year, cache_max_year = min(cache_years), max(cache_years)
                                # æ£€æŸ¥æœ€å°å€¼å’Œæœ€å¤§å€¼æ˜¯å¦ç›¸åŒ
                                if cache_min_year == cache_max_year:
                                    st.write(f"å¹´ä»½: {cache_min_year}ï¼ˆæ‰€æœ‰æ–‡æ¡£å¹´ä»½ç›¸åŒï¼‰")
                                else:
                                    cache_year_range = st.slider(
                                        "æŒ‰å¹´ä»½ç­›é€‰ç¼“å­˜:", 
                                        min_value=cache_min_year, 
                                        max_value=cache_max_year, 
                                        value=(cache_min_year, cache_max_year),
                                        key="cache_year_filter"
                                    )
                    
                    # åº”ç”¨ç¼“å­˜æ•°æ®çš„ç­›é€‰
                    filtered_cache_df = cached_processed_df.copy()
                    
                    if 'area' in cached_processed_df.columns and cache_selected_area != 'å…¨éƒ¨':
                        filtered_cache_df = filtered_cache_df[filtered_cache_df['area'] == cache_selected_area]
                    
                    if 'method' in cached_processed_df.columns and cache_selected_method != 'å…¨éƒ¨':
                        filtered_cache_df = filtered_cache_df[filtered_cache_df['method'] == cache_selected_method]
                    
                    if 'year' in cached_processed_df.columns and cache_years:
                        # åªæœ‰å½“æœ€å°å€¼å’Œæœ€å¤§å€¼ä¸åŒæ—¶æ‰åº”ç”¨å¹´ä»½ç­›é€‰
                        if cache_min_year != cache_max_year:
                            # ç¡®ä¿yearåˆ—çš„æ•°æ®ç±»å‹æ˜¯æ•°å€¼å‹
                            filtered_cache_df['year'] = pd.to_numeric(filtered_cache_df['year'], errors='coerce')
                            filtered_cache_df = filtered_cache_df[(filtered_cache_df['year'] >= cache_year_range[0]) & 
                                                             (filtered_cache_df['year'] <= cache_year_range[1])]
                    
                    # æ·»åŠ åˆ é™¤åŠŸèƒ½
                    if "to_delete_results" not in st.session_state:
                        st.session_state.to_delete_results = []
                    
                    # æ˜¾ç¤ºç­›é€‰åçš„ç¼“å­˜æ•°æ®
                    col1, col2 = st.columns([9, 1])
                    with col1:
                        st.write(f"å…±æ‰¾åˆ° {len(filtered_cache_df)} æ¡ç¼“å­˜ç»“æœ")
                    with col2:
                        if st.button("æ‰¹é‡åˆ é™¤", key="batch_delete_cached", disabled=len(st.session_state.to_delete_results) == 0):
                            delete_count = 0
                            for cache_key in st.session_state.to_delete_results:
                                if cache_manager.delete_result(cache_key):
                                    delete_count += 1
                            if delete_count > 0:
                                st.success(f"æˆåŠŸåˆ é™¤{delete_count}æ¡ç»“æœ")
                                st.session_state.to_delete_results = []
                                time.sleep(1)
                                st.rerun()
                    
                    # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼ï¼Œæ·»åŠ å¤é€‰æ¡†ç”¨äºåˆ é™¤æ“ä½œ
                    if not filtered_cache_df.empty:
                        # ä½¿ç”¨é€šç”¨åˆ†é¡µå‡½æ•°æ›¿ä»£ç›´æ¥å®ç°
                        current_df, current_page, total_pages, start_idx, end_idx = paginate_dataframe(filtered_cache_df, "cached")
                        
                        st.write(f"ç­›é€‰ç»“æœ ({len(filtered_cache_df)}æ¡ï¼Œæ˜¾ç¤ºç¬¬ {start_idx+1}-{end_idx} æ¡):")
                        
                        # åˆ†é¡µå¯¼èˆª
                        render_pagination_controls("cached", total_pages, current_page)
                        
                        # å…¨é€‰/å–æ¶ˆå…¨é€‰æŒ‰é’®
                        select_all = st.checkbox("å…¨é€‰å½“å‰é¡µ", key="select_all_cached")
                        
                        # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
                        for i, row in current_df.iterrows():
                            col1, col2 = st.columns([1, 11])
                            
                            cache_key = row['cache_key']
                            with col1:
                                is_selected = cache_key in st.session_state.to_delete_results
                                if st.checkbox("", value=is_selected or select_all, key=f"select_cached_{cache_key}"):
                                    if cache_key not in st.session_state.to_delete_results:
                                        st.session_state.to_delete_results.append(cache_key)
                                else:
                                    if cache_key in st.session_state.to_delete_results:
                                        st.session_state.to_delete_results.remove(cache_key)
                            
                            with col2:
                                with st.expander(f"{row['title'][:50]}..."):
                                    st.write(f"**å¹´ä»½**: {row['year']}")
                                    st.write(f"**é¢†åŸŸ**: {row['area']}")
                                    st.write(f"**æ–¹æ³•**: {row['method']}")
                                    st.write(f"**å…³é”®è¯æ•°é‡**: {row['num_keywords']}")
                                    
                                    # æ˜¾ç¤ºå…³é”®è¯
                                    if row['num_keywords'] > 0:
                                        st.write(f"**å…³é”®è¯**: {', '.join(row['relevant_keywords'])}")
                                    
                                    # å•ç‹¬åˆ é™¤æŒ‰é’®
                                    if st.button("åˆ é™¤", key=f"delete_cached_{cache_key}"):
                                        if cache_manager.delete_result(cache_key):
                                            st.success("å·²åˆ é™¤")
                                            if cache_key in st.session_state.to_delete_results:
                                                st.session_state.to_delete_results.remove(cache_key)
                                            time.sleep(1)
                                            st.rerun()
                                        else:
                                            st.error("åˆ é™¤å¤±è´¥")
                    else:
                        st.info("æ²¡æœ‰ç¬¦åˆç­›é€‰æ¡ä»¶çš„ç¼“å­˜æ•°æ®")
                    
                    # æä¾›æ¸…ç©ºç¼“å­˜çš„é€‰é¡¹
                    if st.button("æ¸…ç©ºæ‰€æœ‰ç¼“å­˜", key="clear_cache_btn"):
                        if st.session_state.get("confirm_clear_cache", False):
                            cache_manager.clear_all_results()
                            st.success("æ‰€æœ‰ç¼“å­˜å·²æ¸…ç©º")
                            st.session_state.confirm_clear_cache = False
                            st.rerun()
                        else:
                            st.session_state.confirm_clear_cache = True
                            st.warning("ç¡®å®šè¦æ¸…ç©ºæ‰€æœ‰ç¼“å­˜å—ï¼Ÿè¿™å°†åˆ é™¤æ‰€æœ‰å·²å¤„ç†çš„ç»“æœã€‚ç‚¹å‡»å†æ¬¡ç¡®è®¤ã€‚")
                else:
                    st.info("ç¼“å­˜ä¸­æ²¡æœ‰å·²å¤„ç†æ•°æ®")
            
            # å¦‚æœæ­£åœ¨å¤„ç†ï¼Œåˆ™å¯åŠ¨å¤„ç†é€»è¾‘
            if is_processing and st.session_state.processing_queue:
                # ä¿å­˜å¤„ç†å‚æ•°åˆ°ä¼šè¯çŠ¶æ€ï¼Œä»¥ä¾¿é‡æ–°åŠ è½½é¡µé¢åä»èƒ½è®¿é—®
                if "batch_size" not in st.session_state:
                    st.session_state.batch_size = 10  # é»˜è®¤å€¼
                if "max_concurrent" not in st.session_state:
                    st.session_state.max_concurrent = 5  # é»˜è®¤å€¼
                
                # åˆ›å»ºè¿›åº¦æ˜¾ç¤ºåŒºåŸŸ
                progress_container = st.container()
                
                with progress_container:
                    # åˆ›å»ºLLMå¤„ç†å™¨
                    processor = get_llm_processor()
                    processor.set_prompts(st.session_state.system_prompt, st.session_state.user_prompt_template)
                    
                    # åˆ›å»ºè¿›åº¦æ¡
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    # è®¡ç®—æ€»è¿›åº¦
                    total_items = len(st.session_state.processing_queue) + len(st.session_state.processed_items)
                    current_progress = len(st.session_state.processed_items) / total_items if total_items > 0 else 0
                    progress_bar.progress(current_progress)
                    status_text.text(f"æ€»è¿›åº¦: {len(st.session_state.processed_items)}/{total_items} ({current_progress*100:.1f}%)")
                    
                    # åˆ›å»ºå¤„ç†çŠ¶æ€åŒºåŸŸ
                    processing_status = st.empty()
                    item_progress = st.empty()
                    item_progress.text("æ­£åœ¨å¤„ç†ä¸­...")
                    
                    # æ‰§è¡Œå¤„ç†
                    try:
                        # ç¡®å®šæœ¬æ¬¡æ‰¹å¤„ç†çš„æ•°é‡
                        current_batch_size = min(st.session_state.batch_size, len(st.session_state.processing_queue))
                        processing_status.info(f"æ­£åœ¨å¹¶è¡Œå¤„ç† {current_batch_size} æ¡æ•°æ®ï¼Œæœ€å¤§å¹¶å‘è¯·æ±‚æ•°: {st.session_state.max_concurrent}")
                        
                        # å‡†å¤‡æ‰¹å¤„ç†æ•°æ®
                        batch_items = st.session_state.processing_queue[:current_batch_size]
                        batch_df = pd.DataFrame(batch_items)
                        
                        # å¤„ç†è¿›åº¦å›è°ƒå‡½æ•°
                        def on_progress(processed, total, result):
                            progress = processed / total
                            item_progress.progress(progress)
                            item_progress.text(f"æ‰¹å¤„ç†è¿›åº¦: {processed}/{total} ({progress*100:.1f}%)")
                        
                        # æ‰¹é‡å¤„ç†æ•°æ®
                        with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®æ‰¹æ¬¡..."):
                            result_df = processor.process_dataframe(
                                batch_df,
                                st.session_state.selected_keywords,
                                on_progress,
                                current_batch_size,  # ä½¿ç”¨è®¾ç½®çš„æ‰¹æ¬¡å¤§å°
                                st.session_state.max_concurrent      # ä½¿ç”¨è®¾ç½®çš„æœ€å¤§å¹¶å‘æ•°
                            )
                            
                            # å°†ç»“æœæ·»åŠ åˆ°å·²å¤„ç†åˆ—è¡¨
                            for _, row in result_df.iterrows():
                                processed_item = row.to_dict()
                                st.session_state.processed_items.append(processed_item)
                                
                                # ç¼“å­˜ç»“æœ
                                if processed_item.get('success'):
                                    cache_key = cache_manager.generate_cache_key(
                                        processed_item['title'],
                                        processed_item['abstract'],
                                        st.session_state.selected_keywords
                                    )
                                    
                                    # è§£æç»“æœ
                                    result = {
                                        "success": processed_item['success'],
                                        "relevant_keywords": json.loads(processed_item['relevant_keywords']) if isinstance(processed_item['relevant_keywords'], str) else processed_item['relevant_keywords'],
                                        "explanations": json.loads(processed_item['explanations']) if isinstance(processed_item['explanations'], str) else processed_item['explanations'],
                                        "raw_response": processed_item['raw_response']
                                    }
                                    
                                    # å‡†å¤‡å…ƒæ•°æ®
                                    metadata = {
                                        "id": processed_item.get('id'),
                                        "title": processed_item['title'],
                                        "abstract": processed_item['abstract'],
                                        "year": int(processed_item['year']) if not pd.isna(processed_item['year']) else None,
                                        "source": processed_item['source'],
                                        "area": processed_item['area'],
                                        "method": processed_item['method'],
                                        "keywords": st.session_state.selected_keywords,  # æ·»åŠ é€‰æ‹©çš„å…³é”®è¯
                                        "cache_key": cache_key  # æ·»åŠ ç¼“å­˜é”®
                                    }
                                    
                                    # ä¿å­˜åˆ°ç¼“å­˜
                                    cache_manager.save_result(cache_key, result, metadata)
                        
                        # ä»å¤„ç†é˜Ÿåˆ—ä¸­ç§»é™¤å·²å¤„ç†é¡¹
                        st.session_state.processing_queue = st.session_state.processing_queue[current_batch_size:]
                        
                        # å¦‚æœé˜Ÿåˆ—ä¸ºç©ºï¼Œåˆ™å¤„ç†å®Œæˆ
                        if not st.session_state.processing_queue:
                            st.session_state.is_processing = False
                            st.success(f"å¤„ç†å®Œæˆ! å…±å¤„ç† {len(st.session_state.processed_items)} æ¡æ•°æ®ã€‚")
                        else:
                            status_text.text(f"æ€»è¿›åº¦: {len(st.session_state.processed_items)}/{total_items} ({len(st.session_state.processed_items)/total_items*100:.1f}%)")
                        
                        # é‡æ–°åŠ è½½é¡µé¢ä»¥æ›´æ–°çŠ¶æ€
                        time.sleep(1)  # ç¨å¾®å»¶è¿Ÿä»¥ç¡®ä¿ç”¨æˆ·èƒ½çœ‹åˆ°çŠ¶æ€
                        st.rerun()
                    
                    except Exception as e:
                        st.error(f"å¤„ç†æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                        # å‘ç”Ÿé”™è¯¯æ—¶ä¹Ÿå°†å½“å‰é¡¹ä»é˜Ÿåˆ—ä¸­ç§»é™¤ï¼Œä»¥é˜²æ­¢æ— é™å¾ªç¯
                        if st.session_state.processing_queue:
                            st.session_state.processing_queue.pop(0)
                        # æ¸…é™¤å½“å‰å¤„ç†é¡¹
                        st.session_state.current_processing = None
                        # é‡æ–°åŠ è½½é¡µé¢
                        time.sleep(2)  # ç¨å¾®å»¶è¿Ÿä»¥ç¡®ä¿ç”¨æˆ·èƒ½çœ‹åˆ°é”™è¯¯
                        st.rerun()
        else:
            st.warning("è¯·å…ˆåŠ è½½æ•°æ®ã€‚")
    
    with main_col2:
        st.subheader("å¤„ç†çŠ¶æ€")
        
        # æ˜¾ç¤ºå½“å‰å¤„ç†çš„ç»Ÿè®¡ä¿¡æ¯
        stats_container = st.container()
        with stats_container:
            if is_processing or st.session_state.processed_items:
                total_count = len(st.session_state.processing_queue) + len(st.session_state.processed_items)
                processed_count = len(st.session_state.processed_items)
                remaining_count = len(st.session_state.processing_queue)
                
                progress_percentage = (processed_count / total_count) * 100 if total_count > 0 else 0
                
                st.metric("æ€»æ•°æ®é‡", total_count)
                st.metric("å·²å¤„ç†", processed_count)
                st.metric("å¾…å¤„ç†", remaining_count)
                st.metric("å®Œæˆç™¾åˆ†æ¯”", f"{progress_percentage:.1f}%")
                
                # å½“å‰å¤„ç†çŠ¶æ€
                if is_processing and st.session_state.current_processing:
                    st.subheader("å½“å‰å¤„ç†ä¸­")
                    current = st.session_state.current_processing
                    st.markdown(f"**æ ‡é¢˜**: {current['title'][:50]}...")
                    st.markdown(f"**å¹´ä»½**: {current.get('year', 'N/A')}")
                    st.markdown(f"**é¢†åŸŸ**: {current.get('area', 'N/A')}")
                    st.markdown(f"**æ–¹æ³•**: {current.get('method', 'N/A')}")
            else:
                st.info("å°šæœªå¼€å§‹å¤„ç†æ•°æ®")
        
        # æ˜¾ç¤ºå…³é”®è¯åŒ¹é…ç»Ÿè®¡ä¿¡æ¯
        if st.session_state.processed_items:
            st.subheader("å…³é”®è¯åŒ¹é…ç»Ÿè®¡")
            
            # ç»Ÿè®¡å…³é”®è¯åŒ¹é…æƒ…å†µ
            keyword_matches = {}
            for item in st.session_state.processed_items:
                if item.get('success'):
                    relevant_keywords = json.loads(item['relevant_keywords']) if isinstance(item['relevant_keywords'], str) else item['relevant_keywords']
                    for kw in relevant_keywords:
                        keyword_matches[kw] = keyword_matches.get(kw, 0) + 1
            
            if keyword_matches:
                keyword_df = pd.DataFrame({
                    "keyword": list(keyword_matches.keys()),
                    "count": list(keyword_matches.values())
                }).sort_values("count", ascending=False)
                
                # æ˜¾ç¤ºå…³é”®è¯åŒ¹é…é¢‘ç‡å›¾è¡¨
                fig = px.bar(keyword_df, x="keyword", y="count", title="å…³é”®è¯åŒ¹é…é¢‘ç‡")
                st.plotly_chart(fig, use_container_width=True)
                
                # æ˜¾ç¤ºè¯¦ç»†çš„ç»Ÿè®¡è¡¨æ ¼
                st.write("å…³é”®è¯åŒ¹é…è¯¦æƒ…:")
                st.dataframe(keyword_df)

# æ·»åŠ åˆ é™¤ç¼“å­˜ç»“æœçš„æ–¹æ³•åˆ°ç¼“å­˜ç®¡ç†å™¨
def add_delete_result_method():
    cache_manager = get_cache_manager()
    
    # åˆ é™¤å•ä¸ªç¼“å­˜ç»“æœ
    def delete_result(cache_key):
        """åˆ é™¤ç‰¹å®šçš„ç¼“å­˜ç»“æœ"""
        if not cache_key:
            return False
            
        try:
            # æ£€æŸ¥ç»“æœæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            result_path = os.path.join(cache_manager.results_dir, f"{cache_key}.json")
            metadata_path = os.path.join(cache_manager.metadata_dir, f"{cache_key}.json")
            
            deleted = False
            
            # åˆ é™¤ç»“æœæ–‡ä»¶
            if os.path.exists(result_path):
                os.remove(result_path)
                deleted = True
            
            # åˆ é™¤å…ƒæ•°æ®æ–‡ä»¶
            if os.path.exists(metadata_path):
                os.remove(metadata_path)
                deleted = True
            
            # å¦‚æœæœ‰æ ‡æ³¨ï¼Œä¹Ÿåˆ é™¤æ ‡æ³¨
            annotation_path = os.path.join(cache_manager.annotations_dir, f"{cache_key}.json")
            if os.path.exists(annotation_path):
                os.remove(annotation_path)
                deleted = True
            
            return deleted
        except Exception as e:
            print(f"åˆ é™¤ç¼“å­˜ç»“æœæ—¶å‡ºé”™: {str(e)}")
            return False
    
    # æ¸…ç©ºæ‰€æœ‰ç»“æœçš„å¢å¼ºç‰ˆæœ¬
    def clear_all_results():
        """æ¸…ç©ºæ‰€æœ‰å¤„ç†ç»“æœ"""
        try:
            # åŸå§‹æ–¹æ³•åªåˆ é™¤äº†results_dirä¸­çš„æ–‡ä»¶
            # å¢å¼ºç‰ˆæœ¬åŒæ—¶åˆ é™¤å…ƒæ•°æ®å’Œæ ‡æ³¨
            results_count = 0
            
            # è·å–æ‰€æœ‰ç»“æœæ–‡ä»¶
            if os.path.exists(cache_manager.results_dir):
                for filename in os.listdir(cache_manager.results_dir):
                    if filename.endswith('.json'):
                        # æå–cache_key
                        cache_key = filename[:-5]  # å»æ‰.jsonåç¼€
                        if delete_result(cache_key):
                            results_count += 1
            
            return results_count
        except Exception as e:
            print(f"æ¸…ç©ºæ‰€æœ‰ç»“æœæ—¶å‡ºé”™: {str(e)}")
            return 0
    
    # æ·»åŠ æ–¹æ³•åˆ°cache_manager
    cache_manager.delete_result = delete_result
    # å¢å¼ºclear_all_resultsæ–¹æ³•
    cache_manager.clear_all_results = clear_all_results
    
    return cache_manager

# æ·»åŠ ç¼ºå¤±çš„ç»“æœæŸ¥çœ‹é¡µé¢å‡½æ•°
def render_results_view_page():
    st.header("ğŸ“‹ ç»“æœæŸ¥çœ‹")
    
    # è·å–ç¼“å­˜ç®¡ç†å™¨
    cache_manager = get_cache_manager()
    # æ·»åŠ åˆ é™¤ç»“æœæ–¹æ³•
    cache_manager = add_delete_result_method()
    
    # è·å–æ‰€æœ‰å·²å¤„ç†çš„é¡¹ç›®
    all_items = cache_manager.get_all_processed_items()
    
    if not all_items:
        st.info("æš‚æ— å¤„ç†ç»“æœã€‚è¯·å…ˆåœ¨LLMå¤„ç†é¡µé¢å¤„ç†æ•°æ®ã€‚")
        return
    
    # ç­›é€‰åŠŸèƒ½
    col1, col2 = st.columns([1, 3])
    
    with col1:
        st.subheader("ç­›é€‰æ¡ä»¶")
        
        # æå–é¢†åŸŸå’Œæ–¹æ³•åˆ—è¡¨
        areas = sorted(set(item.get('area') for item in all_items if item.get('area')))
        methods = sorted(set(item.get('method') for item in all_items if item.get('method')))
        sources = sorted(set(item.get('source') for item in all_items if item.get('source')))
        
        # æŒ‰é¢†åŸŸç­›é€‰
        selected_area = st.selectbox("é¢†åŸŸ:", ["å…¨éƒ¨"] + areas)
        # æŒ‰æ–¹æ³•ç­›é€‰
        selected_method = st.selectbox("æ–¹æ³•:", ["å…¨éƒ¨"] + methods)
        # æŒ‰æ•°æ®æºç­›é€‰
        selected_source = st.selectbox("æ•°æ®æº:", ["å…¨éƒ¨"] + sources)
        
        # æŒ‰æ ‡æ³¨ç­›é€‰
        annotations = cache_manager.get_all_annotations()
        has_annotations = bool(annotations)
        
        if has_annotations:
            annotation_filter = st.radio("æ ‡æ³¨çŠ¶æ€:", ["å…¨éƒ¨", "å·²æ ‡æ³¨", "æœªæ ‡æ³¨"])
        
        # åº”ç”¨ç­›é€‰
        filter_criteria = {}
        if selected_area != "å…¨éƒ¨":
            filter_criteria['area'] = selected_area
        if selected_method != "å…¨éƒ¨":
            filter_criteria['method'] = selected_method
        if selected_source != "å…¨éƒ¨":
            filter_criteria['source'] = selected_source
        
        # è·å–ç­›é€‰åçš„ç»“æœ
        filtered_results = cache_manager.get_results_by_filter(filter_criteria)
        
        # åº”ç”¨æ ‡æ³¨ç­›é€‰
        if has_annotations and annotation_filter != "å…¨éƒ¨":
            if annotation_filter == "å·²æ ‡æ³¨":
                filtered_results = [r for r in filtered_results if r['metadata']['cache_key'] in annotations]
            else:  # æœªæ ‡æ³¨
                filtered_results = [r for r in filtered_results if r['metadata']['cache_key'] not in annotations]
        
        st.write(f"å…±æ‰¾åˆ° {len(filtered_results)} æ¡ç»“æœ")
        
        # è§†å›¾æ§åˆ¶æŒ‰é’®
        view_col1, view_col2 = st.columns(2)
        
        # éšæœºæŸ¥çœ‹æŒ‰é’®
        with view_col1:
            if st.button("éšæœºæŸ¥çœ‹ä¸€æ¡"):
                if filtered_results:
                    random_idx = random.randint(0, len(filtered_results) - 1)
                    st.session_state.selected_result = filtered_results[random_idx]
                    st.session_state.show_detail_view = True
                    st.rerun()  # ç«‹å³æ›´æ–°UI
        
        # æŸ¥çœ‹åˆ—è¡¨æŒ‰é’®
        with view_col2:
            if st.button("æŸ¥çœ‹åˆ—è¡¨"):
                st.session_state.show_detail_view = False
                st.session_state.selected_result = None
                st.rerun()  # ç«‹å³æ›´æ–°UI
        
        # æ·»åŠ åˆ é™¤é€‰ä¸­é¡¹åŠŸèƒ½
        if "to_delete_results" not in st.session_state:
            st.session_state.to_delete_results = []
        
        st.subheader("æ‰¹é‡æ“ä½œ")
        if len(st.session_state.to_delete_results) > 0:
            st.write(f"å·²é€‰æ‹© {len(st.session_state.to_delete_results)} æ¡ç»“æœå¾…åˆ é™¤")
            
        if st.button("åˆ é™¤é€‰ä¸­é¡¹", disabled=len(st.session_state.to_delete_results) == 0):
            try:
                delete_count = 0
                for cache_key in st.session_state.to_delete_results:
                    # åˆ é™¤ç¼“å­˜ç»“æœæ–‡ä»¶
                    if cache_manager.delete_result(cache_key):
                        delete_count += 1
                
                if delete_count > 0:
                    st.success(f"æˆåŠŸåˆ é™¤{delete_count}æ¡ç»“æœ")
                    st.session_state.to_delete_results = []  # æ¸…ç©ºé€‰æ‹©
                    time.sleep(1)
                    # å¦‚æœå½“å‰æ­£åœ¨è¯¦æƒ…è§†å›¾å¹¶ä¸”åˆ é™¤äº†è¯¥ç»“æœï¼Œè¿”å›åˆ—è¡¨è§†å›¾
                    if st.session_state.show_detail_view and st.session_state.selected_result:
                        deleted_key = st.session_state.selected_result['metadata'].get('cache_key', '')
                        if deleted_key in st.session_state.to_delete_results:
                            st.session_state.show_detail_view = False
                            st.session_state.selected_result = None
                    
                    st.rerun()
                else:
                    st.error("åˆ é™¤å¤±è´¥")
            except Exception as e:
                st.error(f"åˆ é™¤ç»“æœæ—¶å‡ºé”™: {str(e)}")
    
    with col2:
        # æŸ¥çœ‹æ¨¡å¼åˆ‡æ¢
        view_mode = st.radio("æŸ¥çœ‹æ¨¡å¼:", ["è¯¦æƒ…è§†å›¾", "åˆ—è¡¨è§†å›¾"], horizontal=True,
                            index=0 if st.session_state.show_detail_view else 1)
        
        # æ ¹æ®é€‰æ‹©æ›´æ–°è§†å›¾çŠ¶æ€
        if st.session_state.show_detail_view != (view_mode == "è¯¦æƒ…è§†å›¾"):
            st.session_state.show_detail_view = (view_mode == "è¯¦æƒ…è§†å›¾")
            # å¦‚æœåˆ‡æ¢åˆ°åˆ—è¡¨è§†å›¾ï¼Œæ¸…é™¤é€‰æ‹©çš„ç»“æœ
            if view_mode == "åˆ—è¡¨è§†å›¾":
                st.session_state.selected_result = None
            st.rerun()  # ç«‹å³æ›´æ–°UI
        
        # æ ¹æ®å½“å‰çŠ¶æ€æ˜¾ç¤ºè¯¦æƒ…æˆ–åˆ—è¡¨
        if st.session_state.show_detail_view and st.session_state.selected_result:
            # æ˜¾ç¤ºè¯¦æƒ…è§†å›¾
            st.subheader("ç»“æœè¯¦æƒ…")
            
            # æ·»åŠ è¿”å›åˆ—è¡¨æŒ‰é’®
            if st.button("è¿”å›åˆ—è¡¨"):
                st.session_state.show_detail_view = False
                st.session_state.selected_result = None
                st.rerun()
            else:
                selected = st.session_state.selected_result
                metadata = selected['metadata']
                result = selected['result']
                
                st.markdown(f"**æ ‡é¢˜**: {metadata.get('title', '')}")
                st.markdown(f"**æ‘˜è¦**: {metadata.get('abstract', '')}")
                st.markdown(f"**å¹´ä»½**: {metadata.get('year', '')}")
                st.markdown(f"**é¢†åŸŸ**: {metadata.get('area', '')}")
                st.markdown(f"**æ–¹æ³•**: {metadata.get('method', '')}")
                
                # æ˜¾ç¤ºå…³é”®è¯åŒ¹é…ç»“æœ
                st.subheader("å…³é”®è¯åŒ¹é…ç»“æœ")
                
                relevant_keywords = result.get('relevant_keywords', [])
                explanations = result.get('explanations', {})
                
                if relevant_keywords:
                    for keyword in relevant_keywords:
                        explanation = explanations.get(keyword, "")
                        st.markdown(f"**{keyword}**: {explanation}")
                else:
                    reason = explanations.get('reason', "æœªæä¾›åŸå› ")
                    st.markdown(f"**æ— åŒ¹é…å…³é”®è¯**: {reason}")
                
                # æ˜¾ç¤ºæ ‡æ³¨ç•Œé¢
                st.subheader("äººå·¥æ ‡æ³¨")
                
                cache_key = metadata.get('cache_key')
                annotation = cache_manager.get_annotation(cache_key) if cache_key else None
                
                is_correct = st.radio(
                    "LLMåˆ¤æ–­æ˜¯å¦æ­£ç¡®:",
                    ["æ­£ç¡®", "éƒ¨åˆ†æ­£ç¡®", "ä¸æ­£ç¡®"],
                    index=0 if not annotation else (0 if annotation.get('is_correct') == "æ­£ç¡®" else 
                                                  1 if annotation.get('is_correct') == "éƒ¨åˆ†æ­£ç¡®" else 2)
                )
                
                feedback = st.text_area(
                    "æ ‡æ³¨åé¦ˆ:",
                    value="" if not annotation else annotation.get('feedback', ""),
                    height=100
                )
                
                if st.button("ä¿å­˜æ ‡æ³¨"):
                    try:
                        annotation_data = {
                            "is_correct": is_correct,
                            "feedback": feedback
                        }
                        
                        if cache_manager.save_annotation(cache_key, annotation_data):
                            st.success("æ ‡æ³¨å·²ä¿å­˜ã€‚")
                            # æ›´æ–°sessionçŠ¶æ€ä¸­çš„æ ‡æ³¨ç»“æœ
                            if 'annotation_results' not in st.session_state:
                                st.session_state.annotation_results = {}
                            st.session_state.annotation_results[cache_key] = annotation_data
                        else:
                            st.error("ä¿å­˜æ ‡æ³¨æ—¶å‡ºé”™ã€‚")
                    except Exception as e:
                        st.error(f"ä¿å­˜æ ‡æ³¨æ—¶å‡ºé”™: {str(e)}")
        else:
            # æ˜¾ç¤ºç»“æœåˆ—è¡¨
            st.subheader("ç»“æœåˆ—è¡¨")
            
            if filtered_results:
                # ä½¿ç”¨é€šç”¨åˆ†é¡µå‡½æ•°
                # å°†åˆ—è¡¨è½¬æ¢ä¸ºDataFrameä»¥ä½¿ç”¨é€šç”¨åˆ†é¡µå‡½æ•°
                results_df = pd.DataFrame([r['metadata'] for r in filtered_results])
                current_df, current_page, total_pages, start_idx, end_idx = paginate_dataframe(results_df, "results_list")
                
                # å¯¹åº”çš„å½“å‰é¡µç»“æœé¡¹
                current_page_items = [filtered_results[i] for i in range(start_idx, end_idx)]
                
                st.write(f"ç»“æœ ({len(filtered_results)}æ¡ï¼Œæ˜¾ç¤ºç¬¬ {start_idx+1}-{end_idx} æ¡):")
                
                # åˆ†é¡µå¯¼èˆª
                render_pagination_controls("results_list", total_pages, current_page)
                
                # å…¨é€‰/å–æ¶ˆå…¨é€‰æŒ‰é’®
                select_all = st.checkbox("å…¨é€‰å½“å‰é¡µ", key="select_all_results")
                if select_all:
                    # å°†å½“å‰é¡µæ‰€æœ‰é¡¹æ·»åŠ åˆ°å¾…åˆ é™¤åˆ—è¡¨
                    for item in current_page_items:
                        cache_key = item['metadata'].get('cache_key', '')
                        if cache_key and cache_key not in st.session_state.to_delete_results:
                            st.session_state.to_delete_results.append(cache_key)
                
                # æ˜¾ç¤ºç»“æœåˆ—è¡¨
                for i, item in enumerate(current_page_items):
                    metadata = item['metadata']
                    result = item['result']
                    cache_key = metadata.get('cache_key', '')
                    
                    # åˆ›å»ºåŒ…å«å¤é€‰æ¡†çš„è¡Œ
                    col1, col2 = st.columns([1, 11])
                    
                    # é€‰æ‹©å¤é€‰æ¡†
                    with col1:
                        is_selected = cache_key in st.session_state.to_delete_results
                        if st.checkbox("", value=is_selected or select_all, key=f"select_{cache_key}"):
                            if cache_key not in st.session_state.to_delete_results:
                                st.session_state.to_delete_results.append(cache_key)
                        else:
                            if cache_key in st.session_state.to_delete_results:
                                st.session_state.to_delete_results.remove(cache_key)
                    
                    # æ˜¾ç¤ºæ•°æ®è¡Œå’ŒæŒ‰é’®
                    with col2:
                        with st.expander(f"ç»“æœ {start_idx + i + 1}: {metadata.get('title', '')[:50]}..."):
                            if st.button("æŸ¥çœ‹è¯¦æƒ…", key=f"view_{i}"):
                                st.session_state.selected_result = item
                                st.session_state.show_detail_view = True
                                st.rerun()
                            
                            # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
                            st.markdown(f"**å¹´ä»½**: {metadata.get('year', '')}")
                            st.markdown(f"**é¢†åŸŸ**: {metadata.get('area', '')}")
                            st.markdown(f"**æ–¹æ³•**: {metadata.get('method', '')}")
                            
                            # æ˜¾ç¤ºå…³é”®è¯ç»Ÿè®¡
                            relevant_keywords = result.get('relevant_keywords', [])
                            if relevant_keywords:
                                st.markdown(f"**ç›¸å…³å…³é”®è¯æ•°é‡**: {len(relevant_keywords)}")
                                st.markdown(f"**å…³é”®è¯**: {', '.join(relevant_keywords)}")
                            else:
                                st.markdown("**æ— åŒ¹é…å…³é”®è¯**")
                            
                            # åˆ é™¤æŒ‰é’®
                            if st.button("åˆ é™¤", key=f"delete_{i}"):
                                try:
                                    if cache_manager.delete_result(cache_key):
                                        st.success("å·²åˆ é™¤")
                                        if cache_key in st.session_state.to_delete_results:
                                            st.session_state.to_delete_results.remove(cache_key)
                                        time.sleep(1)
                                        st.rerun()
                                    else:
                                        st.error("åˆ é™¤å¤±è´¥")
                                except Exception as e:
                                    st.error(f"åˆ é™¤ç»“æœæ—¶å‡ºé”™: {str(e)}")
                
                # æ£€æŸ¥å½“å‰é¡µæ˜¯å¦æœ‰éœ€è¦ä»åˆ é™¤åˆ—è¡¨ä¸­ç§»é™¤çš„é¡¹
                if not select_all:
                    current_page_keys = [item['metadata'].get('cache_key', '') for item in current_page_items]
                    for cache_key in list(st.session_state.to_delete_results):  # ä½¿ç”¨å‰¯æœ¬éå†
                        if cache_key in current_page_keys:
                            # è¿™ä¸ªé”®åœ¨å½“å‰é¡µé¢ä¸Šï¼Œä½†æ²¡æœ‰è¢«é€‰ä¸­ï¼ˆå› ä¸ºä¸æ˜¯å…¨é€‰çŠ¶æ€ï¼‰
                            # æ£€æŸ¥å¯¹åº”çš„å¤é€‰æ¡†æ˜¯å¦æœªè¢«é€‰ä¸­
                            checkbox_key = f"select_{cache_key}"
                            if checkbox_key in st.session_state and not st.session_state[checkbox_key]:
                                st.session_state.to_delete_results.remove(cache_key)
                
                if len(filtered_results) > 10:
                    st.info(f"å½“å‰æ˜¾ç¤ºç¬¬ {start_idx + 1} - {end_idx} æ¡ï¼Œå…± {len(filtered_results)} æ¡ç»“æœ")
            else:
                st.info("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ç»“æœ")

# ç»Ÿè®¡åˆ†æé¡µé¢
def render_statistics_page():
    st.header("ğŸ“Š ç»Ÿè®¡åˆ†æ")
    
    # è·å–ç¼“å­˜ç®¡ç†å™¨
    cache_manager = get_cache_manager()
    
    # è·å–æ‰€æœ‰å·²å¤„ç†çš„é¡¹ç›®
    all_items = cache_manager.get_all_processed_items()
    
    if not all_items:
        st.info("æš‚æ— å¤„ç†ç»“æœã€‚è¯·å…ˆåœ¨LLMå¤„ç†é¡µé¢å¤„ç†æ•°æ®ã€‚")
        return
    
    # ç»Ÿè®¡åˆ†æéƒ¨åˆ†
    st.subheader("å¤„ç†ç»“æœç»Ÿè®¡")
    
    # ç¡®ä¿è·å–çš„æ•°æ®æ ¼å¼æ­£ç¡®
    # å°†ç»“æœè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
    processed_results = []
    for item in cache_manager.get_results_by_filter({}):
        if 'metadata' in item and 'result' in item:
            processed_results.append(item)
    
    if not processed_results:
        st.info("æ²¡æœ‰æ‰¾åˆ°æ ¼å¼æ­£ç¡®çš„å¤„ç†ç»“æœã€‚")
        return
    
    # ç»Ÿè®¡æˆåŠŸç‡
    success_rate = sum(1 for item in processed_results if item['result'].get('success', False)) / len(processed_results)
    st.write(f"æˆåŠŸç‡: {success_rate:.2%}")
    
    # ç»Ÿè®¡å…³é”®è¯æ•°é‡
    total_keywords = sum(len(item['result'].get('relevant_keywords', [])) for item in processed_results)
    st.write(f"æ€»å…³é”®è¯æ•°é‡: {total_keywords}")
    
    # æ–‡ç« æ€»æ•°
    total_papers = len(processed_results)
    st.write(f"æ–‡ç« æ€»æ•°: {total_papers}")
    
    # ç»Ÿè®¡ä¸åŒé¢†åŸŸå’Œæ–¹æ³•çš„å¤„ç†ç»“æœ
    area_counts = {}
    method_counts = {}
    
    for item in processed_results:
        metadata = item['metadata']
        area = metadata.get('area', 'æœªçŸ¥')
        method = metadata.get('method', 'æœªçŸ¥')
        
        area_counts[area] = area_counts.get(area, 0) + 1
        method_counts[method] = method_counts.get(method, 0) + 1
    
    # è½¬æ¢ä¸ºDataFrame
    area_df = pd.DataFrame({'area': list(area_counts.keys()), 'count': list(area_counts.values())})
    method_df = pd.DataFrame({'method': list(method_counts.keys()), 'count': list(method_counts.values())})
    
    # æ’åº
    if not area_df.empty:
        area_df = area_df.sort_values('count', ascending=False)
    if not method_df.empty:
        method_df = method_df.sort_values('count', ascending=False)
    
    # æ·»åŠ åˆè®¡è¡Œ
    if not area_df.empty:
        total_row = pd.DataFrame({'area': ['æ€»è®¡'], 'count': [area_df['count'].sum()]})
        area_df = pd.concat([area_df, total_row]).reset_index(drop=True)
    
    if not method_df.empty:
        total_row = pd.DataFrame({'method': ['æ€»è®¡'], 'count': [method_df['count'].sum()]})
        method_df = pd.concat([method_df, total_row]).reset_index(drop=True)
    
    # æ”¹è¿›åˆ—å
    if not area_df.empty:
        area_df.columns = ['é¢†åŸŸ', 'æ–‡ç« æ•°é‡']
    if not method_df.empty:
        method_df.columns = ['æ–¹æ³•', 'æ–‡ç« æ•°é‡']
    
    st.subheader("æŒ‰é¢†åŸŸç»Ÿè®¡")
    if not area_df.empty:
        st.dataframe(area_df, use_container_width=True)
    else:
        st.info("æ²¡æœ‰é¢†åŸŸæ•°æ®")
    
    st.subheader("æŒ‰æ–¹æ³•ç»Ÿè®¡")
    if not method_df.empty:
        st.dataframe(method_df, use_container_width=True)
    else:
        st.info("æ²¡æœ‰æ–¹æ³•æ•°æ®")
    
    # æŒ‰å…³é”®è¯ç»˜åˆ¶å‘æ–‡é‡é€å¹´ç´¯è®¡å›¾
    st.subheader("å…³é”®è¯å‘æ–‡é‡é€å¹´ç´¯è®¡å›¾")
    
    # å‡†å¤‡ç”¨äºç»˜å›¾çš„æ•°æ®
    # ä»å¤„ç†ç»“æœä¸­æå–å¹´ä»½ã€é¢†åŸŸå’Œå…³é”®è¯ä¿¡æ¯
    plot_data = []
    
    for item in processed_results:
        if 'metadata' not in item or 'result' not in item:
            continue
        
        metadata = item['metadata']
        result = item['result']
        
        year = metadata.get('year')
        method = metadata.get('method', 'æœªçŸ¥')
        source = metadata.get('source', 'æœªçŸ¥')
        relevant_keywords = result.get('relevant_keywords', [])
        
        # è·³è¿‡æ²¡æœ‰å¹´ä»½æˆ–å…³é”®è¯çš„æ•°æ®
        if year is None or not relevant_keywords:
            continue
        
        # è½¬æ¢ä¸ºæ•´æ•°å¹´ä»½
        try:
            year = int(year)
        except (ValueError, TypeError):
            continue
        
        # æ·»åŠ åˆ°ç»˜å›¾æ•°æ®ä¸­
        plot_data.append({
            'year': year,
            'method': method,
            'source': source,
            'keywords': relevant_keywords
        })
    
    if not plot_data:
        st.info("æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®ç»˜åˆ¶å›¾è¡¨ã€‚")
        return
    
    # è½¬æ¢ä¸ºDataFrameä»¥ä¾¿ç»Ÿè®¡
    plot_df = pd.DataFrame(plot_data)
    
    # æå–å”¯ä¸€å¹´ä»½å’Œæ–¹æ³•
    years = sorted(plot_df['year'].unique())
    methods = ["machine learning", "deep learning", "LLMs"]
    sources = sorted(plot_df['source'].unique())
    
    # ç”¨æˆ·æ§åˆ¶
    control_col1, control_col2 = st.columns(2)
    
    with control_col1:
        # é€‰æ‹©æ•°æ®æº
        selected_sources = st.multiselect(
            "é€‰æ‹©æ•°æ®æº:",
            options=sources,
            default=sources
        )
        
        # é€‰æ‹©å›¾è¡¨ç±»å‹
        chart_type = st.radio(
            "å›¾è¡¨ç±»å‹:",
            ["å¹´åº¦å‘æ–‡é‡", "ç´¯è®¡å‘æ–‡é‡"],
            index=1  # é»˜è®¤é€‰æ‹©ç´¯è®¡å‘æ–‡é‡
        )
    
    with control_col2:
        # ä¸ºæ¯ä¸ªæ–¹æ³•é€‰æ‹©å¹´ä»½èŒƒå›´
        st.write("å¹´ä»½èŒƒå›´ç­›é€‰:")
        min_year, max_year = min(years), max(years)
        
        # æœºå™¨å­¦ä¹ å¹´ä»½èŒƒå›´
        ml_min_year, ml_max_year = st.slider(
            "æœºå™¨å­¦ä¹ å¹´ä»½èŒƒå›´:",
            min_value=min_year,
            max_value=max_year,
            value=(min_year, max_year),
            key="ml_year_range"
        )
        
        # æ·±åº¦å­¦ä¹ å¹´ä»½èŒƒå›´
        dl_min_year, dl_max_year = st.slider(
            "æ·±åº¦å­¦ä¹ å¹´ä»½èŒƒå›´:",
            min_value=min_year,
            max_value=max_year,
            value=(min_year, max_year),
            key="dl_year_range"
        )
        
        # LLMå¹´ä»½èŒƒå›´
        llm_min_year, llm_max_year = st.slider(
            "LLMå¹´ä»½èŒƒå›´:",
            min_value=min_year,
            max_value=max_year,
            value=(min_year, max_year),
            key="llm_year_range"
        )
    
    # å¹´ä»½èŒƒå›´æ˜ å°„
    year_ranges = {
        "machine learning": (ml_min_year, ml_max_year),
        "deep learning": (dl_min_year, dl_max_year),
        "LLMs": (llm_min_year, llm_max_year)
    }
    
    # ç­›é€‰æ•°æ®
    if selected_sources:
        plot_df = plot_df[plot_df['source'].isin(selected_sources)]
    
    if plot_df.empty:
        st.info("ç­›é€‰åæ²¡æœ‰æ•°æ®å¯æ˜¾ç¤ºã€‚")
        return
    
    # å®šä¹‰æ–¹æ³•çš„é…è‰²å’Œåç§°
    method_properties = {
        "machine learning": {
            "color": "#FF5733",  # æ©™çº¢è‰²
            "display_name": "Machine Learning",
            "marker_symbol": "circle",
            "line_dash": "solid",
            "opacity": 0.7
        },
        "deep learning": {
            "color": "#3498DB",  # è“è‰²
            "display_name": "Deep Learning",
            "marker_symbol": "square",
            "line_dash": "solid",
            "opacity": 0.7
        },
        "LLMs": {
            "color": "#2ECC71",  # ç»¿è‰²
            "display_name": "Large Language Models",
            "marker_symbol": "star",
            "line_dash": "solid",
            "opacity": 0.7
        }
    }
    
    # åˆ›å»ºå›¾è¡¨
    fig = px.line(title=f"å…³é”®è¯å‘æ–‡é‡{'ç´¯è®¡' if chart_type == 'ç´¯è®¡å‘æ–‡é‡' else 'å¹´åº¦'}å›¾")
    
    # å¤„ç†æ¯ä¸ªæ–¹æ³•çš„æ•°æ®
    for method in methods:
        # ç­›é€‰å½“å‰æ–¹æ³•çš„å¹´ä»½èŒƒå›´
        min_year, max_year = year_ranges[method]
        year_range = list(range(min_year, max_year + 1))
        
        # å¦‚æœå¹´ä»½èŒƒå›´ä¸ºç©ºï¼Œåˆ™è·³è¿‡
        if not year_range:
            continue
        
        # è®¡ç®—æ¯å¹´çš„æ–‡ç« æ•°é‡ï¼Œå¹¶è€ƒè™‘è®ºæ–‡é‡å é—®é¢˜
        yearly_counts = {year: 0 for year in year_range}
        
        for _, row in plot_df.iterrows():
            # å¦‚æœå¹´ä»½ä¸åœ¨èŒƒå›´å†…ï¼Œè·³è¿‡
            if row['year'] not in year_range:
                continue
            
            # è·å–å½“å‰è®ºæ–‡çš„å…³é”®è¯å’Œæ–¹æ³•
            keywords = row['keywords']
            paper_method = row['method']
            
            # åˆ¤æ–­æ˜¯å¦åº”è¯¥è®¡å…¥å½“å‰æ–¹æ³•
            should_count = False
            
            if method == "LLMs":
                # LLMè®ºæ–‡åªè®¡å…¥LLMæ–¹æ³•
                should_count = "LLMs" in keywords or paper_method == "LLMs"
            elif method == "deep learning":
                # æ·±åº¦å­¦ä¹ è®ºæ–‡è®¡å…¥æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œä½†æ’é™¤LLMè®ºæ–‡
                should_count = (("deep learning" in keywords or paper_method == "deep learning") and 
                               not ("LLMs" in keywords or paper_method == "LLMs"))
            elif method == "machine learning":
                # æœºå™¨å­¦ä¹ è®ºæ–‡è®¡å…¥æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œä½†æ’é™¤æ·±åº¦å­¦ä¹ å’ŒLLMè®ºæ–‡
                should_count = (("machine learning" in keywords or paper_method == "machine learning") and 
                               not ("deep learning" in keywords or paper_method == "deep learning") and
                               not ("LLMs" in keywords or paper_method == "LLMs"))
            
            if should_count:
                yearly_counts[row['year']] += 1
        
        # å°†è®¡æ•°è½¬æ¢ä¸ºåˆ—è¡¨
        years_list = list(yearly_counts.keys())
        counts_list = list(yearly_counts.values())
        
        # å¦‚æœæ˜¯ç´¯è®¡å›¾ï¼Œè®¡ç®—ç´¯è®¡å€¼
        if chart_type == "ç´¯è®¡å‘æ–‡é‡":
            cumulative_counts = []
            running_sum = 0
            for count in counts_list:
                running_sum += count
                cumulative_counts.append(running_sum)
            counts_list = cumulative_counts
        
        # è·å–æ–¹æ³•å±æ€§
        props = method_properties[method]
        
        # æ·»åŠ åˆ°å›¾è¡¨
        fig.add_trace(go.Scatter(
            x=years_list,
            y=counts_list,
            mode='lines+markers',
            name=props["display_name"],
            line=dict(color=props["color"], dash=props["line_dash"]),
            marker=dict(symbol=props["marker_symbol"], size=8),
            opacity=props["opacity"]
        ))
    
    # è®¾ç½®å›¾è¡¨å¸ƒå±€
    fig.update_layout(
        xaxis_title="å¹´ä»½",
        yaxis_title="è®ºæ–‡æ•°é‡",
        legend_title="æ–¹æ³•",
        template="plotly_white",
        height=500
    )
    
    # æ˜¾ç¤ºå›¾è¡¨
    st.plotly_chart(fig, use_container_width=True)
    
    # æ·»åŠ ä¸‹è½½å›¾è¡¨æŒ‰é’®
    st.download_button(
        label="ä¸‹è½½å›¾è¡¨ (HTML)",
        data=fig.to_html(),
        file_name=f"keyword_trend_{'cumulative' if chart_type == 'ç´¯è®¡å‘æ–‡é‡' else 'yearly'}.html",
        mime="text/html"
    )

def main():
    # åˆå§‹åŒ–SessionçŠ¶æ€
    init_session_state()
    
    # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨å’Œæ–¹æ³•
    cache_manager = add_data_cache_methods()
    cache_manager = add_delete_result_method()
    
    # åŠ è½½é»˜è®¤æç¤ºè¯
    if not st.session_state.system_prompt or not st.session_state.user_prompt_template:
        load_default_prompts()
    
    # åŠ è½½å·²ä¿å­˜çš„å…³é”®è¯åˆ—è¡¨
    saved_keyword_lists = cache_manager.get_all_keyword_lists()
    for name, keywords in saved_keyword_lists.items():
        st.session_state.keyword_lists[name] = keywords
    
    # æ›´æ–°ä¼šè¯æ—¶é—´
    if st.session_state.last_session_time:
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        st.session_state.last_session_time = current_time
    
    # è®¾ç½®é¡µé¢æ ‡é¢˜
    st.title("ğŸ“š å¤§æ¨¡å‹è®ºæ–‡å…³é”®è¯åŒ¹é…")
    
    # ä¾§è¾¹æ å¯¼èˆª
    page = st.sidebar.radio(
        "å¯¼èˆª",
        ["ğŸ“Š æ•°æ®åŠ è½½", "ğŸ”‘ å…³é”®è¯ç®¡ç†", "ğŸ¤– LLMå¤„ç†", "ğŸ“ ç»“æœæŸ¥çœ‹", "ğŸ“ˆ ç»Ÿè®¡åˆ†æ", "âš™ï¸ æç¤ºè¯ç®¡ç†"]
    )
    
    # æ˜¾ç¤ºå½“å‰æ•°æ®çŠ¶æ€
    with st.sidebar.expander("å½“å‰çŠ¶æ€", expanded=False):
        if st.session_state.loaded_data is not None:
            st.write(f"å·²åŠ è½½ {len(st.session_state.loaded_data)} æ¡æ•°æ®")
        else:
            st.write("æœªåŠ è½½æ•°æ®")
        
        if st.session_state.selected_keywords:
            st.write(f"å·²é€‰æ‹© {len(st.session_state.selected_keywords)} ä¸ªå…³é”®è¯")
        else:
            st.write("æœªé€‰æ‹©å…³é”®è¯")
        
        # ä»ç¼“å­˜ç®¡ç†å™¨è·å–å¤„ç†ç»“æœæ•°é‡
        cache_manager = get_cache_manager()
        processed_count = len(cache_manager.get_results_by_filter({}))
        st.write(f"å·²å¤„ç† {processed_count} æ¡ç»“æœ")
    
    try:
        # æ ¹æ®é€‰æ‹©çš„é¡µé¢æ¸²æŸ“ç›¸åº”çš„å†…å®¹
        if page == "ğŸ“Š æ•°æ®åŠ è½½":
            render_data_loading_page()
        elif page == "ğŸ”‘ å…³é”®è¯ç®¡ç†":
            render_keywords_management_page()
        elif page == "ğŸ¤– LLMå¤„ç†":
            render_llm_processing_page()
        elif page == "ğŸ“ ç»“æœæŸ¥çœ‹":
            render_results_view_page()
        elif page == "ğŸ“ˆ ç»Ÿè®¡åˆ†æ":
            render_statistics_page()
        elif page == "âš™ï¸ æç¤ºè¯ç®¡ç†":
            render_prompts_management_page()
        
        # æ˜¾ç¤ºé¡µè„š
        st.markdown("---")
        st.markdown("ğŸ“š **å¤§æ¨¡å‹è®ºæ–‡å…³é”®è¯åŒ¹é…**")
    
    except Exception as e:
        st.error(f"åº”ç”¨ç¨‹åºå‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        st.exception(traceback.format_exc())


if __name__ == "__main__":
    main() 