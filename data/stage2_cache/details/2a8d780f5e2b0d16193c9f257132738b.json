{
  "paper": {
    "id": 3558,
    "title": "VCONV: A Convolutional Neural Network Accelerator for FPGAs",
    "abstract": "Field Programmable Gate Arrays (FPGAs), with their wide portfolio of configurable resources such as Look-Up Tables (LUTs), Block Random Access Memory (BRAM), and Digital Signal Processing (DSP) blocks, are the best option for custom hardware designs. Their low power consumption and cost-effectiveness give them an advantage over Graphics Processing Units (GPUs) and Central Processing Units (CPUs) in providing efficient accelerator solutions for compute-intensive Convolutional Neural Network (CNN) models. CNN accelerators are dedicated hardware modules capable of performing compute operations such as convolution, activation, normalization, and pooling with minimal intervention from a host. Designing accelerators for deeper CNN models requires FPGAs with vast resources, which impact its advantages in terms of power and price. In this paper, we propose the VCONV Intellectual Property (IP), an efficient and scalable CNN accelerator architecture for applications where power and cost are constraints. VCONV, with its configurable design, can be deployed across multiple smaller FPGAs instead of a single large FPGA to provide better control over cost and parallel processing. VCONV can be deployed across heterogeneous FPGAs, depending on the performance requirements of each layer. The IP's performance can be evaluated using embedded monitors to ensure that the accelerator is configured to achieve the best performance. VCONV can be configured for data type format, convolution engine (CE) and convolution unit (CU) configurations, as well as the sequence of operations based on the CNN model and layer. VCONV can be interfaced through the Advanced Peripheral Bus (APB) for configuration and the Advanced eXtensible Interface (AXI) stream for data transfers. The IP was implemented and validated on the Avnet Zedboard and tested on the first layer of AlexNet, VGG16, and ResNet18 with multiple CE configurations, demonstrating 100% performance from MAC units with no idle time. We also synthesized multiple VCONV instances required for AlexNet, achieving the lowest BRAM utilization of just 1.64 Mb and deriving a performance of 56GOPs.",
    "year": 2025,
    "source": "WOS",
    "area": "portfolio",
    "method": "machine learning",
    "cache_key": "eff81bbb5c1a0a8face9a96c8c6c75be",
    "relevant_keywords": [
      "neural network",
      "deep learning",
      "convolutional neural network",
      "CNN"
    ],
    "stage1_timestamp": "2025-05-15T01:18:20.546630"
  },
  "domain_result": {
    "success": true,
    "application_domains": [
      "None"
    ],
    "justification": "该论文主要研究一种用于FPGA的卷积神经网络加速器（VCONV），专注于硬件设计和性能优化，并未提及在衍生品定价、金融风险管理或投资组合管理等金融领域的应用。",
    "raw_response": "```json\n{\n  \"application_domains\": [\"None\"],\n  \"justification\": \"该论文主要研究一种用于FPGA的卷积神经网络加速器（VCONV），专注于硬件设计和性能优化，并未提及在衍生品定价、金融风险管理或投资组合管理等金融领域的应用。\"\n}\n```"
  },
  "timestamp": "2025-05-20T16:09:19.151775"
}