{
  "paper": {
    "id": 221,
    "title": "Reinforcement Mechanism Design for Electric Vehicle Demand Response in Microgrid Charging Stations",
    "abstract": "Reinforcement learning has become an important scheduling solution with many successes in markets with dynamic pricing options, e.g., electric vehicle charging in a deregulated electricity market. However, the highly-uncertain requests and partially-unknown individual preferences remain major challenges to effective demand responses in the user-centric environment. For charging stations who aim to maximize the long-term revenue in this fast-growing market, an accurate estimate of user's sensitivity, or acceptance, of the prices they offered to the potential customers is the key to the success of dynamic pricing. While most existing pricing schemes assume users will consistently follow stable patterns that are observable or inferrable by the charging service provider, it remains crucial to consider how users may be influenced by historic prices they have observed and react strategically to decide optimal charging demands that can maximize their utilities. To overcome this limitation, this paper presents a new framework based on reinforcement mechanism design to determine the optimal charging price in a mechanism design setting, which can optimize the long-term revenue of charging stations as well as the social welfare of users with private utility functions. Specifically, the strategic interaction between the station and users is modelled as a discrete finite Markov decision process, a Q-learning-based dynamic pricing mechanism is proposed to explore how price affects users' demands over a sequence of time. The experiments demonstrate that our pricing mechanism outperforms the predetermined time-of-use pricing in maximizing the long-term revenue of the charging station.",
    "year": 2020,
    "source": "WOS",
    "area": "derivatives_pricing",
    "method": "machine learning",
    "cache_key": "e998c8045ccc4638f9efde9e02acd6bc",
    "relevant_keywords": [
      "reinforcement learning",
      "Q-learning"
    ],
    "stage1_timestamp": "2025-05-15T01:29:44.184152"
  },
  "domain_result": {
    "success": true,
    "application_domains": [
      "None"
    ],
    "justification": "该论文主要研究基于强化学习的电动汽车充电站动态定价机制，旨在优化充电站的长期收入和用户的社会福利。虽然涉及定价机制，但其应用场景是电力市场和充电服务，而非金融领域的衍生品定价、金融风险管理或投资组合管理。",
    "raw_response": "```json\n{\n  \"application_domains\": [\"None\"],\n  \"justification\": \"该论文主要研究基于强化学习的电动汽车充电站动态定价机制，旨在优化充电站的长期收入和用户的社会福利。虽然涉及定价机制，但其应用场景是电力市场和充电服务，而非金融领域的衍生品定价、金融风险管理或投资组合管理。\"\n}\n```"
  },
  "timestamp": "2025-05-20T16:06:03.663494"
}