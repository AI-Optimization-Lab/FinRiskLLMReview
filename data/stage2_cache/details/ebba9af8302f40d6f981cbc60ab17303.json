{
  "paper": {
    "id": 213,
    "title": "Trading and Pricing Sensor Data in Competing Edge Servers with Double Auction Markets",
    "abstract": "With the development of the IoT (Internet of Things), sensors networks can bring a large amount of valuable data. In addition to be utilized in the local IoT applications, the data can also be traded in the connected edge servers. As an efficient resource allocation mechanism, the double auction has been widely used in the stock and futures markets and can be also applied in the data resource allocation in sensor networks. Currently, there usually exist multiple edge servers running double auctions competing with each other to attract data users (buyers) and producers (sellers). Therefore, the double auction market run on each edge server needs efficient mechanism to improve the allocation efficiency. Specifically, the pricing strategy of the double auction plays an important role on affecting traders' profit, and thus, will affect the traders' market choices and bidding strategies, which in turn affect the competition result of double auction markets. In addition, the traders' trading strategies will also affect the market's pricing strategy. Therefore, we need to analyze the double auction markets' pricing strategy and traders' trading strategies. Specifically, we use a deep reinforcement learning algorithm combined with mean field theory to solve this problem with a huge state and action space. For trading strategies, we use the Independent Parametrized Deep Q-Network (I-PDQN) algorithm combined with mean field theory to compute the Nash equilibrium strategies. We then compare it with the fictitious play (FP) algorithm. The experimental results show that the computation speed of I-PDQN algorithm is significantly faster than that of FP algorithm. For pricing strategies, the double auction markets will dynamically adjust the pricing strategy according to traders' trading strategies. This is a sequential decision-making process involving multiple agents. Therefore, we model it as a Markov game. We adopt Multiagent Deep Deterministic Policy Gradient (MADDPG) algorithm to analyze the Nash equilibrium pricing strategies. The experimental results show that the MADDPG algorithm solves the problem faster than the FP algorithm.",
    "year": 2021,
    "source": "WOS",
    "area": "derivatives_pricing",
    "method": "machine learning",
    "cache_key": "5d27de53a45893ed9e1b75b0c51e4f9b",
    "relevant_keywords": [
      "machine learning",
      "reinforcement learning",
      "deep learning",
      "neural network",
      "Multiagent Deep Deterministic Policy Gradient",
      "MADDPG",
      "Independent Parametrized Deep Q-Network",
      "I-PDQN"
    ],
    "stage1_timestamp": "2025-05-15T01:29:44.163596"
  },
  "domain_result": {
    "success": true,
    "application_domains": [
      "None"
    ],
    "justification": "该论文主要研究传感器数据在边缘服务器中的交易和定价问题，使用双拍卖市场和强化学习算法优化资源分配。虽然提到了双拍卖在股票和期货市场的应用，但论文的核心技术并未直接应用于衍生品定价、金融风险管理或投资组合管理等金融领域。",
    "raw_response": "```json\n{\n  \"application_domains\": [\"None\"],\n  \"justification\": \"该论文主要研究传感器数据在边缘服务器中的交易和定价问题，使用双拍卖市场和强化学习算法优化资源分配。虽然提到了双拍卖在股票和期货市场的应用，但论文的核心技术并未直接应用于衍生品定价、金融风险管理或投资组合管理等金融领域。\"\n}\n```"
  },
  "timestamp": "2025-05-20T16:06:05.009163"
}