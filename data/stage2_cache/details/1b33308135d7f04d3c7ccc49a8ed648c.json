{
  "paper": {
    "id": 692,
    "title": "Differentially Private Empirical Risk Minimization",
    "abstract": "Privacy-preserving machine learning algorithms are crucial for the increasingly common setting in which personal data, such as medical or financial records, are analyzed. We provide general techniques to produce privacy-preserving approximations of classifiers learned via (regularized) empirical risk minimization (ERM). These algorithms are private under the epsilon-differential privacy definition due to Dwork et al. (2006). First we apply the output perturbation ideas of Dwork et al. (2006), to ERM classification. Then we propose a new method, objective perturbation, for privacy-preserving machine learning algorithm design. This method entails perturbing the objective function before optimizing over classifiers. If the loss and regularizer satisfy certain convexity and differentiability criteria, we prove theoretical results showing that our algorithms preserve privacy, and provide generalization bounds for linear and nonlinear kernels. We further present a privacy-preserving technique for tuning the parameters in general machine learning algorithms, thereby providing end-to-end privacy guarantees for the training process. We apply these results to produce privacy-preserving analogues of regularized logistic regression and support vector machines. We obtain encouraging results from evaluating their performance on real demographic and benchmark data sets. Our results show that both theoretically and empirically, objective perturbation is superior to the previous state-of-the-art, output perturbation, in managing the inherent tradeoff between privacy and learning performance.",
    "year": 2011,
    "source": "WOS",
    "area": "financial_risk",
    "method": "machine learning",
    "cache_key": "94bfe5eb9147de2977300e17389dfa34",
    "relevant_keywords": [
      "machine learning",
      "supervised learning",
      "classification",
      "support vector machine",
      "SVM"
    ],
    "stage1_timestamp": "2025-05-15T01:53:59.380248"
  },
  "domain_result": {
    "success": true,
    "application_domains": [
      "None"
    ],
    "justification": "该论文主要研究隐私保护的机器学习算法，特别是差分隐私在经验风险最小化中的应用。虽然提到了金融记录作为潜在的应用场景之一，但论文的核心技术和研究成果并未明确针对衍生品定价、金融风险管理或投资组合管理等特定金融领域。",
    "raw_response": "```json\n{\n  \"application_domains\": [\"None\"],\n  \"justification\": \"该论文主要研究隐私保护的机器学习算法，特别是差分隐私在经验风险最小化中的应用。虽然提到了金融记录作为潜在的应用场景之一，但论文的核心技术和研究成果并未明确针对衍生品定价、金融风险管理或投资组合管理等特定金融领域。\"\n}\n```"
  },
  "timestamp": "2025-05-20T15:55:50.097324"
}