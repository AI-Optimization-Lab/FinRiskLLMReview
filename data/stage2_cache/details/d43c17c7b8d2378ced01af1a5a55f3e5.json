{
  "paper": {
    "id": 1550,
    "title": "Evaluating the Privacy Exposure of Interpretable Global Explainers",
    "abstract": "In recent years we are witnessing the diffusion of AI systems based on powerful Machine Learning models which find application in many critical contexts such as medicine, financial market and credit scoring. In such a context it is particularly important to design Trustworthy AI systems while guaranteeing transparency, with respect to their decision reasoning and privacy protection. Although many works in the literature addressed the lack of transparency and the risk of privacy exposure of Machine Learning models, the privacy risks of explainers have not been appropriately studied. This paper presents a methodology for evaluating the privacy exposure raised by interpretable global explainers able to imitate the original black-box classifier. Our methodology exploits the well-known Membership Inference Attack. The experimental results highlight that global explainers based on interpretable trees lead to an increase in privacy exposure.",
    "year": 2022,
    "source": "WOS",
    "area": "financial_risk",
    "method": "machine learning",
    "cache_key": "1883282da0acf40d33a22c0fd01a2fec",
    "relevant_keywords": [
      "machine learning",
      "classification",
      "decision tree"
    ],
    "stage1_timestamp": "2025-05-15T02:04:20.126258"
  },
  "domain_result": {
    "success": true,
    "application_domains": [
      "None"
    ],
    "justification": "该论文主要研究机器学习解释器的隐私风险，虽然提到了金融市场的应用背景，但核心技术并未专注于衍生品定价、金融风险管理或投资组合管理等特定金融领域。",
    "raw_response": "```json\n{\n  \"application_domains\": [\"None\"],\n  \"justification\": \"该论文主要研究机器学习解释器的隐私风险，虽然提到了金融市场的应用背景，但核心技术并未专注于衍生品定价、金融风险管理或投资组合管理等特定金融领域。\"\n}\n```"
  },
  "timestamp": "2025-05-20T15:48:20.032540"
}