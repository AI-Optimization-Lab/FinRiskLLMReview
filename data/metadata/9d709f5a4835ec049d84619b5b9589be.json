{
  "id": 460,
  "title": "互联网金融与中国商业银行之间的风险溢出效应研究",
  "abstract": "基于2013—2019年国内14家商业银行和互联网金融指数的日股票收盘价数据,采用分位数回归的CoVaR模型,对互联网金融行业与国有银行、股份制银行和城市商业银行之间的双向风险溢出效应进行研究。结果表明:第一,城商行自身风险最大,且互联网金融风险与城商行差别不大,国有银行风险最小;第二,互联网金融与各类型商业银行之间均存在双向不对称的正向风险溢出,且各商业银行对互联网金融的风险溢出效应更强;第三,通过比较分析三类商业银行与互联网金融之间的风险溢出值发现,互联网金融与城商行之间的双向风险溢出效应最强;第四,银行规模大小不是决定风险溢出强度的主要标准,互联网金融与城商行之间的风险溢出效应存在被低估的可能。",
  "year": 2020,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "9d709f5a4835ec049d84619b5b9589be",
  "timestamp": "2025-05-14T22:30:29.672338"
}