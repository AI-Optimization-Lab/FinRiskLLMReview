{
  "id": 3484,
  "title": "Generative AI for Consumer Communications: Classification, Summarization, Response Generation",
  "abstract": "Generative AI showed the unexpected power of large language models (LLMs) for understanding and generation of natural language text and other modalities at the end of 2022. This paper presents a novel generative AI system for text classification, summarization and response generation of consumer communications. The system uses the same foundation model and a uniform pipeline for the tasks proposed. Consumer communications are massive and served mainly via voice and text, and until recently could be handled only with human agents (customer service representatives). However, they must be handled with quality, consistency, speed and low cost, at scale. We limit our attention to financial consumer communications from the U.S. Consumer Financial Protection Bureau (CFPB), publicly available in a dataset of over 4.7 million complaints. Performance reaches 88% accuracy (without fine-tuning) for classification and over 72% for summarization and response generation. Artificial intelligence has great positive impacts for business and society, but its application and deployment also poses risks and unknowns. We thus address the important questions of risk, bias, interpretability, explainability, safety and regulatory compliance with the emerging legal frameworks.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "2c9e78521ed5d9f016923281d11bb238",
  "timestamp": "2025-05-15T02:26:48.519918"
}