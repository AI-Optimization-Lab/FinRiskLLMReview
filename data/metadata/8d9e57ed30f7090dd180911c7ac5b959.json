{
  "id": 3494,
  "title": "For narrower income inequality: traditional finance or microfinance?",
  "abstract": "This paper uses the theory of information imperfections to examine the relationship between income inequality and financial development in a dual financial system comprising traditional finance and microfinance. It uses panel data for 97 developing countries over a period characterized by declining income inequality from 2000 to 2017. Traditional finance is measured through domestic credit relative to GDP and the IMF Financial Development Index. Microfinance is measured through the size of microfinance gross loan portfolio relative to GDP and the number of active microfinance borrowers to the total population. Controlling for various measures of macroeconomic and socioeconomic variables and using different econometric specifications including a random-effects linear regression model with endogenous sample selection, the results show that microfinance consistently predicts a lower income inequality measured by the Gini coefficient, while traditional finance shows no impact. The findings of this paper draw clear policy implications regarding the role of microfinance as a tool for income equality in developing countries.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8d9e57ed30f7090dd180911c7ac5b959",
  "timestamp": "2025-05-15T01:17:54.046480"
}