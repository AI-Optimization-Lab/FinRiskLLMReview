{
  "id": 323,
  "title": "Lessons Learned in Developing and Applying Land Use Model Systems Parcel-Based Example",
  "abstract": "A variety of land use models is driven by theoretical advances, data availability, enhanced computation, and new policy-making needs. This paper describes the process of developing and applying a disaggregate model system that seeks to simulate the subdivision and land use change of parcels and the spatial allocation of households and employment across zones. Relying on multinomial logit specifications, random number generation, and a seemingly unrelated regression model with both spatial lag and spatial error components, the model development process was accompanied by a variety of challenges. Some issues are specific to the model presented here, but many are common for integrated transport-land use models. It is hoped that solutions to these issues and lessons learned offer useful insights for ongoing improvements in land use modeling endeavors of all types. Comparisons of road pricing and trend scenario results for the Austin, Texas, region highlight how policies may shape land and travel futures. Although the road pricing policy did not alter land use intensity patterns in a significant way, it was forecast to increase speeds across the region's network and reduce regional congestion levels.",
  "year": 2009,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "ba38070a45ef05c89dc235c49284ecfd",
  "timestamp": "2025-05-15T01:30:46.351265"
}