{
  "id": 1427,
  "title": "Balanced weighted extreme learning machine for imbalance learning of credit default risk and manufacturing productivity",
  "abstract": "Imbalanced class distribution exists in real world problems and is considered an important research topic. The weighted extreme learning machine (WELM) is a cost sensitive method that effectively handles imbalance problems. However, the effect of data complexity on classifier performance is considered to be greater compared to the imbalance distribution. To address this issue, this work proposes a balanced WELM (BLWELM) by integrating various sampling methods and WELM in k-fold learning to reduce the data complexity and improve class distribution. The main idea is to generate new samples and remove overlapping noisy samples that exist on the borderline to improve the separating boundary between minority and majority class samples. Extensive experimental work on benchmarking datasets has demonstrated the effectiveness of the proposed method. In addition, credit default and manufacturing productivity were predicted by BLWELM. The analyses show that BLWELM gives better classification results compared to WELM and many other popular machine learning methods. The work may be used to facilitate financial institutions in allocating credit to applicants based on their previous history to avoid financial risk, and manufacturing companies can allocate highly productive workers to customer orders that need immediate delivery to avoid delays in the entire supply chain network.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "742712f42efe98a49679bdc8ccd7acb7",
  "timestamp": "2025-05-15T02:03:00.643628"
}