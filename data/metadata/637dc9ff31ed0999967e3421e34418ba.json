{
  "id": 3346,
  "title": "TECHNOLOGICAL COMPLEXITY: A TOOL FOR UNDERSTANDING THE BEHAVIOUR OF CONSUMERS OF HIGH VALUE-ADDED FOODSTUFFS",
  "abstract": "This article proposes and develops the concept of technological complexity (TC) as a useful and simple tool for grouping key attributes that give added value to a product. In addition, it reports an empirical application of this concept to two different food products (cured ham and cured sausage). The authors used a mixed-effects multi-nomial logistic regression model and show that in the cured pork product agribusiness, a low frequency of consumption favours the acceptance of high TC products. The results also confirm that marketing high TC products in stores with a large assortment decreases the chances of success for agribusiness companies that produce cured pork food products. These finding can be used by the managers for designing complementary attributes that improve their product portfolio. Besides, advertising expenditures associated with introducing new products could be reduced if companies strengthened their presence in specialty stores.",
  "year": 2016,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "637dc9ff31ed0999967e3421e34418ba",
  "timestamp": "2025-05-15T01:16:22.075167"
}