{
  "id": 3227,
  "title": "Interaction between Legal and Social Needs in Their Association with Self- rated Health in a National Sample of Veterans",
  "abstract": "Many health-related social needs, such as financial insecurity, are interconnected with legal needs. However, little is known about which social needs are more likely to be associated with legal needs, or whether legal and other needs interact to affect health. Using data from a 2020 national mailed survey assessing social needs among Veterans who had or were at risk for cardiovascular disease (N=2,801) and linked administrative data, linear regression models tested interactions between legal and other social needs, and their asso-ciations with self -rated health. In a model examining the interaction of financial and legal needs, experiencing financial but not legal needs was as strongly associated with worse health (b=- 0.58, 95% CI - 0.69, - 0.46) as experiencing both financial and legal needs (b= - 0.55, 95% CI - 0.70, - 0.40). Financial needs are important to Veterans' health and further research is needed to determine how financial and legal needs should be triaged by providers.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b8b74247bf302808033e0e3b00a0f9df",
  "timestamp": "2025-05-15T02:24:05.051417"
}