{
  "id": 3377,
  "title": "Digital Financial Inclusion and Diversity of Household Financial Asset Allocation: Evidence From China",
  "abstract": "Using panel data from the China Household Finance Survey (CHFS) and the Digital Financial Inclusion Index (DFII) of Peking University, this paper investigates the impacts of DFI development on household financial asset allocation. The results show that DFI development significantly increases the diversity of household financial assets and enhances the breadth and depth of household participation in the investment of stocks, funds, and internet finance products. These effects remain robust to various tests, including the use of instrumental variables, reconstructing the dependent variable, and adopting different regression models. Specifically, DFI increases household asset diversity through two main channels: improving financial literacy and alleviating liquidity constraints. Additionally, the heterogeneity analyses indicate that the promotive effect of DFI is stronger for households with younger heads, higher risk aversion, and greater income uncertainty or those located in rural areas. This research underscores the importance of digital financial inclusion in fostering a more diverse asset allocation landscape in China, with potential implications for other economies as well..",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b86eef499bc6deea9df6bb27cc04774c",
  "timestamp": "2025-05-15T02:25:40.111120"
}