{
  "id": 6516,
  "title": "Tail dependence and smoothness of time series",
  "abstract": "The risk of catastrophes is related to the possibility of occurring extreme values. Several statistical methodologies have been developed in order to evaluate the propensity of a process for the occurrence of high values and the permanence of these in time. The extremal index. (Leadbetter in Z Wahrscheinlichkeitstheor Verw Geb 65:291306, 1983) allows to infer the tendency for clustering of high values, but does not allow to evaluate the greater or less amount of oscillations in a cluster. The estimation of. entails the validation of local dependence conditions regulating the distance between high levels oscillations of the process, which is difficult to implement in practice. In this work, we propose a smoothness coefficient to evaluate the degree of smoothness/oscillation in the trajectory of a process, with an intuitive reading and simple estimation. Application in some examples will be provided. We will see that, in a stationary sequence, it coincides with the tail dependence coefficient. (Sibuya in Ann Inst Stat Math 11:195-210, 1960; Joe in Multivariate models and dependence concepts. Monographs on statistics and applied probability, vol 73. Chapman and Hall, London, 1997), providing a new interpretation of the latter. This relationship will inspire a new estimator for., and its performance will be evaluated based on a simulation study. We illustrate with an application to financial series.",
  "year": 2021,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "dc830be8a6237cb888dd19bb6d9a3c6b",
  "timestamp": "2025-05-15T02:59:07.399659"
}