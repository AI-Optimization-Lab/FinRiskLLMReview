{
  "id": 2789,
  "title": "Fuzzy Value-at-Risk Forecasts Using a Novel Data-Driven Neuro Volatility Predictive Model",
  "abstract": "Quantitative finance has been evolving over last aI decades and combining randomness and fuzziness of the parameters has found growing interest among researchers to solve forecasting problems. Superiority of the fuzzy forecasting method over the minimum mean square forecasting had been demonstrated for fuzzy coefficient (linear as well as nonlinear) time series models in Thavaneswaran et al. [5], However, many proposed fuzzy forecasting methods remain difficult to use in practice and there is a need for data-driven approach to fit the fuzzy coefficient volatility models. A neural network (NN) system can uniformly approximate any real nonlinear function on a compact domain to any degree of accuracy. Artificial NN (ANNs) have been applied to finance problems such as stock index prediction and bankruptcy prediction. In this paper, we introduce a novel direct data-driven neuro predictive model for conditional volatility and study the fuzzy value-at-risk (VaR) forecasts. We apply this model to forecast VaR with actual financial data. Our model shows considerable promise as a decision making and risk managing tool.",
  "year": 2019,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "2428b050a9aecea5736aec4a57313165",
  "timestamp": "2025-05-15T02:19:08.462240"
}