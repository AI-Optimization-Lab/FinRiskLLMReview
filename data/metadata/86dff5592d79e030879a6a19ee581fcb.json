{
  "id": 1288,
  "title": "Enhancing Student Retention with Machine Learning: A Data-Driven Approach to Predicting College Student Persistence",
  "abstract": "This study examined the application of machine learning (ML) models to predict college student persistence. Using a dataset of 8,776 student records spanning 7 years, 10 ML algorithms were evaluated, with a focus on Logistic Regression and Random Forest (RF). Results indicated that RF outperformed other models in accuracy and recall, particularly in identifying at-risk students. The use of the Synthetic Minority Oversampling Technique improved prediction for non-persistent students. Feature importance analysis revealed that cumulative resident terms, grade point average, financial factors, and engagement metrics were key predictors. Adjusting the prediction threshold further enhanced the identification of non-persistent students. Despite data limitations, the study provides actionable insights for improving student retention through data-driven strategies. Future research should refine feature selection, incorporate real-time data, and enhance predictive models to support institutional decision-making.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "86dff5592d79e030879a6a19ee581fcb",
  "timestamp": "2025-05-15T02:01:11.858764"
}