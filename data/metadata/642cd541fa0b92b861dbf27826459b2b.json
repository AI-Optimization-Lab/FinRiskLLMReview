{
  "id": 320,
  "title": "Option pricing under a normal mixture distribution derived from the Markov tree model",
  "abstract": "We examine a Markov tree (MT) model for option pricing in which the dynamics of the underlying asset are modeled by a non-IID process. We show that the discrete probability mass function of log returns generated by the tree is closely approximated by a continuous mixture of two normal distributions. Using this normal mixture distribution and risk-neutral pricing, we derive a closed-form expression for European call option prices. We also suggest a regression tree-based method for estimating three volatility parameters sigma, sigma(+), and sigma(-) required to apply the MT model. We apply the MT model to price call options on 89 non-dividend paying stocks from the S&P 500 index. For each stock symbol on a given day, we use the same parameters to price options across all strikes and expires. Comparing against the Black-Scholes model, we find that the MT model's prices are closer to market prices. (C) 2012 Elsevier B.V. All rights reserved.",
  "year": 2012,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "642cd541fa0b92b861dbf27826459b2b",
  "timestamp": "2025-05-15T01:30:46.337279"
}