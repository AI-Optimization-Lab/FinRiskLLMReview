{
  "id": 3168,
  "title": "Migration and its contribution to the size and value premiums: Australian evidence",
  "abstract": "This paper investigates how different types of migration contribute to the size and value premiums for Australian equities. We find that: (a) the majority of stocks that stay in the same portfolio during the next period contribute to both the size and value premiums, (b) small-cap neutral and small-cap growth stocks that move to a lower market-to-book type contribute moderately to the size premium, (c) value stocks that move to a higher market-to-book type contribute moderately to the value premium (d) small-cap stocks that grow to be big-cap stocks make minor contributions to the size premium and (e) value stocks that change size classification, make minor contributions to the value premium. Overall, small-cap value stocks that stay in the same group account for large portions of both the size and value premiums. (C) 2009 Elsevier B.V. All rights reserved.",
  "year": 2010,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1242af54581aedf26ba6cab3202c7554",
  "timestamp": "2025-05-15T01:14:16.231907"
}