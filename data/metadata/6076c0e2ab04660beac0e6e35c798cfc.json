{
  "id": 5454,
  "title": "Do Country Risks Matter for Tourism efficiency? Evidence from Mediterranean countries",
  "abstract": "This research fills the gap in the existing literature on tourism by examining the impacts of country stability (economic, financial and political) on tourism efficiency (cost and profit). To consider the potential nonlinear relationships among the variables, we employ a new method of moment quantile regression, analyzing panel data from 17 countries between 2000 and 2020. The findings of the study reveal that higher country stability generally leads to higher tourism efficiency. The results suggest that the influence of country risk ratings on tourism efficiency is mainly nonlinear across different tourism efficiency quantiles. Moreover, the various components of risk rating scores have differing effects on tourism efficiency. These insights emphasize the imperative for policymakers to devise nuanced strategies that harness the synergies between stability factors and tourism efficiency for sustainable economic growth. This implies that policymakers should take into account the cost and profit efficiency of their tourism industry when setting country stability strategies.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6076c0e2ab04660beac0e6e35c798cfc",
  "timestamp": "2025-05-15T02:47:43.081512"
}