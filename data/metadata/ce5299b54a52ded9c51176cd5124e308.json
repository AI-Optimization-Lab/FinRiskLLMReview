{
  "id": 6622,
  "title": "Predictors associated with time to default for HIV/AIDS patients under HAART at Debre Tabor Referral Hospital: a Cox regression model",
  "abstract": "The human immunodeficiency virus systematically undermines the immune system, which serves as our body's inherent safeguard against diseases. Currently, it is the most serious threat to public health. Ethiopia is among the countries with the highest prevalence of HIV/AIDS. Defaulting is still a public health issue that must be resolved in order to maximize HAART's benefits. Thus, this study was aimed to assess the proportion of HAART defaulters and to identify associated factors that lead to defaulting from HAART. Data from 230 study participants was analyzed using a Cox PH regression model. The study found that patients who did not adhere to at least 95% of their regimen had a higher risk of defaulting from HAART relative to those who did adhere to at least 95% [HR = 2.924, 95% CI: 2.113, 4.047]. To advance the longevity of HIV/AIDS-infected patients within HAART medication, an intervention should be taken from the concerned body for those patients who had been at high risk of defaulting during initial and some stages of treatment. Interventions might include: following home-based treatment options; mobile health technology; granting access road facilities; accessing fast diagnostic testing procedure; giving medical advice to disclose; giving receive financial support.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "ce5299b54a52ded9c51176cd5124e308",
  "timestamp": "2025-05-15T03:00:04.950768"
}