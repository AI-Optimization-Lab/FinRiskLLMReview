{
  "id": 3619,
  "title": "Correlates of screen-based behaviors among adults from the 2019 Brazilian National Health Survey",
  "abstract": "We aimed to investigate correlates of TV viewing and other types of screen-based behaviors in a nationally representative sample of Brazilian adults. In the 2019 Brazilian National Health Survey (including 88,509 adults), TV viewing time and other types of screen behaviors (computer, tablet, and cellphone use) were self-reported and different geographical, sociodemographic, behavioral, and health status factors were investigated as potential correlates. Multinomial logistic regression models were used for the main analyses. Living in capital cities, urban areas, being unemployed, high consumption of soft drinks, obesity, and elevated depressive symptoms were each associated with more TV viewing and more time using other types of screens. There were differential associations between TV viewing and the use of other types of screen across age and socioeconomic variables. For instance, younger adults have a more diverse portfolio of screen time than older adults. To conclude, levels of screen-based behaviors vary by geographical, sociodemographic, behavioral, and health status characteristics. Interventions should focus on high-risk population groups and may benefit from targeting specific sedentary behaviors of interest.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a3e84385e4385fbbda008d493a674d70",
  "timestamp": "2025-05-15T01:19:00.718426"
}