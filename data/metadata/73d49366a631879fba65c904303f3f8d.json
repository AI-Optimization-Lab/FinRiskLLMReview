{
  "id": 3877,
  "title": "The economic significance of trading based on the size effect in Australia",
  "abstract": "It is generally accepted within the extant literature that a size effect exists, whereby smaller firms tend to experience higher rates of return than those of large firms. This small size effect is identified in a number of studies over a variety of equity markets. Despite this, however, no study to date considers the dollar profits attainable by executing a trading strategy that constructs a portfolio based on stocks within the lowest market capitalization decile. Specifically, this paper seeks to identify the existence of a size effect in Australia, but, moreover, attempts to ascertain if a dollar profit can be obtained from executing a trading strategy based on small market capitalization stocks. In doing this, we consider all stocks listed on the Australian stock exchange, and use volume and bid-ask prices to account for liquidity and transactions costs, respectively. Overall, our regression analysis confirms the existence of a size effect within the Australian equity market. However, in executing a trading strategy based on stocks with low market capitalization, we find that after accounting for liquidity and transaction costs the profits obtainable are extremely small and statistically insignificant. This suggests that while the firm size effect exists, the illiquidity and relatively large transaction costs of small stocks eliminate the potential for economic profits.",
  "year": 2011,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "73d49366a631879fba65c904303f3f8d",
  "timestamp": "2025-05-15T01:21:41.407360"
}