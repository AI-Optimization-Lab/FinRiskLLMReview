{
  "id": 1079,
  "title": "A new gradient-based neural dynamic framework for solving constrained min-max optimization problems with an application in portfolio selection models",
  "abstract": "A neural network model based on a nonlinear dynamic model for solving a class of min-max problems, which is motivated as a non-differentiable optimization problem, is proposed. The main idea is to convert the non-differentiable problem into an equivalent differentiable convex optimization problem using a smoothing scheme called an entropy procedure. A neural network model is then constructed for solving the obtained convex problem. The stability of the equilibrium point and the convergence of the optimal solution are discussed. As an application in economics, we use the proposed scheme to a min-max portfolio optimization problem. Several clarifying examples and simulation results are provided to demonstrate the correctness of the results and the good performance of the presented model.",
  "year": 2019,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1c3e90239a7bc849e6b2789c4812005c",
  "timestamp": "2025-05-15T00:51:25.955501"
}