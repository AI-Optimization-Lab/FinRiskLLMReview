{
  "id": 286,
  "title": "A Novel Bitcoin and Gold Prices Prediction Method Using an LSTM-P Neural Network Model",
  "abstract": "As a result of the fast growth of financial technology and artificial intelligence around the world, quantitative algorithms are now being employed in many classic futures and stock trading, as well as hot digital currency trades, among other applications today. Using the historical price series of Bitcoin and gold from 9/11/2016 to 9/10/2021, we investigate an LSTM-P neural network model for predicting the values of Bitcoin and gold in this research. We first employ a noise reduction approach based on the wavelet transform to smooth the fluctuations of the price data, which has been shown to increase the accuracy of subsequent predictions. Second, we apply a wavelet transform to diminish the influence of high-frequency noise components on prices. Third, in the price prediction model, we develop an optimized LSTM prediction model (LSPM-P) and train it using historical price data for gold and Bitcoin to make accurate predictions. As a consequence of our model, we have a high degree of accuracy when projecting future pricing. In addition, our LSTM-P model outperforms both the conventional LSTM models and other time series forecasting models in terms of accuracy and precision.",
  "year": 2022,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d032d43d4c48a0ccbcdc66f789180497",
  "timestamp": "2025-05-15T01:30:19.150515"
}