{
  "id": 5431,
  "title": "FRAME SEMANTICS METHODOLOGY FOR TEACHING TERMINOLOGY OF SPECIALISED DOMAINS",
  "abstract": "The article attempts to show how the theory of Frame Semantics and the resources of the lexical database FrameNet can be used for teaching/learning terminology of specialised domains. The article discusses the principles of Frame Semantics and presents a use case of application of the frame-based methodology for developing classification of terminology of the selected financial subdomain for learning/teaching purposes. The use case focuses on terms denoting concepts that compose 'CAUSE-RISK' frame which was developed on the basis of several related frames in the FrameNet database. The stages of the use case and its outcomes are described in detail and the benefits of application of the methodology for learning/teaching specialised vocabulary are provided. Hopefully, the provided insights will give ideas to teachers of foreign languages for specific purposes and help to develop effective terminology teaching/learning techniques.",
  "year": 2021,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "aa592daf3479e238a4077d94f7103ab0",
  "timestamp": "2025-05-15T02:47:42.982888"
}