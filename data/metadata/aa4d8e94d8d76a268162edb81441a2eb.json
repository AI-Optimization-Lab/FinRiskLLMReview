{
  "id": 234,
  "title": "FLOOD RISK MAPPING USING RANDOM FOREST AND SUPPORT VECTOR MACHINE",
  "abstract": "Floods are among the natural disasters that cause financial and human losses all over the world every year. By production of a flood risk map and determination of potential flood risk areas, the possible damages of this phenomenon can be reduced. To map the flood extend in Calcasieu Parish, Louisiana, US, conditioning factors affecting the flood occurrence including elevation, slope, plan curvature, land use, distance from rivers, density of rivers, rainfall, normalized difference vegetation index (NDVI), modified normalized difference water index (MNDWI), and normalized difference built-up index ( NDBI) were identified and their information layers produced using the Google Earth Engine (GEE) cloud platform. Then, for flood risk mapping, Random Forest (RF) and support vector machine (SVM) as two machine learning models have been implemented and their results compared. RF and SVM models have been validated based on the maximum absolute error (MAE) index with an accuracy of 0.043 and 0.097, respectively. Visualization of the predicted values in QGIS software confirms that the RF model has provided better outputs than that of the SVM model. By analysing the features importance of the layers in the RF model, it was verified that the elevation, slope, and plan curvature layers have the highest degree of influence on the flood risk with degrees of importance of 0.197, 0.135, and 0.123.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "aa4d8e94d8d76a268162edb81441a2eb",
  "timestamp": "2025-05-15T01:48:30.733837"
}