{
  "id": 3557,
  "title": "Can Blended Finance Be a Game Changer in Sustainable Development? An Empirical Investigation of the Lucas Paradox",
  "abstract": "In recent years, the global development community has been emphasizing blended finance approaches for economic development without taking into consideration practical implications of the Lucas Paradox, or the observation that capital does not flow from rich to poor countries. To prevent misuse of official development funds as catalysts for private flows, it is crucial to consider the direction of blended finance approaches in light of the Lucas Paradox. To fill this important gap in the literature, this paper investigates determinants of capital flows in recipient countries where a blended finance strategy is applied in light of the Lucas Paradox, with a focus on foreign direct investment and portfolio equity investment. For the analysis, this paper utilizes a cross-sectional sample of 157 countries between 2002 and 2018, including ODA recipients and OECD DAC members, by conducting a regression analysis based on the ordinary least squares (OLS). Our findings suggest that the Lucas Paradox strongly exists in all recipient countries that can utilize ODA as a catalyst, which is the core of the blended finance strategy. Institutional quality, human capital and asymmetric information improvement appear to mitigate the Lucas Paradox, although the paradox does not disappear entirely. In addition, total ODA, institutional and human capital appear to be determinants of the paradox in the multiple regression model.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "e2ff1969cc6b616a9d104d3a6698b20d",
  "timestamp": "2025-05-15T01:18:20.545487"
}