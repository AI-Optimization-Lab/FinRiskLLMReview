{
  "id": 62,
  "title": "影子银行内生脆弱性、宏观审慎政策与系统性金融风险防范",
  "abstract": "随着影子银行规模的不断发展，影子银行业务促进了金融市场的竞争与融合，推动了金融创新，其在金融体系中的作用愈加重要。本文选取2013—2022年13家上市银行的影子银行面板数据，通过回归模型、系统GMM方法，分别检验了影子银行内生脆弱性与宏观审慎政策及其共同作用对系统性金融风险的影响。研究发现：影子银行内生脆弱性会导致系统性金融风险的增加，从而加剧了对金融安全的威胁。从宏观审慎政策工具和防范影子银行内生脆弱性的共同作用效果看，宏观审慎政策工具中的资本监管压力和贷款价值比能够与影子银行脆弱性指数形成互补，有效地降低系统性金融风险。研究结果揭示宏观审慎政策与影子银行内部控制是防范系统性金融风险、维护金融安全的主要途径。",
  "year": 2024,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "f4c0dd890708db490e19c9b6d4a970c2",
  "timestamp": "2025-05-14T22:26:31.844881"
}