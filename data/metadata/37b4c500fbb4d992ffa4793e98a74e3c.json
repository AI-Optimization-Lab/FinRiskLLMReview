{
  "id": 65,
  "title": "Option pricing using Machine Learning",
  "abstract": "This paper examines the option pricing performance of the most popular Machine Learning algorithms. The classic parametrical models suffer from several limitations in term of computational power required for parametric calibration and unrealistic economical and statistical assumptions. Therefore, a data driven approach based on non-parametric models is are well justified. Most of the previous researchers focus especially on the neural networks method (NN), the other algorithms being unexplored. Beside NN, this paper also analyses the performance of the Support Vector Regressions and Genetic Algorithms and propose three other Decision Tree methods, respectively Random Forest, XGBoost and LightGMB. In order to emphasize the power of this algorithms, a comparison with classical methods like Black-Scholes and Corrado-Su with both historical and implied parameters have been conducted. The analyzes were performed on European call options who have as underlying asset the WTI crude oil future contracts. Machine Learning algorithms outperform by a great margin the classical approaches regardless of the moneyness and the maturity of the contracts.",
  "year": 2021,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "37b4c500fbb4d992ffa4793e98a74e3c",
  "timestamp": "2025-05-15T01:28:03.873444"
}