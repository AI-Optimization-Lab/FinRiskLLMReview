{
  "id": 5473,
  "title": "Remittances and risk of major depressive episode and sadness among new legal immigrants to the United States",
  "abstract": "BACKGROUND The impact of remittances on health problems like depression among immigrants is understudied. Yet immigrants may be particularly emotionally vulnerable to the strains and benefits of providing remittances. OBJECTIVE This study examines the association between sending remittances and major depressive episode (MDE) and sadness among legal immigrants in the United States. METHODS Cross-sectional data (N=8,236 adults) come from the New Immigrant Survey (2003-2004), a representative sample of new U.S. permanent residents. RESULTS In logistic regression models, immigrants who remitted had a higher risk of MDE and sadness compared to those who did not, net of sociodemographic and health factors. For remitters (N=1,470), the amount of money was not significantly linked to MDE but was associated with a higher risk of sadness among refugees/asylees compared to employment migrants. CONCLUSIONS Among socioeconomically vulnerable migrants such as refugees/asylees, sending remittances may threaten mental health by creating financial hardship. Initiatives that encourage economic stability for migrants may protect against depression.",
  "year": 2016,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "db865e8b04c2b65829fe77e273ab246a",
  "timestamp": "2025-05-15T02:48:23.585815"
}