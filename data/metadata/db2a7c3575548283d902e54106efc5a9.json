{
  "id": 3781,
  "title": "Effects of the fat-tail distribution on the relationship between prospect theory value and expected return",
  "abstract": "This study investigates the negative relationship between prospect theory value and expected return considering the fat-tail property of the return distribution. The results of both decile portfolio and cross-sectional regression show evidence supporting the hypothesis related to prospect theory value. However, these results are very sensitive to whether the model includes a short-term reversal factor. In the empirical design combining the hypothesis with the degree of fat-tail of the return distribution, stock groups with the fat-tail return distribution definitely show that prospect theory value has a significant information value for explaining expected return, regardless of whether the short-term reversal and other factors are included in the models. These results suggest that both the fat-tail property in the stock return distribution and the property of the skewed return distribution must be considered in examining the relationship between prospect theory value and expected return. Furthermore, our findings on the effects of the fat-tail property of the return distribution are verified through robustness testing while considering changes in empirical design and using out-of-sample stock markets of the U.S., Japan, and China, as well as the in-sample Korean stock market.",
  "year": 2020,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "db2a7c3575548283d902e54106efc5a9",
  "timestamp": "2025-05-15T01:20:36.122144"
}