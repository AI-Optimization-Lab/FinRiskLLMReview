{
  "id": 463,
  "title": "ON PROPERTIES OF ANALYTICALLY SOLVABLE FAMILIES OF LOCAL VOLATILITY DIFFUSION MODELS",
  "abstract": "We present some further developments in the construction and classification of new solvable one-dimensional diffusion models having transition densities, and other quantities that are fundamental to derivatives pricing, representable in analytically closed form. Our approach is based on so-called diffusion canonical transformations that produce a large class of multiparameter nonlinear local volatility diffusion models that are mapped onto various simpler diffusions. Using an asymptotic analysis, we arrive at a rigorous boundary classification as well as a characterization with respect to probability conservation and the martingale property of the newly constructed diffusions. Specifically, we analyze and classify in detail four main families of driftless regular diffusion models that arise from the underlying squared Bessel process (the Bessel family), CoxIngersollRoss process (the confluent hypergeometric family), the Ornstein-Uhlenbeck diffusion (the OU family), and the Jacobi diffusion (the hypergeometric family). We show that the Bessel family is a superset of the constant elasticity of variance model without drift. The Bessel family, in turn, is nested by the confluent hypergeometric family. For these two families we find further subfamilies of conservative strict supermartingales and nonconservative martingales with an exit boundary. For the new classes of nonconservative regular diffusions we also derive analytically exact first exit time densities that are given in terms of generalized inverse Gaussians and extensions. As for the two other new models, we show that the OU family of processes are conservative strict martingales, whereas the Jacobi family are nonconservative nonmartingales. Considered as asset price diffusion models, we also show that these models demonstrate a wide range of local volatility shapes and option implied volatility surfaces that include various pronounced skew and smile patterns.",
  "year": 2012,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "e2d4194bb8c4c55e3cbca7c92fd22e7d",
  "timestamp": "2025-05-15T01:32:30.157551"
}