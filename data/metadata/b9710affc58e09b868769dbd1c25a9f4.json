{
  "id": 5027,
  "title": "Resiliency between Islamic and conventional banks in Bangladesh Dynamic GMM and quantile regression approaches",
  "abstract": "Purpose - The purpose of this paper is to examine the resiliency between conventional banks (CBs) and Islamic banks (IBs) in Bangladesh at the financial crisis, pre-crisis and post-crisis period. Design/methodology/approach - Data from 25 banks, 18 CBs and 7 IBs, operating in Bangladesh during the period 2005-2014 have been collected and divided into three stages: the pre-crisis period (2005-2006), the crisis period (2007-2008) and the post-crisis period (2009-2014). Dynamic generalized method of moments and quantile regression analysis have been used for this study. Findings - This paper uses Z-score as an indicator of bank stability and found a significant difference in stability between IBs and CBs during the financial crisis. In addition, this paper also tries to identify the type of banks that performed better during pre-crisis, crisis and post-crisis periods but found no significant differences between IBs and CBs in this regards. For robustness, quantile regression found that the statistical significance level of credit risk, capital adequacy ratio and efficiency ratio of CBs and IBs differ at different percentile. Originality/value - Most of the previous studies were conceptual or narrative and conducted on a global basis, not country-specific. To filling the country-level research gap, this study provides a meaningful insight about how these two types of banks performed in different periods.",
  "year": 2017,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b9710affc58e09b868769dbd1c25a9f4",
  "timestamp": "2025-05-15T02:43:40.121730"
}