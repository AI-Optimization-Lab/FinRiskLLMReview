{
  "id": 1582,
  "title": "Current status and future directions of high-throughput ADME screening in drug discovery",
  "abstract": "During the last decade high-throughput in vitro absorption, distribution, metabolism and excretion (HT-ADME) screening has become an essential part of any drug discovery effort of synthetic molecules. The conduct of HT-ADME screening has been industrialized due to the extensive development of software and automation tools in cell culture, assay incubation, sample analysis and data analysis. The HT-ADME assay portfolio continues to expand in emerging areas such as drug-transporter interactions, early soft spot identification, and ADME screening of peptide drug candidates. Additionally, thanks to the very large and high-quality HT-ADME data sets available in many biopharma companies, in silico prediction of ADME properties using machine learning has also gained much momentum in recent years. In this review, we discuss the current state-of-the-art practices in HT-ADME screening including assay portfolio, assay automation, sample analysis, data processing, and prediction model building. In addition, we also offer perspectives in future development of this exciting field. (c) 2020 Xi'an Jiaotong University. Production and hosting by Elsevier B.V. All rights reserved. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).",
  "year": 2020,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b7869eaf7b7ba171e8550f999f1ec3c9",
  "timestamp": "2025-05-15T00:57:12.722866"
}