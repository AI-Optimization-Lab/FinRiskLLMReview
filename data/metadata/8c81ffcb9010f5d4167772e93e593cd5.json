{
  "id": 75,
  "title": "Deep Reinforcement Learning for Quantitative Portfolio Management",
  "abstract": "Quantitative Portfolio Management (QPM) is a method of efficiently modeling financial data to improve portfolio returns. Modeling financial data in portfolio management tasks is challenging due to non-stationary price series and complex asset correlations, which make it difficult to learn effective feature representations. To address the above challenges, this paper proposes a QPM approach based on Deep Reinforcement Learning (DRL), and we design a Temporal Attention, Temporal Convolutional, and Graph-based Network (TTG), which includes temporal branch, correlation branch and decision-making module. Temporal branch uses temporal attention and Temporal Convolutional Network (TCN) to extract temporal features of asset price series. Correlation branch uses graph convolutional layer to extract correlations among multiple assets. Finally, we utilize softmax to determine the portfolio weights in decision-making module. Experiments on stock datasets demonstrate that the effectiveness of the proposed method in terms of profitability and representation abilities.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8c81ffcb9010f5d4167772e93e593cd5",
  "timestamp": "2025-05-15T00:38:57.038550"
}