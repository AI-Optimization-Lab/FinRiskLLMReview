{
  "id": 1262,
  "title": "The analysis of diversification properties of stablecoins through the Shannon entropy measure",
  "abstract": "The common goal for investors is to minimise the risk and maximise the returns on their investments. This is often achieved through diversification, where investors spread their investments across various assets. This study aims to use the MAD-entropy model to minimise the absolute deviation, maximise the mean return, and maximise the Shannon entropy of the portfolio. The MAD model is used because it is a linear programming model, allowing it to resolve large-scale problems and nonnormally distributed data. Entropy is added to the MAD model because it can better diversify the weight of assets in the portfolios. The analysed portfolios consist of cryptocurrencies, stablecoins, and selected world indices such as the SP500 and FTSE obtained from Yahoo Finance. The models found that stablecoins pegged to the US dollar, followed by stablecoins pegged to gold, are better diversifiers for traditional cryptocurrencies and stocks. These results are probably due to their low volatility compared to the other assets. Findings from this study may assist investors since the MAD-Entropy model outperforms the MAD model by providing more significant portfolio mean returns with minimal risk. Therefore, crypto investors can design a well-diversified portfolio using MAD entropy to reduce unsystematic risk. Further research integrating mad entropy with machine learning techniques may improve accuracy and risk management.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "422b8f33628b562e8c1b946af1652a30",
  "timestamp": "2025-05-15T00:53:42.113088"
}