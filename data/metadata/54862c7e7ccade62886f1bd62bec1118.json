{
  "id": 2677,
  "title": "Flipped Classrooms in Undergraduate Statistics: Online Works Just Fine",
  "abstract": "Background: The flipped classroom method requires that students engage with homework before coming to the classroom so that class time can be spent on active and collaborative learning exercises. Research has demonstrated that this can improve student performance versus traditional lecturer-led teaching methods. Objective: During the COVID-19 pandemic, the vast majority of teaching has been entirely online such that even 'in-class' time has been virtual. The current article examined whether online-only delivery affects the efficacy of the flipped classroom approach. Method: Grades for a research methods and statistics module and a statistics portfolio assignment were compared across consecutive cohorts of undergraduate psychology students taught by different methods. Results: Overall grades on the module did not differ significantly across teaching methods but student performance on statistics tests did. Flipped classrooms, whether accompanied by on-campus or synchronous online classes, led to significantly better performance than traditional methods. No detriment was observed by teaching entirely online. Conclusion: The key advantages of the flipped classroom method appear driven by active learning which can occur irrespective of classroom context. Teaching Implications: Using flipped classrooms can be a useful tool, particularly in subjects where students may otherwise be less engaged with the content.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "54862c7e7ccade62886f1bd62bec1118",
  "timestamp": "2025-05-15T01:09:14.953909"
}