{
  "id": 914,
  "title": "基于多分布GARCH族模型的沪深300指数VaR测度研究",
  "abstract": "运用经济物理学方法验证沪深300指数市场存在的一些特征,进而用四种GARCH模型在不同分布下进行VaR风险测度建模,并用返回测试中的似然比和动态分位数回归加以检验,结果表明:收益分布服从有偏学生t分布的VaR测度模型可靠性显著高于正态分布和学生t分布;在样本内,GARCH、GJR、HYGARCH模型均能有效度量VaR风险,HYGARCH在空头VaR水平较高时精度更高;在样本外,GARCH、GJR、FIGARCH、HYGARCH模型的VaR测度能力相差不大,但HYGARCH模型在空头VaR水平下测度能力更高些。因此,在有偏学生t分布下,能捕捉更多金融资产特征的HYGARCH模型对沪深300指数的VaR测度更精确可靠,这意味着在风险管理时,应更多考虑具有尾部效应的模型进行度量。",
  "year": 2016,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "54fb8afe0286478b63945f85fae5849c",
  "timestamp": "2025-05-14T22:34:27.093589"
}