{
  "id": 6166,
  "title": "Revisiting time series momentum in China's commodity futures market: Evidence on sources of momentum profits",
  "abstract": "Time series momentum (TSM) is a well-documented market anomaly existing in various financial markets, yet few studies clarify the TSM in China's commodity futures market from the lens of sources of momentum profits. Based on the Nanhua commodity index, this study exploits the pooled regression and empirically identifies TSM in Chinese commodity futures market, particularly for investment strategies with a 1-month look-back period. The most significant predictability of the following month's returns comes from the past month's returns. The TSM is a superior investment strategy in China's commodity futures market. It outperforms the time series history strategy that does not require predictability, the cross-sectional momentum, and buy-and-hold strategies in terms of cumulative and risk-adjusted excess returns. Notably, the mechanisms of shorting futures with negative past cumulative returns and effective market timing explain the preferable profits of TSM strategy.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "f307f1f202f068ed7ade41b33c0f1a34",
  "timestamp": "2025-05-15T02:55:44.436616"
}