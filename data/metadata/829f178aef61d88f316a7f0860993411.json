{
  "id": 4240,
  "title": "Does childhood adversity affect household portfolio decisions? Evidence from the Chinese Great Famine",
  "abstract": "We employ the 1959-1961 Chinese Great Famine as a quasi-natural experiment to examine the relationship between experiencing adversity in childhood and financial decisions in adulthood. Using data from the 2017 China Household Finance Survey and the intensity of excess deaths during the Great Famine, results from our preferred two-part fractional regression model suggest that, for an additional excess death per thousand people during the Famine, cohorts who were in their infancy and early childhood during the Famine are 0.2-0.3 percentage points less likely to hold risky financial assets than other cohorts. We also find that, conditional on the decision to hold risky assets, those who experienced an additional excess death per thousand people during the Famine in their middle to late childhood hold 1.1 percentage points higher share of risky assets in their household financial portfolios than those who did not experience the Famine. We explore several potential mechanisms and find that financial literacy, risk-taking preferences and locus of control are channels through which childhood adversity in the famine years affects household portfolio decisions. Our findings are robust to a series of sensitivity checks.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "829f178aef61d88f316a7f0860993411",
  "timestamp": "2025-05-15T02:34:48.920158"
}