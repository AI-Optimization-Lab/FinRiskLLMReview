{
  "id": 6233,
  "title": "Is CSR Expenditure Relevant to the Firms in India?",
  "abstract": "The present study examines the relevance of Corporate Social Responsibility (CSR) expenditure to the firms in the mandatory regime in India. The paper has its theoretical basis from the instrumental aspect of the Stakeholder theory, which assumes a positive influence of CSR over financial performance. Therefore, the study hypothesizes that the firms which fulfil the CSR expenditure requirement will exhibit higher stock returns and lower systematic risk. Since India mandated CSR in the year 2014, the data of four years (2016-2019) for the sample of 426 National Stock Exchange (NSE) listed Indian firms are taken to employ the OLS regression method. The CSR expenditure in the mandatory regime was not found to be relevant to the firms because of an insignificant positive impact of mandatory CSR expenditure on stock returns. Thus, the instrumental aspect is not supported by the findings. However, the findings indicate a decrease in the systematic risk of the firms. Only a few studies in India investigated this phenomenon in the mandatory regime. Further, the contributions of the study to the CSR literature are fairly useful from the perspective of firms, investors, policy-makers, regulators, scholars, and countries that are planning for legislating CSR.",
  "year": 2021,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "63b886d4391e6540464ccb417daacc7a",
  "timestamp": "2025-05-15T02:56:10.916508"
}