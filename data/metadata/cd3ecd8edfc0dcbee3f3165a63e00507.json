{
  "id": 630,
  "title": "Improving Earnings Predictions and Abnormal Returns with Machine Learning",
  "abstract": "SYNOPSIS: Using stepwise logit regression, Ou and Penman (1989) predicts the sign of future earnings changes and uses these predictions to form a profitable hedge portfolio. Increases in computing power and advances in machine learning allow us to extend Ou and Penman (1989) using more data, computer intensive forecasting algorithms, and modern prediction models. Stepwise logit still provides good predictions and can be used to form a trading strategy that generates small abnormal returns, but random forest significantly improves forecast accuracy and returns. The models identify different variables as being important for prediction in high tech and manufacturing, but this does not lead to better predictions or higher returns. Results confirm Ou and Penman's (1989) finding that financial statement information is useful for investment decisions, and suggest that machine learning techniques can be useful in a variety of accounting contexts.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "cd3ecd8edfc0dcbee3f3165a63e00507",
  "timestamp": "2025-05-15T00:45:39.185855"
}