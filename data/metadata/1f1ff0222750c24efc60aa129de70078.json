{
  "id": 1894,
  "title": "A Big Data Framework to Address Building Sum Insured Misestimation",
  "abstract": "In the insurance industry, the accumulation of complex problems and volume of data creates a large scope for actuaries to apply big data techniques to investigate and provide unique solutions for millions of policyholders. With much of the actuarial focus on traditional problems like price optimisation or improving claims management, there is an opportunity to tackle other known product inefficiencies with a data-driven approach. The purpose of this paper is to build a framework that exploits big data technologies to measure and explain Australian policyholder Sum Insured Misestimation (SIM). Big data clustering and dimension reduction techniques are leveraged to measure SIM for a national home insurance portfolio. We then design predictive and prescriptive models to explore the relationship between socioeconomic and demographic factors with SIM. Real-world results from a national home insurance portfolio provide actionable business insight on SIM and facilitate solutions for stakeholders, being government and insurers. & COPY; 2023 Elsevier Inc. All rights reserved.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1f1ff0222750c24efc60aa129de70078",
  "timestamp": "2025-05-15T01:01:06.057319"
}