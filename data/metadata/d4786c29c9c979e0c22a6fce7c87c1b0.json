{
  "id": 859,
  "title": "Obtaining Classification Rules Using LVQ plus PSO: An Application to Credit Risk",
  "abstract": "Credit risk management is a key element of financial corporations. One of the main problems that face credit risk officials is to approve or deny a credit petition. The usual decision making process consists in gathering personal and financial information about the borrower. This paper present a new method that is able to generate classifying rules that work no only on numerical attributes, but also on nominal attributes. This method, called LVQ+PSO, combines a competitive neural network with an optimization technique in order to find a reduced set of classifying rules. These rules constitute a predictive model for credit risk approval. Given the reduced quantity of rules, our method is very useful for credit officers aiming to make decisions about granting a credit. Our method was applied to two credit databases that were extensively analyzed by other competing classification methods. We obtain very satisfactory results. Future research lines are exposed.",
  "year": 2015,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d4786c29c9c979e0c22a6fce7c87c1b0",
  "timestamp": "2025-05-15T01:55:41.744771"
}