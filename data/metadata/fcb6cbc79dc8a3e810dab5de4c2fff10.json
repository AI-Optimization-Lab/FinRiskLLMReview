{
  "id": 1144,
  "title": "论国有银行金融风险的深层原因",
  "abstract": "本文从建立金融风险分析的视角基点，即三种行为主体（地方政府、国有企业、国有银行分支机构）“准经济人”的假设入手，运用博弈论思考方法，以考察人的行为为主线分析了地方政府经济诱导、政策派生，策应说服、强行于预的什锦僭越行为；国有企业以礼攻心、误导隐藏、以动制静、借助外权的僭越行为；国有银行分支机构粗放扩张、秩规替换、邀功饰忧、情感选择的僭越行为。进而从体制环境、人文思想等层面较深刻地揭示了国有银行金融风险之综合归因，即缺少明确的金融产权规范；行政性授权参与约束乏力；参与金融交易设权寻租；非理性渗入道德约束；不良行为“回归”风险。最后指出寻求制度上的分工合作还有较长的路要走。",
  "year": 1999,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "fcb6cbc79dc8a3e810dab5de4c2fff10",
  "timestamp": "2025-05-14T22:36:09.432503"
}