{
  "id": 458,
  "title": "Machine Learning on Imbalanced Data in Credit Risk",
  "abstract": "In Machine Learning, we often encounter instances of imbalanced data which occur whenever there is an unequal representation in the classification categories. New found interest in Machine Learning has made its usage ubiquitous. Its applications encompass a wide plethora of scenarios ranging from Business and Banking to Bioinformatics and Psychology. These problems are often characterized by imbalanced data, the presence of which often leads to inaccurate predictive models, since the distribution of testing data may differ from that of training data while learning, leading to misclassification of the response variable. The primary focus of the paper is on Credit Risk which is defined as the probability of defaulting on the loan or credit acquired from a banking or financial institution. The base risk is that of the loss of primary principal and interest, disruption of cash flows and increased collection costs. Loan Default is an uncommon phenomena, henceforth we obtain the imbalanced data. We've adopted the approach of Logistic Regression and Classification and Regression Trees (CART) with techniques such as undersampling, Prior Probabilities, Loss Matrix and Matrix Weighing to deal with imbalanced data.",
  "year": 2016,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d54db1cb3dc788d024da07bf1c3ed36d",
  "timestamp": "2025-05-15T01:50:52.705107"
}