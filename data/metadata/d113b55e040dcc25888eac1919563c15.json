{
  "id": 307,
  "title": "Systemic risk prediction using machine learning: Does network connectedness help prediction?",
  "abstract": "The global financial crisis not only highlights the important role of financial network connectedness, but also urges regulators pay more attention to systemic risk. We study whether network connectedness helps systemic risk prediction by using machine learning techniques, including k -nearest neighbor (KNN), support vector regression (SVR), extreme gradient boosting (XGB), and feedforward neural network (FNN). Based on prediction results, we use the fingerprint model to deliver interpretability evaluations of financial variables and network connectedness. We find that (1) the linear and nonlinear effects of stock market volatility and network connectedness effectively interpret systemic risk; (2) the interaction effects between stock market volatility and other drivers have a stronger ability to predict system risk in SVR, KNN, and XGB approaches, while network connectedness performs more profoundly in FNN approach; and (3) the interaction effect between stock market volatility and network connectedness is evident in all approaches.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d113b55e040dcc25888eac1919563c15",
  "timestamp": "2025-05-15T01:49:04.692201"
}