{
  "id": 3564,
  "title": "The Impact of Green Lending on Credit Risk in China",
  "abstract": "This study explores China's green credit policy from a credit risk perspective. Green finance has been growing rapidly in China since the government issued its Green Credit Policy. The objective of this study is to explore whether green loans are less risky than non-green loans. Based on a five-year dataset of 24 Chinese banks, we used panel regression techniques, including two-stage least square regression analysis and random-effect panel regression to examine whether a higher green credit ratio reduces a bank's non-performing loan ratio (NPL ratio). The results suggest that allocating more green loans to the total loan portfolio does reduce a bank's NPL ratio. We conclude that institutional pressure by the Chinese Green Credit Policy has a positive effect on both the environmental and the financial performance of banks. The study contributes to the literature on the correlation between green lending and credit risks, as well as to the literature on the impact of institutional pressure on environmental and financial risks.",
  "year": 2018,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "2375a9f74f34cb75137fb6da2675c48a",
  "timestamp": "2025-05-15T02:27:53.935363"
}