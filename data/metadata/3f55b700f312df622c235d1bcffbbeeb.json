{
  "id": 4711,
  "title": "Fiscal mechanism in public administration of social risks",
  "abstract": "Through a critical document-based methodology, the research analyses the essence of social risks as the object of public administration, proposes their classification, tests the need for interconnection of social and fiscal policies, bases the structure of the financial and budgetary mechanism for public management of social risks and, consequently, proposes to improve it by increasing investment in human capital to prevent social risks. It is concluded that the orientation of the social protection system to countervailing measures in relation to certain groups of the population seeks to solve the problem of poverty by strengthening tax distributional processes, increasing the amount of social spending on total state spending, but if it fails to increase the effectiveness of social programmers, the main social problems will not be solved. It is established that the main direction of improvement of the public social risk management tax mechanism should be the minimization of the compensatory nature of the financial provision of the consequences of social risks and, the activation of the application of investment tools for the prevention of their occurrence.",
  "year": 2021,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "3f55b700f312df622c235d1bcffbbeeb",
  "timestamp": "2025-05-15T02:39:57.631416"
}