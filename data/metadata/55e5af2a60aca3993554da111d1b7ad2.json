{
  "id": 3784,
  "title": "A study of early multilingualism in Iran: The effects of mother tongue literacy, socio-economic status and foreground TV exposure",
  "abstract": "This study investigated interactions among linguistics, social and political factors in a linguistically rich environment. For this purpose, two-hundred Iranian preschoolers (aged 5 to 6 years old) from four ethnic/linguistic groups (Arab, Kurd, Turk and Fars) were selected using multi-stage stratified sampling. All participants took part in an Elementary English language course and their exposure to foreground TV was recorded using media exposure portfolio. Maternal education and family income were considered as criteria for socio-economic status. Children's language proficiency was measured through Language Sample Analysis (LSA). The LSA components included total number of utterances produced, total number of words produced, total number of new words produced and mean length of utterances. Regression analysis, ANOVA and t-tests were used for data analyses. The results showed that bilingual children performed slightly better than multilingual children in LSA measures but this cannot be taken for granted. Moreover, socio-economic status and LSA measures were significantly related but TV exposure was not associated with the LSA measures. These results supported the arguments purported by minority language proponents on the importance of using children's mother tongue in educational curriculum.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "55e5af2a60aca3993554da111d1b7ad2",
  "timestamp": "2025-05-15T01:20:36.129865"
}