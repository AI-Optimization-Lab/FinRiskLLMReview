{
  "id": 4323,
  "title": "A novel approach to flood risk zonation: integrating deep learning models with APG in the Aji Chay catchment",
  "abstract": "Each year, floods, as one of the natural calamities, lead to significant destruction in various regions globally. Consequently, precise flood prediction becomes crucial in mitigating human and financial losses and effectively managing water resources. To achieve this, Convolutional Neural Network and Long Short-Term Memory (LSTM) models were utilized in this study to map flood hazards in the Aji Chay watershed. Flood data points were collected from the study area and subsequently divided into two groups using the Absence Point Generation technique. The first group, comprising 70% of the data, served as the training dataset for model construction, while the remaining 30% formed the testing dataset for validation. Seven key factors influencing floods, namely, precipitation, land use, Normalized Difference Vegetation Index, drainage density, flow direction, topographic wetness index, and terrain ruggedness index, were identified through Leave-One-Feature-Out approach and employed in the modeling process. The LSTM model with a Kolmogorov-Smirnov (KS) statistic value of 88.14 was chosen as the best model based on the KS plot. The results revealed that approximately 37% of the study area fell into high and very high flood risk classes. These research findings can be valuable in the effective management of flood-prone areas and the reduction of flood damages.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "61c4f1a3ca796b18f807fc563b85cc5f",
  "timestamp": "2025-05-15T02:36:05.157180"
}