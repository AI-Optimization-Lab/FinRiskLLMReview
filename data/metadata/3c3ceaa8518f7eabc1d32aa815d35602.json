{
  "id": 5285,
  "title": "Accounting Comparability, Audit Effort, and Audit Outcomes",
  "abstract": "Accounting comparability among peer firms in the same industry reflects the similarity and the relatedness of firms' operating environments and financial reporting. From the perspectives of inherent audit risk and external information efficiency, comparability is helpful for auditors in assessing client audit risk and lowers the costs of information acquisition, processing, and testing. I posit that the availability of information about comparable clients helps improve audit efficiency and accuracy. Empirical results show that comparability is negatively related to audit effort (surrogated by audit fees and audit delay). Moreover, comparability is negatively associated with the likelihood of audit opinion errors. These findings are robust to different specifications of regression models, particularly for the endogeneity issues due to the possible reverse causality that auditor style might influence client firms' comparability. In sum, the study shows that accounting comparability enhances the utility of accounting information for external audits.",
  "year": 2018,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "3c3ceaa8518f7eabc1d32aa815d35602",
  "timestamp": "2025-05-15T02:46:16.223704"
}