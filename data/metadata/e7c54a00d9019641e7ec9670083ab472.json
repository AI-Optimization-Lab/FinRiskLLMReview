{
  "id": 2398,
  "title": "CDS Spreads and Contagion Amongst Systemically Important Financial Institutions - A Spatial Econometric Approach",
  "abstract": "This study applies a novel way of measuring, quantifying and modelling the contagion risk amongst financial institutions. The magnitude of risk spill over effects is gauged by introducing a specific weighting scheme to the regression. This approach originally stems from spatial econometrics. The methodology allows for a decomposition of the credit spread into a contagion risk premium, a systematic risk premium and an idiosyncratic risk premium. We identify considerable risk spill overs due to the interconnectedness of the financial institutes in the sample. In stress tests, up to one-fifth of the CDS spread changes are owing to financial contagion. These results also give an alternative explanation for the nonlinear relationship between a debtor's theoretical probability of default and the observed credit spreads - known as the credit spread puzzle'. Copyright (c) 2015 John Wiley & Sons, Ltd.",
  "year": 2015,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "e7c54a00d9019641e7ec9670083ab472",
  "timestamp": "2025-05-15T02:14:50.332365"
}