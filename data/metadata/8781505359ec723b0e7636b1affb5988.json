{
  "id": 3755,
  "title": "Value or Growth Strategy? Empirical Evidence in Brazil",
  "abstract": "This article aimed at verifying the existence of value versus growth and at identifying the variables that best explain their impact on Brazilian stock profits. To this end, we tested book-to-market, price-earnings and price-to-cash flow variables. Two methodological approaches were employed: portfolio analysis, in which portfolios were formed according to each variable of interest; and regression analysis with panel data, based on individual assets. The sample was made up of companies with shares traded in BM&FBovespa during the 1995-2008 period. According to results found, growth stocks presented higher profits than value stocks. Thus, we may conclude that the well-documented value versus growth is not valid in Brazil, since empirical evidence supported growth strategies. Due to the long research period, results may signal prevalence of growth strategy in the long term. Furthermore, the high volatility of emerging countries' capital markets was emphasized, as pointed out by Fama and French (1998). Moreover, to establish investment strategies that allow for greater profits, it was found that the variable that best identifies growth stocks is the book-to-market ratio.",
  "year": 2013,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8781505359ec723b0e7636b1affb5988",
  "timestamp": "2025-05-15T01:20:35.990732"
}