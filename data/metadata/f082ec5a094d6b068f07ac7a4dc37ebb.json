{
  "id": 7930,
  "title": "The link between physician motivation and care",
  "abstract": "Studies report an unexplained variation in physicians' care. This variation may to some extent be explained by differences in their work motivation. However, empirical evidence on the link between physician motivation and care is scarce. We estimate the associations between different types of work motivation and care. Motivation is measured using validated questions from a nation-wide survey of Danish general practices and linked to high-quality register data on their care in 2019. Using a series of regression models, we find that more financially motivated practices generate more fee-for-services per patient, whereas practices characterised by greater altruistic motivation towards the patient serve a larger share of high-need patients and issue more prescriptions for antibiotics per patient. Practices with higher altruism towards society generate lower medication costs per patient and prescribe a higher rate of narrow-spectrum penicillin, thereby reducing the risk of antimicrobial resistance in the population. Together, our results suggest that practices' motivation is associated with several dimensions of healthcare, and that both their financial motivation and altruism towards patients and society play a role. Policymakers should, therefore, consider targeting all provider motivations when introducing organisational changes and incentive schemes; for example, by paying physicians to adhere to clinical guidelines, while at the same time clearly communicating the guidelines' value from both a patient and societal perspective.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "f082ec5a094d6b068f07ac7a4dc37ebb",
  "timestamp": "2025-05-15T03:13:30.664104"
}