{
  "id": 340,
  "title": "The Effectiveness of Supervised Learning Models in Detection of Pump and Dump Activity in Dogecoin",
  "abstract": "B Investment into hazardous assets should always be made with caution, if not avoided completely by risk-averse groups, such as the older workforce. However, as society and technology advance, it becomes almost impossible for regulators to make effective enough laws to mitigate the risk of newly invented financial instruments, such as cryptocurrency. This paper analyzed how effective are modern data science techniques: supervised learning models, such as random forest, K Nearest Neighbors, decision tree, combined with bagging and stacking techniques, could be used to catch the notorious pump and dump activities in the Dogecoin market, which is the cryptocurrency that had a close to positive infinity return in May 2021 during the COVID-19 pandemic. This paper concluded that random forest algorithm, when trained with a five-folded cross-validation technique, could reach an out-of-sample testing accuracy of 100%. Furthermore, the F1 score of 0.84101, precision score of 0.94402, and recall score of 0.77700 could alleviate one's concern about overfitting. In conclusion, the model results suggest modern supervised learning techniques are quite effective in catching suspicious activities in modern financial instruments.",
  "year": 2021,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "fd394811799a8f5b8792f8a30341a171",
  "timestamp": "2025-05-15T01:49:41.054265"
}