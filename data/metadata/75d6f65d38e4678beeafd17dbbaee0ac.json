{
  "id": 306,
  "title": "Learning to Arbitrage Congestion in Electricity Market with Virtual Bids",
  "abstract": "In this paper, we introduce a machine learning-based risk- constrained portfolio optimization framework to arbitrage congestion with virtual bids in wholesale electricity markets. The proposed trading strategy aims to maximize the profit from the perspective of a proprietary trading company. A deep neural network is designed to estimate the difference between congestion spreads in day-ahead (DA) and real-time (RT) markets. A clustering algorithm is adopted to separate pricing nodes into a few groups, between which the congestion spreads can be exploited. We validate the proposed algorithmic trading strategy using publicly available data from California Independent System Operator (CAlSO). The empirical results indicate that our proposed algorithm attains significant profit with modest portfolio budget and low risk tolerance level.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "75d6f65d38e4678beeafd17dbbaee0ac",
  "timestamp": "2025-05-15T00:42:00.409946"
}