{
  "id": 933,
  "title": "A Combined Algorithm Approach for Optimizing Portfolio Performance in Automated Trading: A Study of SET50 Stocks",
  "abstract": "This study investigates portfolio optimization for SET50 stocks using Deep Reinforcement Learning (DRL) algorithms to address market volatility. Five DRL algorithms-Advantage Actor-Critic (A2C), Proximal Policy Optimization (PPO), Deep Deterministic Policy Gradient (DDPG), Soft Actor-Critic (SAC), and Twin Delayed DDPG (TD3)-were evaluated for their effectiveness in managing risk and optimizing returns. We propose an Iterative Model Combining Algorithm (IMCA) that dynamically adjusts model weights based on market conditions to enhance performance. Our results demonstrate that IMCA consistently outperformed traditional strategies, including the Minimum Variance model. IMCA achieved a cumulative return of 14.20% and a Sharpe Ratio of 0.220, compared to the Minimum Variance model's return of -4.35% and Sharpe Ratio of 0.018. This research highlights the adaptability and robustness of DRL algorithms for portfolio management, particularly in emerging markets like Thailand. It underscores the advantages of dynamic, data-driven strategies over static approaches.",
  "year": 2025,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b7ee7d46e0c074e80133d1258d335651",
  "timestamp": "2025-05-15T00:49:36.404910"
}