{
  "id": 355,
  "title": "An Adaptive Neuro-Fuzzy System for Stock Portfolio Analysis",
  "abstract": "We propose an adaptive neuro-fuzzy inference system (ANFIS) for stock portfolio return prediction. Previous work has shown that portfolio optimization can be improved by using predicted stock earnings rather than historical earnings. We show that predicted portfolio returns can be improved by using ANFIS and taking as input a variety of technical and fundamental attributes about various indices of the stock market. To generate membership functions, we use a robust noise rejection-clustering algorithm. The neuro-fuzzy model is tested on portfolios constituted from the Tehran Stock Exchange. In our experiments, the proposed method performs better in predicting the portfolio return than the classical Markowitz portfolio optimization method, a multiple regression, a neural network, and the Sugeno-Yasukawa method. (C) 2010 Wiley Periodicals, Inc.",
  "year": 2011,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "ec7c1ea2f33303d51dbf2119e2aa81e5",
  "timestamp": "2025-05-15T00:42:32.478010"
}