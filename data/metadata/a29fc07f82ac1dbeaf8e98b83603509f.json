{
  "id": 5608,
  "title": "The first shall be last. Size and value strategy premia at the London Stock Exchange",
  "abstract": "The paper analyses the determinants of cross-sectional stock returns at the London Stock Exchange in the last 26 years. It finds that portfolio strategies based on low values of earning per share (EPS), market to book value (MTBV), market Value (MV) and return on equity (ROE) significantly outperform the index. Do size and value (S&V) strategy premia disappear when risk-adjusted or do they reveal gains from trading against noise, near rational, liquidity or weak-hearted traders? We find that the significance of cross-sectional determinants of these strategies is not absorbed by ex post betas. They are not riskier in terms of monthly return standard deviations, covariation with GDP growth and their premia do not disappear when survivorship bias is taken into account. Portfolio mean monthly returns (MMRs), regressed on several risk factors in 3-CAPM models, confirm that S&V strategy premia persist when risk adjusted. Empirical results also mark the difference between ROE and MTBV portfolios, on the one side, and MV and EPS portfolios, on the other. Descriptive statistics on preformation and postformation returns, average balance sheet values and preformation standard deviations clearly show that ROE and MTBV portfolios have a common financial distress factor and are then more exposed to systematic risk. (C) 2000 Elsevier Science B.V. All rights reserved. JEL classification. G11.",
  "year": 2000,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a29fc07f82ac1dbeaf8e98b83603509f",
  "timestamp": "2025-05-15T02:49:21.777104"
}