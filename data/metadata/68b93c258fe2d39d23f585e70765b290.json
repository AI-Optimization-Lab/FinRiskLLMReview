{
  "id": 2181,
  "title": "What is the minimal systemic risk in financial exposure networks?",
  "abstract": "We quantify how much systemic risk can be eliminated in financial contract networks by rearranging their network topology. By using mixed integer linear programming, financial linkages are optimally organized, whereas the overall economic conditions of banks, such as capital buffers, total interbank assets and liabilities, and average risk-weighted exposure remain unchanged. We apply the new optimization procedure to 10 snapshots of the Austrian interbank market where we focus on the largest 70 banks covering 71% of the market volume. The optimization reduces systemic risk (measured in DebtRank) by about 70%, showing the huge potential that changing the network structure has on the mitigation of financial contagion. Existing capital levels would need to be scaled up by a factor of 3.3 to obtain similar levels of DebtRank. These findings underline the importance of macroprudential rules that focus on the structure of financial networks. The new optimization procedure allows us to benchmark actual networks to networks with minimal systemic risk. We find that simple topological measures, like link density, degree assortativity, or clustering coefficient, fail to explain the large differences in systemic risk between actual and optimal networks. We find that if the most systemically relevant banks are tightly connected, overall systemic risk is higher than if they are unconnected. (C) 2020 The Author(s). Published by Elsevier B.V.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "68b93c258fe2d39d23f585e70765b290",
  "timestamp": "2025-05-15T02:12:17.384971"
}