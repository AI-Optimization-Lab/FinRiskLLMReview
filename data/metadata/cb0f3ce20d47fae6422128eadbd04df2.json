{
  "id": 1832,
  "title": "Dimension Estimation using Second Order data in Finance",
  "abstract": "Estimating intrinsic dimension of financial markets informs the number of assets in portfolio selection models and can help archetypal Mean-Variance (MV) single portfolio optimization model pioneered by Markowitz, especially when intrinsic dimension is introduced as a cardinality constraint in the model. The balance between portfolio concentration risk and portfolio diversification benefit is a quintessential active portfolio management problem. Portfolio variance-covariance matrix, a second order dataset derived from first order portfolio constituents return time series, is an essential tool to quantify risk in a portfolio. Our goal in this paper is to estimate financial markets non-linear intrinsic dimension using second order inputs such as distances (dissimilarity) between asset returns. Second-order data is widely used in financial applications such as portfolio optimization, hierarchical clustering, and risk metrics. We demonstrate the effectiveness of our techniques on synthetic data, benchmark image problems, and, most importantly, financial markets.",
  "year": 2021,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "cb0f3ce20d47fae6422128eadbd04df2",
  "timestamp": "2025-05-15T02:08:03.934589"
}