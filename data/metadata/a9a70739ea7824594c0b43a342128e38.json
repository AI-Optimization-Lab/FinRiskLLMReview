{
  "id": 1551,
  "title": "Graduate Admission Chance Prediction Using Deep Neural Network",
  "abstract": "Every year many students apply for graduate admission to different universities. To select an applicant, each university has different selection criteria such as GRE score, CGPA, research background, statement of purpose, letter of recommendation, university rating etc. There are some web applications as well as some consultancy services for suggesting the appropriate university based on students' portfolio. These help to give an idea which universities should be applied for admission. But they have limitations because humans are incapable of considering all the conditions and universities. Moreover, web applications have accuracy problems. In this study, we have proposed a deep neural network (DNN) to predict the chance of getting admitted to a university according to the students portfolio. All the selection criteria are considered here to predict the chance of admission. The DNN model has been compared with existing methods in terms of different performance metrics including mean squared error (MSE), root mean squared error (RMSE), mean absolute error (MAE), R-squared score. It has shown the most promising result that includes R-squared score of 0.8538 and MSE of 0.0031. The proposed method has also outperformed all the existing methods in each benchmark.",
  "year": 2020,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a9a70739ea7824594c0b43a342128e38",
  "timestamp": "2025-05-15T00:57:12.614456"
}