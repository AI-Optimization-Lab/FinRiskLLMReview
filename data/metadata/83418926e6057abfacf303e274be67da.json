{
  "id": 390,
  "title": "Modeling and Forecasting the Volatility of NIFTY 50 Using GARCH and RNN Models",
  "abstract": "The stock market is constantly shifting and full of unknowns. In India in 2000, technological advancements led to significant growth in the Indian stock market, introducing online share trading via the internet and computers. Hence, it has become essential to manage risk in the Indian stock market, and volatility plays a critical part in assessing the risks of different stock market elements such as portfolio risk management, derivative pricing, and hedging techniques. As a result, several scholars have lately been interested in forecasting stock market volatility. This study analyzed India VIX (NIFTY 50 volatility index) to identify the behavior of the Indian stock market in terms of volatility and then evaluated the forecasting ability of GARCH- and RNN-based LSTM models using India VIX out of sample data. The results indicated that the NIFTY 50 index's volatility is asymmetric, and leverage effects are evident in the results of the EGARCH (1, 1) model. Asymmetric GARCH models such as EGARCH (1, 1) and TARCH (1, 1) showed slightly better forecasting accuracy than symmetric GARCH models like GARCH (1, 1). The results also showed that overall GARCH models are slightly better than RNN-based LSTM models in forecasting the volatility of the NIFTY 50 index. Both types of models (GARCH models and RNN based LSTM models) fared equally well in predicting the direction of the NIFTY 50 index volatility. In contrast, GARCH models outperformed the LSTM model in predicting the value of volatility.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "83418926e6057abfacf303e274be67da",
  "timestamp": "2025-05-15T00:35:17.574841"
}