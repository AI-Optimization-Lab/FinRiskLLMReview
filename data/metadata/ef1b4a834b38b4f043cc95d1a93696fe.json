{
  "id": 318,
  "title": "Intelligent Asset Allocation Portfolio Division and Recommendation: Based on Deep Learning and Knowledge Graphs",
  "abstract": "With the continuous development of financial markets, intelligent asset allocation has become a topic of great concern in the investment field. However, traditional asset allocation methods often face difficulties in grasping the relationship between diversity, risk and return, which limits its application in complex market environments. To solve this problem, this study introduces deep learning and knowledge graphs and proposes an intelligent asset allocation model. Our model makes full use of the advantages of the Knowledge Graph Embedding Model (KGE), LSTM, and Genetic Algorithm (GA) to build a multi-level and multi-dimensional asset allocation model. KGE helps capture the complex relationships between different assets, LSTM is used to learn key patterns of historical portfolio performance, and GA finds the optimal asset allocation combination by simulating natural selection and genetic mechanisms. Experimental findings indicate that our model has demonstrated substantial improvements across various performance metrics and outperforms conventional approaches.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "ef1b4a834b38b4f043cc95d1a93696fe",
  "timestamp": "2025-05-15T01:36:59.728772"
}