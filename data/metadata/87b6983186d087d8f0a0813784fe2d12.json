{
  "id": 2643,
  "title": "An Empirical Analysis of Japanese Interest Rate Swap Spread",
  "abstract": "This paper investigates the three risk factors for interest rate swap spreads in the Japanese market: volatility of interest rate, liquidity risk, and default risk of counterparty. These factors have been regarded as main determinants by most previous researches. We compare relative importance of the risk factors among the three different regimes classified by economic conditions in Japan: Lost Decade of Japan, zero-interest rate period and global financial crisis period. We employ a standard constant-coefficient regression model with the GARCH error terms, and extend it to a time-varying coefficient regression model which allows the coefficients possibly change along with time. Our empirical results indicate that the investors' sensitivities to each factor do not stay fixed over the whole sample period, but change along with the day by day market conditions. The risk factors exhibit different properties among the different regimes. The findings of this paper shed some new insights into the interest rate swap market in Japan, and reconfirm results of previous analytical researches on the financial turmoil of Japan in the last twenty years.",
  "year": 2012,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "87b6983186d087d8f0a0813784fe2d12",
  "timestamp": "2025-05-15T02:17:32.236322"
}