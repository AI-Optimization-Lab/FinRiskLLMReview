{
  "id": 1549,
  "title": "Max-one selection of equity prediction models for portfolio construction",
  "abstract": "In many applications that involve prediction of a large number of variables, such as energy consumption or portfolio construction, it is common to employ a single model for predicting multiple target variables at once. Under this monolithic approach, the model is necessarily optimized on average across targets, and not for any one target in particular. Thus, the resulting predictions are likely to be underwhelming for a significant subset of targets. At the other end of the spectrum, optimizing and maintaining a separate prediction model for each of hundreds or thousands of targets, is unrealistic. This work proposes a novel model selection approach, termed max-one, that sits between these two extremes. Our methodology takes advantage of the standard hyperparameter tuning process used with most machine learning models and assigns to each target its own optimal model-hyperparameter combination, based on the criterion of one's choice. In the context of portfolio optimization, which we use as a concrete example, the resulting family of models generates stock predictions which can then be used to construct a portfolio. Applying our suggested framework to an extensive 35-year data set with thousands of United States' stocks, leads to an impressive 7x capital increase after transaction costs. This surpasses the performance of the single model approach and that of major global stock indices and compares favorably with recent relevant works, without sacrificing computational efficiency. Although our domain-specific application involves equities, our proposed approach could be used in settings where a model is tuned to predict multiple target variables.",
  "year": 2025,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a81e6932570bd7cc2bd3cfa09afaa5d1",
  "timestamp": "2025-05-15T00:57:12.610387"
}