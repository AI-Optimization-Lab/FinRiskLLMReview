{
  "id": 3851,
  "title": "Magnitude and persistence of extreme risk spillovers in the global energy market: A high-dimensional left-tail interdependence perspective",
  "abstract": "This paper studies the magnitude and persistence of extreme risk spillovers among stock returns of 124 energy companies worldwide between January 2006 and June 2019, as well as the corresponding firm-specific determinants of firms' extreme risk spillovers. The high-dimensional nonparametric method, the coefficient of tail interdependence (CTI), enables us to make better use of available information and to evaluate risk spillovers more precisely. Moreover, we use spatial panel models that consider spatial heterogeneity among firms to explore the determinants of the risk spillovers. The empirical findings from a study of energy firms' risk spillover effects verify the necessity of persistence measurement. Also, the most systemically risky energy companies do not necessarily have the largest firm sizes, while some relatively small firms can also generate high risk spillovers, which indicates that determinants other than firm size could also affect the spillover effect, such as business complexity and geographic location. Our regression results suggest that the extreme risk spillover of the energy companies is quite different in terms of business and region, which deserves more attention with respect to energy risk management. The estimates can be used for making portfolio decisions and designing regulatory policies. Keywords: (C) 2020 Elsevier B.V. All rights reserved.",
  "year": 2020,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "10e0a6bbb12866fcf868b1b53d72d882",
  "timestamp": "2025-05-15T01:21:41.297931"
}