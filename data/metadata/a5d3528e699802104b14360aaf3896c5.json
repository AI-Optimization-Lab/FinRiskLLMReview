{
  "id": 3131,
  "title": "A structural biology view of target drugability",
  "abstract": "Background: With long and costly drug development times there is a need in the pharmaceutical industry to prioritize targets early in the drug discovery process. One of the possible criteria is 'protein drugability', a term with multiple understandings in the literature. Among others, it is the likelihood of finding a selective, low-molecular weight molecule that binds with high affinity to the target. Objective: Which methods are available for drugability prediction? What can be achieved by such predictions and how can they influence the target prioritization process? Methods: The main focus is on sequence- and structure-related computational methods for drugability prediction, giving an overview on their background as well as their bias and limitations with an emphasis on the structural biology point of view. Results/conclusion: Structural drugability assessment presents one criterion for prioritization of a target portfolio by enabling classification of targets into low, average, or high drugability.",
  "year": 2008,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a5d3528e699802104b14360aaf3896c5",
  "timestamp": "2025-05-15T01:13:45.285936"
}