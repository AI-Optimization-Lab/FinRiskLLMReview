{
  "id": 123,
  "title": "商业银行研究现状及热点——基于CiteSpace的文献计量分析",
  "abstract": "通过CiteSpace可视化软件对中国知网数据库中收录的2010—2022年发表在核心期刊和CSSCI中关于商业银行的9344篇文献从发文量、核心作者、关键词聚类等方面进行分析。结果发现，国内相关文献数量在2014年之后总体呈下滑趋势，核心作者共109位。研究发展经历了2010—2015年、2016—2019年、2020—2022年三个阶段，研究重点集中在数字金融、金融科技、绿色信贷、货币政策及系统性金融风险等几个方面。国内未来研究重点可聚焦在商业银行对乡村振兴的支持、绿色金融发展、金融服务实体经济等领域。应用CiteSpace进行商业银行文献计量，初步直观地展示其研究仍是金融领域的热门，为商业银行后续研究提供可参考的选题思路。",
  "year": 2023,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "9a7be8d416ba2b2cbbaa353a44d87129",
  "timestamp": "2025-05-14T22:26:58.967382"
}