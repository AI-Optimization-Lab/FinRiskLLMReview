{
  "id": 2036,
  "title": "AdaBoost based bankruptcy forecasting of Korean construction companies",
  "abstract": "A lot of bankruptcy forecasting model has been studied. Most of them uses corporate finance data and is intended for general companies. It may not appropriate for forecasting bankruptcy of construction companies which has big liquidity. It has a different capital structure, and the model to judge the financial risk of general companies can be difficult to apply the construction companies. The existing studies such as traditional Z-score and bankruptcy prediction using machine learning focus on the companies of nonspecific industries. The characteristics of companies are not considered at all. In this paper, we showed that AdaBoost (adaptive boosting) is an appropriate model to judge the financial risk of Korean construction companies. We classified construction companies into three groups - large, middle, and small based on the capital of a company. We analyzed the predictive ability of the AdaBoost and other algorithms for each group of companies. The experimental results showed that the AdaBoost has more predictive power than others, especially for the large group of companies that has the capital more than 50 billion won. (C) 2014 Elsevier B.V. All rights reserved.",
  "year": 2014,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5bef44c6420982ba0e611e28d59534df",
  "timestamp": "2025-05-15T02:10:25.755527"
}