{
  "id": 3378,
  "title": "Comparing energy and comfort metrics for building benchmarking",
  "abstract": "Benchmarking energy use is increasingly mandated and tied to consequences such as fines for underperforming buildings. Yet, standard benchmarking methods and metrics may not adequately align with policymakers' or building owners' goals. We demonstrate how benchmarking metrics are non-interchangeable and how they can lead to substantially different building rankings. We analyze the performance of 29 case study buildings using different methods and metrics, divided into three categories: simple energy benchmarking, regression, and comfort. We find that Energy Use Intensity (EUI) serves as a poor proxy for harder-to-measure but more meaningful metrics. For example, factoring in the number of occupants (EUI per person rather than EUI) changes a building's ranking in our group by 24%. We demonstrate how a custom regression analysis and the Observed-to-modeled ratio can be useful for large-portfolio building owners, and how this differs from available benchmarking tools like Energy Star. We benchmark a subset of buildings via reported and monitored comfort factors and, importantly, propose the metrics Overheating/cooling Degree Days. These metrics measure discomfort relative to a building's operation mode and highlight cases of energy waste. The Overheating Degree Days metric highlighted operational problems in one case study building. (C) 2019 Elsevier B.V. All rights reserved.",
  "year": 2019,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b0016408d67f427df941e75e15844d09",
  "timestamp": "2025-05-15T01:16:22.211637"
}