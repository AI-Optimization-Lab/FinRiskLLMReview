{
  "id": 6376,
  "title": "CAPM in Real World: Risk-Friendly Investments",
  "abstract": "The aim of this paper is to show how the existence of equilibrium in CAPM may be obtained when individuals/investors are risk friendly. This assumption is closer to the real world, since risk aversion is rare and the portfolios implying a greater payoff are the ones which increase the variance of the payoff itself. Specifically, we assume that the wage vectors of the individuals/investors do not lie in the market space, which is the usual assumption for CAPM, namely, the payoff of any portfolio is replicated by the wage of the individuals/investors. The interpretation of such an assumption is that the wealth of the individuals/investors may not invest in financial markets as a whole. The second main result is that the perception of risk by the objective probabilities for the states of the world does not affect the equilibrium existence. This is a consequence of the No-Arbitrage assumption. This condition may be stated in terms of the existence of the objective probabilities for the states of the world. Since CAPM is usually considered as a way to compare the return of the so-called market portfolio and the return of any other portfolio, in the final section of this paper, we do provide the regression form of this altered form of CAPM.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "257191ce7221052fd03b36b19465d8e5",
  "timestamp": "2025-05-15T02:57:38.718685"
}