{
  "id": 5047,
  "title": "Volatility spillovers across NFTs news attention and financial markets",
  "abstract": "The aim of this study is to investigate the volatility spillover connectedness between NFTs attention and financial markets. This paper firstly proposes a new direct proxy for the public's attention in the NFT market: the non-fungible tokens attention index (NFTsAI), based on 590m news stories from the LexisNexis News & Business database and applies the historical decomposition to assess the historical variations of the NFTsAI. Then the empirical analysis is performed via a TVP-VAR volatility spillover connectedness model. The empirical results show that NFTsAI indicates NFT markets are dominated by cryptocurrency, DeFi, equity, bond, commodity, F.X. and gold markets. And NFT markets are volatility spillover receivers. In addition, NFT assets could impede financial contagion and have significant diversification benefits. Employing a panel pooled OLS regression model as a supplementary analysis and a GARCH-MIDAS model as a robustness test. This study reveals that NFTsAI has sufficient power to explain the return of NFT assets from a fixed effect perspective, and NFTsAI contains useful forecasting information for both short and long-term volatility of NFT markets, separately. The new NFTsAI and the empirical findings contain useful insights for risk-averse investors, portfolio managers, institutional investors, academics and financial policy regulators.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b169bc431b5c166232da6d9b6df6a990",
  "timestamp": "2025-05-15T02:43:40.232761"
}