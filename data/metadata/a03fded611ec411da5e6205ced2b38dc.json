{
  "id": 5248,
  "title": "Family economic hardship and adolescent mental health during the COVID-19 pandemic",
  "abstract": "ObjectiveThis study examined whether pandemic related family economic hardships influenced adolescents' mental health during the COVID-19 pandemic in Korea. MethodsData were collected from 54,948 adolescents who participated in the 2020 Korea Youth Risk Behavior Web-Based Survey. We performed a multiple logistic regression analysis to examine the association between family economic hardship and mental health (anxiety, depressive symptoms, and suicidal ideation). ResultsAmong the adolescents, 39.7, 24.7, and 5.9% reported slight, moderate, and severe economic hardship, respectively. COVID-19 related family economic hardship was significantly associated with higher odds of adolescents reporting anxiety, depressive symptoms, and suicidal ideation. This association was stronger among adolescents with low to middle family economic status. ConclusionsThis study suggests that adolescents from more economically vulnerable families are likely to be at a higher risk for long-term mental health effects due to the financial consequences of the COVID-19 pandemic.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a03fded611ec411da5e6205ced2b38dc",
  "timestamp": "2025-05-15T02:45:47.455439"
}