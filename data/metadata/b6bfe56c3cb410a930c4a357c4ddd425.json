{
  "id": 2577,
  "title": "QUASI-LIKELIHOOD ESTIMATION OF BENCHMARK RATES FOR EXCESS OF LOSS REINSURANCE PROGRAMS",
  "abstract": "In this paper a method for determining benchmark rates for the excess of loss reinsurance of a Motor Third Party Liability insurance portfolio will be developed based on observed market rates. The benchmark rates are expressed as a percentage of the expected premium income that is available to cover the whole risk of the portfolio. The rates are assumed to be based on a compound process with a heavy tailed severity, such as Burr or Pareto distributions. In the absence of claim data these assumptions propagate the theoretical benchmark rate component of the regression model. Given the whole set of excess of loss reinsurance rates in a given market, the unknown parameters are estimated within the framework of quasi-likelihood estimation. This framework makes it possible to select a theoretical benchmark rate model and to choose a parsimonious submodel for describing the observed market rates over a 4-years observation period. This method is applied to the Belgian Motor Third Party Liability excess of loss rates observed during the years 2001 till 2004.",
  "year": 2009,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b6bfe56c3cb410a930c4a357c4ddd425",
  "timestamp": "2025-05-15T01:08:10.926708"
}