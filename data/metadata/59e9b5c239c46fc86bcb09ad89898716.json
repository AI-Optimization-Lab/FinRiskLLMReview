{
  "id": 7150,
  "title": "Sustainable competitive advantage and stock performance: the case for wide moat stocks",
  "abstract": "In business, I look for economic castles protected by unbreachable Moats'. Warren Buffett Companies that have sustainable competitive advantages should be able to create a barrier (Moat) to prevent or lessen competition from other firms. The wider the Moat the greater the barrier and the more secure the company's profitability. Using the Morningstar classification of Wide Moat' stocks, we construct annually rebalanced equal- and value-weighted portfolios to analyse their performance in order to determine if they deliver superior performance relative to standard benchmark portfolios. The period for our analysis extends from June 2002 through May 2014. We find that the Wide Moat' portfolios outperform both the S&P 500 and Russell 3000 indices generating higher average monthly and annualized returns, Sharpe Ratio, Sortino Ratio, Treynor Ratio, Omega Ratio, Upside Potential Ratio, M-2, M-2 Alpha, and cumulative returns. When we compute alpha using Carhart four-factor and Fama-French five-factor models, we find that Wide Moat' portfolios had significantly positive risk-adjusted alphas with both the models. Wide Moat' portfolios also lost less value during the 2007-2009 financial crisis compared to both S&P 500 and Russell 3000. In conclusion, we find that Wide Moat' stocks have created significant value for their investors over the course of our study.",
  "year": 2016,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "59e9b5c239c46fc86bcb09ad89898716",
  "timestamp": "2025-05-15T03:05:32.087173"
}