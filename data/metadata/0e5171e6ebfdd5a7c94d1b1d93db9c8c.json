{
  "id": 6322,
  "title": "Relevance of the Gaussian classification on the Detection of DDoS Attacks",
  "abstract": "Distributed denial of service (DDoS) attacks have undergone a worrying evolution in recent years. The simplicity of the concept of these attacks, their effectiveness, and the multitude of sources of motivation make this type of attack one of the most used in the world. These attacks generate significant financial losses through service interruption or indirectly, through the damage to the target's image. Because of this shift, many organizations are ill-equipped to handle this current type of attack. Although common out-of-the-box technologies can detect a breach, they are unable to mitigate this new level of risk. In order to keep pace with DDoS hackers, a more humane and proactive approach is also needed. The aim of this study is to show the efficiency conditions of the Gaussian distribution and to propose an approach that shows the relevance of the Gaussian model in a binary classification. The results show that the best performances are obtained when the rate of the small class is between 0.02% and 0.05% compared to the whole data.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "0e5171e6ebfdd5a7c94d1b1d93db9c8c",
  "timestamp": "2025-05-15T02:57:07.668733"
}