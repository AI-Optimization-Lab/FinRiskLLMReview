{
  "id": 3515,
  "title": "Shaping graph pattern mining for financial risk",
  "abstract": "In recent years graph pattern mining took a prominent role in knowledge discovery in many scientific fields. From Web advertising to biology and finance, graph data is ubiquitous making pattern-based graph tools increasingly important. When it comes to financial settings, data is very complex and although many successful approaches have been proposed often they neglect the intertwined economic risk factors, which seriously affects the goodness of predictions. In this paper, we posit that financial risk analysis can be leveraged if structure can be taken into account by discovering financial motifs. We look at this problem from a graph-based perspective in two ways, by considering the structure in the inputs, the graphs themselves, and by taking into account the graph embedded structure of the data. In the first, we use gBoost combined with a substructure mining algorithm. In the second, we take a subspace learning graph embedded approach. In our experiments two datasets are used: a qualitative bankruptcy data benchmark and a real-world French database of corporate companies. Furthermore, we propose a graph construction algorithm to extract graph structure from feature vector data. Finally, we empirically show that in both graph-based approaches the financial motifs are crucial for the classification, thereby enhancing the prediction results. (C) 2017 Elsevier B.V. All rights reserved.",
  "year": 2019,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "407ca69f2e49cda1b5d2c18104b2309f",
  "timestamp": "2025-05-15T02:27:19.057717"
}