{
  "id": 2026,
  "title": "Improving Credit Risk Prediction in Online Peer-to-Peer (P2P) Lending Using Feature selection with Deep learning",
  "abstract": "At the early of 211 century, In the UK Peer2Peer (P2P) lending began with Zopa at the start of 2005. After that, it has grown rapidly in United States, China and some other countries. The main challenge for individual investors in the P2P lending market is to allocate their money efficiently through different loans by accurately evaluating the credit of each loan. The traditional ranking models cannot conform to the needs of individual investors in P2P lending because they do not provide natural mechanisms for asset allocation. P2P loans do not have the presence of traditional financial institutions. In this study, we propose a novel method for analyzing data for this emerging market. We have designed a credit risk model based on advanced machine learning methods, capable of assessing the returns and risks of individual loans. We also applied a selection feature method to eliminate the irrelevant features for improving the efficient of machine learning models. We conducted experiments on real-world data sets from P2P lending markets. The experimental results show that the proposed model can improve the efficiency of investment compared to the existing methods of P2P lending.",
  "year": 2019,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "bef9a2e456d6b6f4fe4532118fc1cd3e",
  "timestamp": "2025-05-15T02:10:25.686481"
}