{
  "id": 287,
  "title": "A Simple Model of Correlated Defaults with Application to Repo Portfolios",
  "abstract": "Credit risk exposure of a cash provider in a repo transaction is limited to 'double default events' when the counterparty and the issuer of the underlying collateral asset both default in a short period of time. This article presents a new and intuitive model for modeling correlated defaults, which are the key drivers of residual credit risk in repo portfolios. In the model, default times of counterparties and collateral issuers are determined by idiosyncratic and systematic factors, whereby a name defaults if it is struck by either factor for the first time. The novelty of the approach lies in representing systematic factors as increasing sequences of random variables. Such a setting allows us to precisely capture the clustering of defaults in time and build a rich dependence structure that is free of the flaws inherent in the Gaussian copula-based approaches still widely used for portfolio credit risk applications. Thanks to its general formulation, the model can be applied not only to repos, but also more broadly to pricing and risk-managing any default-correlation-sensitive instruments, e.g., credit default swaps, default swaptions, and CDOs.",
  "year": 2015,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "23c0dcae47c15ebad372b0c5b715b42d",
  "timestamp": "2025-05-15T01:30:19.154724"
}