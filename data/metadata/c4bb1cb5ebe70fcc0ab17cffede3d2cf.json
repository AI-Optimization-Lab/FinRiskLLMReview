{
  "id": 5289,
  "title": "Be nice to the air: Severe haze pollution and mutual fund risk",
  "abstract": "Motivated by the significant impacts of environmental risks on economic decisions and the increasing roles of mutual funds in financial markets in recent decades, this study examines the impact of ambient pollution on mutual funds' risk outcomes. Our fund fixed-effect regression estimates use manually collected propriety data from several datasets, showing that polluted air increases tracking errors and mutual fund return volatility. Adopting different identification strategies, including instrumental variable estimations and difference-in-difference analyses based on two natural experiments, suggests that the impact of air pollution on mutual funds' risk is causal. Our findings suggest that air pollution harms fund managers' cognitive abilities and impairs their investment efficiency, thereby increasing mutual funds' tracking errors and return volatility. Overall, our findings provide insights into the impact of climate change on social behavior by shedding new light on the impact of air quality on asset managers' behavior.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c4bb1cb5ebe70fcc0ab17cffede3d2cf",
  "timestamp": "2025-05-15T02:46:16.233747"
}