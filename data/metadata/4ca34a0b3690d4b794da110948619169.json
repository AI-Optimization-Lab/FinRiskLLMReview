{
  "id": 818,
  "title": "2017—2018年中国宏观经济再展望",
  "abstract": "\"中国季度宏观经济模型(CQMM)\"课题组于2017年10月27日发布了中国季度宏观经济模型第二十三次预测。预测显示,今明两年中国经济仍处在增速\"稳中趋缓\"的区间里,通货膨胀水平将会有所提升,但仍处于温和可控范围内。预计2017年GDP增速为6.80%,CPI上涨1.72%;2018年GDP增长率将回落至6.65%,CPI涨幅将提高至2.84%。课题组模拟了在地方政府(及国有企业)\"预算软约束\"和\"预算硬约束\"两种不同情境下逐步收紧货币供应量的数量型\"去杠杆\"政策可能产生的宏观经济效应。模拟结果显示,在国有企业存在\"预算软约束\"的情况下,降低M2增速会导致模拟期末国有企业的杠杆率较实际基准值提高,进一步还会导致社会总体投资效率下降,从而对经济增长产生较强的负面影响;相反,在国有企业存在\"预算硬约束\"的情况下,降低M2增速对全社会固定资产投资增速下降和GDP增速下降的影响均相继减弱。因此,课题组建议:必须转变以保增长为中心的发展思路;尽快建立现代财税制度以及对地方政府(国企)\"预算硬约束\"的制度安排;逐步收回超发的货币;合理控制货币总供应量,充分利用金融手段降低非金融国有企业的负债率;加大对影子银行的监管力度,回归金融优化经济资源配置的职能。",
  "year": 2017,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "4ca34a0b3690d4b794da110948619169",
  "timestamp": "2025-05-14T22:33:36.265262"
}