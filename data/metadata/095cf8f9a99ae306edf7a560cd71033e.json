{
  "id": 1125,
  "title": "Deep Neighbor Embedding for Evaluation of Large Portfolios of Variable Annuities",
  "abstract": "Variable annuities are very profitable financial products that pose unique challenges in risk prediction. Metamodeling techniques are popular due to the significant saving in computation time. However, the current metamodeling techniques still have a low valuation accuracy. One key difficulty is the selection of a small number of contracts that optimally represent the whole portfolio. In this paper, we propose a novel and highly effective method for selecting representative contracts. At the center of this method is a deep neighbor embedding that supports robust clustering of the contracts in a portfolio. The embedding is a low-dimensional representation that respects similarities among contracts in both contract-specific features and their historical performance, achieved through abstract representation in a deep neural network. Empirical results show that the proposed model achieves significant improvement in valuation accuracy, often 10 times or more accurate compared with the popular Kriging-based model.",
  "year": 2019,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "095cf8f9a99ae306edf7a560cd71033e",
  "timestamp": "2025-05-15T01:59:21.591851"
}