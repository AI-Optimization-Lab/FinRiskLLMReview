{
  "id": 3064,
  "title": "Study on Information Fusion Based Check Recognition System",
  "abstract": "Automatic check recognition techniques play an important role in financial systems, especially in risk management. This paper presents a novel check recognition system based on multi-cue information fusion theory. For Chinese bank check, the amount can be independently determined by legal amount, Courtesy amount, or E13B code. The check recognition algorithm consists of four steps: preprocessing, check layout analysis, segmentation and recognition, and information fusion. For layout analysis, an adaptive template matching algorithm is presented to locate the target recognition regions on the check. The hidden markov model is used to segment and recognize legal amount. Courtesy and E13B code are recognized by artificial neural network method, respectively. Finally, D-S evidence theory is then introduced to fuse above three recognition results for better recognition performance. Experimental results demonstrate that the system can robustly recognize checks and the information fusion based algorithm improves the recognition rate by 5 similar to 10 percent.",
  "year": 2009,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "f61cfccd3e09436afb7d46078a486905",
  "timestamp": "2025-05-15T02:22:25.051064"
}