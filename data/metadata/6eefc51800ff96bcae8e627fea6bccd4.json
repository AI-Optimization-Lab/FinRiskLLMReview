{
  "id": 7966,
  "title": "The effect of resource loss on depression and peritraumatic distress during the early period of the COVID-19: considering the pandemic-situational and social context",
  "abstract": "BackgroundThe public experienced loss of resources, including their health and property during the COVID-19 pandemic. The Conservation of Resources (COR) theory is a useful tool to explain the effect of resource loss on mental health. This paper examines the effect of resource loss on depression and peritraumatic distress considering the situational and social context of the COVID-19 pandemic applying COR theory.MethodsAn online survey was conducted for Gyeonggi residents when the second wave of COVID-19 in South Korea declined (5 October to 13 October 2020); 2,548 subjects were included in the hierarchical linear regression analysis.ResultsCOVID-19 infection-related experiences, resource losses (e.g., financial burden, deterioration of health, and decline of self-esteem), and fear of stigma were related to elevated levels of peritraumatic distress and depression. Risk perception was associated with peritraumatic distress. Reduced income or job loss were related to depression. Social support was a protective factor for mental health.ConclusionsThis study suggests that we need to focus on COVID-19 infection-related experiences and loss of daily resources in order to understand mental health deterioration during the COVID-19 pandemic. Moreover, it is important to monitor the mental health of medically and socially vulnerable groups and those who have lost resources due to the pandemic and to provide them with social support services.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6eefc51800ff96bcae8e627fea6bccd4",
  "timestamp": "2025-05-15T03:14:07.144885"
}