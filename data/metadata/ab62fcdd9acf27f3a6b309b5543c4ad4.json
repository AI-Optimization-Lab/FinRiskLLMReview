{
  "id": 3384,
  "title": "SPED - Public Digital Bookkeeping System: influence in the economic-financial results declared by companies",
  "abstract": "By deploying the Public Digital Bookkeeping System (SPED), tax administration seeks to increase the subjective perception of risk between taxpayers and reduce the tax gap. The objective of this research is to verify whether the implementation of Accounting SPED had an influence on the economic and financial results declared by companies (gross revenue and net profit). The null hypothesis of the research - the lack of relationship between these variables - was tested through the regression model with panel data. The sample was selected from the 500 largest companies listed in the database Best and Biggest, by Exame Melhores e Maiores magazine. The data collected comprise financial statements of these companies on the calendar years 2004 to 2009. Regression models were estimated using random effects, with unbalanced panels. The Accounting SPED showed significance in all regression models of gross revenue and net profit, allowing the rejection of the null hypothesis of no relationship between these variables. Finally, according to the analysis models of tax evasion exposed in the literature review, considering that the Accounting SPED increases the effectiveness and efficiency of auditing mechanisms of the tax administration, an increase on the economic and financial results declared by companies of the sample was expected, which was confirmed in research.",
  "year": 2013,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "ab62fcdd9acf27f3a6b309b5543c4ad4",
  "timestamp": "2025-05-15T02:25:40.162969"
}