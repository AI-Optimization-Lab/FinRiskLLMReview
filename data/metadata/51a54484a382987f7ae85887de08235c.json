{
  "id": 2662,
  "title": "Generating trading rules on US Stock Market using strongly typed genetic programming",
  "abstract": "Extracting rules from stock market data is an important and exciting problem, where investment decisions should be as clear and intuitive as possible in order for investors to choose the composition of their portfolios. Thus, it is important to guarantee that this process is done with a good framework and reliable techniques. In this context, portfolio composition is a puzzle with respect to selecting the appropriate assets and the optimal timing to invest. There are several models and algorithms to make these decisions, and in recent years, machine learning applications have been used to solve this puzzle with exceptional results. This technique allows a large amount of data to be processed, resulting in more informed recommendations on which asset to choose. Our study uses strongly typed genetic programming to generate rules to buy, hold and sell stocks in the US stock market, considering a rolling windows approach. We propose a different training approach, focusing the fitness function on a ternary decision based on the return prediction of each stock analyzed. The ternary rule matches perfectly with the three decisions: buy, hold and sell. Therefore, the rules are simple, intuitive, and easy for investors to understand. The results show that the proposed algorithm generates higher profits than the classical optimization approach. Moreover, the profits obtained are higher than the buy-and-hold strategy and the return of the indexes representative of the US stock market.",
  "year": 2020,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "51a54484a382987f7ae85887de08235c",
  "timestamp": "2025-05-15T01:09:14.918910"
}