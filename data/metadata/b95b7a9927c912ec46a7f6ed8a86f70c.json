{
  "id": 212,
  "title": "Connectedness and portfolio hedging between NFTs segments, American stocks and cryptocurrencies Nexus",
  "abstract": "The paper examines the dynamic spillover and hedging effectiveness between five main segments of NFTs, which are Collectibles, Art, Game, Metaverse, and Utility, and the other asset classes namely Bitcoin and the American Stocks (S&P500). The study sample covers the period from April 27, 2018 to September 15, 2022. Using a Time Varying connectedness approach through the TVP-VAR model and inspired by the Diebold and Yilmaz spillover index, the results show weak dynamic return spillovers between NFTs and the other assets, indicating that these new digital assets are still relatively decoupled from traditional asset and Bitcoin. We find also that Bitcoin is a major transmitter of spillover whereas Collectibles, Utility and S&P500 are net recipients of spillovers. Using the DCC-GARCH model, we extract the optimal weights, hedge ratios, and hedging effectiveness for the pairwise portfolios composed of S&P500/NFTs and Bitcoin/NFTs. The results indicate that investors and portfolio managers should consider adding NFTs in their portfolios of either S&P500 or Bitcoin to achieve diversification benefits. Finally, for Robustness Checks, we forecast the performance of the hedged versus the unhedged portfolios using the Long Short-Term Memory (LSTM) networks. Our findings confirm almost the results of the hedging effectiveness of NFTs and stem for the superiority of metaverse among these assets to serve as a perfect hedge.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b95b7a9927c912ec46a7f6ed8a86f70c",
  "timestamp": "2025-05-15T00:33:39.431813"
}