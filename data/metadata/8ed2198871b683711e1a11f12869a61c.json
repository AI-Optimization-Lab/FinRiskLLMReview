{
  "id": 3083,
  "title": "Rule-based credit risk assessment model using multi-objective evolutionary algorithms",
  "abstract": "Credit risk assessment is considered as one of the vital topics in financial institutions. The existing credit risk evaluation methods are based on black box models or transparent models. The black box models cannot adequately reveal information hidden in the data and the credit risk evaluation remains difficult. In addition, there exist relatively few transparent models that take into consideration interpretability and comprehensibility. To address this problem, we aim to build a reliable credit risk evaluation model which generates a set of classification rules. In fact, we consider the credit risk evaluation as a search-based optimization problem where the goal is to minimize the complexity of the generated solution, to maximize the accuracy, and also to maximize weight which represents rules importance. We conducted a comparative study of four multi-objective evolutionary algorithms in terms of their performance. The obtained results confirm the efficiency of the SMOPSO Algorithm regarding generating classification rules for credit risk assessment. The proposed credit risk evaluation model revealed an attractive trade-off between accuracy and comprehensibility. (C) 2019 Elsevier Ltd. All rights reserved.",
  "year": 2019,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8ed2198871b683711e1a11f12869a61c",
  "timestamp": "2025-05-15T02:22:25.099788"
}