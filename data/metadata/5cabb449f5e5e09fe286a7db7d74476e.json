{
  "id": 1755,
  "title": "An optimistic value iteration for mean-variance optimization in discounted Markov decision processes",
  "abstract": "This paper proposes an optimistic value iteration for steady -state mean-variance optimization in infinite-horizon discounted Markov decision processes (MDPs). The involved variance metric concerns reward variability in the long run, and future deviations are discounted to their present values. This mean-variance optimality criterion is time-inconsistent since its reward function depends on the mean, which renders traditional dynamic programming methods inapplicable. A family of policy/value iteration algorithms can be developed under a bilevel optimization algorithm framework, but there are still several problems to solve for a reinforcement learning (RL) extension. One problem is that in the value iteration, the inner optimization should achieve a near -optimal solution to ensure convergence before the outer update, which is required in every outer iteration. However, in an RL scenario, it is impractical to determine when the inner optimization should be stopped. To deal with this problem, we propose an optimistic value iteration, where the outer updates can be merged into the inner optimization with a learning rate. We prove the algorithm convergence and conduct a numerical experiment on portfolio management to validate the proposed algorithm.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5cabb449f5e5e09fe286a7db7d74476e",
  "timestamp": "2025-05-15T00:59:22.929505"
}