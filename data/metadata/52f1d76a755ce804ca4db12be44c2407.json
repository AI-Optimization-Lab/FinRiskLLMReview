{
  "id": 736,
  "title": "A new corporate credit scoring system using semi-supervised discriminant analysis",
  "abstract": "Corporate credit scoring is important for investors and banks in risk management. However, the high dimensional data available from public financial statements make credit analysis difficult. To address the problem, dimensionality reduction is a key step to enhance scoring accuracy. By using semi-supervised discriminant analysis (SSDA) and support vector machines (SVMs), this study develops a novel system for credit scoring, where SSDA transforms high dimensional data space (over 50 financial variables) to a perfect low dimensional representative subspace with maximal discriminating power. Constructing SVM classifier in the new space effectively reduces overfitting and enhances classification accuracy. Empirical results indicate that SSDA is better than traditional dimensionality reduction schemes, and it significant improves SVM performance. More importantly, the new classification system substantially outperforms conventional classifiers. The new decision support system can help corporate bond investors make good assessments on their risks and substantially reduce their losses.",
  "year": 2011,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "52f1d76a755ce804ca4db12be44c2407",
  "timestamp": "2025-05-15T01:54:34.042041"
}