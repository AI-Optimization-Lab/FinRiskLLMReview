{
  "id": 3872,
  "title": "Exposure from cooking with biofuels: pollution monitoring and analysis for rural Tamil Nadu, India",
  "abstract": "In this paper, statistical analysis to examine the links between pollution and the types of kitchen and fuels is carried out for rural houses by first monitoring the indoor air quality (IAQ) followed by regression analysis of 418 households in Tamil Nadu, India. Exposures to the chief cook (females, who are mainly involved in the cooking during monitoring) are measured with personal monitors. The result shows that the values of respirable particles (PM10) ranged from 500-2000 mug/m(3) during a two-hour cooking period from burning biofuels. The range depends on the type of kitchen and fuel use. Stationary monitors, placed two metres away from the stove, also recorded similar concentrations. Thus, the individuals who stay inside the houses using biofuels also face high concentrations even if they are not cooking. They could be senior citizens, children or adult males. Thus, there are two major findings from this analysis. Improved house designs that pay attention to kitchen location and put up partitions should also be considered in the intervention portfolio. Secondly, the exposure is not limited to the cooks alone. The rest of the family in the vicinity is also exposed through a passive cooking effect. (C) 2001 Elsevier Science Ltd. All rights reserved.",
  "year": 2001,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "e3ee6e569ae02ffc60b4a7ff86ed4dd4",
  "timestamp": "2025-05-15T01:21:41.381360"
}