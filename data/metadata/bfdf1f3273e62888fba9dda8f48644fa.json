{
  "id": 1246,
  "title": "A Six Sigma approach to predicting corporate defaults",
  "abstract": "The progression of a corporation from a status of financial stability into the status of financial distress usually happens over relatively large periods of time, raising the opportunity of identifying these 'falling' corporations ahead of time. Consequently, a critical risk management objective is to provide investment portfolio managers with an early notice of deteriorating financial status for a corporation. We consider a model built using equity inferred Probability of Default (PD) metrics. We follow a Design for Six Sigma Define, Measure, Analyze, Design, Verify (DMADV) approach to enhance the predictability power of the PD by constructing a two-dimensional risk space for estimating likelihood of default. We use such techniques as classification and regression tree (CART) analysis and logistic regression, and build a control plan using censored data analysis. We test our model on two actual portfolios. The potential savings revealed by these tests are significant, re-assuring us of the performance of our methodology. Copyright (c) 2005 John Wiley T Sons, Ltd.",
  "year": 2005,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "bfdf1f3273e62888fba9dda8f48644fa",
  "timestamp": "2025-05-15T02:00:30.594195"
}