{
  "id": 201,
  "title": "Hedging under the influence of transaction costs: An empirical investigation on FTSE 100 index options",
  "abstract": "The Black-Scholes (BS; F. Black & M. Scholes, 1973) option pricing model, and modern parametric option pricing models in general, assume that a single unique price for the underlying instrument exists, and that it is the mid- (the average of the ask and the bid) price. In this article the authors consider the Financial Times and London Stock Exchange (FTSE) 100 Index Options for the time period 1992-1997. They estimate the ask and bid prices for the index, and show that, when substituted for the mid-price in the BS formula, they provide superior option price predictors, for call and put options, respectively. This result is reinforced further when they fit a non-parametric neural network model to market prices of liquid options. The empirical findings in this article suggest that the ask and bid prices of the underlying asset provide a superior fit to the mid/closing price because they include market maker's, compensation for providing liquidity in the market for constituent stocks of the FTSE 100 index. (c) 2007 Wiley Periodicals, Inc.",
  "year": 2007,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6b50dfa99c5634eb149ebbeb61c6451a",
  "timestamp": "2025-05-15T01:29:44.139865"
}