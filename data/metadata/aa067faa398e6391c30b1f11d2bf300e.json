{
  "id": 4320,
  "title": "Neural network predictions of the high-frequency CSI300 first distant futures trading volume",
  "abstract": "Predictions of financial index trading volumes represent an essential issue to market participants and policy makers. We investigate this problem for the high-frequency one-minute CSI300 first distant futures trading volume from the launch of the futures index to two years after all its constituent stocks becoming shortable, a period with generally continuously expanding trading magnitude. We utilize the neural network to model this complex and irregular trading volume series and attempt to answer the following questions: can the trading volume be predicted by its own lags, and if so, how far to predict and how well; can the nearby futures or spot trading volume series help predictions, and if so, by how much; how complex does the model need to be and how robust can it be? We find that the trading volume could be predicted using one to thirty minutes ahead data through a relatively low complex model with five hidden neurons based on its own lags, resulting in generally accurate and stable performance based on the relative root mean square error. Incorporating the nearby futures or spot trading volume series generally does not help improve predictions. Results here should be of interest and use to design trading platforms, monitor system risk, and form index price predictions.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "aa067faa398e6391c30b1f11d2bf300e",
  "timestamp": "2025-05-15T02:36:05.144248"
}