{
  "id": 2154,
  "title": "Stock market prediction with time series data and news headlines: a stacking ensemble approach",
  "abstract": "Time series forecasting models are gaining traction in many real-world domains as valuable decision support tools. Stock market analysis is a challenging domain, characterized by a complex multi-variate and time-evolving nature, with high volatility, and multiple correlations with exogenous factors. Autoregressive, machine learning, and deep learning models for temporal data have been adopted thus far to solve this task. However, they are usually limited to the analysis of a single data source or modality, and do not collectively deal with all the inherent challenges and complexities presented by stock market data. In this paper, inspired by the promising learning capabilities of hybrid ensemble methods, we propose a novel stacking ensemble approach for stock market prediction that jointly considers news headlines, multi-variate time series data, and multiple base models as predictors. By taking multiple factors into consideration, our model is able to learn historical patterns leveraging multiple data sources and models. Our experiments showcase the ability of our model to outperform popular baselines on next-day stock market trend prediction. A portfolio analysis reveals that our method is also able to yield potential gains or capital preservation capabilities when its predictions are exploited for trading decisions.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6f3480d1071907144b3c222a0412edad",
  "timestamp": "2025-05-15T01:03:36.646212"
}