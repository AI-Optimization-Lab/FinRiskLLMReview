{
  "id": 1740,
  "title": "Towards a Crime Hotspot Detection Framework for Patrol Planning",
  "abstract": "By monitoring crime incidence with quantitative techniques, many studies have shown that it is possible to improve decision making through pattern recognition and prediction. In a smart city scenario, such approaches can be used to compose analytical background to improve resource allocation. This work presents a novel framework to improve patrol planning that precisely provides places and times that are likely to be more dangerous than short-term average using a portfolio of machine learning algorithms. Our approach follows an algorithm-as-a-service architecture (AaaS), providing insights to existing public safety systems and platforms. The service comprises the broader ROTA framework, a robust public safety platform devised for the ongoing smart cities initiative of Natal, Brazil. Results of an experimental evaluation provided insights about spatial granularity effects on the performance of the estimators adopted. Furthermore, an evaluation on algorithm selection demonstrates its outcomes on the hotspot detection task.",
  "year": 2018,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "9b01e7c30652aed280b63f4c75bce091",
  "timestamp": "2025-05-15T00:59:22.885217"
}