{
  "id": 4756,
  "title": "Forecasting time to risk based on multi-party data: An explainable privacy-preserving decentralized survival analysis method",
  "abstract": "Forecasting time-to-risk poses a challenge in the information processing and risk management within financial markets. While previous studies have focused on centralized survival analysis, how to forecast the time to risk using multi-party data in a decentralized and privacy-preserving setting with the requirements of explainability and mitigating information redundancy is still challenging. To this end, we propose an explainable, privacy-preserving, decentralized survival analysis method. Specifically, we transform time-to-risk forecasting into a multi-label learning problem by independently modeling for multiple time horizons. For each forecasting time horizon, we use Taylor expansion and homomorphic encryption to securely build a decentralized logistic regression model. Considering the information redundancy among multiple parties, we design and add decentralized regularizations to each model. We also propose a decentralized proximal gradient descent method to estimate the decentralized coefficients. Empirical evaluation shows that the proposed method yields competitive forecasting performance and explainable results as compared to benchmarked methods.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1b3649b52a50bfd15fa15a9bd24be8e8",
  "timestamp": "2025-05-15T02:40:28.001180"
}