{
  "id": 2924,
  "title": "Assessing the multiscale meteor shower effect from oil to the central and eastern European stock indices",
  "abstract": "This paper investigates the idiosyncratic volatility spillover effect from the Brent oil futures market to the 11 stock markets of Central and Eastern European economies. As volatility proxies, we use regime-switching conditional volatilities, obtained from two-states MS-GARCH model. In order to determine the level of this effect in different market conditions and in different time-horizons, we combine wavelet methodology with the quantile regression approach. Our results indicate that the volatility spillover effect is not particularly strong across the countries and the wavelet scales, except in those conditions when stock market volatility is exceptionally high. Also, the wavelet-based quantile parameters report that the volatility transmission effect gradually subsides with the flow of time, and it applies for the majority of the indices. Romanian BET index experiences the strongest volatility spillover effect from oil in conditions when Romanian stock market is under extreme stress. The reason for this finding probably lies in the facts that Romania is the largest oil and gas producer among all CEECs, and oil and gas markets tend to comove strongly. Based on findings of wavelet quantile parameters and wavelet correlations, we can conclude that hedgers and portfolio managers can build their portfolio strategies, combining Brent oil futures with the CEE indices.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "35cd453122380624c7a7988872c006c8",
  "timestamp": "2025-05-15T01:11:48.458447"
}