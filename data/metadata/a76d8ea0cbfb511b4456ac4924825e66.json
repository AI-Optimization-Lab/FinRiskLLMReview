{
  "id": 5102,
  "title": "Risk adjustment for people with chronic conditions in private sector health plans",
  "abstract": "Background. Although the problem of adverse selection into more generous health insurance plans has been the focus of previous work, risk adjustment systems have only recently begun to be implemented to blunt its effect. Objectives. This study examines the ability of the leading risk adjustment systems to predict health core expenditures for people with chronic conditions, using claims and enrollment data from 2 large employers. Research design. Predictive errors and total financial losses/gains are compared for different risk adjustment approaches (primarily hierarchical condition categories [HCCs] and adjusted clinical groups) for several chronic conditions. Results. One of the best performing risk adjustment systems was a regression-based HCC method, which had an average under-prediction error rate of 9% or 6%, depending on the employer. In comparison, more typical actuarial risk adjustments based on just age, gender, and prevailing area wages lead to a prediction error of at least 50%. We did not find evidence that payments for particular chronic conditions would be consistently and significantly under- or overestimated. Conclusion. The leading risk adjustment approaches substantially reduce the incentives for adverse selection but do not eliminate them.",
  "year": 2003,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a76d8ea0cbfb511b4456ac4924825e66",
  "timestamp": "2025-05-15T02:44:11.079794"
}