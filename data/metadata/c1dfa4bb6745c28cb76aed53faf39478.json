{
  "id": 3860,
  "title": "Improving solar forecasting using Deep Learning and Portfolio Theory integration",
  "abstract": "Solar energy has been consolidated as one of the main renewable energy sources capable of contributing to supply global energy demand. However, the solar resource has intermittent feature in electricity production, making it difficult to manage the electrical system. Hence, we propose the application of Deep Learning (DL), one of the emerging themes in the field of Artificial Intelligence (AI), as a solar predictor. To attest its capacity, the technique is compared with other consolidated solar forecasting strategies such as Multilayer Perceptron, Radial Base Function and Support Vector Regression. Additionally, integration of AI methods in a new adaptive topology based on the Portfolio Theory (PT) is proposed hereby to improve solar forecasts. PT takes advantage of diversified forecast assets: when one of the assets shows prediction errors, these are offset by another asset. After testing with data from Spain and Brazil, results show that the Mean Absolute Percentage Error (MAPE) for predictions using DL is 6.89% and for the proposed integration (called PrevPT) is 5.36% concerning data from Spain. For the data from Brazil, MAPE for predictions using DL is 6.08% and 4.52% for PrevPT. In both cases, DL and PrevPT results are better than the other techniques being used. (C) 2020 Elsevier Ltd. All rights reserved.",
  "year": 2020,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c1dfa4bb6745c28cb76aed53faf39478",
  "timestamp": "2025-05-15T01:21:41.327137"
}