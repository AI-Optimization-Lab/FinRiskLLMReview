{
  "id": 4235,
  "title": "Cost Model for Verifying Requirements",
  "abstract": "Testable requirements are the foundation to any development program. The number of requirements and the technical difficulty of satisfying those requirements are factors that drive program cost and schedule. Being able to quickly assess the scope of requirement verification and costing that activity is essential to the proposal process. For awarded programs, controlling and costing requirements volatility is critical to ensuring sufficient resources to execute the program and meet customer need dates. When considering requirements verification, to include regression testing, a balance is often needed between the cost and the coverage provided. These challenges are commonly encountered during program startup and execution. This paper presents a cost model, Cost Model for Verifying Requirements (CMVR), to assist program managers in quickly assessing the financial impact of verifying requirements as a result of changing (e.g. adding, modifying, and deleting) requirements. Of note, this paper focuses on more formal testing and verification activities, but does not address development and integration aspects. For the CMVR model to provide accurate results, the test team should first fully map requirements to test events. In doing so, requirements should be traced from the stakeholder (e.g. customer requirements) through derived requirements to test objectives and ultimately to test scripts/procedures. Each test script and procedure will need to be assessed to determine the cost (man-hours and duration) to complete the test objective. With the linkage between requirements and test events established, programs can then use the cost model for bidding, evaluating requirements volatility, and developing test sets that optimize the cost-benefit ratio. Bidding: During bidding, requirements are often not fully developed. The CMVR model addresses these ambiguities by providing a portfolio mix (easy, moderate, difficult) based on historical data, enabling program managers to select or alter similar to tailoring ones 401K plan. Requirements Volatility: Evaluating the impact of requirements volatility on test costs requires assessing development, test setup, execution, and analysis of potential efficiencies that can be leveraged from overlapping tests. Developing Test Sets: With limited time and resources, programs may need to identify a subset of tests to execute (such as for regression testing). Programs will need to determine the focus areas of requirements (Depth), the test requirement coverage (breadth), and the critical must-test requirements. This paper also includes examples of utilizing the CMVR model and demonstrating how this capability enables quickly assessing cost and schedule impacts due to a change in requirements. In summary, The CMVR cost model provides program managers with an important tool to quickly assess the testing cost of requirements.",
  "year": 2016,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "37ec19052306b8b8f78df9ce8cc147f5",
  "timestamp": "2025-05-15T01:24:51.542161"
}