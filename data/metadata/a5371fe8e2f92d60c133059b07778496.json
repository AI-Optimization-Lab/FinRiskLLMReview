{
  "id": 4737,
  "title": "Household measures for river flood risk reduction in the Czech Republic",
  "abstract": "Interviews with 304 households were used to determine flood risk reduction measures adopted in the case study of the Becva River in the Czech Republic. Uptake of measures was low, irrespective of experience with floods. Financial cost seemed to be a barrier towards implementation, but more work is needed to understand the combination of factors limiting adoption of household flood risk reduction measures. Regression analysis indicated that socio-demographic factors play an important role in household decision making. More men and more children in a household support the adoption of measures. Perception of living in a flood risk zone, rather than actual experience of flooding, also positively influenced probability of adopting some measures. When a house is elevated up from ground level by 1 metre or more, the likelihood of taking further measures decreased by 20%. Further investigation of these factors and why, not just how, they influence household choices would support flood risk reduction measures, especially under a changing climate.",
  "year": 2017,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a5371fe8e2f92d60c133059b07778496",
  "timestamp": "2025-05-15T02:40:27.954328"
}