{
  "id": 826,
  "title": "A hybrid optimized deep learning model via the Golden Jackal Optimizer for accurate stock price forecasting",
  "abstract": "Stock markets have historically been the reference point of the worldwide financial environment throughout the years. Investing in the stock market carries risk; however, it can offer significant short- or long-term returns for the investor. Forecasting stock prices has been a vital topic among professionals and researchers; however, it has always been a difficult task. Machine learning and metaheuristic algorithms over the last years have shown remarkable performance in a variety of sectors, encompassing the financial sector. In this work, we propose an optimized hybrid deep learning model via the Golden Jackal Optimizer (GJO) algorithm for the task of precise stock price prediction. We select the twenty highest stocks in terms of market capitalization from the S&P 500 index as our benchmark dataset. We compare the proposed model with eighteen different neural network models, as well as the PSO-GRU | LSTM and GA-GRU | LSTM models, which refer to optimized deep learning models using the Particle Swarm Optimization (PSO) algorithm and Genetic Algorithms (GA), respectively. The experiments are evaluated based on RMSE, MAE, and MAPE criteria. The results demonstrate that metaheuristicoptimized models outperform standard approaches, with the proposed GJO-GRU | LSTM model enhancing forecasting quality.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a7fe1e0b4aafdb8fe3fd577f64d8cc11",
  "timestamp": "2025-05-15T01:55:41.549149"
}