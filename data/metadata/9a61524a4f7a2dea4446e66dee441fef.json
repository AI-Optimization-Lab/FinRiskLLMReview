{
  "id": 244,
  "title": "Portfolio selection under non-gaussianity and systemic risk: A machine learning based forecasting approach",
  "abstract": "The Sharpe-ratio-maximizing portfolio becomes questionable under non-Gaussian returns, and it rules out, by construction, systemic risk, which can negatively affect its out-of-sample performance. In the present work, we develop a new performance ratio that simultaneously addresses these two problems when building optimal portfolios. To robustify the portfolio optimization and better represent extreme market scenarios, we simulate a large number of returns via a Monte Carlo method. This is done by obtaining probabilistic return forecasts through a distributional machine learning approach in a big data setting and then combining them with a fitted copula to generate return scenarios. Based on a large-scale comparative analysis conducted on the US market, the backtesting results demonstrate the superiority of our proposed portfolio selection approach against several popular benchmark strategies in terms of both profitability and minimizing systemic risk. This outperformance is robust to the inclusion of transaction costs. (c) 2023 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "9a61524a4f7a2dea4446e66dee441fef",
  "timestamp": "2025-05-15T00:41:04.724129"
}