{
  "id": 1415,
  "title": "ML methods for assessing the risk of fraud in auto insurance",
  "abstract": "The car insurance fraud level assessment is an urgent and complex task, which is largely due to the activities of fraudulent groups. For the confident management of insurance companies in the anti-fraud strategy, a tool to assess the current state of the claim's portfolio is needed. Modern machine learning methods make it possible to carry out such an assessment using data on policyholders and insurance cases. When applying these approaches, a number of problems arise that do not allow achieving the required quality of fraud detection. These include class imbalance and the so-called concept drift, which arises as a result of changes in the scenarios of fraudsters' schemes and the subjectivity of the expert assessment of a specific insurance case. This study proposes an approach to improve model metrics for detecting fraud in a claims portfolio. A numerical experiment conducted on two open data sets demonstrated a significant improvement in the detection rate of insurance fraud compared to classical modeling. Specifically, there was an increase in the completeness of fraud detection by 49 and 19 percentage points for the two datasets, respectively.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d245c9c89569864e79ddc5523ef32e68",
  "timestamp": "2025-05-15T00:55:28.482500"
}