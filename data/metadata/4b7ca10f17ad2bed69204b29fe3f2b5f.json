{
  "id": 3651,
  "title": "The Propensity to Use FinTech: Input from Bankers in the Kingdom of Bahrain",
  "abstract": "This study aims to assess why users are willing/hesitant to continue using FinTech services based on their perceived benefits and risks pertaining to the use of FinTech technology. Data was collected, using an adopted survey instrument, from bankers based in Bahrain, the financial and FinTech hub of the Middle East. Data analysis was applied to assess the reliability and validity of this study's conceptual model along with its nine hypotheses with 374 valid responses subsequently being analysed using multiple regression via SPSS version 23. The empirical findings of this study supported all the hypotheses, revealing that both perceived benefit and risks affect the intent to continue using FinTech. Perceived benefit has a stronger effect than the perceived risk, and convenience perceived most beneficial while financial risk perceived riskiest for using FinTech technology by the bankers of Bahrain.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "4b7ca10f17ad2bed69204b29fe3f2b5f",
  "timestamp": "2025-05-15T02:28:29.414993"
}