{
  "id": 532,
  "title": "Predicting the Product Life Cycle of Songs on the Radio How Record Labels can Manage Product Portfolios and Prioritise Artists by Using Machine Learning Techniques",
  "abstract": "In terms of determining the success of a musical artist's song, there is a positive correlation of radio play success and music sales success. Therefore, being able to forecast the future plays of a song on the radio can serve as powerful risk management and product portfolio management tools for record labels and other stakeholders of a song. This research strives to predict the remaining product life cycle of a song on the radio after it has been played for one or two months. The best results were achieved using a k-d tree to calculate the songs the most similar to the test songs and use a Random Forest model to forecast radio plays. Accuracy of 82.78% and 83.44% was achieved for the two time periods, respectively. This explorative research leads to over 4500 test metrics to find the best combination of models and pre-processing techniques. Other algorithms tested were KNN, MLP, and CNN. The features only consist of daily radio plays and use no musical features.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "99d3a053b3652c64a7cd1722148f6075",
  "timestamp": "2025-05-15T00:37:01.801123"
}