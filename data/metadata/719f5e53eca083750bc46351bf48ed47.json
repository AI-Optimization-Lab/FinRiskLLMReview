{
  "id": 595,
  "title": "Machine learning and the prediction of changes in profitability",
  "abstract": "This study uses machine-learning methods to predict next-period change in profitability based on a model proposed by Penman and Zhang (2004, Working paper, Columbia University and University of California, Berkeley; PZ). We find that new machine-learning methods predict out of sample substantially better than traditional regression methods and provide richer interpretations about the role and impact of different predictor variables through their nonlinear relationships and interaction effects. For example, our results contrast with previous research by showing that both components of the DuPont decomposition (change in profit margin and change in asset turnover) are informative of next-period changes in profitability. Our results are robust across different performance metrics, alternative machine-learning models, and software. Furthermore, an unconstrained machine-learning model using a larger feature space could not significantly improve the performance of the PZ model. PZ variables alone accounted for most of the explanatory power of the unconstrained model, suggesting the PZ model is both well specified (in terms of feature selection) and robust in higher dimensional settings. With respect to the economic significance of this information, we find mixed results. The market appears to adjust its expectations more in line with the machine-learning predictions relative to the PZ model but the portfolio returns are not significantly different.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "719f5e53eca083750bc46351bf48ed47",
  "timestamp": "2025-05-15T00:45:39.059988"
}