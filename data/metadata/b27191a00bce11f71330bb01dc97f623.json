{
  "id": 214,
  "title": "基于集成学习的在线高维投资组合策略",
  "abstract": "文章结合机器学习中的交叉验证、在线学习和集成学习方法,对基于不同高维协方差估计量的投资策略权重进行动态组合,以获得优于传统投资组合策略的样本外表现.基于这一目标,文章对机器学习中比较前沿的在线加权集成(online weighted ensemble,OWE)算法的样本更新方式、学习模型和目标函数进行了替换和修改,改进后的mixed-OWE算法能够更好地适用于多组合的动态混合策略投资.通过数值模拟,文章将mixed-OWE应用在基于二次效用目标函数的投资问题上,结果表明其样本外表现优于传统静态方法.随后,文章进一步使用A股近10年的数据作为样本对mixed-OWE进行了全局最小方差组合投资,经过一定的参数调整后,mixed-OWE策略实现的组合方差优于其成分组合以及等权重组合.",
  "year": 2020,
  "source": "CNKI",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b27191a00bce11f71330bb01dc97f623",
  "timestamp": "2025-05-14T22:21:50.505762"
}