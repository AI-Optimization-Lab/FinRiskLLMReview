{
  "id": 3746,
  "title": "The liquidity impact of Chinese green bonds spreads",
  "abstract": "Green bond is widely treated as one of the most crucial financial instruments for achieving carbon neutrality. While existing research is insufficient to provide an in-depth understanding of the liquidity impact of green bonds, it obstructs this emerging asset's promotion and investment. This paper expands the current periphery of research by centering on Chinese green bonds. After employing the portfolio-based and the entire sample regression approach, we evaluate nine potential proxies' performance to clarify liquidity measurement metrics. We document that issued amount, time to maturity, yield dispersion, the specific target of proceeds or not, and reputation of the underwriter are the five effective indicators. Consequently, the average Chinese green bond liquidity premium is estimated based on these proxies, 28.14 bps, occupying 16.92% of the whole green bond yield spreads. The results of time-varying liquidity premiums furtherly point out some significant findings of the current circumstance for developing the Chinese green bonds. By combining a matching process, we display the corresponding conventional bonds' liquidity impact with an average premium of 19.4 bps. Based on such differences between the two, we imply some unique features of green bonds.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c1bb48a1170f1079108504d32ee51c37",
  "timestamp": "2025-05-15T01:20:35.944674"
}