{
  "id": 4317,
  "title": "Forecasting the Number of Tenants At-Risk of Formal Eviction: A Machine Learning Approach to Inform Public Policy",
  "abstract": "Eviction of tenants has reached a crisis level in the U.S. and its consequences pose significant challenges to society. To tackle this eviction crisis, policymakers have been allocating financial resources but a more efficient resource allocation would need an accurate forecast of the number of tenants atrisk of evictions ahead of time. To help enhance the existing eviction prevention/diversion programs, in this work, we propose a multi-view deep neural network model, named as MARTIAN, that forecasts the number of tenants at-risk of getting formally evicted (at the census tract level) n months into the future. Then, we evaluate MARTIAN's predictive performance under various conditions using realworld eviction cases filed across Dallas County, TX. The results of empirical evaluation show that MARTIAN outperforms an extensive set of baseline models in terms of predictive performance. Additionally, MARTIAN's superior predictive performance is generalizable to unseen census tracts, for which no labeled data is available in the training set. This research has been done in collaboration with Child Poverty Action Lab (CPAL), which is a pioneering non-governmental organization (NGO) working for tackling poverty-related issues across Dallas County, TX. The usability of MARTIAN is under review by subject matter experts. We release our codebase at https://github.com/maryam-tabar/ MARTIAN.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "aa1b35714cc95f46b7bfaf9ddf98ed2a",
  "timestamp": "2025-05-15T02:36:05.141349"
}