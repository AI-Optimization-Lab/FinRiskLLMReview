{
  "id": 1872,
  "title": "The role of size effects in moderating the benefits of sustainable investing",
  "abstract": "Using an extensive sample of environmental, social, and governance (ESG) ratings, we reexamine the corporate social responsibility (CSR) factor premium in the developed equity markets between 2007 and 2019 and show that its extent is contingent upon size effects. Consistent with the novel market equilibrium, we contend that the exponential growth of socially responsible investment (SRI) has rendered the risk-adjusted returns of large CSR-leading firms in line with or even below their lagging counterparts. In line with the neglected effect, greater market segmentation, lower market efficiency, and lower investor awareness of CSR enable us to observe the former market equilibrium in the smaller corporation partition, where CSR-lagging firms exhibit lower returns than leading ones. We thus theorize a two-stage CSP-CFP relationship, where size effects are considered a relevant moderator. This contention is robust to portfolio and panel regression settings. However, our partly contradicting results with the existent literature emphasize the divergence in ESG ratings across rating agencies. JEL Classification M14; G11; G15",
  "year": 2025,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c429288b5317a4338ef9c1182e849533",
  "timestamp": "2025-05-15T01:00:27.412287"
}