{
  "id": 3440,
  "title": "Determinants of time varying co-movements among international stock markets during crisis and non-crisis periods",
  "abstract": "In this paper, we use the DCC MIDAS approach to assess the validity of the wake-up call hypothesis for developed and emerging markets during the global financial crisis (GFC). We use this approach to decompose the total correlations into short-(daily) and long-run (quarterly) correlations for the period from 1999 to 2011. We then examine the transmission mechanisms by regressing the quarterly economic, financial, and behavioral variables on the quarterly DCC-MIDAS correlations. We find that country specific factors are crisis contingent transmission mechanisms for the co-movements of emerging country pairs and mixed pairs of advanced and emerging countries during the global financial crisis. However, we do not observe wake-up calls in the transmission of the crisis among advanced country pairs. The classification of the transmission mechanisms for crisis and non-crisis periods with the different country pairs has important implications for crisis management as well as for portfolio investment strategies. Thus, our findings contribute to the discussion on the role and effectiveness of the international financial architecture. (C) 2016 Elsevier B.V. All rights reserved.",
  "year": 2016,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "465df155f3b4e03ad82f1dd76a8ebe6e",
  "timestamp": "2025-05-15T01:17:25.390231"
}