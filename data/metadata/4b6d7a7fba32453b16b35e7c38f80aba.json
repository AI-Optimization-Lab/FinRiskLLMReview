{
  "id": 654,
  "title": "Feature selection for financial credit-risk evaluation decisions",
  "abstract": "Credit-risk evaluation decisions are important for the financial institutions involved due to the high level of risk associates with wrong decisions. Various machine learning methods have been shown to perform reasonably well for this complex and unstructured problem. However, selecting a good set of features to be used in any learning system is a hard problem. We survey recent developments in feature selection and propose a new methodology based on the Blurring measure. The proposed feature selection method (FSB) is used to preprocess input data for induced decision trees. Three financial credit-risk evaluation data sets are used to illustrate the performance of the proposed method. In addition to FSB, results from randomly selected features, features selected using the Patrick-Fisher probabilistic distance, measure, as well as no feature selection are provided for comparison purposes. Given the characteristics of the financial credit-risk evaluation domain, any improvement in classification performance is deemed beneficial. Preliminary results indicate that far comparable tree size, classification performance of FSB on classifying heretofore unseen examples is good compared to the other three methods evaluated in this study.",
  "year": 1999,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "4b6d7a7fba32453b16b35e7c38f80aba",
  "timestamp": "2025-05-15T01:53:24.968457"
}