{
  "id": 3613,
  "title": "Does the EU sustainable finance disclosure regulation mitigate greenwashing?",
  "abstract": "This paper examines the impact of the Sustainable Finance Disclosure Regulation (SFDR) on greenwashing by equity mutual funds in the EU. We propose a unique measure called the Greenwashing Index, based on a fund's decarbonisation effort relative to its flows, to quantify the level of greenwashing. Using a difference-in-differences analysis, we find that following the enactment of the SFDR, Article 9 funds experience a lower level in their greenwashing index relative to a control group of funds. However, for Article 8 funds we do not observe any significant reduction in the level of their greenwashing index relative to the same control group. We also use a regression discontinuity design (RDD) and find that the decline in the greenwashing index is more concentrated in Article 9 than in Article 8 funds which indicates a different effect of the SFDR on greenwashing behaviour between those funds. Our findings also show that Article 9 funds decarbonise their portfolios by primarily following a portfolio tilting strategy to overweight low carbon-intensive holdings following the introduction of the SFDR.",
  "year": 2025,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b3112b2bea6eedca81c3080f06d15b9b",
  "timestamp": "2025-05-15T01:19:00.697116"
}