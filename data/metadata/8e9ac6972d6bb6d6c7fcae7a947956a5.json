{
  "id": 180,
  "title": "RETRACTED: Research on Securities Portfolio Model Based on Genetic Optimization Neural Network (Retracted Article)",
  "abstract": "Portfolio is an investment management concept different from individual asset management. This consideration leads to an interesting result, that is, investors should buy a variety of securities at the same time instead of one kind of securities for diversified investment. Aiming at the limitations of BPNN (BP neural network) in traditional artificial neural network and its shortcomings such as many iterations, low convergence accuracy, and poor generalization, a portfolio method based on GA_BPNN (Genetic Optimization Neural Network) was proposed. The setting of GA (genetic algorithm) parameters and BPNN parameters are discussed in detail, and the implementation steps of genetic BP algorithm are described. The results show that the evaluation indexes of GA_BPNN prediction model are obviously better than those of the comparison prediction model, with the coincidence rate of 77.96% and the average absolute error of 12.451. The combination of GA and BPNN can effectively solve this problem. The simulation results of optimizing securities portfolio show that its optimization scheme is better than quadratic programming method, and this method is more correct, efficient, and practical.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8e9ac6972d6bb6d6c7fcae7a947956a5",
  "timestamp": "2025-05-15T00:40:02.131183"
}