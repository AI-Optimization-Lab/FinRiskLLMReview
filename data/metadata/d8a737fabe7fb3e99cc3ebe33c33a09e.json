{
  "id": 2231,
  "title": "Housing Provident Fund, risk attitude, and household financial investment engagement: an asset-building perspective",
  "abstract": "The income gap stemming from disparities in asset ownership is a significant contributor to economic inequality and social polarization. Asset income is derived from the growth and realization of these assets, with financial investment serving as the key mechanism for transforming household assets into asset-generated income. Institutionalized wealth accumulation mechanisms play a vital role in facilitating household asset growth through the influence of risk preferences.The Housing Provident Fund (HPF), an integral component of China's social welfare and security system, is one such policy aimed at promoting asset building. This study employs linear regression and ordered logit regression, using cross-sectional data from the 2019 China Household Finance Survey (CHFS), to investigate the relationship between HPF possession, risk attitude, and financial investment engagement. To ensure robustness, a bootstrap mediation analysis is conducted to evaluate the mediating role of household heads' risk attitudes in this relationship. The results indicate that HPF possession is positively associated with financial investment engagement (beta = 0.091, p < 0.001) and the risk preferences of household heads (beta = 0.130, p < 0.01). Moreover, household heads' risk preferences partially mediate the relationship between HPF possession and financial investment engagement, with an indirect effect of 0.011 (10.3%, p < 0.05).",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d8a737fabe7fb3e99cc3ebe33c33a09e",
  "timestamp": "2025-05-15T02:12:50.994408"
}