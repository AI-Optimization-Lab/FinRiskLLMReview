{
  "id": 5098,
  "title": "Shadow banking and commercial bank: evidence from China",
  "abstract": "In China, commercial banks participate in shadow banking activities through interbank or channel businesses, which should be called bank's shadow banking activities. Based on the co-opetition game model, we first analyse the fund flow mechanism between bank's shadow banking and traditional credit business, which confirms that the greater the proportion of bank's shadow banking investment, the higher the bank profit. By sampling 147 commercial banks in China during 2003 to 2019, we empirically study the impact of bank's shadow banking on the individual risk of commercial bank by OLS regression and on the systemic risk of banks through the randomized effect model from the micro-level. The results confirm that Chinese bank's shadow banking will increase the individual operating risk of commercial bank and its rapid development will increase the probability of banking system risk. Meanwhile, we find that global financial crisis has no significant effect on the risk of individual banks or banking systems, but the regulatory overhaul of bank's shadow banking activities can significantly inhibit the individual bank's operational risk, especially for listed banks.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "bf42d0282eda6207f76b4386bb0e100d",
  "timestamp": "2025-05-15T02:44:11.063772"
}