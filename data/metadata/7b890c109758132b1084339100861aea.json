{
  "id": 6039,
  "title": "Can Network Linkage Effects Determine Return? Evidence from Chinese Stock Market",
  "abstract": "This study used the dynamic conditional correlations (DCC) method to identify the linkage effects of Chinese stock market, and further detected the influence of network linkage effects on magnitude of security returns across different industries. Applying two physics-derived techniques, the minimum spanning tree and the hierarchical tree, we analyzed the stock interdependence within the network of the China Securities Index (CSI) industry index basket. We observed that that obvious linkage effects existed among stock networks. CII and CCE, CAG and ITH as well as COU, CHA and REI were confirmed as the core nodes in the three different networks respectively. We also investigated the stability of linkage effects by estimating the mean correlations and mean distances, as well as the normalized tree length of these indices. In addition, using the GMM model approach, we found inter-node influence within the stock network had a pronounced effect on stock returns. Our results generally suggested that there appeared to be greater clustering effect among the indexes belonging to related industrial sectors than those of diverse sectors, and network comovement was significantly affected by impactive financial events in the reality. Besides, stocks that were more central within the network of stock market usually had higher returns for compensation because they endured greater exposure to correlation risk.",
  "year": 2016,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7b890c109758132b1084339100861aea",
  "timestamp": "2025-05-15T02:54:03.437430"
}