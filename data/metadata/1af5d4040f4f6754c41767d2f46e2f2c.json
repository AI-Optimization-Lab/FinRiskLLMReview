{
  "id": 2543,
  "title": "Super-exponential endogenous bubbles in an equilibrium model of fundamentalist and chartist traders",
  "abstract": "We introduce a model of super-exponential financial bubbles with two assets (risky and risk-free), in which fundamentalist and chartist traders co-exist. Fundamentalists form expectations on the return and risk of a risky asset and maximize their constant relative risk aversion expected utility with respect to their allocation on the risky asset versus the risk-free asset. Chartists are subjected to social imitation and follow momentum trading. Allowing for random time-varying herding propensity, we are able to reproduce several well-known stylized facts of financial markets such as a fat-tail distribution of returns and volatility clustering. In particular, we observe transient faster-than-exponential bubble growth with approximate log-periodic behavior and give analytical arguments why this follows from our framework. The model accounts well for the behavior of traders and for the price dynamics that developed during the dotcom bubble in 1995-2000. Momentum strategies are shown to be transiently profitable, supporting these strategies as enhancing herding behavior. (C) 2015 Elsevier B.V. All rights reserved.",
  "year": 2015,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1af5d4040f4f6754c41767d2f46e2f2c",
  "timestamp": "2025-05-15T02:16:32.685563"
}