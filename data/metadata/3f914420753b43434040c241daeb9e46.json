{
  "id": 788,
  "title": "What can we learn from what a machine has learned? Interpreting credit risk machine learning models",
  "abstract": "For being able to analyze unstructured and alternative data, machine learning algorithms are gaining popularity in financial risk management. Alongside the technological advances in learning power and the digitalization of society, new financial technologies are also leading to more innovation in the business of lending. However, machine learning models are often viewed as lacking in terms of transparency and interpretability, which hinders model validation and prevents business users from adopting these models in practice. In this paper, we study a few popular machine learning models using LendingClub loan data, and judge these on performance and interpretability. Our study independently shows LendingClub has sound risk assessment. The findings and techniques used in this paper can be extended to other models.",
  "year": 2021,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "3f914420753b43434040c241daeb9e46",
  "timestamp": "2025-05-15T01:55:08.022825"
}