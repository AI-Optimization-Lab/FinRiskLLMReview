{
  "id": 3458,
  "title": "Implementation and profitability of sustainable investment strategies: An errors-in-variables perspective",
  "abstract": "Firm-level studies of sustainable investment performance are typically limited by an errors-in-variables bias (i.e., a distortion of estimated regression coefficients caused by measurement error in explanatory variables). Using recent advances in statistical methodology, we present the first cross-sectional analysis of sustainable stock selection which adequately corrects for this bias and additionally answers the question of whether betas with respect to sustainable risk factors or sustainable characteristics (i.e., environmental, social, and governance ratings) are more relevant in portfolio selection. Within the universe of S&P 500 stocks, which is highly relevant from the investor attention and liquidity perspectives, we find that, after accounting for errors-in-variables bias, both types of variables become insignificant. Consequently, they do not add value to investment portfolios and are not vital in models explaining stock returns. Among classic predictors with a long history of use in the investment fund industry, only the market-to-book ratio provides independent investment and pricing information.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "3b3b8e2443bac2da8400db858eea1deb",
  "timestamp": "2025-05-15T01:17:25.463123"
}