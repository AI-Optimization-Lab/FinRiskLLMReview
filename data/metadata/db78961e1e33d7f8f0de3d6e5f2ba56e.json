{
  "id": 813,
  "title": "Forecasting Bank Default Risk with Interpretable Machine Learning: The Study of Chinese Banks",
  "abstract": "Bank occupies an important position in the financial system. The stable operation of the banking industry is not only one of the important factors in achieving sustainable economic growth but also related to the stability of the entire financial system. This research collects data from 507 banks in China from 2000 to 2021, uses the non-performing loan ratio as the measurement indicator of bank risk, and selects indicators from five levels (macroeconomic environment, industry economic environment, economic policy uncertainty, financial openness and bank financial status) On this basis, we use interpretable machine learning models to predict the bank's default risk, analyze and compare the interpretable machine learning model and the post-hoc explainable methods. The results indicate that Provision Coverage (PC), Loan Provision Coverage (LPC), Liquidity Ratio (LR), and KOF Financial Globalization Index (KOFFiGI) have strong predictive capability for bank default risk. Our research can provide a reference for banks, government and financial regulatory authorities to construct the prediction model and indicator monitoring platform for bank default risk.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "db78961e1e33d7f8f0de3d6e5f2ba56e",
  "timestamp": "2025-05-15T01:55:41.530651"
}