{
  "id": 1689,
  "title": "Forthcoming applications of quantum computing: peeking into the future",
  "abstract": "We all have been using classical computers for a long time. Quantum computing uses the phenomena of quantum mechanics like superposition and entanglement. Quantum computations can help achieve for the breakthroughs we have been looking for in science, machine learning, financial planning, medicine, etc., where classical computers' computing power is not enough. It was not long back when quantum computing's applications in our life were all just theoretical. However, to utilise the power of quantum computations for real-life applications, several recent developments have been made. Keeping that in mind, this study aims to explore the existing and upcoming applications of quantum computing. In this study, they start with an introduction of quantum computing fundamentals, following which, they give a brief overview of various applications of quantum computing in several significant areas of computer science, such as cryptography, machine learning, deep learning, and quantum simulations. They also cover various real-life scenarios such as risk analysis, logistics, and satellite communication.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "05d5a3082d82e3041ae617c0f7b2eb4e",
  "timestamp": "2025-05-15T02:06:22.462140"
}