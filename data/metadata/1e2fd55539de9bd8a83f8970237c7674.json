{
  "id": 14,
  "title": "Concept Drift-Oriented Adaptive and Dynamic Support Vector Machine Ensemble With Time Window in Corporate Financial Risk Prediction",
  "abstract": "This paper proposes a novel method of corporate financial risk prediction (FRP) modeling called the adaptive and dynamic ensemble (ADE) of support vector machine (SVM) (ADE-SVM), which integrates the inflow of new data batches for FRP with the process of time. Namely, the characteristic change of corporate financial distress hidden in the data flow is considered as the concept drift of financial distress, and it is handled by ADE-SVM that keeps updating in time. Using the criteria of predictive ability and classifier diversity, the SVM ensemble is dynamically constructed by adaptively selecting the current base SVMs from candidate ones. The candidate SVMs are incrementally updated by considering the newest data batch at each new current time point. The results of the base SVMs are dynamically weighted by their validation accuracies on the latest data batch to generate the final prediction. Experiments were carried out on real-world data sets with current data for training and future data for testing. The results show that ADE-SVM overall outperforms the other three traditional dynamic modeling methods, particularly for harder FRP task with more insufficient information and more obvious concept drift.",
  "year": 2013,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1e2fd55539de9bd8a83f8970237c7674",
  "timestamp": "2025-05-15T01:46:03.755246"
}