{
  "id": 280,
  "title": "The Empirical Research on the Performance of Pricing based on TAIEX Options under Different Volatility Models",
  "abstract": "This study introduces a variety of volatility estimation methods, including historical volatility, implied volatility and VIX, to assess and compare the performance of pricing TAIEX Options. The empirical results indicate that the evaluation performance of implied volatility model outperformed those of historical volatility and VIX models. In the analysis of causes of option's price errors by multiple variables regression, moneyness, time to maturity, volatility and index returns have significant impacts on the pricing errors, while trading volume and open interest do not have significant impacts on every pricing error. Even though the latter two factors are in the case of significance, their coefficients are negatively related to the absolute error.",
  "year": 2016,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "565d2bfd1891d364d1ce1c25f14519d2",
  "timestamp": "2025-05-15T01:30:19.119627"
}