{
  "id": 1398,
  "title": "NEW INTERNAL RATING APPROACH FOR CREDIT RISK ASSESSMENT",
  "abstract": "The assessment and modeling of the credit risk is one of the most important topics in the field of financial risk management. In this investigation the credit risk assessment model was developed and tested for Lithuanian companies. 20 financial ratios of the companies were calculated for each year of the 3 year period of interest. The analysis of variance (ANOVA) and Kolmogorov-Smirnov test were applied and the set of variables reduced from 60 to 25. Logistic regression was used for the classification of the companies into reliable and not reliable ones. Financial ratios, having the highest correlation to the possibility of default were selected for further investigation and several credit ratings were attributed to the companies according to these variables' values. The average values of Mahalanobis Distances calculated for the most reliable companies were the lowest and these values increased with a decreased reliability of the company. The differences between Mahalanobis Distances of the companies having different credit ratings confirmed the reliability of the model results.",
  "year": 2011,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "3041e10d755dcbe9afc4015731ff1633",
  "timestamp": "2025-05-15T02:02:22.759477"
}