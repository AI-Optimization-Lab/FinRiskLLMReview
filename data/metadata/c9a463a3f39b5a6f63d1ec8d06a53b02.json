{
  "id": 4548,
  "title": "Has sustainable investing made an impact in the period of COVID-19?: evidence from Australian exchange traded funds",
  "abstract": "We study the impact of sustainability on the financial performance of exchange-traded funds (ETFs) in the period of COVID-19. Using a sample of 244 Australian ETFs rated by Morningstar in April 2020, we conducted the portfolio analysis and cross-sectional regression analysis, and the results show that ETF portfolios with lower carbon risk and fossil fuel exposure tend to outperform. However, ETF portfolios with higher social risk tend to deliver a better performance. We also find that ETF portfolios with high environmental risk, governance risk, carbon risk and fossil fuel exposure are more likely to experience high volatility in stock returns. The findings will serve as an important point of reference for investors, businesses and wider stakeholders. The sustainable investing is proving to be resilient during the COVID-19 and a closer look at ESG risks is a lens through which business leaders can build better and more resilient enterprises.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c9a463a3f39b5a6f63d1ec8d06a53b02",
  "timestamp": "2025-05-15T02:38:20.436207"
}