{
  "id": 1050,
  "title": "Cluster-driven Hierarchical Representation of Large Asset Universes for Optimal Portfolio Construction",
  "abstract": "This work presents an alternative to conventional Markowitz portfolio construction for large asset universes by employing a hierarchical framework. This approach involves initially representing the large asset universe as a smaller-dimensional space of synthetic assets through clustering. Specifically, stocks with high correlations are grouped into clusters, each representing a new synthetic asset. By reducing the dimensionality of the asset universe, the traditional Markowitz framework for optimal portfolio construction becomes more tractable, mitigating issues related to the large size of the covariance matrix, such as ill-conditioning and the curse of dimensionality. To perform clustering, the correlation matrix is interpreted as the adjacency matrix of a signed graph, with nodes representing assets and edges indicating the correlations between asset pairs. Signed spectral clustering algorithms are then applied to this correlation matrix to achieve the desired groupings. After conducting Markowitz optimization on this smaller asset universe, weights are assigned to the original assets by mapping the results back from the clusters using the Markowitz weights. The efficacy of this approach is demonstrated through a trading strategy that sequentially constructs portfolios using clustering. The results reveal that this strategy significantly outperforms traditional portfolio construction methods and various benchmarks in terms of both volatility and returns.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "2f7d51471ee485602a5a07dfb9d26173",
  "timestamp": "2025-05-15T00:51:25.852353"
}