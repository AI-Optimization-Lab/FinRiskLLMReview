{
  "id": 4286,
  "title": "Small Nuclear Power Plants - Primary Avenue for Reducing Risks and their Consequences in Nuclear Power",
  "abstract": "The potential for improving safety and systems efficiency via unit power reduction of NPP in spite of an increase of the specific costs is investigated. An approach to significant reduction of the risk due to the human factor by switching to small- and medium-size power-generating units is considered. This approach can becharacterized as a method of risk reduction by means of 'power insurance.' The qualitative technical and economic effects from the reduction of different forms of risk in the implementation of small- and mediumsize NPP designs as compared with large NPP are analyzed: public acceptance; search for investors and their financial risk; availability of NPP sites; cost increase due to longer construction times; radiation and nuclear safety risks; electric power interruptions; minimization of the reserve power in the power system; and, adaptability to the rate of regional energy growth. Variants of the classification of integral risks over the entire life cycle of an NPP design are presented.",
  "year": 2019,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b4853abd501ed9f54246137829911b1a",
  "timestamp": "2025-05-15T02:35:26.273206"
}