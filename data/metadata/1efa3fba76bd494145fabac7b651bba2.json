{
  "id": 6502,
  "title": "MARKET EFFICIENCY HYPOTHESIS - THE CZECH FOREX MARKET CASE IN 2015",
  "abstract": "In this article we present the famous Eugene F. Fama hypothesis about efficient markets in the Economy. We describe the recent modern modification and critique. Moreover we discuss the options of verifications/falsification of this theory in the real dataset in the recession. For instance comparison provided with article of Kristoufek, Vosvrda Commodity futures and market efficiency where there were explained the evolution in the 25 commodity futures markets. Differences from the Market Efficiency Hypothesis equilibrium can be explained with the existence of Peso problem, the bubbles in the financial assets market, the risk premium and the problems with expectations and with the imperfect processing of Information. Theoretically most useful method of the FOREX market Efficiency verification is in the sample of CZK/EUR time series of exchange rates and forward rates. Traditional methods are the basic regression analysis, the time series cointegration method, Pedroni's panel cointegration and non - linear adjustment of exchange rate to its equilibrium.",
  "year": 2015,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1efa3fba76bd494145fabac7b651bba2",
  "timestamp": "2025-05-15T02:58:34.279542"
}