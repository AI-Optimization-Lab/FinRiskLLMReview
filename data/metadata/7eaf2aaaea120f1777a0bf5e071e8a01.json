{
  "id": 149,
  "title": "数字普惠金融省域发展特征及影响因素研究",
  "abstract": "文章使用2013—2020年省级面板数据，建立基于“绝对量”“增量”“增速”“变异程度”四项指标的综合距离面板数据聚类方法对我国数字普惠金融省域发展特征进行分析，并采取半参数理论的分析方法研究数字普惠金融发展的影响因素。研究发现：第一，我国数字普惠金融的发展在省域层面上存在明显的异质性。从空间上看，经济发达的沿海地区和经济欠发达的内陆地区的数字普惠金融发展特征具有较大差异，青海、贵州、西藏的数字金融发展均呈现高增长量、高增速、高波动的特征。第二，数字经济发展、居民金融素养、金融规模均对我国数字普惠金融发展具有显著的线性促进作用，而投资规模和金融风险存在一定的非线性影响。具体来说，投资规模过大不利于数字普惠金融的发展，金融安全性过高会对数字普惠金融发展产生抑制作用。",
  "year": 2023,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7eaf2aaaea120f1777a0bf5e071e8a01",
  "timestamp": "2025-05-14T22:27:22.003620"
}