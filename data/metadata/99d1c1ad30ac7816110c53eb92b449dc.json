{
  "id": 2016,
  "title": "Optimal Balancing of Wind Parks with Virtual Power Plants",
  "abstract": "In this paper, we explore the optimization of virtual power plants (VPP), consisting of a portfolio of biogas power plants and a battery whose goal is to balance a wind park while maximizing their revenues. We operate under price and wind production uncertainty and in order to handle it, methods of machine learning are employed. For price modeling, we take into account the latest trends in the field and the most up-to-date events affecting the day-ahead and intra-day prices. The performance of our price models is demonstrated by both statistical methods and improvements in the profits of the virtual power plant. Optimization methods will take price and imbalance forecasts as input and conduct parallelization, decomposition, and splitting methods in order to handle sufficiently large numbers of assets in a VPP. The main focus is on the speed of computing optimal solutions of large-scale mixed-integer linear programming problems, and the best speed-up is in two orders of magnitude enabled by our method which we called Gradual Increase.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "99d1c1ad30ac7816110c53eb92b449dc",
  "timestamp": "2025-05-15T01:02:10.219271"
}