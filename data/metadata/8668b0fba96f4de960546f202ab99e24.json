{
  "id": 408,
  "title": "基于增强多维多粒度级联森林的信用评分模型",
  "abstract": "信用风险是商业银行所面临的主要金融风险之一,而传统的基于统计学习的信用评分方法不能有效利用现有的特征学习方法,因此预测准确度不高。为解决这个问题,提出一种增强多维多粒度级联森林的方法建立信用评分模型,借鉴残差学习的思想,建立了多维多粒度级联残差森林(grc Forest)模型,从而大幅增加提取的特征。除此之外,使用多维多粒度的扫描尽可能多地提取原始数据的特征,从而提高了特征提取的效率。对各模型的实验结果通过AUC(Area Under Curve)、准确率等指标进行评价,同时把所提模型与现有的统计学习和机器学习算法在四个不同的信用评分数据集上进行对比,可知所提出的模型的AUC值相较于轻量级梯度提升机(Light GBM)方法平均高1.13%,相较于极端梯度提升(XGBoost)方法平均高1.44%。从实验结果可以看出,提出的模型预测效果最佳。",
  "year": 2021,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8668b0fba96f4de960546f202ab99e24",
  "timestamp": "2025-05-14T22:30:01.765417"
}