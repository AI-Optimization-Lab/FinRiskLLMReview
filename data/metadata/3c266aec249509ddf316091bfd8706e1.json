{
  "id": 48,
  "title": "Deep joint learning valuation of Bermudan swaptions",
  "abstract": "This paper addresses the problem of pricing involved financial derivatives by means of advanced deep learning techniques. More precisely, we methodically integrate several sophisticated neural network-based concepts like differential machine learning, Monte Carlo simulation-like training samples and joint learning to come up with an efficient numerical solution. The application of the latter development represents a novelty in the context of computational finance. We also propose a novel design of interdependent neural networks to price early-exercise products, in this case, Bermudan swaptions. The improvements in efficiency and accuracy provided by the approach proposed here are widely illustrated throughout a range of numerical experiments. Moreover, this novel methodology can be extended to the pricing of other financial derivatives.",
  "year": 2025,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "3c266aec249509ddf316091bfd8706e1",
  "timestamp": "2025-05-15T01:28:03.800829"
}