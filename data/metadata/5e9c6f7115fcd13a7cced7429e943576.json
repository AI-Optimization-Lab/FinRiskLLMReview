{
  "id": 2578,
  "title": "Research on the impact mechanism of financial fraud risk among urban elderly in the context of population aging: Empirical data from China aging finance forum",
  "abstract": "This study uses data from the China Aging Finance 50 Forum's (CAFF50) surveys conducted in 2021, 2022, and 2023, applying panel regression analysis to examine the factors influencing financial fraud risks among urban elderly individuals in the context of population aging. Findings show that financial literacy helps protect urban seniors from financial losses due to fraud. Educational attainment partially mediates the relationship between financial literacy and susceptibility to financial fraud among this population. Moreover, pension savings are shown to moderate the link between financial literacy and fraud risk, with the effect varying across regions. This study provides valuable empirical evidence and theoretical insights, aligning with SSCI standards, to guide targeted financial protection policies for older people, enhance their financial literacy, and optimize pension savings strategies.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5e9c6f7115fcd13a7cced7429e943576",
  "timestamp": "2025-05-15T02:17:01.647284"
}