{
  "id": 1318,
  "title": "Semiparametric dynamic portfolio choice with multiple conditioning variables",
  "abstract": "Dynamic portfolio choice has been a central and essential objective for investors in active asset management. In this paper, we study the dynamic portfolio choice with multiple conditioning variables, where the dimension of the conditioning variables can be either fixed or diverging to infinity at certain polynomial rate of the sample size. We propose a novel data-driven method to estimate the optimal portfolio choice, motivated by the model averaging marginal regression approach suggested by Li et al. (2015). More specifically, in order to avoid the curse of dimensionality associated with the multivariate nonparametric regression problem and to make it practically implementable, we first estimate the marginal optimal portfolio choice by maximizing the conditional utility function for each univariate conditioning variable, and then construct the joint dynamic optimal portfolio through the weighted average of the marginal optimal portfolio across all the conditioning variables. Under some regularity conditions, we establish the large sample properties for the developed portfolio choice procedure. Both the simulation study and empirical application well demonstrate the finite-sample performance of the proposed methodology. (C) 2016 Elsevier B.V. All rights reserved.",
  "year": 2016,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b49e870a0ceada47f04c3442e9f9e53f",
  "timestamp": "2025-05-15T00:54:24.654098"
}