{
  "id": 2725,
  "title": "Earnings-based and accrual-based market anomalies: one effect or two?",
  "abstract": "This paper investigates whether the accrual pricing anomaly documented by Sloan (1996, The Accounting Review 71(3), 289-316) for annual data holds for quarterly data and whether this form of market mispricing is distinct from the post-earnings announcement drift anomaly. We find that the market appears to overestimate the persistence of the accrual component of quarterly earnings and, therefore, tends to overprice accruals. Moreover, the accrual mispricing appears to be distinct from post-earnings announcement drift. A hedge portfolio trading strategy that exploits both forms of market mispricing generates abnormal returns in excess of those based on either unexpected earnings or accruals information alone. (C) 2000 Elsevier Science B.V. All rights reserved. JEL classification: G14; M41.",
  "year": 2000,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d3a27b6035acc228bec0cb9949d6d9bc",
  "timestamp": "2025-05-15T01:09:43.381147"
}