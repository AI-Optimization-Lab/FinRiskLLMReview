{
  "id": 1411,
  "title": "Expected shortfall model based on a neural network",
  "abstract": "Considering both the limitations of traditional models of value-at-risk and expected shortfall (ES) for risk estimation in the context of the Basel standards and the possibilities of applying neural network models for risk estimation purposes, our paper presents a new ES model or, more specifically, an ES-extreme-value-theory (ESEVT) model improvement, as it is a combination of the standard multilayer perceptron model and the ES model based on EVT. This model exploits the advantages of both approaches in estimating financial risk. The model was tested on 15 example indexes of emerging European capital markets. The model quality assessment against the ES-EVT model used mean squared error, while model validation in the context of the Basel III standards was done using Berkowitz's ES backtesting, based on bootstrap simulation, and Acerbi and Szekely's first method. The results obtained imply that our neural network application improves ES-EVT model performance.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7224512caf6943296d8163c30afef710",
  "timestamp": "2025-05-15T02:02:22.818602"
}