{
  "id": 1306,
  "title": "Application of Pretopological Hierarchical Clustering for Buildings Portfolio",
  "abstract": "Our paper deals with the problem of the comparison of heterogeneous energy consumption profiles for energy optimization. Doing case-by-case in depth auditing of thousands of buildings would require a massive amount of time and money as well as a significant number of qualified people. Thus, an automated method must be developed in order to establish a relevant and effective recommendations system. Comparing sites to extract similar profiles refers to a machine learning set of methods called clustering. To answer this problematic, pretopology is used to model the sites' consumption profiles and a multi-criteria hierarchical clustering algorithm, using the properties of pretopological space, has been developed using a Python library. The pretopological hierarchical clustering algorithm is able to identify the clusters and provide a hierarchy between complex items. Tested on benchmarks of generated time series (from literature and from french energy company), the algorithm is able to identify the clusters using Pearson's correlation with an Adjusted Rand Index of I and returns relevant results on real energy systems' consumption data.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "24db1e53c5bc3cb930402d75a2373740",
  "timestamp": "2025-05-15T00:54:24.636744"
}