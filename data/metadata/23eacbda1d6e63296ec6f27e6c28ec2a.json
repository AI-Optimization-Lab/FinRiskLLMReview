{
  "id": 1780,
  "title": "Portfolio construction using bootstrapping neural networks: evidence from global stock market",
  "abstract": "The study investigates the investment value of global stock markets by a portfolio construction method combined with bootstrapping neural network architecture. A residual sample will be generated from bootstrapping sample procedure and then incorporated into the estimation of the expected returns and the covariant matrix. The outputs are further processed by the traditional Markowitz optimization procedure. In order to examine the efficacy of the proposed approach, the illustrated case was compared with traditional Markowitz mean-variance analysis, as well as the James-Stein and minimum-variance estimators. From the empirical results, it indicated that this novel approach significantly outperforms most of benchmark models based on various risk-adjusted performance measures. It can be shown that this new approach has great promise for enhancing the estimation of the investment value by Markowitz mean-variance analysis in the global stock markets.",
  "year": 2020,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "23eacbda1d6e63296ec6f27e6c28ec2a",
  "timestamp": "2025-05-15T00:59:23.045940"
}