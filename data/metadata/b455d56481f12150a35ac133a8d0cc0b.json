{
  "id": 58,
  "title": "Hierarchical Learning for Option Implied Volatility Pricing",
  "abstract": "Machine learning has been a popular option implied volatility pricing approach. It brings a good generalization in pricing by avoiding building different models for different options. However, it suffers from a relatively low prediction accuracy besides a model selection issue. In this study, we propose a novel hierarchical learning approach to enhance machine learning implied volatility pricing. It is designed for the 'learning-hard' problem and boosts different machine learning models' performance for different option data on behalf of moneyness besides identifying the optimal learning models. In particular, the proposed hierarchical learning can be an excellent way to enhance implied volatility pricing for the option datasets with more noise. In addition, we find out-of-the-money options fit machine learning prediction better than the other options. This pioneering study provides a robust way to enhance implied volatility pricing via machine learning and will inspire similar studies in the future.",
  "year": 2021,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b455d56481f12150a35ac133a8d0cc0b",
  "timestamp": "2025-05-15T01:28:03.822422"
}