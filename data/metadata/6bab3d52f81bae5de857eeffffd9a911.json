{
  "id": 798,
  "title": "Detection of Banking Financial Frauds Using Hyper-Parameter Tuning of DL in Cloud Computing Environment",
  "abstract": "When income, assets, sales, and profits are inflated while expenditures, debts, and losses are artificially lowered, the outcome is a set of fraudulent financial statements (FFS). Manual auditing and inspections are time-consuming, inefficient, and expensive options for spotting these false statements. Auditors will find great assistance from the use of intelligent methods in the analysis of several financial declarations. Now more than ever, victims of financial fraud are at risk since more and more individuals are using the Internet to conduct their financial transactions. And the frauds are getting more complex, evading the protections that banks have put in place. In this paper, we offer a new-fangled method for detecting fraud using NLP models: an ensemble model comprising Feedforward neural networks (FNNs) and Long Short-Term Memories (LSTMs). The Spotted Hyena Optimizer is a unique metaheuristic optimization technique used to choose weights and biases for LSTM (SHO). The proposed method takes inspiration from the law of gravity and is meant to mimic the group dynamics of spotted hyenas. Mathematical models and discussions of the three fundamental phases of SHO - searching for prey, encircling prey, and at-tacking prey - are presented. We build a model of the user's spending habits and look for suspicious outliers to identify fraud. We do this by using the ensemble mechanism, which helps us predict and make the most of previous trades. Based on our analysis of real-world data, we can confidently say that our model provides superior performance compared to state-of-the-art approaches in a variety of settings, with respect to both precision and.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6bab3d52f81bae5de857eeffffd9a911",
  "timestamp": "2025-05-15T01:42:44.471052"
}