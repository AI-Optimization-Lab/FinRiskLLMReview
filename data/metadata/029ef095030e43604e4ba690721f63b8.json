{
  "id": 6165,
  "title": "Bond pricing with a surface of zero coupon yields",
  "abstract": "We present a new method for consistent cross-sectional pricing of all traded bonds in the fixed income market. By applying thin plate regression splines (Wood, 2003) to bootstrapped zero coupon bond yields (Hagan and West, 2006), the method decomposes traded yields into a risk-free component plus premia for credit and liquidity risks, where the decomposition is consistent with the market valuations and underlying cash flows of the bonds. We apply the framework to end of quarter yield data from 2008 to 2011 on Australian dollar denominated semi-government, supranational and agency (SSA) bonds, and find that the surface provides an excellent fit to the underlying zero coupon yield curves. Further, the decomposition of selected yield time series and cross-sections demonstrates how credit premia increased for Australian SSA bonds through the Global Financial Crisis (GFC), but were counterbalanced by liquidity discounts as investors sought safe haven securities.",
  "year": 2013,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "029ef095030e43604e4ba690721f63b8",
  "timestamp": "2025-05-15T02:55:44.433117"
}