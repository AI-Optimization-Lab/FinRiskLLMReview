{
  "id": 7645,
  "title": "Payment reform and changes in health care in China",
  "abstract": "This paper is intended to assess the primary effects on cost, utilization and quality of care from payment reform of capitation and open enrollment in Changde city, Hunan Province of China. Open enrollment policy was introduced to deal with possible cream skimming associated with capitation. Based on the longitudinal Urban Resident Basic Medical Insurance (URBMI) Household Survey, this study analyses the URBMI data through a set of regression models. The original data included over five thousand inpatient admissions during the study period between 2008 and 2010. The study finds the payment reform to reduce its inpatient out-of-pocket cost by 19.7%, out-of-pocket ratio by 9.5%, and length of stay by 17.7%. However, the total inpatient cost, drug cost ratio, treatment effect, and patient satisfaction showed little difference between Fee-For-Service and capitation models. We conclude that the payment reform in Changde did not reduce overall inpatient expenditure, but it decreased the financial risk and length of stay of inpatient patients without compromising quality of care. The findings would contribute to the health care payment literatures from developing countries and open further research tracks on the ability of open enrollment to compensate for capitation drawbacks. (C) 2014 Elsevier Ltd. All rights reserved.",
  "year": 2014,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b9e2bc23546cd93a1df6aaf685a2f117",
  "timestamp": "2025-05-15T03:10:33.068377"
}