{
  "id": 2144,
  "title": "The context of Industry 4.0 in the educational process of engineering",
  "abstract": "The advent of Industry 4.0 directly changes the industrial environment, making the boundaries between technologies, human beings, digital and physical world increasingly smaller. In this context, it is important for people and machines to start working together and collaboratively. Such changes interfere in the dynamics of companies and the job market, increasing the demand for multifunctional professionals who present a varied portfolio of technical and socio-emotional skills. Given these changes, universities are expected to assist students in developing what is expected by the market. However, there is an incompatibility between what is currently required by companies and what is offered in educational institutions. Faced with this situation, a question arises: How does the new dynamics of the job market interfere in the teaching-learning process of engineers? This article aims to answer this question, analyzing the necessary skills for engineers and how to develop them using Active Learning Methodologies, in view of the advent of Industry 4.0.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "950b3968da4253e5c9404cf64c55bdf8",
  "timestamp": "2025-05-15T01:03:36.611573"
}