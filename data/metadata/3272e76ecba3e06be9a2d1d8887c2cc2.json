{
  "id": 2964,
  "title": "The Optimal Hedge Ratio of Stock Index Futures : An Empirical Analysis Based on Copula-GARCH Model",
  "abstract": "One of the main functions of the stock index futures is hedging. Hedgers can use futures contracts to reduce or shift the risk of price fluctuation for risk management. Based on the traditional way of calculating the optimal hedge ratio, this paper resorted to copula approach and Kendall's tau rank correlation parameter to calculate the tail-related correlation in order to capture certain nonlinear features of financial time-series such as heavy-tailed distributions and clustering of outliers. We implement this method to do an empirical study with the data of KOSPI200 stock index futures in South Korea and the empirical tests show that the hedge performance has been improved by introducing the nonlinear correlation coefficient.",
  "year": 2008,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "3272e76ecba3e06be9a2d1d8887c2cc2",
  "timestamp": "2025-05-15T02:21:19.178394"
}