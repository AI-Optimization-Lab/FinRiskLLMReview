{
  "id": 409,
  "title": "Carbon risk and return prediction: Evidence from the multi-CNN method",
  "abstract": "This paper investigates the carbon risk and its role in stocks' return prediction by identifying the carbon risk information implied in feature engineering. We predict the stock returns with different neural networks, construct the investment portfolio according to the predicted returns and reflect the returns of stocks with different carbon risks through the relevant evaluation of the investment portfolio. Our Multi-CNN method can best collect information on different relationship types and make full use of graph structure data to identify carbon risks. With or without carbon factor, the stock market performance of high-carbon industry is better than that of medium-carbon industry, and the performance of low-carbon industry is the worst. Moreover, our finding is consistent in both Chinese and American markets. Investment should pay attention to carbon risk and requires corresponding carbon risk premium.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "fd2ef1f22557519ad99574e2fb7811ac",
  "timestamp": "2025-05-15T00:35:49.669803"
}