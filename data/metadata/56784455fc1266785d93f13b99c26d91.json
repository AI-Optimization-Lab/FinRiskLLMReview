{
  "id": 5933,
  "title": "Quantity of Acellular Dermal Matrix in Immediate Breast Reconstruction and Outcomes",
  "abstract": "Purpose This study aimed to determine the impact of the quantity of acellular dermal matrix (ADM), ADM burden, used in implant-based breast reconstruction on infection, drain duration, and seroma formation. Methods A single-institution, retrospective review from 2015 to 2020 was conducted for patients who underwent immediate, implant-based breast reconstruction after mastectomy. Three cohorts were generated based on the amount of ADM used: (1) total ADM, (2) sling ADM, and (3) no ADM. Results In total, there were 374 patients who satisfied the inclusion criteria yielding 641 breasts with 143, 432, and 66 breasts in the total ADM, sling ADM, and no-ADM groups, respectively. The no-ADM group had higher mastectomy weights (788.4 g) than the sling (654.2 g) and total ADM (503.4 g) groups (F = 10.8, P < 0.001). Total ADM had higher rates of explantation secondary to infection compared with no ADM (P < 0.001). Linear regression analysis for drain duration was significant for body mass index (P < 0.0001) but not for ADM quantity (P = 0.52). Logistic regression analysis demonstrated a higher risk of infection in the total ADM group (odds ratio [OR], 5.4; P < 0.0001). Diabetes mellitus was a risk factor for both infection (OR, 3.6; P = 0.05) and seroma formation (OR, 0.04; P = 0.04). Conclusions Higher ADM burden is associated with an increased risk of infections and device explantation secondary to those infections. Although ADM has created new avenues in breast reconstruction, these findings indicate a need to evolve the technique to minimize the ADM burden. By doing so, patients can minimize their risk of postoperative complications while reducing the financial impact on institutions.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "56784455fc1266785d93f13b99c26d91",
  "timestamp": "2025-05-15T02:53:03.075508"
}