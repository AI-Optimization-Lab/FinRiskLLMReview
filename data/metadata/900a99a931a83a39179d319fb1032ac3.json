{
  "id": 7952,
  "title": "Convex-concave effect of financial flexibility on hospitality performance: quantile regression approach",
  "abstract": "Purpose - The purpose of this paper is to study the influence of financial flexibility (FF) on enterprise performance (EP) within Taiwan's hospitality industry during the COVID-19 shock and explore whether EP varies with hospitality industry characteristics. Design/methodology/approach - Secondary data of 39 Taiwan Stock Exchange-listed hospitality firms were collected from the Taiwan Economic Journal databases. Quantile regression analysis was applied to examine the FF-EP relationship Findings - The results evidence that there is a U-shaped (convex) FF-EP relationship for hospitality firms in the 10th, 25th and 50th Tobin's Q quantiles and in asset-heavy firms. For asset-light firms, FF has an inverted U-shaped (concave) effect on EP in the 90th Tobin's Q quantile Practical implications - The empirical results highlight the need for Taiwan's hospitality industry as a whole to take rolling adjustment and optimization of FF and concentrate on liquidity risk management after the COVID-19 pandemic and for long-term sustainability. Originality/value - To the best of the authors' knowledge, this study is one of the first to examine the nonlinear FF-EP relationship in the hospitality industry of Taiwan, particularly amid the COVID-19 shock. Moreover, this study extends current literature by revealing the hospitality industry's FF-EP relationship and highlights the importance of the pandemic crisis context.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "900a99a931a83a39179d319fb1032ac3",
  "timestamp": "2025-05-15T03:13:30.712160"
}