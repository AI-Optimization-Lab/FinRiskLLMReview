{
  "id": 531,
  "title": "Financial time series prediction using l2,1 RF-ELM",
  "abstract": "Financial time series forecasting is a complicated task because the behavior of investors can be influenced by lots of tiny and unpredictable factors. In this paper, in order to maximize the return of capital and manage liquidity risk effectively, an l(2,1)-norm and Random Fourier Mapping based Extreme Learning Machine(l(2,1) RF-ELM) is applied to the problem of financial time series prediction. The advantages of ELM in efficiency and generalization performance over traditional fuzzy neural network( FNN) algorithms have been demonstrated on a wide range of problems from different fields, thanks to the integration of l(2,1)-norm, the l(2,1) RF-ELM is able to automatically prune the irrelevant and redundant hidden neurons to form a more discriminative and compact hidden layer. The performance of the l(2,1) RF-ELM is compared with other hidden layer enforcement algorithms, two long-term time series data sets, including TianChi and BCS, are used for this comparison. The performance of the l(2,1) RF-ELM was comparable to those of other widely used machine learning techniques like support vector machines (SVM), artificial neural networks (ANN) and other popular ELM method. The experiments demonstrate favorable prediction results of the l(2,1) RF-ELM in terms of annualized return, prediction error and running time. In addition, we also find that the underlying rules of the correlation between cash inflow and outflow that can help us improve accuracy, which is valuable for financial institutions to predict the trend of liquidity. (C) 2017 Elsevier B.V. All rights reserved.",
  "year": 2018,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "af26825569d771b86a42fa5aa7bf0f4f",
  "timestamp": "2025-05-15T01:52:12.234669"
}