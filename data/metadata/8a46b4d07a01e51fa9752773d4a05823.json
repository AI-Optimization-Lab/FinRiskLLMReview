{
  "id": 6890,
  "title": "Predicting bankruptcy in resort hotels: a survival analysis",
  "abstract": "Purpose - This study aims to examine variables influencing resort hotels' survival in Spain, which had not previously been analysed. In this country, determining whether the reasons resort hotels close are different from other hotels could be imperative to resort hotels' survival. Design/methodology/approach - The survival analysis used Cox's semi-parametric proportional hazards regression to determine which variables influence hotel closure and how much each variable increases risk of closure. Findings - Resort hotel closure depends on hotel size, location, executive management and the business cycle. Survival is not affected by hotel type or financial structure. Research limitations/implications - While this methodology is common in business survival analyses, it has seldom been applied to hotels and has never been used to study the survival of resort hotels. Practical implications - Companies need to rethink the location of new hotels. For already-built facilities, good management practices are strategically important for resort hotels' survival. Originality/value - This paper explores the reasons why resort hotels survive. The study's selection of variables and methodology and its conclusions are unique.",
  "year": 2019,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8a46b4d07a01e51fa9752773d4a05823",
  "timestamp": "2025-05-15T03:02:41.274923"
}