{
  "id": 68,
  "title": "我国金融市场输入性风险的时变分析与预警研究",
  "abstract": "随着中国金融市场的高水平开放，中国应对外部输入性风险的压力将进一步上升。探索中国金融市场所面临的输入性风险动态变化并构建预警体系具有重要意义。本文运用时变参数向量自回归模型(TVP-VAR)和深度神经网络模型SCInet(Sample Convolution and Interaction Network),对我国金融市场输入性风险进行测度和前瞻性预警。研究发现：(1)TVP-VAR模型能有效识别极端风险事件发生前的风险积累，极端风险事件时期输入性风险水平会显著提高；(2)通过与主要发达国家(或地区)和发展中国家的输入性风险对比，发现发达经济体的输入性风险波动幅度较小，通过研究各国（地区）对我国的输入性风险，发现香港对我国内地的风险输入水平最高，以美国为主的发达国家和以印度为主的发展中国家也向我国输送了大量风险；(3)相比于其他机器学习和神经网络模型，SCInet模型具有最优的预警性能，在输入性风险异常波动前能提前预警。本研究或可为个人规避风险、企业可持续发展、国家金融稳定提供参考和帮助。",
  "year": 2024,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "824f30dec90df58a3504cc5d6d7704a4",
  "timestamp": "2025-05-14T22:26:31.849934"
}