{
  "id": 2704,
  "title": "2D:4D, Optimism, and Risk Taking",
  "abstract": "Testosterone has been associated with a wide range of behaviors. Digit ratio (2D:4D), a somatic marker of prenatal testosterone, has been associated with risk taking, but the findings are inconsistent. The present study sought to investigate an interactionist model combining biological and personality factors in explaining risk taking. Power has been previously found to moderate the relationship between 2D:4D and risk taking. It has also been suggested that optimism plays a mediating role in the relationship between power and risk taking. In light of these interconnections, the present study explored the interaction between 2D:4D and optimism as a predictor of self-reported risk taking. Two hundred and eleven participants (102 men and 109 women) completed self-report measures of optimism and risk taking, and their prenatal testosterone was estimated by left and right 2D:4D ratios. Moderated regression analysis showed that optimism moderated the association between left 2D:4D and general risk taking, with men and women taking more risk with lower 2D:4D and lower optimism levels. Further moderated regression analysis, including participants' sex, revealed that optimism moderated the association between right 2D:4D and financial risk taking, but only in women, exhibiting more financial risk taking with lower 2D:4D but higher optimism levels.",
  "year": 2019,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "9d6aec44103712997a39ef95ed605bce",
  "timestamp": "2025-05-15T02:18:06.271279"
}