{
  "id": 2550,
  "title": "Unleashing the Potential of Mixed Frequency Data: Measuring Risk with Dynamic Tail Index Regression Model",
  "abstract": "Understanding why extreme events occur is crucial in many fields, particularly in managing financial market risk. In order to explain such occurrences, it is necessary to use explanatory variables. However, flexible models with explanatory variables are severely lacking in financial market risk management, particularly when the variables are sampled at different frequencies. To address this gap, this article proposes a novel dynamic tail index regression model based on mixed-frequency data, which enables the high-frequency variable of interest to depend on both high- and low-frequency variables within the framework of extreme value regression. Specifically, it concurrently leverages information from low-frequency macroeconomic variables and high-frequency market variables to model the tail distribution of high-frequency returns, consequently enabling the computation of high-frequency Value at Risk and Expected Shortfall. Monte Carlo simulations and empirical studies show that the proposed method effectively models stock market tail risk and produces satisfactory forecasts. Moreover, including macroeconomic variables in the model provides insights for macroprudential regulation.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "26e7aecdd1244a46b46a836eaeb29caa",
  "timestamp": "2025-05-15T02:16:32.714560"
}