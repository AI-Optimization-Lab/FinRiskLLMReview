{
  "id": 205,
  "title": "Gated Neural Network-Based Mean-EVaR-Skewness Portfolio Optimization under Uncertain Environment",
  "abstract": "Numerous empirical studies show that portfolio returns are generally asymmetric, and investor would prefer a portfolio return with larger degree of asymmetry along with risk and return. In this paper, a concept of skewness is defined as the third central moment and studied its mathematical properties. To predict the stock prices, a novel recurrent neural network with gated recurrent unit (GRU) cell is preferred. Based on these predictions, stock returns, entropic value at risks and skewness are calculated. A mean-EVaR-skewness multi-objective portfolio optimization model is devised to account for market uncertainty. Cardinality, bounding restrictions, and liquidity are considered in addition to risk and return to make the model more effective. Uncertain goal programming is used to solve the proposed model. Finally, an example portfolio is presented to display the efficacy and the feasibility of the model suggested in this paper.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c30048db0056052c4890b1f8d1151aa4",
  "timestamp": "2025-05-15T00:40:34.107767"
}