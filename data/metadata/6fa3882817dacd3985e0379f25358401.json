{
  "id": 4884,
  "title": "The Effect of Regulatory Pressure on the Capital Level and Risk Level in Chinese Banks",
  "abstract": "The outbreak of the US subprime mortgage financial crisis swept across the world in 2008 and international regulatory authorities adopted the most representative measure-Basel III- against the crisis in 2010. The present work brings insight into the effect of capital regulation on commercial bank based on the panel data of ten Chinese commercial banks from 2006 to 2013. This paper uses the multiple linear regression equation which was established by Shrieves and Dahl. This work chooses capital level and risk level as the dependent variables. The evaluating variables are bank's size of asset, net profit level, rate of bad loans, regulatory pressure and ownership structure. The results show that the regulatory pressure has negative effect on capital level, while nearly has no significance on risk level.",
  "year": 2015,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6fa3882817dacd3985e0379f25358401",
  "timestamp": "2025-05-15T02:42:04.864153"
}