{
  "id": 3216,
  "title": "NEUD-TRI: Network Embedding Based on Upstream and Downstream for Transaction Risk Identification",
  "abstract": "Invoices serve as records of financial transactions of taxpayers and significant b asis t o c ontrolling t ax source and collection of tax, via analyzing which, we can discern diversified tasks of tax risk, such as industry identification, hidden transaction detection, and illegal behavior mining. Among all the existing studies related to the identification of t ax r isk, there are some weaknesses through the machine learning model and network analysis because of the dependence on tax knowledge. Different from the manual selection of indicators and the manual definitions mode with the guidance of tax knowledge in the past, in this paper, we propose a novel method, namely, network embedding based on upstream and downstream for tax risk identification (NEUD-TRI), which considers the taxpayers serving as both seller and purchaser. The method designs optimization functions respectively to capture local and global static network structures and dynamic network structure. In view of the significant discrepancy of weights in the transaction network, this paper normalizes the weight within the range of the upstream and downstream of the vertex. Negative sampling and edge sampling are adopted to deal with the large-scale trait of the transaction network. Empirical results on tax data-sets of a province substantiate the effectiveness of our models.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "436855fa1d0f37b4d77b64944cf71ee8",
  "timestamp": "2025-05-15T02:24:05.010414"
}