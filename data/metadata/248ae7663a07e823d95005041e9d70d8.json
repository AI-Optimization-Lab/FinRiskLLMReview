{
  "id": 1002,
  "title": "On the Effectiveness of Graph Statistics of Shareholder Relation Network in Predicting Bond Default Risk",
  "abstract": "Starting from the theoretical effectiveness of shareholder relation network information for predicting bond default risk, we propose two efficient schemes for extracting two different graph statistics of shareholder relation networks: graph structure statistics and graph distance statistics. In order to test the effectiveness of the two schemes, seven machine learning methods and three types of prediction tasks are used. The shareholder relation network information's effectiveness and machine learning methods are also analyzed. Results show that the graph statistics of shareholder relationship networks are insufficient to be used independently as input features for predicting bond default risk but can provide helpful incremental information based on financial features. The shareholder relation information is effective for predicting bond default risk. The structure statistics perform best among all graph statistics overall, and Cascade Forest and LightGBM perform best among all seven machine learning methods.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "248ae7663a07e823d95005041e9d70d8",
  "timestamp": "2025-05-15T01:57:29.969560"
}