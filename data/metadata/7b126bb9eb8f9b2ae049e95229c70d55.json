{
  "id": 1420,
  "title": "Towards firm-specific technology opportunities: A rule-based machine learning approach to technology portfolio analysis",
  "abstract": "Despite the substantial contributions of many studies on firm-specific technology opportunity analysis (TOA), there is a lack of understanding of the technology portfolios of organizations and actors of technology innovation activities. The study proposes a new firm-specific TOA approach using graph representation, rule-based machine learning, and index analysis. First, organizations' technology portfolios are characterized by multiple graphs consisting of technological components based on their own patent information. Second, given an organization of interest for a TOA, its core technology, which is represented as links between technological components, is defined and significant association rules are identified through our rule-based machine learning pipeline. Third, new-to-firm technology opportunities are identified from a set of association rules and evaluated using quantitative metrics. Finally, we examine the evaluation metrics on which each organization focuses by tracking the patenting activities of the organizations after the analysis period. Consequently, we can enhance the understanding of organizational technology portfolios and provide firm-specific technology opportunities. Our empirical results for multiple organizations showed that the proposed approach is effective and valuable as a decision-supporting tool for TOA in practice.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7b126bb9eb8f9b2ae049e95229c70d55",
  "timestamp": "2025-05-15T00:55:28.520095"
}