{
  "id": 2109,
  "title": "Constrained matrix factorization for financial data clustering",
  "abstract": "Financial time series analysis is crucial to a successful assets allocation. Applying a matrix factorization technique can generate genuine grouping knowledge for the allocation of assets according to their association with a number of underlying bases. A constrained nonnegative matrix factorization NSMF is proposed to incorporate three penalties in order to compute a solution which can maximize between-base disjointness and volatility difference. A series of quantitative measures are designed for evaluation of bases and their volatility. Different types of real data are used in the experiments and compared regarding clustering consistency. Experimental analysis of historical prices of US blue chip stocks indicates that NSMF is superior to agglomerative clustering and independent component analysis and NSMF can extract bases with a higher discrepancy of volatility. The non-stochasticity constraint increases the dissimilarity of bases and it governs basis deviation over smoothness and sparseness. The clustering results of bases and persistent pairs, which are gained from NSMF, can consolidate our understanding of financial data properties and they provide meaningful knowledge in the construction of a well risk-balanced and diversified portfolio.",
  "year": 2015,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "03697880ea5570aa0d2dacd253ff5e52",
  "timestamp": "2025-05-15T02:10:59.113335"
}