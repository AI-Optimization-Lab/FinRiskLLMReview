{
  "id": 313,
  "title": "Portfolio use in general practice vocational training: a survey of GP registrars",
  "abstract": "Background Portfolios are increasingly advocated in medical education. Qualitative studies have suggested their value in stimulating experiential learning, promoting deep learning and encouraging reflection. This study explored the use of educational portfolios in reflective learning by general practice (GP) registrars in Yorkshire, England. Method A postal questionnaire was sent to the 92 registrars of a deanery in November 2001, after a pilot study with registrars in a single district had been carried out. The questionnaire explored the registrars' use of the portfolio to collect information and for reflection, as well as registrars' attitudes towards the portfolio. It was returned by 71 registrars, representing a 77% response rate. Structured in-depth interviews were used to support the results obtained. Results Of the registrars who responded, 65% recorded information on a regular basis and 42% used the portfolio in reflective learning. Experienced registrars used the portfolio least. Those with supportive trainers used the portfolio more in reflection. Conclusions The study suggests that the role of the trainer/supervisor is vital in portfolio-based learning. It raises questions about the acceptability of portfolio learning. It adds weight to the suggestion that careful introduction of portfolios and training of supervisors is vital. Further work to establish the role of portfolios in reflective learning is recommended.",
  "year": 2004,
  "source": "WOS",
  "area": "portfolio",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "df26ce72e42c74e4f68b218a48ad59ab",
  "timestamp": "2025-05-15T00:34:44.332554"
}