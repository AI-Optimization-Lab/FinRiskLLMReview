{
  "id": 1447,
  "title": "Weight bound constraints in mean-variance models: a robust control theory foundation via machine learning",
  "abstract": "Using an innovative representation of the weight bound constrained Markowitz's (Portfolio selection. J. Finance, 1952, 7, 77-91) mean-variance model, developed using the support vector data description, a machine learning algorithm introduced by Tax and Duin (Support vector data description. Mach. Learn., 2004, 54, 45-66), we provide an innovative interpretation of the robustness of these bound constraints in terms of robust control theory in the sense of Hansen and Sargent (Robust control and model uncertainty. Am. Econ. Rev., 2001, 91, 60-66). Building on these insights, firstly, we detail the method for quantifying the degree of misspecification in Markowitz's (1952) mean-variance model using its counterpart with weight upper bounds. Additionally, we show that this degree of misspecification is a decreasing piecewise linear function of the bound. Secondly, we empirically investigate two simulation-based methods, inspired by Michaud's (The Markowitz optimization enigma: Is 'optimized' optimal? Financ. Anal. J., 1989, 45, 31-42) resampling technique, for choosing the bound. Thirdly, we compare the robustness of the weight upper bound constrained mean-variance model with that of Goldfarb and Iyengar's (Robust portfolio selection problems. Math. Oper. Res., 2003, 28, 1-38) robust maximum return model.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "076141bdfaaee75cf8aeb64018ca98ca",
  "timestamp": "2025-05-15T00:56:08.256053"
}