{
  "id": 807,
  "title": "Portfolio optimization through hybrid deep learning and genetic algorithms vine Copula-GARCH-EVT-CVaR model",
  "abstract": "This study investigates the potential benefits of using the Conditional Value at Risk (CVaR) portfolio optimization approach with a GARCH model, Extreme Value Theory (EVT), and Vine Copula to obtain the optimal allocation decision for a portfolio consisting of Bitcoin, gold, oil, and stock indices. First, we fit a suitable GARCH model to the return series for each asset, followed by employing the Generalized Pareto Distribution (GPD) to model the innovation tails. Next, we construct a Vine Copula-GARCH-EVT model to capture the interdependence structure between the assets. To refine risk assessment, we combine our model with a Monte Carlo simulation and MeanCVaR model to optimize the portfolio. In addition, we utilize a novel version of deep machine learning's genetic algorithm to address the optimization decision. This research contributes new evidence to the CVaR portfolio optimization approach and provides insights for portfolio managers seeking to optimize multi-asset portfolios.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5a66f66625a7387b3b80a89546c953f9",
  "timestamp": "2025-05-15T00:48:22.364883"
}