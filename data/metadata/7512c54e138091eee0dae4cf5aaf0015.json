{
  "id": 2397,
  "title": "Higher-order comoments and asset returns: evidence from emerging equity markets",
  "abstract": "This article examines the role of co-skewness and co-kurtosis in explaining portfolio excess returns utilizing time-series and Fama-Macbeth cross-sectional regression methods in the context of an emerging market. The sample consists of listed firms in Vietnam stock market covering the period from September 2011 to December 2016. This paper reports that co-skewness and co-kurtosis are not important in explaining stock returns in Vietnam stock market. More importantly, we find that market risk premium is the most important factor while other popular factors such as SMB, HML and UMD have minor impact on stock returns. This finding is crucial in identifying factors significantly influencing stock returns in emerging equity markets. This paper also supports the proposition that findings from advanced markets might not be able to generalize into the context of emerging markets. The finding has direct implications for portfolio analysis and risk management.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7512c54e138091eee0dae4cf5aaf0015",
  "timestamp": "2025-05-15T01:06:38.030477"
}