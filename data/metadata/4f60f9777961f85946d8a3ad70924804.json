{
  "id": 1021,
  "title": "CVA Hedging with Reinforcement Learning",
  "abstract": "This work considers the problem of a trader who must manage the Credit Valuation Adjustment (CVA) of a derivative, defined as the risk-neutral expectation of losses incurred if the counterparty of the derivative defaults. CVA can be regarded as a hybrid product, one of the most complex actively managed by a trading desk. Standard delta hedging based on sensitivities is not completely satisfactory for this product, because it ignores trading costs and jump-to-default risk while introducing unavoidable simplifications in the pricing model. In this paper we use risk-averse Reinforcement Learning to learn a superior hedging strategy compared to the standard delta hedging approach. Specifically, we generalize risk-averse Reinforcement Learning to stochastic horizons, to be compatible with counterparty defaults, and we introduce a realistic framework for the mechanics of the hedger's portfolio in which the data generating process of the underlying risk drivers can be inconsistent with the risk-neutral laws used to price the CVA and the hedging instruments. The potential of the proposed approach is investigated empirically by numerical examples on hedging the CVA of a forex forward.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "4f60f9777961f85946d8a3ad70924804",
  "timestamp": "2025-05-15T00:50:40.820690"
}