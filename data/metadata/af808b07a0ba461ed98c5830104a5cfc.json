{
  "id": 203,
  "title": "投资组合视角下机构投资者治理行为分析：一个权变的观点",
  "abstract": "作为独立于管理层与股东之外的第三方力量，机构投资者在提高公司治理水平方面一直被国内外学者和政府监管部门寄予厚望。然而，目前公司治理领域有关机构投资者治理角色研究尚存在有效监督、无效监督、战略合谋三种争论。为回答机构投资者在公司治理中究竟发挥何种作用的问题，文章以企业两类代理成本为切入点，从投资组合角度重新审视了机构投资者的治理行为，并结合不同内外情境解释了其参与治理行为的权变观点。基于委托代理理论和有限注意理论，利用2013—2017年我国沪、深A股上市公司样本数据。通过定义监督型机构投资者，从投资组合权重与投资组合集中度两个维度，采用固定效应回归模型实证检验了机构投资者对公司两类代理成本的影响，并运用工具变量法对结果进行稳健性检验，同时结合公司内外不同情境，借助分样本检验辩证分析了机构投资者的治理行为差异。研究结果表明：投资组合作为机构投资者分散风险的投资行为模式，在参与治理的过程中表现出了“双刃剑”效应，监督型机构投资者与投资组合集中度在降低大股东与中小股东之间第二类代理成本的同时，却以提升股东与管理层之间的第一类代理成本为代价。进一步从外部市场环境与内部高管、控股股东三个方面，发现机构投资者在不同情境下的治理行为存在差异，具体表现为在欠发达地区与存在强权高管的上市公司内，机构投资者加剧第一类代理成本的现象表现得更为明显；而公司内支持型控股股东的存在，则会加强机构投资者对第二类代理成本的抑制作用。上述研究运用权变的观点，实现了从以往关注机构投资者“持股数量”向“投资组合集中度”研究的创新性转变，在丰富机构投资者研究视角的同时，为以权变观点看待机构投资者治理行为的合理性提供依据。研究一方面能够帮助上市公司通过引入监督型机构投资者进行管理创新，提升其治理水平实现高质量发展；另一方面也为证监会创新监管模式，运用权变的观点充分认识机构投资者的治理行为，制定分类引导异质机构投资者的相关文件提供理论参考。",
  "year": 2022,
  "source": "CNKI",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "af808b07a0ba461ed98c5830104a5cfc",
  "timestamp": "2025-05-14T22:12:12.722278"
}