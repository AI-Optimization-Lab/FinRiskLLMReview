{
  "id": 1078,
  "title": "Quantitative Investment with Machine Learning in US Equity Market",
  "abstract": "Quantitative investment attempts to use computer algorithms to predict the price of securities and make automatic trading, in order to gain excess return on the stocks. This paper introduces a strategy based on machine learning algorithms and technical indicators. The model uses several popular technical indicators as inputs and predicts the movement of stock price after a certain short period. Then, a portfolio is constructed using the prediction result. The strategy buys the stocks whose returns exceed the predetermined threshold and sells (shorts) the stocks whose return are below the negative threshold. The empirical results show that the annual return is above 40%, which is far higher than the S&P500 index(2.14%). Considering the risk-adjusted return, the machine learning strategy is better than the S&P500 index. The Sharpe Ratio is higher than that of the S&P500.",
  "year": 2018,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "98966022c6a6842e289ae0532c9d92b7",
  "timestamp": "2025-05-15T00:51:25.954499"
}