{
  "id": 3078,
  "title": "A New Extended Geometric Distribution: Properties, Regression Model, and Actuarial Applications",
  "abstract": "In this paper, a new modified version of geometric distribution is proposed. The newly introduced model is called transmuted record type geometric (TRTG) distribution. TRTG distribution is a good alternative to the negative binomial, Poisson and geometric distributions in modeling real data encountered in several applied fields. The main statistical properties of the new distribution were obtained. We determined the measures of value at risk and tail value at risk for the TRTG distribution. These measures are important quantities in actuarial sciences for portfolio optimization under uncertainty. The TRTG parameters were estimated via maximum likelihood, moments, proportions, and Bayesian estimation methods, and the simulation results were determined to explore their performance. Furthermore, a new count regression model based on the TRTG distribution was proposed. Four real data applications were adopted to illustrate the applicability of the TRTG distribution and its count regression model. These applications showed empirically that the TRTG distribution outperforms some important discrete models such as the negative binomial, transmuted geometric, discrete Burr, discrete Chen, geometric, and Poisson distributions.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "e2227c5de2fb177e3937c9be5b67e814",
  "timestamp": "2025-05-15T01:13:09.904890"
}