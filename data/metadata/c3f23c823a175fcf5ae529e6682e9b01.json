{
  "id": 5847,
  "title": "Early Care and Education Workers' Experience and Stress during the COVID-19 Pandemic",
  "abstract": "Early care and education (ECE) workers experience many job-related stressors. During the COVID-19 pandemic, ECE programs either closed or remained open while workers faced additional demands. We deployed a survey of the center-based ECE workforce in Washington State (United States) one year into the COVID-19 pandemic to assess impacts and workers' perceived stress levels. We describe the prevalence of reported impacts, including workplace closures; job changes; COVID-19 transmission; risk factors for severe COVID-19; the use of social distancing practices; satisfaction with workplace responses; perceptions of worker roles, respect, and influence; and food and financial insecurity. Themes from open-ended responses illustrate how workers' jobs changed and the stressors that workers experienced as a result. Fifty-seven percent of ECE workers reported moderate or high levels of stress. In a regression model assessing unique contributions to stress, work changes that negatively impacted home life contributed most to stress. Feeling respected for one's work and feeling positive about one's role as an essential worker contributed to lower levels of stress. Experiencing financial insecurity, caring for school-aged children or children of multiple ages, being younger, and being born in the United States also contributed to higher stress. Findings can inform policies designed to support the workforce.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c3f23c823a175fcf5ae529e6682e9b01",
  "timestamp": "2025-05-15T02:51:58.643450"
}