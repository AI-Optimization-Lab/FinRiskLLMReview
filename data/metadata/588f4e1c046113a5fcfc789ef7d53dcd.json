{
  "id": 1228,
  "title": "Research on Support Vector Regression in the Stock Market Forecasting",
  "abstract": "As the stock market has high noise, nonlinearity, uncertainty characteristics as well as traditional neural network forecasting method deficiencies of the problem, this paper presents a support vector regression (SVR) and financial time series methods to forecast future stock market; follows the value investment philosophy, reduces dimensional space by support vector machines the input vector mapped to a high dimensional space, and nonlinear problem into a linear problem, establish the value of the equity investments of prediction models under the principle of structural risk minimization. For an empirical test of the model to get the stock opened at 0.02% error of 3.66%, closing error of 0.00% to 3.41%, the results showed that SVR prediction in the stock market index has certain advantages.",
  "year": 2012,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "588f4e1c046113a5fcfc789ef7d53dcd",
  "timestamp": "2025-05-15T02:00:30.510907"
}