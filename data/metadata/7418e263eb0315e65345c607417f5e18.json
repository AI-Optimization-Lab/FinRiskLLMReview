{
  "id": 459,
  "title": "Stock market extreme risk prediction based on machine learning: Evidence from the American market",
  "abstract": "Extreme risk in stock markets poses significant challenges, necessitating greater attention in related research. This study presents an effective machine-learning model for forecasting extreme risks in the American stock market. Specifically, to address the issues of imbalanced data distribution and concept drift, we introduced class weight and time weight parameters to enhance the AdaBoost algorithm. Moreover, we improved the active learning framework by transitioning from manual to algorithmic annotation. Experiments on the S&P 500 index from 2005 to 2022 revealed that our optimal model significantly enhanced the classification performance, particularly for risk instances. Additionally, we validated the efficacy of customized sample weight values, the significance of the density-weight strategy, and the robustness of the overall framework under different risk definition criteria and feature lag periods. Our research is significant for the adoption of appropriate macroeconomic policies to mitigate downside risks and provides a valuable tool for achieving financial stability.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7418e263eb0315e65345c607417f5e18",
  "timestamp": "2025-05-15T01:50:52.713725"
}