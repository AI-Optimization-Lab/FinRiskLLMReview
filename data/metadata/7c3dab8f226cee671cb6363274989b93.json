{
  "id": 229,
  "title": "Distributed Generative Adversarial Networks for Fuzzy Portfolio Optimization",
  "abstract": "Financial time series is one of the most important data in the field of economics and finance, and it is important to forecast and simulate such data effectively based on historical patterns and trends. Existing forecasting models mainly forecasting one-step ahead, and cannot retain the complex characteristics of financial time series data such as serial correlation and the long-term time-dependent relationship. On the other hand, the large-scale data makes the training of the deep learning models a time-consuming process. Therefore, how to forecast financial time series multi-step ahead efficiently has become a key point to improve the asset management capability. At the same time, constructing a fuzzy portfolio optimization for different distributions is also an important direction to improve the robustness of a portfolio model. This paper proposes a distributed financial time series simulating model AssetGANs that simulating multi-step ahead based on GANs, and apply GANs as a parameter simulation method to fuzzy portfolio optimization to provide users with better strategy choices. The paper carries on numerical experiments on real market stock data, compares the results with LSTM and achieves a training speedup of over 573 with 8 GPUs compared to the CPU version.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7c3dab8f226cee671cb6363274989b93",
  "timestamp": "2025-05-15T00:33:39.486038"
}