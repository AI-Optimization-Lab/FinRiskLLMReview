{
  "id": 276,
  "title": "Investor sentiment-aware prediction model for P2P lending indicators based on LSTM",
  "abstract": "In recent years, online lending has created many risks while providing lending convenience to Chinese individuals and small and medium-sized enterprises. The timely assessment and prediction of the status of industry indicators is an important prerequisite for effectively preventing the spread of risks in China's new financial formats. The role of investor sentiment should not be underestimated. We first use the BERT model to divide investor sentiment in the review information of China's online lending third-party information website into three categories and analyze the relationship between investor sentiment and quantitative indicators of online lending product transactions. The results show that the percentage of positive comments has a positive relationship to the borrowing interest rate of P2P platforms that investors are willing to participate in for bidding projects. The percentage of negative comments has an inverse relationship to the borrowing period. Second, after introducing investor sentiment into the long short-term memory (LSTM) model, the average RMSE of the three forecast periods for borrowing interest rates is 0.373, and that of the borrowing period is 0.262, which are better than the values of other control models. Corresponding suggestions for the risk prevention of China's new financial formats are made.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d6f96472d1eed3a9a3a1a8a4e26aaf6a",
  "timestamp": "2025-05-15T01:36:21.909708"
}