{
  "id": 128,
  "title": "A Suspicious Financial Transaction Detection Model Using Autoencoder and Risk-Based Approach",
  "abstract": "This study focuses on the detection of suspicious transactions characterized by the opaque and complex electronic channels that have emerged with the advancement of electronic financial technology. A model that can immediately reflect trends in various types of fund and transaction flows, and autonomously learn complex transaction types, is proposed. As a key outcome, an internal control model for detecting suspicious transactions based on the risk-based approach is constructed by utilizing autoencoder to enhance anti-money laundering (AML) operations, and this method surpasses traditional AML methods. Additionally, the proposed model facilitates the extraction of candidate factors for suspicious transactions and updates warning models in AML monitoring systems, thereby allowing for the analysis of alert cases. As a result, AML operations based on the proposed model are quantitatively and qualitatively superior to those based on the traditional approaches, resulting in swift processing by avoiding exhaustive examinations of suspicious transaction types. This research provides information that can improve the AML operation systems used within the financial sector by evaluating the risk of suspicious transactions and reflecting various elements of funds and transactions.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a49381e76bcc7d4d1e6c730bf6d8fbb3",
  "timestamp": "2025-05-15T01:34:25.376727"
}