{
  "id": 910,
  "title": "Telecom Churn Prediction Using CNN with Variational Autoencoder",
  "abstract": "Customer churn is a major problem across traditional and new age companies like telecom, digital services providers, online marketplace, payment banking and social media companies. Customer churn means customer is moving out from the company, hence impacting the top line of financial sheets. This is particularly more relevant for companies having subscription-based plans. Telecom industry which has sizable customer base and cut-throat competition is at higher risk of impact due to churn. With the customer database size running into petabyte and terabytes, it is a tedious and time-taking task to accurately predict customer churn based on some random logic. While machine learning appears to be an easier alternative, often such database contains large number of string attributes that are tough to use in machine learning algorithms. Various traditional machine learning and data mining techniques have been applied for handling such big data. All such techniques have leveraged different techniques for data engineering. In this study, we have demonstrated how a new and powerful technique convolutional neural network with variational autoencoder can help predict churn with higher accuracy. CNN automatically has the ability of good feature selection and representation of input data, and this study has come with a new aspect, i.e. integrating all string attributes in dataset (ISAD) for using all existing string variable of database helping in enhancing model performance. Experiment is done on three telecom companies Cell2Cell, Telco and Orange datasets of size 51,048, 7048 and 3333, respectively. Model outperformed on all three datasets and achieved a good accuracy level. ISAD model helped to enhance the performance by giving more feature option for predicting the customer behaviour correctly.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "499398f09b53bef863cda3ca67a23d04",
  "timestamp": "2025-05-15T01:56:17.614706"
}