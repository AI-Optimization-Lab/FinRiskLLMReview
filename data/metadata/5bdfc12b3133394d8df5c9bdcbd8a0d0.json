{
  "id": 634,
  "title": "Machine Learning Algorithms to Classify Future Returns Using Structured and Unstructured Data",
  "abstract": "This study employs a machine learning (ML) algorithm to classify future stock returns into three categories: large positive, large negative, and all others (zero). We provide evidence of marginal classification improvement after using ML tools, which employ analysts' earnings estimate revisions and natural language processing to extract the tone and events of interest from news stories written about a firm. However, this improvement is statistically very significant. An application of this study is in portfolio rebalancing and short-term trading decisions, especially in quantitative portfolio management. With broad portfolios, during a normal rebalancing, one can delay the sale of a few stocks with prices predicted to increase significantly in the short term and substitute stocks with similar characteristics and alpha expectations. Likewise, one can delay the purchase of stocks that the quantitative model wishes to buy, but the ML model predicts to decrease significantly in the short term.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5bdfc12b3133394d8df5c9bdcbd8a0d0",
  "timestamp": "2025-05-15T00:45:39.197355"
}