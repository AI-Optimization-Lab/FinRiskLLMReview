{
  "id": 563,
  "title": "An Unsupervised Approach for Disaggregating Major Loads in Small Commercial Buildings",
  "abstract": "This paper proposes a new novel way for Non Intrusive Load Monitoring (NILM). The technique can be applied to develop a powerful framework for low-cost power monitoring in buildings, particularly in the small commercial sector. This approach thus solves one of the major challenges in power monitoring and energy management, which has been the development. of robust unsupervised learning algorithms that eliminate the need for costly human involvement. A proposal is made about filtering out the major loads in a sequential process from the aggregate power signal. Specifically, exterior lights and Rooftop units are extracted, the latter with the help of an unsupervised clustering method. The method is shown to be computationally compatible with handling a large data set obtained across a large portfolio. Finally, a case is studied for disaggregating major loads obtained from a bank building to demonstrate a basic test case in the real world.",
  "year": 2017,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d8ebd9d33ee82c30d5654ff2bb485047",
  "timestamp": "2025-05-15T00:45:01.312155"
}