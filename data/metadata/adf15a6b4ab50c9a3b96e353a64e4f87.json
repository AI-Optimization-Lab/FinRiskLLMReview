{
  "id": 64,
  "title": "Pricing derivatives with modeling CO2 emission allowance using a regime-switching jump diffusion model: with regime-switching risk premium",
  "abstract": "Carbon markets trade the spot European Union Allowance (EUA), with one EUA providing the right to emit one tone of carbon dioxide (CO2). We examine the spot EUA returns in BlueNext that exhibit jumps and a volatility clustering feature. We propose a regime-switching jump diffusion model (RSJM) with a hidden Markov chain to capture not only a volatility clustering feature, but also the dynamics of the spot EUA returns that are influenced by change in the CO2 emission economic conditions. In addition, the switching jump intensities of the RSJM are shown to be affected by change in the carbon-market macroeconomic environment. We further derive the theoretical futures-option prices with a constant convenience yield under the RSJM via the generalized Esscher transform where regime-switching risk is priced with a risk premium. The empirical study shows that the derived futures-option pricing model under the RSJM with regime-switching risk is a more complete model than a jump diffusion model for pricing CO2 options.",
  "year": 2016,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "adf15a6b4ab50c9a3b96e353a64e4f87",
  "timestamp": "2025-05-15T01:28:03.862337"
}