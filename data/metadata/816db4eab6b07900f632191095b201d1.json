{
  "id": 2004,
  "title": "Forecasting cryptocurrency volatility: a novel framework based on the evolving multiscale graph neural network",
  "abstract": "Cryptocurrency is a remarkable financial innovation that has affected the financial system in fundamental ways. Its increasingly complex interactions with the conventional financial market make precisely forecasting its volatility increasingly challenging. To this end, we propose a novel framework based on the evolving multiscale graph neural network (EMGNN). Specifically, we embed a graph that depicts the interactions between the cryptocurrency and conventional financial markets into the predictive process. Furthermore, we employ hierarchical evolving graph structure learners to model the dynamic and scale-specific interactions. We also evaluate our framework's robustness and discuss its interpretability by extracting the learned graph structure. The empirical results show that (i) cryptocurrency volatility is not isolated from the conventional market, and the embedded graph can provide effective information for prediction; (ii) the EMGNN-based forecasting framework generally yields outstanding and robust performance in terms of multiple volatility estimators, cryptocurrency samples, forecasting horizons, and evaluation criteria; and (iii) the graph structure in the predictive process varies over time and scales and is well captured by our framework. Overall, our work provides new insights into risk management for market participants and into policy formulation for authorities.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "816db4eab6b07900f632191095b201d1",
  "timestamp": "2025-05-15T02:09:48.443993"
}