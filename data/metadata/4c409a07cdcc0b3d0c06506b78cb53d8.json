{
  "id": 3814,
  "title": "Predicting returns using moving averages: the role of investor inattention",
  "abstract": "PurposeInvestors are inattentive to continuous information as opposed to discrete information, resulting in underreaction to continuous information. This paper aims to examine if the well-documented return predictability of the strategies based on the ratio of short-term to long-term moving averages can be enhanced by conditioning on information discreteness. Anchoring bias has been the popular explanation for the source of underreaction in the context of moving averages-based strategies. This paper proposes and studies another possible source based on investor inattention that can potentially result in superior performance of these strategies.Design/methodology/approachThe paper uses portfolio sorting as well as Fama-MacBeth cross-sectional regressions. For examining the role of information discreteness in the return predictability of the moving average ratio, the sample stocks are double-sorted based on the moving average ratio and information discreteness measure. The returns to these portfolios are computed using standard approaches in the literature. The regression approach controls for various well-known return predictors.FindingsThis study finds that the equally-weighted monthly returns to the long-short moving average ratio quintile portfolios increase monotonically from 0.54% for the discrete information portfolio to 1.37% for the continuous information portfolio over the 3-month holding period. This study observes a similar pattern in risk-adjusted returns, value-weighted portfolios, non-January returns, large and small stocks, for alternative holding periods and the ratio of 50-day to 200-day moving average. The results are robust to control for well-known return predictors in cross-sectional regressions.Research limitations/implicationsTo the best of the authors' knowledge, this is the first paper to document the significant role of investor inattention to continuous information in the return predictability of strategies based on the moving average ratios. There are many underreaction anomalies that have been reported in the literature, and the paper's results can be extended to those anomalies in subsequent research.Practical implicationsThe findings of this paper have important practical implications. Strategies based on moving averages are an extremely popular component of a technical analyst's toolkit. Their profitability has been well-documented in the prior literature that attributes the performance to investors' anchoring bias. This paper offers a readily implementable approach to enhancing the performance of these strategies by conditioning on a straightforward measure of information discreteness. In doing so, this study extends the literature on the role of investor inattention to continuous information in anomaly profits.Originality/valueWhile there is considerable literature on technical analysis, and especially on the performance of moving averages-based strategies, the novelty of this paper is the analysis of the role of information discreteness in strategy performance. Not only does the paper document robust evidence, but the findings suggest that the investor's inattention to continuous information is a more dominant source of underreaction compared to anchoring. This is an important result, given that anchoring has so far been considered the source of return predictability in the literature.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "4c409a07cdcc0b3d0c06506b78cb53d8",
  "timestamp": "2025-05-15T01:21:08.219842"
}