{
  "id": 5280,
  "title": "Bagging Supervised Autoencoder Classifier for credit scoring",
  "abstract": "Automatic credit scoring, a crucial risk management tool for banks and financial institutes, has attracted much attention in the past few decades. As such, various approaches have been developed to accurately and efficiently estimate defaults in loan applicants and seamlessly improve and facilitate decision-making in the lending process. However, the imbalanced nature of credit scoring datasets, as well as the heterogeneous nature of features in credit scoring task pose many challenges in developing and implementing effective credit scoring models, targeting the generalization power of classification models on unseen data. To mitigate these challenges, in this paper, we propose the Bagging Supervised Autoencoder Classifier (BSAC). BSAC is a learning model which simultaneously leverages the superior power of supervised autoencoders and representation learning in classification, as well as the Bagging mechanism to handle the irregularities in feature space. Supervised autoencoder has been exploited to learn an optimal latent space from heterogeneous features and perform classification on top of the learned latent space. In particular, the Bagging mechanism has been employed in the learning process to construct various samples of original data to tackle the problem that arises from imbalanced data and irregularities of features in latent space. Extensive experiments on various real-world and benchmark datasets validate the superiority and robustness of the proposed method in predicting the outcome of loan applications.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "f595bfac7cb556ff3ddc26798790402b",
  "timestamp": "2025-05-15T02:46:16.196203"
}