{
  "id": 3247,
  "title": "Estimating ensemble weights for bagging regressors based on the mean-variance portfolio framework",
  "abstract": "This paper presents a novel ensemble learning framework inspired by modern portfolio optimization to address regression problems. This formulation in the ensemble learning field allows determining the ensemble's weights considering the error predictions of the base learners, the variability in their predictions, and the covariance among their predictions' errors, which is completely aligned with the bias-variance-covariance theory. Under the framework proposed, four potential instantiations have also been provided. The first two ensemble models impose the non-negativity constraints on the ensemble's weights (along with the equality constraint that the ensemble's weights sum up to one) and are solved with the active set algorithm. The second two ensemble models do not include the non-negativity constraints on the ensemble's weights (which in the financial literature are called the non-shorting constraints), giving rise to a convex quadratic programming (QP) problem (as the matrix included in the quadratic term is symmetric and positive definite) that is solved by the Lagrangian procedure. Extensive experiments with regression datasets evaluate the proposed ensemble framework. Comparisons with other state-of-the-art ensemble methods confirm that the ensemble framework yields the best overall performance.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "df7407f22ebc11a206a3911b92702fd5",
  "timestamp": "2025-05-15T01:15:26.047226"
}