{
  "id": 177,
  "title": "Quantitative investment prediction analysis for enterprise asset management using machine learning algorithms",
  "abstract": "Quantitative investment can manage enterprise assets better to obtain higher revenues. This paper analyzed quantitative investment prediction using machine learning algorithms. First, the support vector machine (SVM) algorithm was introduced, and stock changes were predicted by the SVM algorithm. Then, the feature factors in stock data were extracted by maximum information coefficient (MIC) as the input of the SVM algorithm. Finally, the performance and backtest results of the SVM algorithm was analyzed. It was found that the SVM algorithm had a good performance, and its Fl-score was 0.9884, which was better than C4.5 and random forest algorithms. In terms of backtesting, the portfolio built based on the prediction results of the SVM algorithm obtained a higher annualized return rate when the number of stocks was small; when the number of stocks was 10, the portfolio built based on the SVM algorithm had an annualized return rate of 83.67%, a smaller maximum retracement, and a higher Sharpe ratio than the other algorithms, which balanced the risk and return well. The results demonstrate the reliability of the SVM algorithm in predicting quantitative investment, which is beneficial to achieving the optimization of enterprise asset management.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "434f219623d842fa6ac54429e6d2f15b",
  "timestamp": "2025-05-15T00:40:02.123147"
}