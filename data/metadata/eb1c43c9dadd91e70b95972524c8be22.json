{
  "id": 1232,
  "title": "Efficient Frontiers in Portfolio Optimisation with Minimum Proportion Constraints",
  "abstract": "This work chronicles research into the solution of portfolio problems with metaheuristic solvers. In particular, a genetic algorithm for solving the cardinality constrained portfolio optimisation problem with minimum asset proportions is presented and tested on the datasets of [1]. These datasets form benchmark instances used to test portfolio optimisers and are based upon indices ranging from 31 to 225 assets. The results of the GA are indicatively compared to solutions of [2] for a variety of minimum proportions, suggesting that solutions exhibit certain clustering characteristics for higher proportions. Further work is also discussed. This research is based upon the first part of the ongoing PhD thesis of the first author.",
  "year": 2019,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "eb1c43c9dadd91e70b95972524c8be22",
  "timestamp": "2025-05-15T00:53:09.995908"
}