{
  "id": 2608,
  "title": "Black Magic Meta Data - get a glimpse behind the scene",
  "abstract": "This paper presents how we utilise natural language processing techniques in order to automagically classify information stored in a CRIS, and aggregate the information in a researchers portfolio into a fingerprint describing a researchers research interest. Our approach exploits the fact that entities in a CRIS typically include some kind of text - most notable example being publication abstracts. We explain how the approach can result in automatic detailed classification of information, and argue how we can take advantage of such information in order to facilitate networking. Finally, we describe how we have realised the solution within our CRIS system. (C) 2014 Elsevier B.V",
  "year": 2014,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "e68656fe56ca7f6a21b7cef6d4588d6c",
  "timestamp": "2025-05-15T01:08:41.883026"
}