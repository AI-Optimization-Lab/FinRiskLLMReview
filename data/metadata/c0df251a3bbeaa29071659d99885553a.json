{
  "id": 4191,
  "title": "Tobacco use among low-income housing residents: does hardship motivate quit attempts?",
  "abstract": "The purpose of this study was to examine material hardship among smokers to determine whether such hardship was positively associated with current attempts to quit tobacco use. We analyzed cross-sectional data from the Health in Common (HIC) study, an observational study to investigate social and physical determinants of cancer risk-related behaviors among residents of low-income housing in three cities in the Boston metropolitan area. In this study, three indicators of hardship were used: food hardship, financial hardship, and material hardship (food and financial hardship combined). Logistic regression models were used to obtain the odds of currently trying to quit among current smokers in the HIC (n = 170) across hardship types experienced, adjusting for sociodemographic and psychosocial factors. Fully adjusted models revealed no statistically significant association between trying to quit tobacco use and indicators of material hardship: food hardship and financial hardship present (OR 1.33 (0.42-4.2); food hardship and no financial hardship OR 3.83 (0.97-15.13); and financial hardship but no food hardship OR 0.5 (0.1-2.39). These findings suggest that even in the presence of material hardship, low-income housing resident tobacco users are not more likely to quit tobacco use; therefore, cessation efforts focused on the financial benefits of quitting may be insufficient to motivate quit attempts among low-income smokers.",
  "year": 2015,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c0df251a3bbeaa29071659d99885553a",
  "timestamp": "2025-05-15T02:34:13.438443"
}