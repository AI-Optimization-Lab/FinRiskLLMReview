{
  "id": 2194,
  "title": "Digital Bank Runs: A Deep Neural Network Approach",
  "abstract": "The introduction of Central Bank Digital Currency (CBDC) could represent a deep structural change to the financial sector, and in particular to the banking sector. This paper proposes a Deep Neural Network (DNN) design to model the introduction of CBDC and its potential impact on commercial banks' deposits. The model proposed forecasts the likelihood of the occurrence of bank runs as a function of the system characteristics and of the intrinsic features of CBDC. The success rate of CBDC and the impact on the banking sector is highly dependent on its design. Whether CBDC should carry any form of interest, if the amount of CBDC should be capped by account or if convertibility from banks' deposits should be guaranteed by commercial banks are important features to consider. Further, the design of CBDC needs to contribute to enhancing the sustainability of the financial system, hence a CBDC design that promotes financial inclusion is paramount. The model is initially calibrated with Euro area system data. Results show that an increase in the financial system risk perception would trigger a significant transfer of wealth from bank deposits to CBDC, while the wealth transfer to CBDC is to a lesser extent also sensitive to its interest rate.",
  "year": 2021,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "84583b1d937447599ecbae3fcf16a910",
  "timestamp": "2025-05-15T02:12:17.451747"
}