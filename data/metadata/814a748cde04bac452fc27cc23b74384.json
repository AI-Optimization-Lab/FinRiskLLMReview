{
  "id": 6508,
  "title": "Narcotic and Antidepressant Use and Hospital Readmission Rates in Children With Functional Abdominal Pain",
  "abstract": "Functional abdominal pain is a common presentation in the pediatric population, and it carries a large financial and emotional burden. The objective of this study was to describe the association between the use of narcotics and antidepressants and hospital readmission in children admitted for abdominal pain without an organic cause. We analyzed data from the Pediatric Health Information System database. A multivariate logistical regression model was used to assess the association between medication type and hospital readmission rates within 30 and 90 days. There was a positive association between readmission rates. Readmission rates were higher for children who were older, male, Black, had Medicaid insurance, had a longer hospital stay, or were treated with a selective serotonin reuptake inhibitor/tricyclic antidepressant/narcotic. While not standard practice, patients with functional abdominal pain who receive these medications may be at an increased risk for readmission and subsequent health care contacts and are good candidates for future healthcare coordination.",
  "year": 2017,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "814a748cde04bac452fc27cc23b74384",
  "timestamp": "2025-05-15T02:58:34.316737"
}