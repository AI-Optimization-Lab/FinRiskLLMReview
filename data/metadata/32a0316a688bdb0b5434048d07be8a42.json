{
  "id": 1084,
  "title": "金融监管的“宽柔之手”与“大手覆盖”——基于金融监管方式的比较分析",
  "abstract": "在金融监管的历史上,每当发生更为严重的银行或金融危机,政府就从金融监管的\"宽柔之手\"转向\"大手覆盖\"。当前爆发的金融危机,促使各国政府从倡导金融自由化,向谨慎监管的理性回归。事实证明,在一个现代金融服务的复杂化程度日益提高,以及金融风险无处不在的金融世界里,更多地使用\"大手覆盖\"而较少地使用\"宽柔之手\",更有利于金融体系的安全性和稳定性。",
  "year": 2010,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "32a0316a688bdb0b5434048d07be8a42",
  "timestamp": "2025-05-14T22:35:44.452450"
}