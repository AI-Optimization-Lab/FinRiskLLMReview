{
  "id": 11,
  "title": "New Paradigm for Economic and Financial Research With Generative AI: Impact and Perspective",
  "abstract": "In the past few years, we have witnessed the rapid development and exponential growth of generative artificial intelligence (GAI) technologies including large language models (LLMs)-enabled ChatGPT and peripheral innovations. These technologies are designed to be humanlike intelligence and intuitive by providing direct access to systems using application programming interfaces (APIs). The GAI applications can fundamentally change economic and financial activities, through revolutionizing the ways that humans interact with machines and giving rise to new modes of production and behavior patterns. It is imperative to develop a new research paradigm that is more suitable than the currently dominating conventional research paradigms. This article presents the new paradigm for economic and financial research with GAI, covering the research objectives, scientific data, and models, and explores the underlying impact and perspective that bring to this field. We elaborate on the potential five scenarios including portfolio management, economic and financial prediction, extreme scenario analysis, policy analysis, and financial fraud detection. The new research paradigm with GAI proposed in this article can provide significant insights for a comprehensive understanding of innovation and transformation in this domain.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "LLMs",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1df6f93b7af06db3f3b835a3e4c9001a",
  "timestamp": "2025-05-15T00:38:16.173291"
}