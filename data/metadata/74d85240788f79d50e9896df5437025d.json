{
  "id": 2660,
  "title": "Rethinking the diffusion of renewable energy policies: A global assessment of feed-in tariffs and renewable portfolio standards",
  "abstract": "This article examines the global diffusion of two dominant renewable energy policies: feed-in tariffs (FIT) and renewable portfolio standards (RPS). It focuses on four mechanisms of policy diffusion: emulation, suasion, learning and competition. The findings of quantitative methods (logistic regression models and event history analysis) show strong support for emulation mechanisms in the diffusion of FIT and RPS. In the diffusion of FIT and RPS there is some support for learning and suasion. There is a robust finding of support that the competition mechanism does not explain diffusion of RPS and FIT.",
  "year": 2018,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "74d85240788f79d50e9896df5437025d",
  "timestamp": "2025-05-15T01:09:14.906421"
}