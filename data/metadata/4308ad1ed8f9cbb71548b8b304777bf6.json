{
  "id": 5882,
  "title": "Poor and satisfied? A review of the monetary poverty indicator in the EU",
  "abstract": "This article seeks to contribute to the generation of more accurate poverty indicators in the EU, by providing some further evidence of potential bias when joint income-wealth perspective on poverty measurement is not considered. Using the 2018 EU-SILC, we compare the individuals' financial satisfaction and his/her household classification as at risk of poverty (AROP). We detect a significant group of people whose households are classified as poor but who are satisfied with their economic situation. The explanations for this mismatch lie both in errors in the income estimation and in the presence of household wealth. Through an exploratory analysis with certain limitations, we find that those in this group have different characteristics from the rest of the poor and are more similar to those who are neither poor nor dissatisfied when we analyse economic stress and proxy wealth variables. The article supports the recommendation to revise the AROP indicator based on the joint income-wealth distribution.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "4308ad1ed8f9cbb71548b8b304777bf6",
  "timestamp": "2025-05-15T02:52:31.419575"
}