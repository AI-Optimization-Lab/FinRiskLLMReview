{
  "id": 316,
  "title": "PATTERNS OF 50 ETF OPTIONS IMPLIED VOLATILITY IN CHINA: ON IMPLIED VOLATILITY FUNCTIONS",
  "abstract": "The aim of this study is to examine the volatility smile based on the European options on Shanghai stock exchange 50 ETF. The data gives evidence of the existence of a well-known U-shaped implied volatility smile for the SSE 50 ETF options market in China. For those near-month options, the implied volatility smirk is also observed. And the implied volatility remains high for the short maturity and decreases as the maturity increases. The patterns of the implied volatility of SSE 50 ETF options indicate that in-the-money options and out-of-the-money options are more expensive relative to at-the-money options. This makes the use of at-the-money implied volatility for pricing out-of- or in-the-money options questionable. In order to investigate the implied volatility, the regression-based implied volatility functions model is considered employed to study the implied volatility in this study as this method is simple and easy to apply in practice. Several classical implied volatility functions are investigated in this paper to find whether some kind of implied volatility functions could lead to more accurate options pricing values. The potential determinants of implied volatility are the degree of moneyness and days left to expiration. The empirical work has been expressed by means of simple ordinary least squares framework. As the study shows, when valuing options, the results of using volatility functions are mixed. For far-month options, using atthe-money implied volatility performs better than other volatility functions in option valuation. For near-month options, the use of volatility functions can improve the valuation accuracy for deep in-the-money options or deep out-of-the-money options. However, no particular implied volatility function performs very well for options of all moneyness level and time to maturity.",
  "year": 2021,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "0f442dc78c763cd299bba5d1252c5063",
  "timestamp": "2025-05-15T01:30:46.328694"
}