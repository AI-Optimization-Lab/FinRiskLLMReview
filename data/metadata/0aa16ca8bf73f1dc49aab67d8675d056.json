{
  "id": 536,
  "title": "中国股票市场过度反应行为:完整牛市和熊市周期中的实证",
  "abstract": "应用Jegadeesh和Titman的研究方法 ,通过延长不同组合策略的持有期 ,全面考察了中国股票市场短中长期的过度反应现象。时段选取为 1997～ 2 0 0 3年 (一个完整的牛熊周期 ) ,形成期和持有期为 1- 2 4个月。研究结果发现 ,在短期水平上 ,形成期和持有期均为 4～ 6个月的投资组合 ,无论赢家组合还是输家组合都存在一定程度的动量利润 ,赢家组合的动量利润大约为输家组合的 2倍。在 12到 2 4个月的中长期水平上 ,赢家组合与输家组合均表现出比较明显的过度反应现象 (统计检验显著 ) ,反转策略最高可以获取 14 .36 %的超额收益。回归方程检验结果显示中长期水平上不同形成期和持有期的反转策略存在时变风险溢价所不能解释的超额收益。",
  "year": 2004,
  "source": "CNKI",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "0aa16ca8bf73f1dc49aab67d8675d056",
  "timestamp": "2025-05-14T22:23:31.683317"
}