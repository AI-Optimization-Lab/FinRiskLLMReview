{
  "id": 2041,
  "title": "Factor Investing Webinar",
  "abstract": "In this webinar, Frank Fabozzi moderated a discussion with four prominent quantitative investment professionals. The experts were asked about their approaches to factor investing, the characteristics they look for in a factor, and which factors they believed in and why. The webinar covered topics such as the viability of value as a factor over the past decade, the role of ESG as a factor, and the possibility of discovering new factors. The difference between factors and signals was discussed, along with the potential for factor timing. The panelists also examined how to incorporate factors into portfolios, identified the biggest challenges facing factor investing, and shared the main findings from research on factor portfolio construction. They also discussed the most promising areas of research in the field, including Machine Learning and the application of factors to private markets. Additionally, the discrepancy between the use of factors in equities versus fixed income was discussed. Overall, the webinar provided a comprehensive overview of the challenges and opportunities associated with factor investing.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b129116e56758cde9f17dbc14c45f456",
  "timestamp": "2025-05-15T01:02:32.788303"
}