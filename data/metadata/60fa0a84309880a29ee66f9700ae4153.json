{
  "id": 4740,
  "title": "Socioecological Model of a Military Family's Health and Well-Being: Inside a Slovenian Military Family",
  "abstract": "The purpose of this article is to analyze the ecosystem of a military family, focusing on the risk factors that influence their health and well-being on various socioecological levels (individual, micro, meso, and macro). We develop a theoretical model of health outcomes and risk factors and test it empirically using quota sampling of 460 respondents from military families in Slovenia. Thirty-three regression models were calculated to measure the impact of theoretically defined risk factors on the health outcomes of military families. Surprisingly, a long daily commute, one of the most military-specific factors in Slovenian society, is viewed more positively than negatively. Moreover, risk factors related to the family on the micro and individual levels, such as poor financial situation or parental stress, are responsible for the greatest impact on military family health. Meanwhile, spouses report that military work-related stress affects the servicemembers' overall health and increases the possibility of intimate partner violence.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "60fa0a84309880a29ee66f9700ae4153",
  "timestamp": "2025-05-15T02:40:27.959711"
}