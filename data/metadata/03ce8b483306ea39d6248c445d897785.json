{
  "id": 5979,
  "title": "Do Islamic Banks Perform Better than Conventional Banks?",
  "abstract": "This study aims to compare the performance of Islamic and conventional banks in Pakistan for the period 2007-2016. For the purpose, the study first employs CAMELS composite rating to find the ratios to highlight the managerial and financial performance of the banks. The study then uses logistic regression technique for the performance comparison of Islamic and Conventional banks. The composite rating results reveal that both Islamic and conventional banks fall in rank 3 and need help from regulatory authorities to improve the performance of banking sector in Pakistan. Furthermore, the logistic regression results reveal that Islamic banks perform well in asset quality, management adequacy and sensitivity to market risk whereas conventional banks are efficient in capital adequacy and liquidity. Robustness of results is achieved by performance comparison of the same size Islamic and conventional banks. This analysis is important because Pakistan's banking sector is hybrid where both Islamic and conventional banks work in the same environment and under the same regulator. Findings of this study are not only useful for Islamic and conventional banks operating in Pakistan but would also help the policymakers in devising future policies.",
  "year": 2021,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "03ce8b483306ea39d6248c445d897785",
  "timestamp": "2025-05-15T02:53:33.380862"
}