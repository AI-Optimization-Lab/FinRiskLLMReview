{
  "id": 3770,
  "title": "Heterogeneous beliefs and idiosyncratic volatility puzzle: evidence from China",
  "abstract": "Purpose The purpose of our study is to explore the idiosyncratic volatility puzzle in Chinese stock market from the perspective of investors' heterogeneous beliefs. To delve into the relationship between idiosyncratic volatility and investors' heterogeneous beliefs, and uncover the ability of heterogeneous beliefs, as well as to explain the idiosyncratic volatility puzzle, we construct our study as follows. Design/methodology/approach Our study adopts the unexpected trading volume as proxies of heterogeneity, the residual of Fama-French three-factor model as proxies of idiosyncratic volatility. Portfolio strategies and Fama-MacBeth regression are used to investigate the relationship between the two proxies and stock returns in Chinese A-share market. Findings Investors' heterogeneous beliefs, as an intermediary variable, are positively correlated with idiosyncratic volatility. Meanwhile, it could better demonstrate the negative correlation between the idiosyncratic volatility and future stock returns. It is one of the economic mechanisms linking idiosyncratic volatility to subsequent stock returns, which can account for 11.28% of the puzzle. Originality/value The findings indicate that idiosyncratic volatility is significantly and positively correlated with heterogeneous beliefs and that heterogeneous beliefs are effective intervening variables to explain the idiosyncratic volatility puzzle.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "f7914341e352250b6f4cf3829b988dd0",
  "timestamp": "2025-05-15T01:20:36.099164"
}