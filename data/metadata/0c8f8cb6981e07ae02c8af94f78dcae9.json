{
  "id": 2536,
  "title": "Asset pricing with time-varying betas for stocks traded on S&P 500",
  "abstract": "This study uses a novel approach for capturing time variation in betas whose pattern is treated as a function of market returns. A two-factor model (TFM) is constructed using estimated coefficients of a nonlinear regression. The model is tested against the CAPM and the Fama and French three-factor model in the context of time series regressions. The used stocks are traded on S&P 500. The period spans from 1993 to 2011. The time series regression results depict the superiority of the TFM in explaining portfolio returns including momentum ones. We also provide evidence that the particular portfolios employed at the construction of the new model accommodate different fundamental characteristics and different risk levels.",
  "year": 2014,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "0c8f8cb6981e07ae02c8af94f78dcae9",
  "timestamp": "2025-05-15T01:07:35.788856"
}