{
  "id": 1656,
  "title": "Induction of rule-based scoring functions",
  "abstract": "We consider the problem that many portfolio managers face of selecting, on a regular basis, stocks for investment and recommendation to clients. In typical solution strategies, binary rules are developed to classify stocks as strong or weak performers based on technical indicators. Strategies based on binary classification rules have been shown to be very effective at maximizing the total profitability of the stocks that are selected. Having a fixed number of target stocks is important for portfolio maintenance and for client choice, however, and so the selection problem also engenders the additional constraint of limiting the total number of stocks selected. Binary classification rule strategies do not address this constraint. In this paper we investigate the use of scoring functions, which have the advantage of allowing one to rank order the population based on profitability, as an alternative to binary classification rules. A key feature of this work is that we develop the scoring functions by incorporating binary classification rules. In particular, we induce the score model by assigning optimal weights to sets of implicit positive binary classification rules. We use a genetic algorithm with supervised, batch learning to evolve classification rules. Fitness of a rule set is evaluated based on the success of the scoring function that it induces. We report on the relative empirical performance of this method on several large historical data sets.",
  "year": 1998,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "908f7685285b5b2031adfc7477f42423",
  "timestamp": "2025-05-15T00:58:18.284035"
}