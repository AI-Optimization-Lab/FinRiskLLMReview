{
  "id": 5618,
  "title": "GARCH models in value at risk estimation: empirical evidence from the Montenegrin stock exchange",
  "abstract": "This article considers the adequacy of generalised autoregressive conditional heteroskedasticity (GARCH) model use in measuring risk in the Montenegrin emerging market before and during the global financial crisis. In particular, the purpose of the article is to investigate whether GARCH models are accurate in the evaluation of value at risk (VaR) in emerging stock markets such as the Montenegrin market. The daily return of the Montenegrin stock market index MONEX is analysed for the period January 2004-February 2014. The motivation for this research is the desire to approach quantifying and managing risk in Montenegro more thoroughly, using methodology that has not been used for emerging markets so far. Our backtesting results showed that none of the eight models passed the Kupiec test with 95% of confidence level, while only the ARMA (autoregressive moving-average model) (1,2)-N GARCH model did not pass the Kupiec test with a confidence level of 99%. The results of the Christoffersen test revealed three models (ARMA(1,2)-TS GARCH(1,1) with a Student-t distribution of residuals, the ARMA(1,2)-T GARCH(1,1) model with a Student-t distribution of residuals, and ARMA(1,2)-EGARCH(1,1) with a reparameterised unbounded Johnson distribution [JSU] distribution of residuals) which passed the joint Christoffersen test with a 95% confidence level. It seems that these three models are appropriate for capturing volatility clustering, since all of them failed for a number of exceptions. Finally, none of the analysed models passed the Pearson's Q test, whether with 90%, 95% or 99%.",
  "year": 2017,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "60a510dff7cc23bed0d04783a8efa583",
  "timestamp": "2025-05-15T02:49:50.206761"
}