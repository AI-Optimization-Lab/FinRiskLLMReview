{
  "id": 2042,
  "title": "Measuring cryptocurrency moment convergence using distance analysis",
  "abstract": "This study measures the convergence and divergence of major cryptocurrencies by applying two distance measures used in machine learning. Particularly, the time-varying Euclidean distance measure was constructed by combining the first four moments (i.e. mean, variance, skewness and kurtosis) of the return distributions of cryptocurrencies following the l(2)-normalisation. It was found that major cryptocurrencies converged to the centroid during the 2018 market crash, but diverged before and after the crash. Their divergence could be due to the uncertainty arising frommarket news and regulatory events. In addition, Bitcoin cosine similarity measure was developed to provide further insights into the relationship between Bitcoin and other cryptocurrencies. This cosine similarity shows how each cryptocurrency moves relative to Bitcoin, which is not captured by the Euclidean distance. More importantly, it was demonstrated that the divergence of major cryptocurrencies from their centroids can improve Markowitz's efficient frontier and provide more diversification benefits to investors and portfolio fund managers. Finally, a profitable trading strategy was provided based on the Euclidean distance.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "286a30ae65f5ac736126e1a889061bc8",
  "timestamp": "2025-05-15T01:02:32.791281"
}