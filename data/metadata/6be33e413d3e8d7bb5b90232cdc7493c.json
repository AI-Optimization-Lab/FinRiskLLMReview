{
  "id": 259,
  "title": "A three-stage prediction model for firm default risk: An integration of text sentiment analysis",
  "abstract": "Predicting firm default risk is vital for financial institutions to avert significant economic losses, making the enhancement of its prediction precision both imperative and intricate. This research introduces a three-stage prediction model, including association rule algorithm (ARA), support vector machine (SVM) and modified particle swarm optimization algorithm (MPSO). Features selected by ARA are used as inputs for SVM, and penalty parameter and kernel parameter of SVM is optimized by MPSO that uses the adaptive inertia weight. The importance of text sentiment variables are emphasized to predict firm default risk. In the first stage, feature selection seeks to curtail the dimensions of both financial and non-financial variables. The empirical findings validate the efficacy of the ARA, revealing a strong correlation between text sentiment and default risk. The subsequent two stages deploy the SVM, refined by the MPSO, to predict the default risk. Compared with renowned models, the proposed model displays superior prediction precision and a reduced computational overhead. This research furnishes a potent instrument for regulators and firms alike, aiding in mitigating prospective default risks and forestalling broader economic upheavals.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6be33e413d3e8d7bb5b90232cdc7493c",
  "timestamp": "2025-05-15T01:48:30.829646"
}