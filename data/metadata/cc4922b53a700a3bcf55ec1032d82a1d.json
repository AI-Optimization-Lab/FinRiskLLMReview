{
  "id": 920,
  "title": "Credit risk evaluation in peer-to-peer lending with linguistic data transformation and supervised learning",
  "abstract": "The widespread availability of various peer-to-peer lending solutions is rapidly changing the landscape of financial services. Beside the natural advantages over traditional services, a relevant problem in the domain is to correctly assess the risk associated with borrowers. In contrast to traditional financial services industries, in peer-to-peer lending the unsecured nature of loans as well as the relative novelty of the platforms make the assessment of risk a difficult problem. In this article we propose to use traditional machine learning methods enhanced with fuzzy set theory based transformation of data to improve the quality of identifying loans with high likelihood of default. We assess the proposed approach on a real-life dataset from one of the largest peer-to-peer platforms in Europe. The results demonstrate that (i) traditional classification algorithms show good performance in classifying borrowers, and (ii) their performance can be improved using linguistic data transformation.",
  "year": 2018,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "cc4922b53a700a3bcf55ec1032d82a1d",
  "timestamp": "2025-05-15T01:56:49.546027"
}