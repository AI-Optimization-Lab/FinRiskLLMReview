{
  "id": 30,
  "title": "Multi-scale least squares support vector machine for financial time series forecasting",
  "abstract": "Financial time series is of scale property, such as price fluctuation data. It is very significant for the derivative price, risk control, market management and price forecasting to research the scale property of price fluctuation data. Recent studies have revealed that emerging modern machine learning techniques are advantageous to statistical models for time series forecasting, such as artificial neural network (ANN) and support vector regression (SVR). Least squares support vector machine achieves faster speed at the cost of loosing the sparseness. In this paper, we propose a new method, called multi-scale sparse least squares support vector machine (MS-LS-SVM), to design futures price forecasting system, and achieve the multi-scale decomposition, modeling for the sub-systems and the integration adaptively. The multi-scale decomposition for the original data is obtained by wavelet packet decomposition and the correlations among these scales are obtained by the way of learning MS-LS-SVM. Experiments in futures time series prediction demonstrate that MS-LS-SVM can achieve excellent performance and sparseness at the same time. In addition, the effect of different scales for the output can be achieved. The proposed method improves the interpretability and gives another way for model evaluation.",
  "year": 2007,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "76fa3edced435e79323caf5742e0012b",
  "timestamp": "2025-05-15T01:46:03.808363"
}