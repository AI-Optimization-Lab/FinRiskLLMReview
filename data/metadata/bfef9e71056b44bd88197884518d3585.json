{
  "id": 2305,
  "title": "Portfolio management and dependencies among precious metal markets: Evidence from a Copula quantile-on-quantile approach",
  "abstract": "This study examines the dependence structure among four major precious metal markets: gold, palladium, platinum, and silver. Using the novel Copula Quantile-on-Quantile Regression (C-QQR) approach of Sim (2016), we show that precious metals share a systemic relationship despite their different demand-supply interplays, applications, and the macroeconomic factors, which influence their values. Our results also suggest that correlations among markets do not remain constant over time. Furthermore, we identify the quantiles of returns for two metals where maximum benefits of negative correlations can be obtained to enhance portfolio diversification. This knowledge provides an opportunity for hedgers to decide when they should avoid going long or short on a particular metal. Finally, we find that our approach determines optimal portfolio weights that can reduce risk in metals markets more efficiently than traditional, conditional covariance-based approaches.",
  "year": 2019,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "bfef9e71056b44bd88197884518d3585",
  "timestamp": "2025-05-15T01:05:39.614338"
}