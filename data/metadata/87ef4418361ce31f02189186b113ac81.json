{
  "id": 1929,
  "title": "The FA-SAA Algorithm for CVaR Optimization",
  "abstract": "This paper develops a unified algorithm to address the Conditional Value at Risk (CVaR) optimization problem characterized by two levels of expectations, where the inner-level expectation handles the repricing of the financial instruments and the outer-level expectation represents the risk measure. We propose an FA-SAA algorithm that tackles the inner-level expectation through function approximation (FA) method and addresses the outer-level expectation by sample average approximation (SAA). A variety of machine learning methods can be incorporated into this algorithm and eventually the optimization problem is reformulated into a linear programming problem, whose optimal value and optimal solution converge to the actual ones. Besides, we demonstrate that the convergence rate of optimal value can achieve O-P(Gamma(-1/2)). The numerical results substantiate the efficacy of our proposed algorithm.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "87ef4418361ce31f02189186b113ac81",
  "timestamp": "2025-05-15T02:09:14.337673"
}