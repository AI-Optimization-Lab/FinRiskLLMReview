{
  "id": 6865,
  "title": "Incidence, Inequality and Determinants of Catastrophic Health Expenditure in India",
  "abstract": "This study tries to estimate the incidence, intensity and inequality of Catastrophic Health Expenditure in India and its determinants using unit-level data from the four consecutive surveys of NSSO on 'Healthcare Consumption and Morbidity' spread across a 23-year period. For CHE incidence, a 10% threshold level of household consumption expenditure is considered. Additionally, socio-economic determinants of CHE were identified using multivariate logistic regression. Study reveals that the demand for healthcare services has increased gradually during the period 1995-2014 but this demand is primarily financed from out-of-pocket expenditures and hence leading to an increased risk of financial catastrophe, peaking at 23.45% in 2014. But a significant reduction in demand for healthcare is seen in the latest 75th round. Although the incidence of catastrophe has decreased, the inequality of catastrophic burden has increased. The results show that economic and social vulnerability have a significant impact on the likelihood of CHE incidence in households. The findings suggest that a targeted approach is required to alleviate the socially and economically vulnerable households from health expenditure catastrophe.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "bbfddc9bfec8f1a7119e2792dc66b16a",
  "timestamp": "2025-05-15T03:02:41.140796"
}