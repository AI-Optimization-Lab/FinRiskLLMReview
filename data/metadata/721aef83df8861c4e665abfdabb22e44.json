{
  "id": 3579,
  "title": "Using Equity Analyst Coverage to Determine Stock Similarity",
  "abstract": "With the observation that equity analysts tend to cover similar stocks, we propose a simple, intuitive method to convert their coverage sets into pairwise similarity values among stocks. These values are shown to have a strong positive relationship with future stock-return correlation. Further, these values are easily combined with historical correlation. Together, they produce more accurate predictions of future correlation than either does separately. Using an agglomerative clusterer and a genetic algorithm in a pipeline approach, we use the pairwise values to form clusters of similar stocks. We compare these clusters against a leading industry classification system, GICS, finding that the clusters from the combined analyst and correlation pairwise values tend to perform at least as well as GICS and often better. In an application of our pairwise values, we consider a hypothetical scenario where an investor wishes to hedge a long position in a single stock. Our results indicate that using the analyst similarity values to select a hedge portfolio leads to greater risk reduction than using GICS or hedging with a broad-market index. Using a combination of historical correlation with the analyst values leads to even greater improvements.",
  "year": 2014,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "721aef83df8861c4e665abfdabb22e44",
  "timestamp": "2025-05-15T01:18:20.611151"
}