{
  "id": 1507,
  "title": "On the empirical performance of different covariance-matrix forecasting methods",
  "abstract": "In the study of financial time series, covariance/correlation matrices play a central role in risk-related applications, including financial contagion and portfolio selection. Different methodologies have been used in their prediction, from methods based on Financial Econometrics DCC-GARCH (Engle in J Bus Econ Stat 20(3):339-350, 2002), to others linked to Ecophysics like Random Matrix Theory (Wang et al. in Comput Econ 51:607-635, 2018), and more recently to Machine Learning (Fiszeder and Orzeszko in Appl Intell 51(10):7029-7042, 2021). Despite these developments, there is no state-of-the-art study that compares all these methods and assesses their predictive power in an out-of-sample setting. Indeed, in this work, we focus on measuring the out-of-sample predictive power of correlation matrices of these different statistical methods, in particular from three different fields that have converged in recent years in the analysis of financial data: Econometrics, Econophysics, and Machine Learning. Thus, using a moving window scheme, we studied the correlation matrices of 29 stock market indexes from different latitudes of the world. Among our findings, we see the relationship between the measures of Eigen Entropy found in the market, with the error found in the forecast of each method in the form of Square Forecast Error. We find that in the period from 2008 to 2022, considering 2608 moving windows, the out-of-sample error tends to converge between the different methods, highlighting the performance of DCC-GARCH.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5fb29523fb0ca6d66a9f33a9b95f63fd",
  "timestamp": "2025-05-15T02:03:39.851304"
}