{
  "id": 1316,
  "title": "When one domino falls, others follow: A machine learning analysis of extreme risk spillovers in developed stock markets",
  "abstract": "This study investigates the potential for extreme risk spillovers across developed stock markets using a machine learning approach. We utilize a novel methodology, proposed by Keilbar and Wang (2022), that combines extreme value theory with artificial neural networks to quantify the likelihood and magnitude of risk spillovers among twenty-three major developed stock markets for the period encompassing January 1991 to July 2022. The results reveal significant evidence of risk spillovers across the markets based on the extent of trade integration among countries. Secondly, during prolonged and vigorous periods of crisis events, extreme risk spillovers and corresponding contagion(s) within this integrated system of markets are likely to return. Moreover, the authors find that the magnitude of spillovers can be influenced by factors such as economic interconnectedness, size, book -to -market, investment portfolio and financial market volatility. The study offers important insights into the nature and dynamics of risk spillovers in developed stock markets and highlights the potential benefits of incorporating machine learning techniques into risk management strategies.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a5843d6311bf41a97a9f56d8b76402fc",
  "timestamp": "2025-05-15T02:01:44.667619"
}