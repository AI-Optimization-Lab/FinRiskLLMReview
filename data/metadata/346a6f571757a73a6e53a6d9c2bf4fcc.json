{
  "id": 2377,
  "title": "Typology for flight-to-quality episodes and downside risk measurement",
  "abstract": "We propose a total return-based framework to measure downside risk associated with phenomenon of capital outflows from riskier to safer financial markets. The proposed method consists of three elements: (i) the general definition of the flight-to-quality (FtQ) phenomenon, (ii) the typological classification of the flight-to-quality occurrences for associating them with the phases of the business cycle and (iii) the automated technique to diagnose the time frames and to measure the impact of flight-to-quality on financial instruments. The proposed framework is applied to analyse the global-scale capital inflows/outflows from emerging markets public debt to the US Treasuries and vice versa. The results show that different phases of business cycles and GDP growth rates, including turning points, could be associated with flights-to-quality of different types and causality origins. Addressing downside risk crystallizations in flight-to-quality occurrences, new perspectives of integrated interest rate risk and credit risk management are discussed. For strengthening financial stability, we suggest the use of flight-to-quality windows as scenarios for stress testing, both for banks and financial institutions.",
  "year": 2016,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "346a6f571757a73a6e53a6d9c2bf4fcc",
  "timestamp": "2025-05-15T02:14:50.284574"
}