{
  "id": 947,
  "title": "Research on short term stock selection strategy based on machine learning",
  "abstract": "Based on theoretical analysis, this paper constructs a short-term stock selection strategy based on machine learning. The sample set is constructed based on the closing price trend of individual stocks in the last 20 trading days, and the machine learning algorithms GBDT and GBRank are used for training, and machine learning is used to automatically perform pattern recognition on the processing capabilities of high-dimensional nonlinear data. When forecasting, the former will rank stocks with higher rising probability in the next 3 trading days, and the latter will rank stocks with greater gains in the nest 3 trading days. The stock selection strategy swaps positions every 3 trading days, and each time the top 10 stocks given by the equal-weight buying algorithm are used to construct an investment portfolio. The experimental results show that the short-term quantitative stock selection strategy based on the GBDT algorithm can outperform the market combination, namely the Shanghai and Shenzhen 300 Index, and has certain practicability.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "69c7b4a2de176d2995abeeab53924ce5",
  "timestamp": "2025-05-15T00:50:08.665326"
}