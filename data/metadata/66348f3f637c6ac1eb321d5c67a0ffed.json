{
  "id": 1673,
  "title": "A Hierarchical Bayesian Network-Based Approach to Keyword Auction",
  "abstract": "Prosperity of the online keyword auctions greatly facilitates the penetration of search-engine marketing in various industries. However, the current operation rules of the search engine make it very difficult for those inexperienced advertisers to make sound bids without the support of powerful tools. Therefore, many studies have been conducted to help advertisers understand such dynamic, infinite, and opaque auction situation, and obtain as good as possible bidding result. This paper, focusing on predicting the return on investment (ROI) of a keyword portfolio, develops a hierarchical Bayesian network (BN) model to forecast keyword auctions' performance. Few papers directly predict the ROI of a keyword portfolio. This approach effectively echoes advertisers' expectation for a keyword auction by choosing the right keywords and bids to achieve the desired outcome. The building blocks of the prediction model, such as bid and rank, are organized in a tree-shaped structure with a set of joint conditional probabilities. To infer the posterior probabilities of the predictors, a Bayesian parameter-learning algorithm is conducted after validating the network's structural relationships. The empirical study demonstrates that the prediction model is appropriate and effective for keyword auctions. Moreover, the proposed hierarchical BN model shows a higher accuracy than the popular prediction approach-the back-propagation artificial neural network.",
  "year": 2015,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "66348f3f637c6ac1eb321d5c67a0ffed",
  "timestamp": "2025-05-15T00:58:18.373615"
}