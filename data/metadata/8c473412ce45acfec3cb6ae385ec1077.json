{
  "id": 1879,
  "title": "Chinese corporate fraud risk assessment with machine learning",
  "abstract": "Corporate fraud is becoming a vital concern of Chinese financial industry in recent years. However, manual investigation of certain suspicious companies could result in mass consumption of resources. Aside from financial variables which were widely used in previous research, this paper has included novel features to assess Chinese corporate fraud, such as transfer of shares and Institutional Shareholdings, and these features are proven to be effective. We also present an efficient and accurate framework for corporate fraud detection that could be used as a fraud risk early warning system for financial institutions and regulatory authorities. Five machine learning methods have been implemented in the experiment and are compared using six metrics. Among these methods, XGboost has relatively higher performance overall in comparison to other models. Feature analysis has also been performed to analyze the influences of different groups of features in different models. This result illustrates that the models would achieve the best performance when all features are included, while financial condition has the most important impact among these groups. In addition, since the dataset being used is public, the result is simple for other researchers to reproduce and improve.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8c473412ce45acfec3cb6ae385ec1077",
  "timestamp": "2025-05-15T02:08:39.016908"
}