{
  "id": 81,
  "title": "A comparison of wavelet networks and genetic programming in the context of temperature derivatives",
  "abstract": "The purpose of this study is to develop a model that describes the dynamics of the daily average temperature accurately in the context of weather derivatives pricing. More precisely, we compare two state-of-the-art machine learning algorithms, namely wavelet networks and genetic programming, with the classic linear approaches that are used widely in the pricing of temperature derivatives in the financial weather market, as well as with various machine learning benchmark models such as neural networks, radial basis functions and support vector regression. The accuracy of the valuation process depends on the accuracy of the temperature forecasts. Our proposed models are evaluated and compared, both in-sample and out-of-sample, in various locations where weather derivatives are traded. Furthermore, we expand our analysis by examining the stability of the forecasting models relative to the forecasting horizon. Our findings suggest that the proposed nonlinear methods outperform the alternative linear models significantly, with wavelet networks ranking first, and that they can be used for accurate weather derivative pricing in the weather market. (C) 2016 The Authors. Published by Elsevier B.V. on behalf of International Institute of Forecasters.",
  "year": 2017,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6d9968b8dfeb08b0203df383070875f8",
  "timestamp": "2025-05-15T01:28:03.940880"
}