{
  "id": 2445,
  "title": "Online Estimation of Stochastic Volatility for Asset Returns",
  "abstract": "An important application of financial institutions is quantifying the risk involved in investing in an asset. These are various measures of risk like volatility or value-at-risk. To estimate them from data, a model for underlying financial time series has to be specified and parameters have to be estimated. In the following, we propose a framework for estimation of stochastic volatility of asset returns based on adaptive fuzzy rule based system. The model is based on Takagi-Sugeno fuzzy systems, and it is built in two phases. In the first phase, the model uses the Subtractive Clustering algorithm to determine group structures in a reduced data set for initialization purpose. In the second phase, the system is modified dynamically via adding and pruning operators and a recursive learning algorithm determines automatically the number of fuzzy rules necessary at each step, whereas one step ahead predictions are estimated and parameters are updated as well. The model is applied for forecasting financial time series volatility, considering daily values the REAL/USD exchange rate. The model suggested is compared against generalized autoregressive conditional heteroskedaticity models. Experimental results show the adequacy of the adaptative fuzzy approach for volatility forecasting purposes.",
  "year": 2012,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6f6cff5d8ccb1c1e484fadbaf7672f58",
  "timestamp": "2025-05-15T02:15:27.075164"
}