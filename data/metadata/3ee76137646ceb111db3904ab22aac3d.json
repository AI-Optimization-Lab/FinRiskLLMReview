{
  "id": 5900,
  "title": "Quantitative trading of gold and silver using nonlinear models",
  "abstract": "The main aim of this paper is to forecast gold and silver daily returns with advanced regression analysis using various linear and non-linear models. ARMA models are used as a linear benchmark for comparison purposes with established non-linear models such as Nearest Neighbours and MultiLayer Perceptron (MLP), and Higher Order Neural Networks (HONN) whose application to financial markets is quite new. All models are assessed using statistical criteria such as correct directional change as well as financial criteria such as risk adjusted return. The main aim is to find which of these models generate the best returns and if nonlinear models can be used for generating excess returns in the precious metals market. This is achieved by implementing a trading simulation where the forecast is translated into a trading signal. Profit statistics are calculated taking into account transaction costs. It is concluded that, for the January 2000-May 2006 period under review, non-, linear models like MLPs and HONNs did outperform the linear ARMA models. In the end, the performance of both MLP and HONN models showed the presence of nonlinearities in the gold and silver prices as it was found that nonlinear models can be effectively used for generating excess returns in these markets.",
  "year": 2007,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "3ee76137646ceb111db3904ab22aac3d",
  "timestamp": "2025-05-15T02:52:31.495946"
}