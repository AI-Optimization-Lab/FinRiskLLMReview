{
  "id": 287,
  "title": "基于自回归移动平均反转的在线投资组合选择",
  "abstract": "针对现有均值反转类策略未充分考虑噪声数据、单周期假设和数据的非平稳性等问题,提出了一种基于多周期的高效的在线自回归移动平均反转(OLAR)算法。首先,利用自回归移动平均算法得到了股价预测模型,并经过合理的假设将其转化为自回归模型;然后,结合损失函数和正则项构造出了目标函数,并利用损失函数的二阶信息得到了参数的闭式解;接着,利用在线被动攻击(PA)算法得到了投资组合的闭式更新。理论分析和实验仿真结果表明,与鲁棒中位数反转(RMR)相比,OLAR在NYSE(O)、NYSE(N)、道琼斯工业指数(DJIA)和MSCI数据集上的累积收益分别提高了455.6%,221.5%,11.2%和50.3%;同时,统计检验结果表明,OLAR的表现并不是由随机因素造成的。此外,与RMR和在线滑动平均反转(OLMAR)等算法相比,OLAR获得了最大的年化收益率、夏普比率和Calmar比率;最后,OLAR的运行时间与RMR和OLMAR基本相同,因此也适合大规模的实时应用。",
  "year": 2018,
  "source": "CNKI",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "92f9f99a3b4d47afa6d4e3f3c90c123d",
  "timestamp": "2025-05-14T22:22:16.564102"
}