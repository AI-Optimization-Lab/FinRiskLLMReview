{
  "id": 1732,
  "title": "Erythropoietin and preoperative autologous blood donation in the prevention of hepatitis C infection: necessity or luxury?",
  "abstract": "BACKGROUND: Prevention of exposure to allogeneic blood transfusion during surgery is an important financial issue when recombinant human erythropoietin (rHuEPO) is used in addition to preoperative blood donation. STUDY DESIGN AND METHODS: The aim of this study was to carry out a cost-effectiveness analysis of the use of rHuEPO in preoperative blood donation in orthopedic surgery. The study, based on a decision tree analysis of the use of rHuEPO, was conducted from the perspective df the French health care system. The efficacy criterion was the number of hepatitis C infections prevented. The decision tree analysis was constructed as follows: the residual risk of hepatitis C infection was 8.26 per million units transfused, and the chance node was defined according to the number of units transfused. RESULTS: With the use of rHuEPO in preoperative brood donation, 0.30562 cases of hepatitis C infection per 100,000 patients were prevented. The incremental cost of one prevented hepatitis C infection amounted to $888,000,000 (US). CONCLUSION: Despite the limitations of our model, the cast-effectiveness ratio was so large that variations only slightly modified the size of the result. From the societal perspective it was not cost-effective to add rHuEPO to preoperative blood donation.",
  "year": 1999,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "e9179e95acc62614140951a5c730204a",
  "timestamp": "2025-05-15T02:06:52.680197"
}