{
  "id": 21,
  "title": "Research on Pricing Methods of Convertible Bonds Based on Deep Learning GAN Models",
  "abstract": "This paper proposes two data-driven models (including LSTM pricing model, WGAN pricing model) and an improved model of LSM based on GAN to analyze the pricing of convertible bonds. In addition, the LSM model with higher precision in traditional pricing model is selected for comparative study with other pricing models. It is found that the traditional LSM pricing model has a large error in the first-day pricing, and the pricing function needs to be further improved. Among the four pricing models, LSTM pricing model and WGAN pricing model have the best pricing effect. The WGAN pricing model is better than the LSTM pricing model (0.21%), and the LSM improved model (1.17%) is better than the traditional LSM model (2.26%). Applying the generative deep learning model GAN to the pricing of convertible bonds can circumvent the harsh preconditions of assumptions, and significantly improve the pricing effect of the traditional model. The scope of application of each model is different. Therefore, this paper proves the feasibility of the GAN model applied to the pricing of convertible bonds, and enriches the pricing function of derivatives in the financial field.",
  "year": 2023,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "aafa4c535b237e28b8c2471d45288121",
  "timestamp": "2025-05-15T01:26:26.410014"
}