{
  "id": 1745,
  "title": "LEARNING TEMPORAL RELATIONSHIPS BETWEEN FINANCIAL SIGNALS",
  "abstract": "Portfolio risk control is vital to financial institutions: investors seek to build equities with the highest return but with minimum risk. However, a general phenomenon is significant comovement among many financial signals, such as stocks and futures. One investment strategy is to choose less correlated assets. Classic approaches quantifying such relationships in real financial markets make it difficult to exclude factors such as market trends and autocorrelation. In this paper, we propose a signal process perspective for quantitative measurement. A machine learning based algorithm is designed to model returns, taking account of market sensitivity, autocorrelation, and relationships with other stocks. We then extend the model training algorithm using regularized least square and gradient descent to estimate parameters. A penalty factor is designed in the optimization function to address extreme large negative returns. After denoising common factors, the learned pure relationship parameters are applied to construct a relationship matrix. Finally, we use this matrix to build portfolios by constrained optimization. Empirical experiments on two stock datasets show that the proposed method outperforms several state-of-the-art methods in terms of mean average precision and cumulative returns.",
  "year": 2018,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d5e61430e6367b361352cea5a4cfc845",
  "timestamp": "2025-05-15T02:06:52.715217"
}