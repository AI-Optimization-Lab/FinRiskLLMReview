{
  "id": 3419,
  "title": "Does gold act as a hedge or a safe haven for stocks? A smooth transition approach",
  "abstract": "This study deals with the issue whether gold actually exhibits the function of a hedge or a safe haven as often referred to in the media and academia. In order to test the Baur and Lucey (2010) hypotheses, we contribute to the existing literature by the augmentation of their model to a smooth transition regression (STR) using an exponential transition function which splits the regression model into two extreme regimes. One accounts for periods in which stock returns are on average and therefore allows to test whether gold acts as a hedge for stocks, the other one accounts for periods characterized by extreme market conditions where the volatility of the stock returns is high. The latter state enables us to test whether gold can be regarded as a safe haven for stocks. The study includes a broad set of 18 individual markets as well as five regional indices and covers a sample period running from January 1970 to March 2012 on a monthly frequency. Overall, our findings show that gold serves as both a hedge and a safe haven. However, this ability seems to be market-specific. In addition, by applying a portfolio analysis we also show that our findings are useful for investors. (C) 2014 Elsevier BM. All rights reserved.",
  "year": 2015,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "347f2d2588498ff69f5468fdddd6e01d",
  "timestamp": "2025-05-15T01:16:55.531702"
}