{
  "id": 183,
  "title": "Efficient multimodal learning for corporate credit risk prediction with an extended deep belief network",
  "abstract": "Precise corporate credit risk (CCR) prediction empowers investors, banks and other financial institutions to build risk prevention and crisis evasion mechanisms. Currently, CCR prediction gradually trends towards integrating multi-source data for more accurate prediction, but the effective fusion of these data is still insufficient. For this purpose, this paper presents a novel method titled the multimodal extended deep belief network (MEDBN) for CCR prediction. First, a multimodal dataset comprising numerical, categorical, and textual data is constructed based on two public corporate credit rating datasets, with textual data sourced from 10-K/Q filings. Each modality is processed using specialized preprocessing techniques. Then, to effectively extract features from each modality while addressing the challenges of multimodal fusion and joint representation learning, the DBN is extended by incorporating advanced deep learning techniques, including residual networks (ResNet), embedding layers, and bidirectional encoders (BERT). Finally, MEDBN undergoes two-stage training consisting of unsupervised pretraining followed by supervised fine-tuning, enabling sufficient learning of joint representations to enhance model performance. Extensive experimental results indicate that MEDBN consistently outperforms benchmark models across most key metrics, with particularly notable robustness on smaller datasets. These findings imply that MEDBN can effectively fuse and utilize multimodal data to achieve more reliable predictions. Additionally, this study demonstrates how the textual content influences performance, providing interpretable insights to support the decision-making process.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "91bdb886547d29b2e56c7dd8c76f8cab",
  "timestamp": "2025-05-15T01:35:04.421689"
}