{
  "id": 7307,
  "title": "Length of Stay From the Hospital Perspective Practice of Early Discharge Is Not Associated With Increased Readmission Risk After Lung Cancer Surgery",
  "abstract": "Objective: To determine if hospitals that routinely discharge patients early after lobectomy have increased readmissions. Background: Hospitals are increasingly motivated to reduce length of stay (LOS) after lung cancer surgery, yet it is unclear if a routine of early discharge is associated with increased readmissions. The relationship between hospital discharge practices and readmission rates is therefore of tremendous clinical and financial importance. Methods: The National Cancer Database was queried for patients undergoing lobectomy for lung cancer from 2004 to 2013 at Commission on Cancer-accredited hospitals, which performed at least 25 lobectomies in a 2-year period. Facility discharge practices were characterized by a facility's median LOS relative to the median LOS for all patients in that same time period. Results: In all, 59,734 patients met inclusion criteria; 2687 (4.5%) experienced an unplanned readmission. In a hierarchical logistic regression model, a routine of early discharge (defined as a facility's tendency to discharge patients faster than the population median in the same time period) was not associated with increased risk of readmission (odds ratio 1.12, 95% confidence interval 0.97-1.28, P = 0.12). In a risk-adjusted hospital readmission rate analysis, hospitals that discharged patients early did not experience more readmissions (P = 0.39). The lack of effect of early discharge practices on readmission rates was observed for both minimally invasive and thoracotomy approaches. Conclusions: It is possible for hospitals to develop early discharge practices without increasing readmissions. Further study is needed to identify the critical practice elements that have enabled hospitals to aggressively discharge patients without increasing readmission risk.",
  "year": 2017,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "48b8fbb77692df2b15586071535202d4",
  "timestamp": "2025-05-15T03:07:02.709984"
}