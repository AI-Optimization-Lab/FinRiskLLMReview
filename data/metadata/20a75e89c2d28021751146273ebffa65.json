{
  "id": 6016,
  "title": "A large cross sectional study on diaper utilization and beneficial role in outdoor activity and emotions among incontinence elderly people",
  "abstract": "This study was designed based on a cross-sectional investigation conducted Shanghai, China. Demographic characteristics, diaper utilization, Activities of Daily Living (ADL) and emotion were collected by Unified Needs Assessment Form for Elderly Care Questionnaire. Cognition function was assessed by Mini-mental State Examination (MMSE) scale. Multivariate logistic regression was used for statistical analysis. The diaper utilization rate was 31.2%. Female, higher level of education, poorer ADL and cognition, more severe incontinence and financial dependence on others were facilitating factors for diaper usage (P < 0.05). The possibility of using diaper differed according to the intimacy of caregivers. Among incontinent individuals with relatively good ADL and cognition level, diaper utilization can significantly decrease the risk of going out only once a month (OR: 2.63 vs 4.05), and going out less than once a month (OR: 5.32 vs 6.53). Incontinence people who going out at least once a week had a lower risk of some negative emotion. Significantly, diaper utilization further decreased this risk. In conclusion, for incontinence elderly people with relatively independent ability, proper use of diaper may improve the frequency of outdoor activity and emotion. Nevertheless, diaper utilization should be decided based on elderly people's own will.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "20a75e89c2d28021751146273ebffa65",
  "timestamp": "2025-05-15T02:54:03.319798"
}