{
  "id": 22,
  "title": "MDAEN: Multi-Dimensional Attention-based Ensemble Network in Deep Reinforcement Learning Framework for Portfolio Management",
  "abstract": "Reinforcement Learning algorithms are widely applied in many diverse fields, including portfolio management. Ensemble of Identical Independent Evaluators (EIIE) framework proposed by Jiang et al. achieved portfolio management based on their deep reinforcement learning algorithm. In the implementation of EIIE framework, a neural network such as the Convolutional Neural Network is applied as the policy network, to uncover more patterns in the data. However, this network typology is inefficient due to its simple structure. To overcome the shortcoming of EIIE framework, this paper introduces a novel algorithm, the Multi-Dimensional Attention-based Ensemble Network (MDAEN) strategy, which consists of a features-attention module and an assets-attention module. The MDAEN applies different types of attention mechanisms to extract information from the assets. Having adopted the reinforcement learning framework fromJiang et al., the agent is able to process transactions through MDAEN in a market. In our portfolio establishment, Bitcoin together with eleven other cryptocurrencies is selected to validate the performance of MDAEN against seven traditional portfolio strategies and EIIE. The experimental result demonstrates the efficacy of our strategy outperforming all other strategies by at least 35% in profitability and at least 30% in Sharpe Ratio.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "be55b2a1c167182c28f70c94dee896c8",
  "timestamp": "2025-05-15T00:38:16.272581"
}