{
  "id": 238,
  "title": "Dynamic interrelationships among crude oil, green bond, and carbon markets: Evidence from fuzzy logic autoencoders",
  "abstract": "This paper investigates the dynamic interrelationships among various markets covering crude oil, green bonds, and carbon emissions from January 2014 to October 2022, using a Fuzzy Logistic Autoencoder (FLAE) model, which elevates methodological sophistication and helps capturing intricate and complex relationships across the three markets. Different features of FLAE, such as identifying crossed lags and introducing a novel sigmoid-type activation function, enhance structural stability and establish the model as a reference for studying crosstemporal effects across markets. The key findings indicate that green bond returns negatively impact the returns of carbon emission allowances and Brent oil in the short and medium term. The impact of carbon emission allowance returns and oil returns on the forecast of green bond returns is comparatively trivial. Forecasting green bond returns is primarily driven by its short-term lags. These findings should be useful for portfolio managers in energy markets, environmentally conscious investors, and policy-makers concerned with financial sustainability amid the energy transition.",
  "year": 2025,
  "source": "WOS",
  "area": "portfolio",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "3b9778208e4d93a6ec5dc1d44d2dc07f",
  "timestamp": "2025-05-15T00:33:39.517799"
}