{
  "id": 3410,
  "title": "Inconsistency in Managers' Disclosure Tone: The Signalling Perspective",
  "abstract": "This article examines the factors contributing to the disparity in managers' disclosure tone from a signalling perspective. According to this viewpoint, managers intentionally choose their tone to convey information to the market. To determine the origin of tone inconsistency, we explored the association between future financial performance (as measured by the rate of return on assets (ROA) and rate of return on equity (ROE)) and future financial risk (as measured by the standard deviation of ROA and ROE) with the tone of management discussion and analyses (MD&As). The Loughran and McDonald dictionaries were utilised to assess managers' tone in the MD&As. Our dataset consisted of 1510 MD&As from 156 companies listed on the Tehran Stock Exchange, covering 2013 to 2022. Multiple regression analysis was employed, controlling for industry and year fixed effects. The findings revealed a significant relationship between future financial performance, future financial risk, and MD&A tone inconsistency. Thus, the biased tone observed in Iranian managers' MD&As can be explained by signalling theory. This study contributes to the existing literature by being the first to investigate signalling as a source of inconsistency in managers' disclosure tone.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d746d4c03f40b62b854bc04a353b4b31",
  "timestamp": "2025-05-15T02:25:40.246304"
}