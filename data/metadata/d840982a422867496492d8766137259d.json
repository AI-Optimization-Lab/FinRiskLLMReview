{
  "id": 3002,
  "title": "Multi-Source Correlation Factor Analysis of Carbon Finance Market Risk Based on Copula",
  "abstract": "Low carbon economy has become the important impetus for the sustainable development to all nations. Carbon market not only deploys resources effectively but also promotes low carbon economy development. As we know, financial market is always full of risks caused by uncertainty, meanwhile the risk is caused by multi-sources. Such as, there are capital turnover and different currency settlement ways through international trade for domestic enterprises, so the international carbon finance market risk primarily contains three correlative risk factors: carbon price volatility, interest rate volatility and exchange rate volatility. This paper taking Chinese enterprises for an example mainly uses Copula theory to analyze carbon finance market risk and measure the VaR. The research findings: (1) The three risk factors all have GARCH effect, time-varing and clustering; (2) The VaR would be overestimated if ignoring the correlation between different risk factors; (3) The integrated VaR rises with the confidence level growth; (4) Interest rate volatility is the most sensitive market risk factor in the carbon finance.",
  "year": 2014,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d840982a422867496492d8766137259d",
  "timestamp": "2025-05-15T02:21:19.290760"
}