{
  "id": 4571,
  "title": "Motives and profiles of ICO investors",
  "abstract": "Research on initial coin offerings (ICOs) is nascent and assesses ICOs from the perspectives of ventures and regulators. Little is known about the equally important group of investors who provide their capital to ventures in ICOs. Using a primary dataset of 517 ICO investors, we identify and categorize the motivations to invest in ICOs using factor analysis. We find that investors are driven by ideological, technological, and financial motives. Regarding the relative importance of the motives, we find that technological motives are the most important motives to ICO investors, followed by financial and ideological motives. To further profile investors, we conduct a regression analysis to distinguish investors across different motives. For example, we show significant differences across motives with regard to investors' risk perception, sources of information, and demand for strict regulation. The implications of this study for both theory and practice are considerable.",
  "year": 2021,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "640041dc117c8f9a687c4d04de3ccf43",
  "timestamp": "2025-05-15T02:38:56.220630"
}