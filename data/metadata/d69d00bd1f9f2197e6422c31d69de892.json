{
  "id": 565,
  "title": "An Empirical Evaluation of Distance Metrics in Hierarchical Risk Parity Methods for Asset Allocation",
  "abstract": "Hierarchical Risk Parity methods address instability, concentration, and underperformance in asset allocation by taking advantage of machine learning techniques to build a diversified portfolio. HRP methods produce a hierarchical structure to the correlation between assets by means of tree clustering that results in a reorganization of the covariance matrix of returns. However, HRP admits multiple variations in terms of clustering algorithms and distance metrics. In this paper, we evaluate the out-of-sample performance of alternative hierarchical distance metrics for clustering purposes using real stock markets in three different market scenarios: bull market, sideways trend, and bear market. We pay special attention to the mean-variance performance of the output portfolios as an estimation of the ability of alternative methods to estimate future return and risk. Our results show that correlation-based metrics provide better performance than non-correlation metrics. In addition, HRP methods outperform quadratic optimizers in two of the three stock market scenarios.",
  "year": 2025,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d69d00bd1f9f2197e6422c31d69de892",
  "timestamp": "2025-05-15T00:45:01.318761"
}