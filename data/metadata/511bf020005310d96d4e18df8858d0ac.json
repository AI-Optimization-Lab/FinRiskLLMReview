{
  "id": 7237,
  "title": "The effects of donor and recipient practices on transplant center finances",
  "abstract": "Over the past several years we have noted a marked decrease in this profitability of our kidney transplant program. Our hypothesis is that this reduction in kidney transplant institutional profitability is related to aggressive donor and recipient practices. The study population included all adults with Medicare insurance who received a kidney transplant at our center between 1999 and 2005. Adopting the hospital perspective, multi-variate linear regression models to determine the independent effects of donor and recipient characteristics and era effects on total reimbursements and total hospital margin. We note statistically significant decreased medical center incremental margins in cases with ECDs (-$5887) and in cases of DGF (-4937). We also note an annual change in the medical center margin is independently associated with year and changes at a rate of -$5278 per year, related to both increasing costs and decreasing Medicare reimbursements. The financial loss associated with patient DGF and the use of ECD kidneys may resonate with other centers, and could hinder efforts to expand kidney transplantation within the United States. The Centers for Medicare and Medicaid Services (CMS) should consider risk-adjusted reimbursement for kidney transplantation.",
  "year": 2008,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "511bf020005310d96d4e18df8858d0ac",
  "timestamp": "2025-05-15T03:06:35.387323"
}