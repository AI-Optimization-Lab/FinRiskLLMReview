{
  "id": 3785,
  "title": "Investor sentiments and stock markets during the COVID-19 pandemic",
  "abstract": "This study examines the relationship between positive and negative investor sentiments and stock market returns and volatility in Group of 20 countries using various methods, including panel regression with fixed effects, panel quantile regressions, a panel vector autoregression (PVAR) model, and country-specific regressions. We proxy for negative and positive investor sentiments using the Google Search Volume Index for terms related to the coronavirus disease (COVID-19) and COVID-19 vaccine, respectively. Using weekly data from March 2020 to May 2021, we document significant relationships between positive and negative investor sentiments and stock market returns and volatility. Specifically, an increase in positive investor sentiment leads to an increase in stock returns while negative investor sentiment decreases stock returns at lower quantiles. The effect of investor sentiment on volatility is consistent across the distribution: negative sentiment increases volatility, whereas positive sentiment reduces volatility. These results are robust as they are corroborated by Granger causality tests and a PVAR model. The findings may have portfolio implications as they indicate that proxies for positive and negative investor sentiments seem to be good predictors of stock returns and volatility during the pandemic.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "164a9f7c775a5c9a58497ecbc9ba2242",
  "timestamp": "2025-05-15T01:20:36.131055"
}