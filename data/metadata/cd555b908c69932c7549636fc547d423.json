{
  "id": 5868,
  "title": "The role of banking supervision in credit risk disclosures and loan loss provisions",
  "abstract": "Purpose - The aim of this paper is to analyse the effect of the level of supervisory power on the level of disclosure of loan loss provisions and on the use of this item for income smoothing purposes. Design/methodology/approach - Our sample includes 60 European banks from 15 countries, covering the period between 2012 and 2015. We use an index based on the measure of supervisory power and we estimate three regression models in order to investigate the role of banking supervision in credit risk disclosure and in the use of loan loss provisions for income smoothing purposes. Findings - The results show that banks from countries with a higher level of supervisory power disclose more information about loan loss provisions. However, banks from countries with a higher level of supervisory power only disclose more information regarding Pillar 3 and not IFRS 7. Additionally, we conclude that managerial discretion is lower in banks domiciled in countries with high enforcement. Originality/value - This study is useful for bank supervisors as it raises awareness about their influence on the disclosure of impairment losses on financial assets, and for users of financial statements as insights are provided about the relationship between supervisory power and income smoothing.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "cd555b908c69932c7549636fc547d423",
  "timestamp": "2025-05-15T02:52:31.362247"
}