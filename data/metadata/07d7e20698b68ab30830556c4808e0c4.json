{
  "id": 2006,
  "title": "Data Cleaning for Personal Credit Scoring by Utilizing Social Media Data: An Empirical Study",
  "abstract": "With the accumulation of data on personal behavior and the development of machine learning models and algorithms, it is becoming possible to use social media data for personal credit scoring. In this article, we use the systematic sampling method to obtain Douban's social media data. Because there are many abnormal users in these data, they are real but false data for personal credit evaluation. In order to better carry out personal credit scoring, we propose three criteria, power exponents of time interval distribution of individual user $\\gamma _i$gamma i, user activity $A_i$Ai, and the ratio of out-degree and in-degree $R_i$Ri of user $i$i, which are used to systematically clean the data. And then, we used the logistic regression method to score the individual credits of users before and after data cleaning, and found that the rank order of personal credit scoring has changed significantly. This change is largely attributed to the changes of network structure after data cleaning. We believe that our work is very important to use the social media data to establish a credible personal credit evaluation system to reduce the credit risk of the current Internet financial industry.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "07d7e20698b68ab30830556c4808e0c4",
  "timestamp": "2025-05-15T02:09:48.446575"
}