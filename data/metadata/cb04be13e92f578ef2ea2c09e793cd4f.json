{
  "id": 2199,
  "title": "Readability of Financial Footnotes, Audit Fees, and Risk Management Committee",
  "abstract": "We find that the readability of financial footnotes and risk management committees contributes to audit fees. We use observations from 758 companies listed in Indonesia for 2014-2018, and moderated regression analysis is used for statistical analysis. The results show that the readability of financial footnotes will affect audit fees paid, and RMC strengthens the relationship between the readability of financial footnotes and audit fees. In addition, we also used robustness assays to address endogeneity issues with consistent results as moderated regression analysis (hereafter MRA). These findings provide evidence for policymakers about the relationship between the readability of financial footnotes, RMC, and audit fees.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "cb04be13e92f578ef2ea2c09e793cd4f",
  "timestamp": "2025-05-15T02:12:17.458742"
}