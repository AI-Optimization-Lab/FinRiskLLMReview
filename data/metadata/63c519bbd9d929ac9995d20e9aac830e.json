{
  "id": 207,
  "title": "逆周期调节的宏观审慎政策有效性研究",
  "abstract": "2008年国际金融危机的爆发，凸显出在金融监管中融入宏观审慎思维的重要性。当前全球金融风险因素明显增多，新冠肺炎疫情全球蔓延导致金融体系脆弱性程度进一步提高，宏观审慎政策正成为宏观调控政策中的重要支柱。本文着眼于从逆周期调节分析宏观审慎政策的有效性。统计分析和回归结果显示，宏观审慎政策总体而言能够降低金融体系的顺周期性。并且，各类宏观审慎政策工具对于降低顺周期性的作用存在显著差异。基于研究结果，结合监管发展情况，本文提出几点建议：(1)定期开展宏观审慎政策效果评估，总结各类工具的实践经验；(2)在宏观审慎政策的运用中，进一步增强对金融周期等反映系统性风险指标的关注；(3)多维度加强宏观审慎政策相关领域数据要素利用，为提高政策效能提供决策参考。",
  "year": 2022,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "63c519bbd9d929ac9995d20e9aac830e",
  "timestamp": "2025-05-14T22:27:55.649305"
}