{
  "id": 463,
  "title": "Risk-Aversion Adjusted Portfolio Optimization with Predictive Modeling",
  "abstract": "We propose a multi-period portfolio optimization method rooted on the mean-risk framework, in which the risk aversion coefficient is adjusted in response to the market trend movement predicted by machine learning models. We use the Gini's Mean Difference to characterize the risk of the portfolio, and employ a series of technical indicators as the features to feed the predictive machine learning models. A set of comprehensive computational tests are carried out within a rolling-horizon approach to evaluate the performance of the generated portfolios. The empirical results show that the regularized logistic regression model provides the best prediction of market trend movement, while the proposed dynamic risk-aversion adjusted portfolio rebalancing strategy generates portfolios with higher time-series cumulative returns than a static strategy with fixed risk-aversion coefficient.",
  "year": 2019,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7e808de81098e25bb09a6be3f5873797",
  "timestamp": "2025-05-15T00:43:47.351369"
}