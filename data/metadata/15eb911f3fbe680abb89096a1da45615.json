{
  "id": 6999,
  "title": "Pacifier use and morbidity in the first six months of life",
  "abstract": "Objective. To assess the prevalence of pacifier use and whether this habit adversely affects the health of B-month-old infants. Design. Data collected via self-completion questionnaires from mothers forming part of the prospective, population-based Avon Longitudinal Study of Pregnancy and Childhood. Methods. The mothers of 10 950 infants gave information on their child's use of a pacifier at 4 weeks and 6 months of age and the presence of specific health symptoms. Adjusted logistic regression was performed to identify any associations between pacifier use and ill health. Results. Two thirds of the sample had been given a pacifier at some point, with 42% being reported as having one at both ages. Younger, lower educated mothers, mothers who smoked, those living in council and overcrowded accommodation, and those reporting financial difficulties were significantly more likely to give their infant a pacifier. Pacifier use was associated significantly with a higher risk of symptoms such as wheezing, earache, vomiting, fever, diarrhea, and colic as well as with the general practitioner being called to the home and hospital admission. Conclusions. Although significant differences exist in the risk of experiencing several health symptoms between infants who do and infants who do not use a pacifier, stronger and more detailed evidence is required before recommendations can be made to discourage the use of pacifiers based purely on reducing occurrences of these symptoms.",
  "year": 1999,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "15eb911f3fbe680abb89096a1da45615",
  "timestamp": "2025-05-15T03:03:55.830748"
}