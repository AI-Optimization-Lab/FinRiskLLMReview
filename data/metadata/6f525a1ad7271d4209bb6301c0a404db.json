{
  "id": 3837,
  "title": "Little science, big science - Strategies for research portfolio selection in academic surgery departments",
  "abstract": "Objective: To evaluate National Institutes of Health (NIH) funding for academic surgery departments and to determine whether optimal portfolio strategies exist to maximize this funding. Summary Background Data: The NIH budget is expected to be relatively stable in the foreseeable future, with a modest 0.7% increase from 2005 to 2006. Funding for basic and clinical science research in surgery is also not expected to increase. Methods: NIH funding award data for US surgery departments from 2002 to 2004 was collected using publicly available data abstracted from the NIH Information for Management; Planning, Analysis, and Coordination (IMPAC) II database. Additional information was collected from the Computer Retrieval of Information on Scientific Projects (CRISP) database regarding research area (basic vs. clinical, animal vs. human, classification of clinical and basic sciences). The primary outcome measures were total NIH award amount, number of awards, and type of grant. Statistical analysis was based on binomial proportional tests and multiple linear regression models. Results: The smallest total NIH funding award in 2004 to an individual surgery department was a single $26,970 grant, whereas the largest was more than $35 million comprising 68 grants. From 2002 to 2004, one department experienced a 336% increase (greatest increase) in funding, whereas another experienced a 73% decrease (greatest decrease). No statistically significant differences were found between departments with decreasing or increasing funding and the subspecialty of basic science or clinical research funded Departments (n = 5) experiencing the most drastic decrease (total dollars) in funding had a significantly higher proportion of type K (P = 0.03) grants compared with departments (n = 5) with the largest increases in total funding; the latter group had a significantly increased proportion of type U grants (P = 0.01). A linear association between amount of decrease/increase was found with the average amount of funding per grant and per investigator (P < 0.01), suggesting that departments that increased their total funding relied on investigators with large amounts of funding per grant. Conclusions: Although incentives to junior investigators and clinicians with secondary participation in research are important, our findings suggest that the best strategy for increasing NIH funding for surgery departments is to invest in individuals with focused research commitments and established track records of garnering large and multiple research grants.",
  "year": 2007,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6f525a1ad7271d4209bb6301c0a404db",
  "timestamp": "2025-05-15T01:21:08.341740"
}