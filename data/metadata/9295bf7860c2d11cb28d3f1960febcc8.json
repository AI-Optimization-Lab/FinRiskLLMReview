{
  "id": 462,
  "title": "Random Matrix Theory and Nested Clustered Optimization on high-dimensional portfolios",
  "abstract": "This work aims to address the optimal allocation instability problem of Markowitz's modern portfolio theory in high dimensionality. We propose a combined strategy that considers covariance matrix estimators from Random Matrix Theory (RMT) and the machine learning allocation methodology known as Nested Clustered Optimization (NCO). The latter methodology is modified and reformulated in terms of the spectral clustering algorithm and Minimum Spanning Tree (MST) to solve internal problems inherent in the original proposal. Markowitz's classical mean-variance allocation and the modified NCO machine learning approach are tested on the financial instruments that compose the S&P 500 index listed on the New York Stock Exchange (NYSE) from 2012 to 2021. The modified NCO algorithm achieves stable allocations by incorporating RMT covariance estimators. A particular combination of covariance estimators, known as two-step estimators involving a hierarchical clustering technique, achieves the best portfolio performance. Surprisingly, a common pattern suggests that the improvement in performance is agnostic to the allocation strategy and, in fact, relies heavily on the covariance estimator selection. Our results suggest that the amount of leverage can be drastically reduced in investment strategies through RMT inference and statistical learning techniques.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "9295bf7860c2d11cb28d3f1960febcc8",
  "timestamp": "2025-05-15T00:43:47.347902"
}