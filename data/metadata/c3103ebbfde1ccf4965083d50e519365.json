{
  "id": 2615,
  "title": "INFORMATION RELATED TO POSTAL FLOWS AND BIG DATA ANALYSIS POTENTIAL. THE CASE OF SPAIN",
  "abstract": "National Post Offices manage huge volumes of letters and parcels. Data associated to these flows are growing fast, with a great variety related to the diversity of postal products. The research described in this paper has classified all information flows of Correos, the Spanish National Post Office. In spite of the complexity of the current postal service portfolio, only four categories of matrices allow the classification of all postal information flows. Thanks to the migration towards new products, analyses with simple techniques will provide more and better information in the future, due to the structured nature of existing databases. (C) 2016 The Authors. Published by Elsevier B.V.",
  "year": 2016,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c3103ebbfde1ccf4965083d50e519365",
  "timestamp": "2025-05-15T01:08:41.928140"
}