{
  "id": 2299,
  "title": "Realized Volatility, Jump and Beta: evidence from Canadian Stock Market",
  "abstract": "Inclusion of jump component in the price process has been a long debate in finance literature. In this paper, we identify and characterize jump risks in the Canadian stock market using high-frequency data from the Toronto Stock Exchange. Our results provide a strong evidence of jump clustering - about 30% of jumps occur within first 30 minutes of trading hours, and about 25% of jumps are due to the overnight returns. While average intraday jump is negative, jumps induced by overnight returns bring a cancellation effect yielding average size of the jumps to zero. We show that the economic significance of jump component in volatility forecasting is significant but nominal. Our results further demonstrate that market jumps and overnight returns bring significant changes in systematic risk of stocks. From a cross-sectional perspective, while the average effect of market jumps on the beta is not significantly different from zero, the average effect of overnight returns is statistically significant. Overall, our results suggest that systematic risk induced by the market jumps could be hedged by combining value stocks and growth stocks in a portfolio whereas the systematic risk induced by overnight returns can not be hedged even with a well diversified portfolio.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8205aab4a788525c14184b3710ecb088",
  "timestamp": "2025-05-15T01:05:39.600326"
}