{
  "id": 7727,
  "title": "Developing a two stage optimized random vector functional link neural network based predictor model utilizing a swift crow search algorithm",
  "abstract": "Investment in financial markets, such as indices, derivatives, commodities, currency exchanges, and so forth, is becoming more and more popular among the general public with the growth of economy. Accurate financial time-series prediction is now vital for investors, researchers, and investment firms due to its high-risk, high reward nature. For many years, specialists have tried to look into the underlying patterns of the market, anticipate future prices, and determine which way the market would move. Therefore applying modern forecasting models can be quite useful for comprehending and foreseeing market changes. In light of this, this paper proposes a novel two-stage optimized random vector functional link network (RVFLN) based predictor model with the dual goals of forecasting the upcoming stock index close price and predicting whether the upcoming trend will be upward or downward. For selecting optimal input features and weights of RVFLN, an improved variant of the crow search algorithm (CSA) known as the swift crow search algorithm (SCSA) is suggested in the study. In order to achieve the ideal balance between exploration and exploitation, improving convergence, the SCSA is developed by introducing the good point set (GPS) strategy in initial population generation, the chaotic map and mutation operator of differential evolution (DE) in the position update scheme, and catfish behavior in the search process of the original CSA. Specifically SCSA is used at two stages in the process of building the model. To improve the prediction performance, initially features from multiple domains are accumulated, including raw, statistical, technical, and decomposed domains. Since a broader feature space can lead to the curse of dimensionality and overfitting, a binary feature selection algorithm utilizing SCSA is used in conjunction with RVFLN in the first stage. In the subsequent stage following feature selection, the randomly generated input weights of RVFLN were optimized using SCSA to enhance its prediction performance even further. The theorized trend predictor model is empirically validated using historical data from three stock indices acquired before and during the COVID19 timeframe, including the BSE SENSEX, S&P 500, and DJIA datasets. In both timeframes, the proposed two-stage model outperforms the state-of-the-art baseline models in terms of three prediction and three classification evaluation criteria. Furthermore, in all the benchmark datasets, the proposed SCSA outperforms traditional optimization techniques. The qualitative relevance test, in addition to the statistical test, indicates that the proposed two-stage framework outperforms other compared models in three benchmark datasets for both time frames and is suitable for financial time-series forecasting in both ideal and highly volatile markets.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "0cc40dd9e60ad7d91295700645683ea6",
  "timestamp": "2025-05-15T03:11:38.453617"
}