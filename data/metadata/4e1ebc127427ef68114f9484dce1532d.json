{
  "id": 384,
  "title": "Probabilistic machine learning for local volatility",
  "abstract": "The local volatility model is widely used for pricing and hedging financial derivatives. While its main appeal is its capability of reproducing any given surface of observed option prices - it provides a perfect fit - the essential component is a latent function that can be uniquely determined only in the limit of infinite data. To (re)construct this function, numerous calibration methods have been suggested that involve steps of interpolation and extrapolation, most often of parametric form and with point-estimate representations. We use probabilistic machine learning to look at the calibration problem in a probabilistic framework based on Gaussian processes. This immediately gives a way of encoding prior beliefs about the local volatility function and a hypothesis model that is highly flexible yet not prone to overfitting. Besides providing a method for calibrating a (range of) point estimate(s), we draw posterior inference from the distribution over local volatility. This leads to a better understanding of uncertainty associated with the model in general, and with the calibration in particular. Further, we infer dynamical properties of local volatility by augmenting the hypothesis space with a time dimension. Ideally, this provides predictive distributions not only locally, but also for entire surfaces forward in time. We apply our approach to S&P 500 market data.",
  "year": 2021,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "4e1ebc127427ef68114f9484dce1532d",
  "timestamp": "2025-05-15T01:31:13.205419"
}