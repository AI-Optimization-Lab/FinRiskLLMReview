{
  "id": 8238,
  "title": "The Influence of Hedge, Arbitrage, and After-Hours Trading on the Holding Returns of TAIEX Futures",
  "abstract": "This study points out a new explanation of the non-trading effect of financial derivatives from the perspective of hedging demand. We examine the influence of hedging demand on the non-trading effect of TAIEX (Taiwan Stock Exchange Capitalization Weighted Stock Index) Futures. By dividing the sample period into trading period and non-trading period and testing the difference between the risk premiums in these two intervals, we find that there is a non-trading effect in TAIEX Futures, which means that the holding returns of TAIEX Futures in the non-trading period are higher than those in the trading period. By estimating a dummy-regression model, the evidence shows that when the VIX (Taiwan Index Option Volatility Index) indicator is relatively high, the non-trading effect will be more significant, indicating that the non-trading effect may come from investors' hedging needs. In addition, it is found that when the futures index is higher than the spot index, the non-trading effect becomes less obvious. The possible reason is that when there is a positive spread in index futures, investors will expect a bull market, thus reducing the hedging demand of index futures. In the end, we find that the liquidity in the after-hours trading session is poor, resulting in high hedging costs, and forcing investors to hedge during the regular trading period. Therefore, the after-hours trading of TAIEX Futures fails to reduce the non-trading effect.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "cbbdb6e30324fde2a13ac2c887c75f32",
  "timestamp": "2025-05-15T03:16:48.959925"
}