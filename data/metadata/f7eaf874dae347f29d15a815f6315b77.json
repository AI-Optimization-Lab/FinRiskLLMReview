{
  "id": 4731,
  "title": "Home country environment and the downside risk implications of multinationality: Empirical evidence from Chinese SMEs",
  "abstract": "According to real options theory, a global network built through multinational investments endows a firm with a series of options for future development. These options can enhance a firm's operational flexibility, reducing its downside risk. This study aims to investigate the home country conditions necessary to achieve multinationality's downside risk effect in Chinese small and medium-sized enterprises (SMEs). Using data from Chinese manufacturing SMEs from 2003 to 2021 and a Tobit regression model, this study finds that multinationality can significantly reduce the downside risk of Chinese SMEs. Moreover, the degree of home country economic openness and financial development can significantly enhance multinationality's negative effect on downside risk. Further analysis suggests that the moderating effects of the home country environment are more prominent for state-owned firms than for privately-owned firms. Our findings emphasize the important role of a home country environment in achieving the value of multinationality's flexibility.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "f7eaf874dae347f29d15a815f6315b77",
  "timestamp": "2025-05-15T02:40:27.943245"
}