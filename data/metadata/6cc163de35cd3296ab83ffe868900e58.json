{
  "id": 4921,
  "title": "Threshold effects of credit risk on renewable energy consumption and green financial policies nexus: evidence from OECD countries",
  "abstract": "Previous research on renewable energy financing has often underestimated or neglected the important impact of credit risk on the energy transition process. The study addresses this gap by exploring the threshold effect of credit risk on renewable energy consumption (REC) and green financial policies (GFP) nexus in 47 OECD countries from 2000 to 2020. Using a Panel Smooth Transition Regression (PSTR) model, we find a positive relationship between GFP and REC. However, exceeding a specific threshold of credit risk significantly decreases the effectiveness of bank financing for renewable energy projects. The threshold is approximately 74% for the entire sample, with slight variations between developed (77%) and developing countries (72%). Despite the risk, banks in developed countries are more involved in financing green projects than their counterparts in developing nations. These results remain consistent after adding control variables and employing an alternative model and estimation method. The findings highlight the importance of credit risk management in optimising banks' green lending policies and facilitating the transition towards renewable energy sources.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6cc163de35cd3296ab83ffe868900e58",
  "timestamp": "2025-05-15T02:42:36.121813"
}