{
  "id": 3906,
  "title": "Financial communities",
  "abstract": "Postings on Internet discussion boards provide an unusual opportunity to explore the sociological mechanics underlying the impounding of information into stock prices and to examine any implications for portfolio construction. Graph-theoretic techniques applied to contacts across the web network of stock discussion allow classification of stocks into two types: communities of connected stocks, and disconnected stocks. Connected stocks outperform others in a risk-adjusted sense. Adopting the concept of centrality from the sociology literature reveals that stocks with high centrality covary more with other stocks, suggesting greater analyst scrutiny. Classifying stocks into financial communities provides a novel way to look at risk-return trade-offs and to direct analyst attention, and offers new diversification insights for portfolio managers.",
  "year": 2005,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "0f574f836dd56cbf38715782f3075b1e",
  "timestamp": "2025-05-15T02:30:58.388343"
}