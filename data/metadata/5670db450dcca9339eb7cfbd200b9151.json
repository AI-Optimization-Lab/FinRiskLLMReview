{
  "id": 3801,
  "title": "Risk factors in stock returns of US oil and gas companies: evidence from quantile regression analysis",
  "abstract": "The boom and bust in oil prices during the last two decades have attracted many investors to oil and gas companies in search of returns and risk diversification benefits. This study analyzes the impact of several risk factors, including oil and gas prices, overall stock market returns, stock market volatility index, and the trade-weighted U.S. Dollar Index (DXY) on stock returns of U.S. oil and gas companies, using a quantile regression (QR) method. The findings suggest that most firms in the U.S. oil and gas sector have significant risk exposures to changes in market portfolio returns and oil prices. The analysis also reveals that risk factor sensitivities are not equal across quantiles, indicating asymmetric responses of oil and gas stock returns to various systematic risk factors. Changes in oil prices, in general, are likely to have the strongest impact in the left tail, and this impact gradually decreases toward the right tail. This implies that an investor with a long position in an oil and gas stock will be exposed to a substantially greater risk than an investor with a short position.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5670db450dcca9339eb7cfbd200b9151",
  "timestamp": "2025-05-15T01:21:08.065704"
}