{
  "id": 4229,
  "title": "Volatility Model Based GARCH Minimum Variance Hedging",
  "abstract": "In the risk management, volatility as the important parameter for estimation in the issue of hedging. Volatility model is the regression based forecasting model. GARCH (Generalized Autoregressive Conditional Heteroscedasticity) model is one of volatility model, it presents the variance rate at the current time step is a weighted average of a constant long run average variance rate, the variance rate at the previous time steps and the most recent information about the variance rate. Hence, there are many literatures supposed to use the GARCH minimum variance hedging the financial derivatives. Thus, the bivariate GARCH model provides a superior performance to other dynamic or constant hedge for financial derivatives. In the paper, it estimates the minimum variance hedge based on an advanced econometric model (GARCH model) with time varying minimum variance hedge.",
  "year": 2018,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6ceb2aefcc8397d99ff2b1f40762cb43",
  "timestamp": "2025-05-15T02:34:48.894675"
}