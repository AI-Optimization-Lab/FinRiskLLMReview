{
  "id": 3413,
  "title": "Scenario selection with LASSO regression for the valuation of variable annuity portfolios",
  "abstract": "Variable annuities (VAs) are increasingly becoming popular insurance products in many developed countries which provide guaranteed forms of income depending on the performance of the equity market. Insurance companies often hold large VA portfolios and the associated valuation of such portfolios for hedging purposes is a very time-consuming task. There have been several studies focusing on inventing techniques aimed at reducing the computational time including the selection of representative VA contracts and the use of a metamodel to estimate the values of all contracts in the portfolio. In addition to the selection of representative contracts, this paper proposes using LASSO regression to select a set of representative scenarios, which in turn allows for the set of representative contracts to expand without significant increase in computational load. The proposed approach leads to a remarkable improvement in the computational efficiency and accuracy of the metamodel.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "aa93dfea21fac0b939eefe38213a9326",
  "timestamp": "2025-05-15T01:16:55.495686"
}