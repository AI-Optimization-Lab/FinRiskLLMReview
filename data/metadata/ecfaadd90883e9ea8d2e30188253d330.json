{
  "id": 278,
  "title": "Modeling for project portfolio benefit prediction via a GA-BP neural network",
  "abstract": "Project portfolio benefit (PPB) prediction can effectively help managers monitor the acquisition of PPBs, thereby better achieving their target benefits. However, no valid model is available for PPB prediction. To narrow this research gap, we develop a model based on a backpropagation neural network improved with a genetic algo-rithm (GA-BPNN) to quantitatively forecast PPBs. First, the evaluation criteria for benefits are determined. Second, the input and output variables of the model are determined and calculated. Third, the initial weights and thresholds of the BPNN are improved by the GA. Fourth, based on the above optimization results, the GA-BPNN model is trained and tested. Last, the numerical example is provided to demonstrate the application of the proposed model. The results indicate that the established model is feasible and effective in predicting PPBs, with an average prediction accuracy rate of 98.64 %, which is 18.24 % better than that of the base BPNN. The model proposed in this paper effectively realizes the quantitative prediction of PPBs, enriching the research on project portfolio management (PPM) and providing managers with a tool to effectively predict PPBs.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "ecfaadd90883e9ea8d2e30188253d330",
  "timestamp": "2025-05-15T00:41:04.847399"
}