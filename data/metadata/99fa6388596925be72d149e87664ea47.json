{
  "id": 5455,
  "title": "Risk selection and heterogeneous preferences in health insurance markets with a public option",
  "abstract": "Conventional wisdom suggests that if private health insurance plans compete alongside a public option, they may endanger the latter's financial stability by cream-skimming good risks. This paper argues that two factors may contribute to the extent of cream-skimming: (i) degree of horizontal differentiation between public and private options when preferences are heterogeneous; (H) whether contract design encourages choice of private insurance before information about risk is revealed. I explore the role of these factors empirically within the unique institutional setting of the German health insurance system. Using a fuzzy regression discontinuity design to disentangle adverse selection and moral hazard, I find no compelling support for extensive cream-skimming of public option by private insurers despite their ability to fully underwrite risk. A model of demand for private insurance supports the idea that heterogeneity in non pecuniary preferences and long-term structure of private insurance contracts may be muting cream skimming in this setting. (C) 2016 Elsevier B.V. All rights reserved.",
  "year": 2016,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "99fa6388596925be72d149e87664ea47",
  "timestamp": "2025-05-15T02:47:43.083001"
}