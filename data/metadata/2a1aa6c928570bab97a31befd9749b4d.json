{
  "id": 407,
  "title": "新时代强化我国金融风险防控能力的理论指南——习近平关于防范化解金融风险的重要论述",
  "abstract": "作为当前我国金融工作的重要任务和关键环节,防控金融风险事关我国经济与金融的良性循环与高质量发展。党的十八大以来,面对错综复杂的国内外金融环境与发展形势,习近平关于防控金融风险的一系列重要论述基于维护国家金融安全的战略定位,紧紧把握不发生系统性金融风险的防控底线,以推动金融回归服务实体经济遏制\"脱实向虚\"的风险隐患,以深化金融供给侧结构性改革与扩大金融高水平对外开放凝聚防控金融风险的内外合力,从而形成了在\"防风险\"中\"保安全\"、在\"归实体\"\"推改革\"\"促开放\"中\"防风险\"的理论体系。这一系列重要论述明确了当前我国金融风险防控的基本原则、工作导向和实践路径,为推动完善我国金融风险防控的制度建设与政策实践提供了理论武器和行动指南。",
  "year": 2021,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "2a1aa6c928570bab97a31befd9749b4d",
  "timestamp": "2025-05-14T22:30:01.764419"
}