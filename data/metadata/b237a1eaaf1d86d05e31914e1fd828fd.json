{
  "id": 4169,
  "title": "Household's Overindebtedness during the COVID-19 Crisis: The Role of Debt and Financial Literacy",
  "abstract": "The COVID-19 pandemic has shown how important it is to prepare one's own financial budget for the unexpected loss of income. In this dimension, the financial education of the society plays an invaluable role. It allows us to account for events that may adversely affect personal finances in our budget management decisions. Therefore, the aim of the article is to check whether households with a higher level of financial and debt literacy have better management skills from the perspective of a household's budget, which in the face of a crisis reduces the risk of individuals not paying their liabilities. Thus, at the turn of June and July 2020, we conducted surveys among 1300 Polish citizens. Using the multinomial logistic regression, we show that people with a higher financial and debt literacy are less affected by overindebtedness. During the crisis, people who have a higher debt literacy are better prepared to manage credit liabilities; in this situation, financial literacy is less important. In addition, the type of credit experience turned out to be significant. Respondents who have experience with consumer loans (potentially high-margin products) are more likely to have debt repayment problems than those with mortgage loans experiences.",
  "year": 2021,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b237a1eaaf1d86d05e31914e1fd828fd",
  "timestamp": "2025-05-15T02:34:13.322699"
}