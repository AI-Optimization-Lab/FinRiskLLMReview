{
  "id": 1674,
  "title": "Sign Prediction and Volatility Dynamics with Hybrid Neurofuzzy Approaches",
  "abstract": "Reliable forecasting techniques for financial applications are important for investors either to make profit by trading or hedge against potential market risks. In this paper the efficiency of a trading strategy based on the utilization of a neurofuzzy model is investigated, in order to predict the direction of the market in case of FTSE100 and New York stock exchange returns. Moreover, it is demonstrated that the incorporation of the estimates of the conditional volatility changes, according to the theory of Bekaert and Wu (2000), strongly enhances the predictability of the neurofuzzy model, as it provides valid information for a potential turning point on the next trading day. The total return of the proposed volatility-based neurofuzzy model including transaction costs is consistently superior to that of a Markov-switching model, a feedforward neural network as well as of a buy & hold strategy. The findings can be justified by invoking either the volatility feedback theory or the existence of portfolio insurance schemes in the equity markets and are also consistent with the view that volatility dependence produces sign dependence. Thus, a trading strategy based on the proposed neurofuzzy model might allow investors to earn higher returns than the passive portfolio management strategy.",
  "year": 2011,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a7fb2afcf906f506bdcd0130906f0797",
  "timestamp": "2025-05-15T00:58:18.378143"
}