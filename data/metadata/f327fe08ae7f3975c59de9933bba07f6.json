{
  "id": 6474,
  "title": "Dependence structures between Chinese stock markets and the international financial market: Evidence from a wavelet-based quantile regression approach",
  "abstract": "In this study, we investigate the dependence structures between six Chinese stock markets and the international financial market including possible safe haven assets and global economic factors under different market conditions and investment horizons. The research is conducted by combining a quantile regression approach with a wavelet decomposition analysis. Although we find little or insignificant dependence under short investment horizons, we detect the strong asymmetric dependence of oil prices and the US dollar index on the six Chinese stock markets in the medium and long terms. Moreover, not only is crude oil not a safe haven, it may damage Chinese stock markets as it increases over the long term, even in bull markets. Meanwhile, appreciation of the US dollar (depreciation of RMB) damages (boosts) Chinese stock markets during bull (bear) market conditions under long investment horizons. Moreover, we find that VIX (volatility index)-related derivatives may serve as good risk management tools under any market condition, while gold is a safe haven asset only during crisis periods.",
  "year": 2018,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "f327fe08ae7f3975c59de9933bba07f6",
  "timestamp": "2025-05-15T02:58:34.103605"
}