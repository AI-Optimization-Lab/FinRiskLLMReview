{
  "id": 4643,
  "title": "Corporate Social Responsibility Risk and Firm Performance: A Network Perspective",
  "abstract": "This study explored how corporate social responsibility (CSR) risk, social networks, and firm performance interacted in light of resource dependence theory and information asymmetry theory to bridge the literature gap between CSR risk and firm performance under the conditions of China's network. We used data from Shanghai and Shenzhen A-share listed firms in China from 2010 to 2019 to conduct a social network analysis and random-effects GLS regression analysis. The study revealed the following: (1) CSR risk hurts financial performance, while structural holes and network density attenuate this effect; (2) CSR risk positively impacts capital performance, which is amplified by closeness centrality; (3) CSR risk harms innovation performance, while betweenness centrality and network density mitigate this effect. Despite CSR risk bringing short-term benefits, this effect is not sustained. Generally, CSR risks are more detrimental to firms than beneficial. In this study, we strengthen the basis of the research on CSR risk and firm performance, along with research on social networks, advising firms to avoid CSR risks and utilize their networks to mitigate such risks and achieve a better performance.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "735bac9801c172b38891c32272f4df1c",
  "timestamp": "2025-05-15T02:39:27.002310"
}