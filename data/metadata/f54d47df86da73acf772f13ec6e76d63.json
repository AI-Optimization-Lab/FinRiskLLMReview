{
  "id": 347,
  "title": "An empirical study on credit risk management: the case of nonbanking financial companies",
  "abstract": "The existing banking structure in India is very rich and serves its customers and borrowers very efficiently and effectively to meet their respective requirements and expectations. The main function of both banking and nonbanking financial institutions is to provide loans to their clients. We build a risk assessment model to rate the risk associated with the credit exposure on a probability scale and consequently to map probability to score bands for nonbank financial company (NBFC) customers. Our aim is to predict future default behaviors of NBFC customers using credit scores. The Pearson chi-squared test is used to study the association between two categorical variables. Logistical regression, neural network and decision tree models are developed and compared in order to find the best fit. For model comparison we use Kolmogorov-Smirnov, the receiver operator characteristic index, average square error and Gini statistics. The score card is used to check the creditworthiness of each customer. This research should provide key determinants of defaulters for the NBFC sector.",
  "year": 2018,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "f54d47df86da73acf772f13ec6e76d63",
  "timestamp": "2025-05-15T01:49:41.078678"
}