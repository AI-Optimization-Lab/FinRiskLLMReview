{
  "id": 4272,
  "title": "Forecasting VaR and ES using the joint regression combined forecasting model in the Chinese stock market",
  "abstract": "PurposeThis paper aims to better jointly estimate Value at Risk (VaR) and expected shortfall (ES) by using the joint regression combined forecasting (JRCF) model.Design/methodology/approachCombining different forecasting models in financial risk measurement can improve their prediction accuracy by integrating the individual models' information. This paper applies the JRCF model to measure VaR and ES at 5%, 2.5% and 1% probability levels in the Chinese stock market. While ES is not elicitable on its own, the joint elicitability property of VaR and ES is established by the joint consistent scoring functions, which further refines the ES's backtest. In addition, a variety of backtesting and evaluation methods are used to analyze and compare the alternative risk measurement models.FindingsThe empirical results show that the JRCF model outperforms the competing models. Based on the evaluation results of the joint scoring functions, the proposed model obtains the minimum scoring function value compared to the individual forecasting models and the average combined forecasting model overall. Moreover, Murphy diagrams' results further reveal that this model has consistent comparative advantages among all considered models.Originality/valueThe JRCF model of risk measures is proposed, and the application of the joint scoring functions of VaR and ES is expanded. Additionally, this paper comprehensively backtests and evaluates the competing risk models and examines the characteristics of Chinese financial market risks.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "32d02b0d63ae8068573e5bc8feac7fa1",
  "timestamp": "2025-05-15T02:35:26.242982"
}