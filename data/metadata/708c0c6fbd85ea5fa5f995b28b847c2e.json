{
  "id": 632,
  "title": "回归本源强主业 化解风险重担当——对金融资产管理公司高质量发展的思考",
  "abstract": "在我国经济转向高质量发展阶段的背景下,作为化解金融风险专业机构的金融资产管理公司必须坚持新发展理念和\"质量第一、效益优先\"基本方针,摒弃规模、速度情结,回归本源,深耕不良资产主业,保持公司稳健运营;充分利用国家赋予资产管理公司相关政策,发挥自身专业技术和人才优势,综合运用企业并购、资产重组,市场化债转股、资产证券化等综合手段,着力解决有重大影响的问题项目和问题机构的债务问题,增强不良债权市场流动性,盘活优化存量资源、推动传统行业转型升级,推进供给侧结构性改革,服务实体经济发展;创新驱动、做精专业,不断提升化解金融风险能力,在防范和化解系统性金融风险中发挥更大作用,从而实现自身高质量发展。",
  "year": 2019,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "708c0c6fbd85ea5fa5f995b28b847c2e",
  "timestamp": "2025-05-14T22:31:55.739811"
}