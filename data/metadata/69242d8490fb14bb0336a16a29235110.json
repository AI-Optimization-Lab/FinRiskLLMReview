{
  "id": 1767,
  "title": "On the prediction of stock price crash risk using textual sentiment of management statement",
  "abstract": "PurposeSince stock return and volatility matters to investors, this study proposes to incorporate the textual sentiment of annual reports in stock price crash risk prediction.Design/methodology/approachSpecific sentences gathered from management discussions and their subsequent analyses are tokenized and transformed into numeric vectors using textual mining techniques, and then the Naive Bayes method is applied to score the sentiment, which is used as an input variable for crash risk prediction. The results are compared between a collection of predictive models, including linear regression (LR) and machine learning techniques.FindingsThe experimental results find that those predictive models that incorporate textual sentiment significantly outperform the baseline models with only accounting and market variables included. These conclusions hold when crash risk is proxied by either the negative skewness of the return distribution or down-to-up volatility (DUVOL).Research limitations/implicationsIt should be noted that the authors' study focuses on examining the predictive power of textual sentiment in crash risk prediction, while other dimensions of textual features such as readability and thematic contents are not considered. More analysis is needed to explore the predictive power of textual features from various dimensions, with the most recent sample data included in future studies.Originality/valueThe authors' study provides implications for the information value of textual data in financial analysis and risk management. It suggests that the soft information contained within annual reports may prove informative in crash risk prediction, and the incorporation of textual sentiment provides an incremental improvement in overall predictive performance.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "69242d8490fb14bb0336a16a29235110",
  "timestamp": "2025-05-15T02:07:25.649980"
}