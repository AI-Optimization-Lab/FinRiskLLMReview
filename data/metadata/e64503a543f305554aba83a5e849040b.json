{
  "id": 5100,
  "title": "Optimized contaminated land investigation at minimum overall cost to achieve fitness-for-purpose",
  "abstract": "A methodology for optimized contaminated land investigation (OCLI) is described that balances the uncertainty of measurements against the cost of taking the measurements and the financial losses that may arise from misclassification of the land. Uncertainty from the sources of both field sampling and chemical analysis is estimated using existing techniques, based on the taking of duplicated samples. The actual costs of sampling and analysis and the expected costs that could arise from either false positive or false negative classification of areas of land were estimated. A loss function was constructed that calculates the expectation of financial loss that will arise for a given uncertainty of measurement. The function shows a clear minimum value of cost at an optimal value of uncertainty. Application of this OCLI technique to two case studies demonstrated this minimum value. Below the optimum value of uncertainty, the costs increased due to higher measurement costs. Above the optimum, the costs increased due to increasing risk of factors such as unnecessary remediation or potential litigation over undetected contamination. Many areas for further development of OCLI are identified, but the technique is demonstrated as a useful new approach to judging fitness-for-purpose of such measurements.",
  "year": 2002,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "e64503a543f305554aba83a5e849040b",
  "timestamp": "2025-05-15T02:44:11.077805"
}