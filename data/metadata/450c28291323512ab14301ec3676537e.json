{
  "id": 970,
  "title": "Weighted Multivariate Mean Reversion for Online Portfolio Selection",
  "abstract": "Portfolio selection is a fundamental task in finance and it is to seek the best allocation of wealth among a basket of assets. Nowadays, Online portfolio selection has received increasing attention from both AI and machine learning communities. Mean reversion is an essential property of stock performance. Hence, most state-of-the-art online portfolio strategies have been built based on this. Though they succeed in specific datasets, most of the existing mean reversion strategies applied the same weights on samples in multiple periods and considered each of the assets separately, ignoring the data noise from short-lived events, trend changing in the time series data, and the dependence of multi-assets. To overcome these limitations, in this paper, we exploit the reversion phenomenon with multivariate robust estimates and propose a novel online portfolio selection strategy named Weighted Multivariate Mean Reversion (WMMR) (Code is available at: https://github.com/boqian333/WMMR).. Empirical studies on various datasets show that WMMR has the ability to overcome the limitations of existing mean reversion algorithms and achieve superior results.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "450c28291323512ab14301ec3676537e",
  "timestamp": "2025-05-15T00:50:08.759636"
}