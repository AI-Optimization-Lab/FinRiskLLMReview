{
  "id": 261,
  "title": "A novel finite-time q-power recurrent neural network and its application to uncertain portfolio model",
  "abstract": "This paper presents a novel finite-time q-power recurrent neural network (FT-QPNN) for uncertain port-folio model. An uncertain mean-variance-skewness model under concave transaction costs is discussed. This portfolio model is essentially a nonconvex nonlinear optimization problem with a non-positive def-inite Hessian matrix of the Lagrange function. The non-positive definite Hessian matrix leads to the fail-ure of many recurrent neural network methods in solving the problem, and many recurrent neural networks cannot converge to the equilibrium point in finite time. To overcome these difficulties, the FT-QPNN is proposed. Combined with finite-time activation function and local convexification method, the FT-QPNN can solve the optimization problem with non-positive definite Hessian matrix and converge to the equilibrium point in finite time. The global finite-time stability and robustness properties of the FT-QPNN are proved theoretically and verified by numerical experiments. Furthermore, the proposed FT-QPNN is applied to solve the uncertain portfolio model. The application simulation results and comparative experiments with other methods respectively illustrate the feasibility and superiority of the FT-QPNN. (c) 2021 Elsevier B.V. All rights reserved.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b038dd9316d38511a6244de5ad7dd0dd",
  "timestamp": "2025-05-15T00:41:04.759573"
}