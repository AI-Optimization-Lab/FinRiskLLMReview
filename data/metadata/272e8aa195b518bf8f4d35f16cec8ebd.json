{
  "id": 267,
  "title": "Data ming-based financial fraud detection: Current status and key issues",
  "abstract": "Recent advances in information, detection, data mining, risk and security technologies have given rise to a new era of research, known as data mining based financial fraud detection (FFD). Several data mining algorithms including regression, neural network, decision tree, Bayesian and Stacking variant methodology, incorporating financial ratio and learning mechanisms, have been developed that allow one to extract relevant knowledge from large amount of data like fraudulent financial statements (FFS). FFD is a new attempt; thus, several research questions have often being asked. For instance: (1) how to finish the detection process for these algorithms? (2) how to understand and classify these algorithms in terms of fraud detecting? (3) will they require specific data? (4) what kind of detection approach are used? (5) which one is the most popular method in use? To help answer these questions, we conduct an extensive review on literature. We present a generic FFD framework and a classification scheme to guide the review process. Frequencies of different techniques/algorithms used are tableau and analyzed. Finally, we share directions for future research.",
  "year": 2007,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "272e8aa195b518bf8f4d35f16cec8ebd",
  "timestamp": "2025-05-15T01:49:04.522739"
}