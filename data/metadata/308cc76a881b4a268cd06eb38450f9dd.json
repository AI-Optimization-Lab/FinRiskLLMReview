{
  "id": 2336,
  "title": "Multifunctional Expectile Regression Estimation in Volterra Time Series: Application to Financial Risk Management",
  "abstract": "We aim to analyze the dynamics of multiple financial assets with variable volatility. Instead of a standard analysis based on the Black-Scholes model, we proceed with the multidimensional Volterra model, which allows us to treat volatility as a stochastic process. Taking advantage of the long memory function of this type of model, we analyze the reproduced movements using recent algorithms in the field of functional data analysis (FDA). In fact, we develop, in particular, new risk tools based on the asymmetric least squares loss function. We build an estimator using the multifunctional kernel (MK) method and then establish its asymptotic properties. The multidimensionality of the Volterra process is explored through the dispersion component of the convergence rate, while the nonparametric path of the risk tool affects the bias component. An empirical analysis is conducted to demonstrate the ease of implementation of our proposed approach. Additionally, an application on real data is presented to compare the effectiveness of expectile-based measures with Value at Risk (VaR) in financial risk management for multiple assets.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "308cc76a881b4a268cd06eb38450f9dd",
  "timestamp": "2025-05-15T02:14:19.596384"
}