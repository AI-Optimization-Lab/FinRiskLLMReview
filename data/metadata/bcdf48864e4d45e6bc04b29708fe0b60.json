{
  "id": 949,
  "title": "Deep Learning for Multi-factor Models in Regional and Global Stock Markets",
  "abstract": "Many studies have been undertaken with machine learning techniques to predict stock returns in terms of time-series prediction. However, from the viewpoint of the cross-sectional prediction with machine learning techniques, there are no examples that verify its profitability in regional and global stock markets. This paper implements deep learning for multi-factor models to predict stock returns in the cross-section in these stock markets and investigates the performance of the method. Our results show that deep neural networks generally outperform representative machine learning models all over the world. These results indicate that deep learning shows promise as a skillful machine learning method to predict stock returns in the cross-section. Although deep learning performs quite well, it has significant disadvantages such as a lack of transparency and limitations to the interpretability of the prediction. Then, we present the application of layerwise relevance propagation (LRP) to decompose attributes of the predicted return. By applying LRP to each stock and averaging them in a portfolio, we can determine which factor contributes to prediction. We illustrate which factor contributes to prediction in regional and global stock markets.",
  "year": 2020,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "bcdf48864e4d45e6bc04b29708fe0b60",
  "timestamp": "2025-05-15T00:50:08.677859"
}