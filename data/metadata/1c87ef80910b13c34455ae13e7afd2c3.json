{
  "id": 1247,
  "title": "Assessment of Carbon-Aware Flexibility Measures From Data Centres Using Machine Learning",
  "abstract": "Potential solutions for unlocking operational flexibility from data centres are investigated. Two types of data centres, in terms of their cooling facilities, are modelled in order to provide an in-depth assessment of potential variations in data centre performance based on their energy consumption and server temperatures. Using synthetic datasets generated from year-long building dynamic simulations under distinct system conditions, four machine learning (ML) models are designed and trained to predict data centre energy consumption and server temperatures. Three different ML algorithms are considered, including random forest, XGBOOST, and multiple linear regression, which all achieve high accuracy ranging from 93.8% to 98.1% for the mean absolute percentage error. The resulting ML models are then utilised to represent a system-wide fleet of data centres, which are integrated within a power system unit scheduling framework for potential demand shifting based on (system) carbon intensity. Five alternative flexibility scenarios are introduced and compared, with the objective of determining the achievable flexibility from a system-wide portfolio of data centres, focusing on concerns relating to server temperatures. On average, a 6.5% load reduction is seen to be achievable for a winter day during periods of high CO2 intensity.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1c87ef80910b13c34455ae13e7afd2c3",
  "timestamp": "2025-05-15T00:53:42.047879"
}