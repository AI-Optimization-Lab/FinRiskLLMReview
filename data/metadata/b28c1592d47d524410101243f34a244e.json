{
  "id": 243,
  "title": "Automatic Generation of Critical Audit Matters (CAMs) Using LSTM-MacBert-Based Dual-Stream Transfer Learning",
  "abstract": "The disclosure of critical audit matters (CAMs) plays an important part in audit report reform and financial risk warnings. Current CAMs include matters that need to be focused on from the audit after a comprehensive evaluation of the internal control and other enterprise information, combined with the experience of the project manager, which is closely related to subjective factors, such as auditor professionalism and independence. An increase in subjective judgment becomes a breeding ground for audit failure. First, since long short-term memory (LSTM) is often used to process temporal data, MacBERT is often used as a text encoding, so LSTM is used to encode financial information to overcome the influence of subjective factors, and MacBert is used to encode nonfinancial information. The two modes are then separately encoded to form a dual-stream structure that simulates the process of auditors reviewing documents. Second, a transformer is used to perform multimodal interactions on the dual-stream encoding results to simulate the process of auditors integrating important information. Finally, the multimodal interaction results are fed into the fully connected layers and the SoftMax function to achieve cross-modal fusion, which simulates the process of auditors obtaining CAMs. Simulating single-modal coding, multimodal interaction, and cross-modal fusion helps to realize the automatic generation of CAMs. This ensemble model is called the CAMs automatic generation model and is based on LSTM-MacBert dual-stream transfer learning. The experimental results show that the features of financial statements and public disclosure text extracted by the model can effectively screen CAMs and realize the automatic generation of high-level CAMs.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b28c1592d47d524410101243f34a244e",
  "timestamp": "2025-05-15T01:35:45.582796"
}