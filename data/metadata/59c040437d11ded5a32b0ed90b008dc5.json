{
  "id": 3475,
  "title": "Estimation & Forecasting of Volatility using Arima, Arfima and Neural Network based Techniques",
  "abstract": "Volatility is used to indicate the stock market movement; in general terms can be defined as the risk associated with stocks. Volatility is measured as standard deviation and variance of Closing Prices. Forecasting volatility has been a prime issue in financial market and lots of researchers are working on it since more than a decade. The main goal of this paper is to forecast volatility with a high accuracy. The volatility is calculated using traditional volatility calculation techniques called volatility estimators. The volatility is calculated using Close, Garman klass, Parkinson, Roger and Yang estimating methods. Time series forecasting techniques ARIMA, ARFIMA and a feed forward Neural Network based techniques are used for forecasting volatility. The results of all the three techniques are compared to find an accurate estimation and forecasting technique. The best forecasting technique is shortlisted by comparing the error results of all the forecasting techniques with error measuring parameters such as ME, RMSE, MAE, MPE, MAPE, MASE and ACF1. Garman klass estimator with Arima technique as the forecasting methods yields more accurate volatility forecasts for next 10 days.",
  "year": 2015,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "59c040437d11ded5a32b0ed90b008dc5",
  "timestamp": "2025-05-15T02:26:48.471388"
}