{
  "id": 147,
  "title": "恶意透支型信用卡诈骗罪特别从宽于诈骗罪的再认识——以337件不起诉、无罪案件为例",
  "abstract": "我国刑法理论多从诈骗罪的教义学解读金融诈骗罪，忽略了金融诈骗罪的“金融”属性，进而将金融诈骗罪的“骗”等同于诈骗罪的“骗”。从恶意透支型信用卡诈骗罪的立法、司法演进来看，我国对于恶意透支型信用卡诈骗罪的处罚逐步宽容，没有严格套用诈骗罪的构成要件来理解信用卡诈骗罪。实务中，在现有立法及司法解释的基础之上，进一步缩小了信用卡诈骗罪的适用范围。金融诈骗罪的适用与经济、科技、经营理念等密切相关，而非孤立地考查加害方与被害方之间的“骗与被骗”。尤其是大数据、人工智能、机器学习等先进金融科技在信用卡风险监控中的应用，使商业银行对风险的掌控能力也随之提升，不能动辄将金融风险上升到犯罪的高度，更不能将金融诈骗行为以更重的诈骗罪论处。未来还应结合我国经济、金融的发展及趋势，适时调整包括信用卡诈骗罪在内的金融诈骗罪构成要件及司法上的适用范围，在惩罚犯罪与保障经济、金融发展之间寻求平衡。",
  "year": 2023,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "254362ac01b58eee0a5e453573e8862d",
  "timestamp": "2025-05-14T22:27:22.001120"
}