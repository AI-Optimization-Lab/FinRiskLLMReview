{
  "id": 325,
  "title": "A clustering-based portfolio strategy incorporating momentum effect and market trend prediction",
  "abstract": "The hierarchical clustering algorithm has been proved useful in portfolio investment, which is one of the hottest issues in finance. In our new portfolio strategy, central, peripheral and dispersed portfolios constructed from clusters detected using unweighted and weighted modularity are compared according to their past performances, and the optimal portfolio is used in the investment period only if the market index return predicted by the LR, WMA or BP models is positive to avoid losses when the market drops. Our strategy is tested using the daily data of Chinese A-share market from January 4, 2008 and December 31, 2016, and the average investment return during different moving investment periods and 200 repeated runs is calculated. We find that although incorporating dispersed portfolio into our strategy has no significant effect in raising the investment return, it shows a similar performance as the peripheral portfolio, and the strategy constructed using unweighted modularity generally outperforms its counterpart by using weighted modularity. In addition, the market trend prediction can refine the investment return of our strategy. In brief, the strategy constructed using the BP model and unweighted modularity has the best investment return, which also outperforms the Markowitz portfolio. (C) 2018 Elsevier Ltd. All rights reserved.",
  "year": 2018,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "67ae0f5ef32beaa102c4b2f49336ae4e",
  "timestamp": "2025-05-15T00:42:00.447294"
}