{
  "id": 5751,
  "title": "GA based FCMAC-BYY model for bank solvency analysis",
  "abstract": "Since the collapse or failure of a bank could trigger an adverse financial repercussion and generate negative impacts, it is desirable to have an Early Warning System (EWS) that identifies potential bank failures or high-risk banks through the traits of financial distress. This research is aimed to construct a novel GA-FCMAC-BYY model as an alternative to analyze bank solvency. The proposed model attempts to advance our previous work which uses Fuzzy Cerebellar Model Arithmetic Controller - Bayesian Ying-Yang (FCMAC-BYY) network. Inspired by the ancient Chinese Ying Yang philosophy, FCMAC-BYY obtains optimal solution by achieving harmony between inputs and fuzzy clusters sets. However, it optimizes the fuzzy sets in the individual dimensions, resulting in the lost of relative binding data and global optimization may not be achieved. Genetic Algorithm (GA) is introduced here to look into the issue. GA operates on a population of potential solutions based on the principle of survival of the fittest to produce better approximations to a solution. Populations of candidate solutions are evaluated using fitness functions to determine the best solution. Thereafter, chromosomes would be evolved to produces new genes in the search of the optimal solution. The performance of the proposed GA-FCMAC-BYY model as a bank failure classification and early warning system is very encouraging.",
  "year": 2007,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "f425882b88036d505bce376916eb6573",
  "timestamp": "2025-05-15T02:50:54.005694"
}