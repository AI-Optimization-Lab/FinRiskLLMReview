{
  "id": 3066,
  "title": "Towards Personal Financial Sustainability Based on Human Capital Analysis in Korea",
  "abstract": "Financial sustainability for individuals has become more important due to the increase in life expectancy. In personalized lifetime financial planning, human capital is critical for incorporating the life-cycle of individuals. This study focuses on human capital modeling based on features such as education level and working industry, and presents how difference in human capital can affect the optimal asset allocation. By analyzing the Korean labor and income panel survey data, fixed effects regression was performed to model human capital and a portfolio model that maximizes utility of total wealth is solved to optimize the lifetime financial plan. The empirical results show that individuals with human capital that are more correlated with stocks are advised to reduce allocation in stocks.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7798156465d0bf8d6527e007a17f7b07",
  "timestamp": "2025-05-15T01:13:09.868977"
}