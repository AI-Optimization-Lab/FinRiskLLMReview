{
  "id": 3072,
  "title": "Foreign exchange volatility and stock returns",
  "abstract": "This paper explores whether foreign exchange volatility is a priced factor in the US stock market. Our investigation is motivated by a number of empirical as well as theoretical considerations. Empirically. Menkhoff et al. (2012) find that foreign exchange volatility is a pervasive factor across a variety of test assets. Theoretically, Shapiro (1974), Dumas (1978), and Levi (1990) imply that foreign exchange volatility can influence firms' cash flow volatility therefore the discount rate. In terms of empirical implementation, we employ the cross-sectional regression methodology of Fama and MacBeth (1973) as well as the time-series regression approach of Fama and French (1996). For robustness, we also use the mimicking portfolio approach of Fama and French (1993). We find that foreign exchange volatility has no power to explain either the time-series or the cross-section of stock returns, which calls for more research on foreign exchange risk. Bartov et al. (1996) and Adrian and Rosenberg (2008) suggest an alternative and maybe promising direction. (C) 2012 Elsevier B.V. All rights reserved.",
  "year": 2012,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8ac6b05f8fd82f296ce13d72767ea432",
  "timestamp": "2025-05-15T01:13:09.883365"
}