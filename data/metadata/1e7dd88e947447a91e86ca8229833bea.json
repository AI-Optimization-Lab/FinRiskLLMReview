{
  "id": 423,
  "title": "基于大数据的智能风险防控平台设计与实现",
  "abstract": "金融安全是国家安全的重要组成部分,防范化解金融风险是金融工作的根本性任务。为帮助商业银行加快打造适应数字经济时代发展需要的风险防控平台,本文基于大数据应用的关键技术,提出了一种\"五层两域\"智能风险防控平台总体框架;纵向包含风险数据层、特征计算层、风险模型层、决策引擎层、业务接入层,各层之间松耦合、无状态、可扩展;横向则划分为生产部署域、业务运营域,可最大程度兼顾系统运行的稳定性与业务应用的灵活度。该设计有助于商业银行实现风险数据的统一治理和统一管理,在保证风险防控平台高效稳定运行的同时,又能在风险防控运营、数据分析、模型设计、规则调整等方面为风险防控业务人员提供充足的支撑。以某金融机构部署的智能风险防控平台为例,阐述了该平台的应用情况及实际成效,并对智能风险防控平台的应用发展提出建议。",
  "year": 2020,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1e7dd88e947447a91e86ca8229833bea",
  "timestamp": "2025-05-14T22:30:01.780984"
}