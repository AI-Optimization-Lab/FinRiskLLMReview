{
  "id": 367,
  "title": "Educating capable doctors-A portfolio approach. Linking learning and assessment",
  "abstract": "Background: Teachers want students to focus on their learning to become capable doctors; yet, students primarily want to focus on passing their exams. How much of this paradox is explained by learning and assessment being seen as two different entities rather than as the continuum of one and the same process? How may the two areas be more closely and effectively linked? Aim: This article describes and illustrates a conceptual framework for an approach termed capability-based portfolio assessment. Results and conclusions: Thinking about capability, i.e. the ability to perform in the real world, is needed for a contemporary curriculum and assessment design. A capability-focus will help students to integrate the foundations of medical practice with learning how to become a capable, reflective and life-long learner. A well-structured capability portfolio, regularly presented and reviewed, will be a useful tool to guide the journey, and should have the potential to help drive deep learning and allow the assessment of capabilities that are hard to assess using conventional approaches. Assessment based on portfolio approaches should not equate to increasing the overall assessment burden as it will reduce the need for more traditional assessment methods.",
  "year": 2009,
  "source": "WOS",
  "area": "portfolio",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b2b25e30f37ad7680499039b17c4481a",
  "timestamp": "2025-05-15T00:35:17.467257"
}