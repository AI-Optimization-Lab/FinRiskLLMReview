{
  "id": 694,
  "title": "Clustering financial time series to generate a new method of factor neutralization: An empirical study",
  "abstract": "In this paper, we consider the problem of clustering the long financial time series of the Chinese A-share market, applying k-means, k-Shape, agglomerative hierarchical clustering, affinity propagation, and Gaussian mixture to redivide the Chinese stock market. The results after parameter tuning show that the stocks in redivided industries are more similar than those of Shenwan first-class industry. Then we generate a new method of factor neutralization, using the new industries to neutralize factors, and then constructing the investment portfolios to test the four basic factors. The experimental results show that the investment portfolio based on k-means can steadily defeat the benchmark and the portfolio based on classical industry classification. This new method of factor neutralization can bring a stable and effective improvement to the returns of the factors and it is allowed be applied to other factors, which has a significant impact on factor investing.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "ed5f7c98845efd07378209632a40617f",
  "timestamp": "2025-05-15T00:47:18.448938"
}