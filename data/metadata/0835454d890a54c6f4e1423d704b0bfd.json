{
  "id": 97,
  "title": "Predictive multi-period multi-objective portfolio optimization based on higher order moments: Deep learning approach",
  "abstract": "We propose a Multi-Period Multi-Objective Portfolio Optimization model (MPMOPO). We used deep-learning approach to predict future behavior of stock returns. We consider four objectives, i.e., wealth, variance, skewness, and kurtosis and several constraints such as cardinality, budget, upper and lower limits of purchase, and diversification to address real-world situations. The investor can rebalance the portfolio through daily trade by buying or selling subject to transaction costs. We applied the proposed method in a daily closing price prediction of six stocks from FTSE 100. Goal programming method was used to solve the models. The results of statistical analysis show the applicability and efficacy of the proposed method in comparison with those methods which used historical data to form the portfolio.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "0835454d890a54c6f4e1423d704b0bfd",
  "timestamp": "2025-05-15T00:31:50.410935"
}