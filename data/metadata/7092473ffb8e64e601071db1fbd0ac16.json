{
  "id": 316,
  "title": "我国中老年家庭金融风险预警与因素层级研究——基于中国情境下的辨识与重构",
  "abstract": "家庭金融风险的防范与化解影响着家庭金融安全，而金融诈骗问题的层出不穷给中老年家庭金融安全带来严重困扰与潜在风险，对此应当给予更多关注。文章回归金融诈骗受害方视角，立足文献研究，基于CHARLS(2018)数据，采用XGBoost算法识别出中国情境下影响我国中老年家庭金融风险的关键因素，并使用ISM模型分析各影响因素间的层级结构关系，深层次挖掘各因素之间的关联关系。相较于决策树和随机森林，通过XGBoost算法构建的家庭金融风险预警模型具有更好的预测性能，在准确率、召回率、F1值和AUC值上均有良好的表现，并基于此模型辨识出影响中老年家庭金融风险的前35个重要因素。遵循从因素辨识到模型重构的思路，按照各因素之间由浅入深的逻辑构成，重构了兼具代际关系、人情关系与社会保障的因素层级，并将其归纳为浅层诱导因素、中层影响因素、深层根源因素。基于上述研究，进一步提出具有针对性的预防中老年家庭金融诈骗风险的对策建议，以便从源头上系统性防范中老年家庭金融风险。",
  "year": 2022,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7092473ffb8e64e601071db1fbd0ac16",
  "timestamp": "2025-05-14T22:29:10.680997"
}