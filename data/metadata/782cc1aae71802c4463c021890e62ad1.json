{
  "id": 2763,
  "title": "DOES PREMIUM EXIST IN THE STOCK MARKET FOR LABOR INCOME GROWTH RATE? A SIX-FACTOR-ASSET-PRICING MODEL: EVIDENCE FROM PAKISTAN",
  "abstract": "The objective of this study is to explore Roy and Shijin [(2018). A six factor assets pricing model. Borsa Istanbul Review, 18(3), 205-217] six-factor-model of asset pricing by extending Fama and French five-factor model to include human capital as a sixth factor in the context of Pakistan - an emerging country in Asia, and to test the validity of the six-factor asset pricing model in explaining time-series variations in portfolio returns of Pakistan equity market. For this purpose, we use Fama and Macbeth's two-pass time series regression technique to test the validity and applicability of the six-factor model. The findings indicate that the six factors model is an appropriate asset pricing model for explaining time-series variations in Pakistan. Furthermore, the human capital (labor income growth rate) is significant for most of the portfolios constructed in this study, which implies that the human capital significantly explains time-series variations in portfolio returns. The empirical results encourage all types of investors and academics to incorporate human capital into asset pricing models. It helps in more accurately estimating the required rate of return, which can improve asset pricing models.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "782cc1aae71802c4463c021890e62ad1",
  "timestamp": "2025-05-15T01:10:16.481347"
}