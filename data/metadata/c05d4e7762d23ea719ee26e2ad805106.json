{
  "id": 4980,
  "title": "How an idiosyncratic (zero-beta) risk can greatly increase the firm's cost of capital",
  "abstract": "The celebrated capital asset pricing model ('CAPM') brought numerous appealing insights and spawned a new theory of capital budgeting. One key intuition is that there is 'no penalty for diversifiable risk' - that is, any risky payoff that has zero-correlation with the wider economy, and hence zero-beta, is treated as 'risk-free'. Does that mean that managers can bet the firm on a spin of the roulette wheel without attracting a higher CAPM discount rate? Our re-interpretation of CAPM reveals that potential financial losses which are conventionally regarded as firm-specific 'unpriced' risks can bring a large increase in the firm's beta and CAPM cost of capital, despite having zero-beta and making only negligible difference at the aggregate market level. This mathematical result clashes with textbook expositions but is easily demonstrated and can be traced to authoritative but overlooked parts of the theoretical CAPM literature. JEL Classification: G11, G12",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c05d4e7762d23ea719ee26e2ad805106",
  "timestamp": "2025-05-15T02:43:06.743894"
}