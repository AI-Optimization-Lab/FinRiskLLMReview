{
  "id": 640,
  "title": "Feature Selection on Credit Risk Prediction for Peer-to-Peer Lending",
  "abstract": "Lending plays a key role in economy from early civilization. One of the most important issue in lending business is to measure the risk that the borrower will default or delay in loan payment. This is called credit risk. After Lehman shock in 2008-2009, big banks increased verification for lending operation to reduce risk. As borrowing from established financial institutions is getting harder, social lending also called Peer-to-Peer (P2P) lending, is becoming the popular trend. Because the client information at P2P lending is not sufficient as in traditional financial system, big data and machine learning become the default methods for analyzing credit risk. However, cost of computation and the problem of training the classifier with imbalance data affect the quality of result. This paper proposes a machine learning model with feature selection to measure credit risk of individual borrower on P2P lending. Based on our experimental results, we showed that the credit risk prediction for P2P lending can be improved using Logistic Regression in addition to proper feature selection.",
  "year": 2019,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "032b5db1c68f87ece121ae33b369a7af",
  "timestamp": "2025-05-15T01:53:24.869051"
}