{
  "id": 1447,
  "title": "Reducing systemic risk in a multi-layer network using reinforcement learning",
  "abstract": "This paper introduces a novel framework to assess and manage systemic risk in a multi-layer financial network by taking advantage of reinforcement learning (RL). The reduction of systemic risk in the financial network is achieved by applying the deep deterministic policy gradient algorithm (DDPG) to reorganize the interbank lending structure of the network into an orientation that better mitigates the spread of con-tagion. The reorganization procedure itself was constrained in order to preserve the balance sheet of every bank. To achieve this, we develop a constraint DDPG model consisting of a safety layer coupled with a linear mapping to satisfy the total borrowing and lending amounts of each bank. Moreover, we propose a new multi-layer DebtRank (DR) algorithm taking into account how contagion spreads from one layer to another. Testing against networks of varying size and depth, our DDPG agent was able to reduce systemic risk levels by significant amounts, suggesting the feasibility and utility of employing RL in managing systemic risk through aiding regulatory policy design. We observe an increase in sparsity and an increase in network dissimilarity between the different layers of the network after optimization.(c) 2022 Elsevier B.V. All rights reserved.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "08cc1a9b4d03cf24fa9f2223095936e7",
  "timestamp": "2025-05-15T02:03:00.781362"
}