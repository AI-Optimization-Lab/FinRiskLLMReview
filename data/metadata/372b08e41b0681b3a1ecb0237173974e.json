{
  "id": 1337,
  "title": "Operations Research Enables Auction to Repurpose Television Spectrum for Next-Generation Wireless Technologies",
  "abstract": "In 2017, the U.S. Federal Communications Commission completed the world's first two-sided spectrum auction, reclaiming radio frequency spectrum from television broadcasters to meet exploding demand for mobile broadband, 5G, and other wireless services. Operations research-including a customized series of optimization models, decompositions, cuts, heuristics, large neighborhood searches, and a portfolio of propositional satisfiability solvers whose parameters were determined by machine learning- was essential to the design and implementation of the auction. The auction repurposed 84 megahertz of spectrum and generated gross revenue of nearly $20 billion, providing more than $10 billion in capital for the broadcast television industry and over $7 billion for federal deficit reduction.",
  "year": 2019,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "372b08e41b0681b3a1ecb0237173974e",
  "timestamp": "2025-05-15T00:54:24.733319"
}