{
  "id": 1772,
  "title": "INVESTMENT PERFORMANCE ATTRIBUTION OF THE U.S. SMALL-SIZE VALUE MUTUAL FUNDS USING FAMA-FRENCH FIVE-FACTOR MODEL",
  "abstract": "The purpose of this study is to get an insight into the investment performance of the U.S. small-size value mutual funds. The Fama-French five-factor model was used to perform the regression of the portfolio returns composed out of the mutual funds with the chosen investment theme, as well as the regression at the individual level for 64 analyzed mutual funds, against the model's factors. The study covers the period from January 2010 until November 2021, using monthly returns. Our findings suggest that the factors from the original three-factor models are in line with the expectations and there is no presence of the potential style drift. In addition, the operating profit factor shows the expected causality relation. However, the exposure relating to the investing factor is slightly negative and may be surprising to a certain extent, having in mind the stated value style. Investment performance attribution of the portfolio explained the portfolio returns in the relation to the factors and found out that there is a statistically significant underperformance. Positive contributors to the investment performance are, in the presented order of the importance, market premium, as well as portfolio tilt towards stocks of the companies with the strong operating profit, small-capitalization, and aggressive investing policy. Lastly, value-style tilt led to negative performance contribution because the style was out of favor.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "f3a645645ced4f2f17b3f22e7b86c043",
  "timestamp": "2025-05-15T00:59:23.011957"
}