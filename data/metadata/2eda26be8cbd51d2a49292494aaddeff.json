{
  "id": 6768,
  "title": "Rough-Granular Computing in Human-Centric Information Processing",
  "abstract": "In the area of ubiquitous computing, users will continuously interact with computing devices by suggesting strategies, hypothesis, by communicating some new facts from domain knowledge, explaining untypical cases in dialogs with devices (agents), etc. Hence, compound vague concepts used by humans should be understandable, at least in an approximate sense, by these devices. We discuss some basic issues of interactive computations in the framework of rough-granular computing for approximation of complex concepts. Among these issues are hierarchical modeling of granule structures and interactions between granules of different complexity. Interactions between granules on which computations are performed are among the fundamental concepts of Wisdom Technology (Wistech). Wistech is encompassing such areas as interactive computations, multiagent systems, cognitive computation, natural computing, complex adaptive and autonomous systems, or knowledge representation and reasoning about knowledge. We outline current results on approximation of compound vague concepts which are based on rough-granular computing. In particular, hierarchical methods are used for approximation of domain ontologies of vague concepts. The developed methodology has been tested on real-life problems related to such areas as unmanned area vehicle control, robotics, predicting of risk patterns from temporal medical and financial data, sun spot classification, bioinformatics.",
  "year": 2009,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "2eda26be8cbd51d2a49292494aaddeff",
  "timestamp": "2025-05-15T03:01:31.350560"
}