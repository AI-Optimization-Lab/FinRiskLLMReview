{
  "id": 6483,
  "title": "Implementation of Computerized Maintenance Management System in Upgraded Pillar Point Sewage Treatment Works",
  "abstract": "In the past, monitoring and scheduling the operation and maintenance activities of physical assets in Sewage Treatment Works (STWs) of Drainage Services Department (DSD) follow a traditional risk based approach with due consideration to the financial as well as the state of the assets. For newly Upgraded Pillar Point Sewage Treatment Works (PPSTW), Recursive Auto-Regression (RAR) modelling [1] technique is adopted to automatically predict specific equipment's remaining useful life (RUL) and compare the lead time of components' delivery and process time of overhaul sub-contracting so as to establish an optimum preventive maintenance schedule with delivery, resources and cost optimization. Prediction accuracy of the developed RAR model is verified by numerical simulation with inputs to CMMS condition monitoring engine. A pilot study on the integration of CMMS with the SCADA system has been implemented on the outfall screw pump shaft bearings for experimental validation of the RUL model and investigating the feasibility of its application.",
  "year": 2015,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7c05f412a7a5fa6a7ab37706e3613b37",
  "timestamp": "2025-05-15T02:58:34.178831"
}