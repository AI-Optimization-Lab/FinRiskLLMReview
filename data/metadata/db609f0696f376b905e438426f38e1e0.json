{
  "id": 1138,
  "title": "Deep learning for enhanced index tracking",
  "abstract": "We develop a novel deep learning method for the enhanced index tracking problem, which aims to outperform an index while effectively controlling the tracking error. We generate a dynamic trading policy from a neural network that accepts a set of features as inputs. We design four blocks in the neural network architecture to handle different types of features, including regimes of the index and stocks, their short-term characteristics, and the current allocation. Outputs from the blocks are integrated into the final output that changes the portfolio allocation. We test our model on several indexes in empirical studies based on real market data. Out-of-sample results reveal the importance of different features and demonstrate the ability of our method in obtaining excess returns while effectively controlling the tracking error, downside risk, and transaction costs.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "db609f0696f376b905e438426f38e1e0",
  "timestamp": "2025-05-15T00:52:00.419887"
}