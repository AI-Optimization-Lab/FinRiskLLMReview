{
  "id": 156,
  "title": "Pricing and calibration in the 4-factor path-dependent volatility model",
  "abstract": "We consider the path-dependent volatility (PDV) model of Guyon and Lekeufack (2023), where the instantaneous volatility is a linear combination of a weighted sum of past returns and the square root of a weighted sum of past squared returns. We discuss the influence of an additional parameter that unlocks enough volatility on the upside to reproduce the implied volatility smiles of S&P 500 and VIX options. This PDV model, motivated by empirical studies, comes with computational challenges, especially in relation to VIX options pricing and calibration. We propose an accurate pathwise neural network approximation of the VIX which leverages on the Markovianity of the 4-factor version of the model. The VIX is learned pathwise as a function of the Markovian factors and the model parameters. We use this approximation to tackle the joint calibration of S&P 500 and VIX options, quickly sample VIX paths, and price derivatives that jointly depend on S&P 500 and VIX. As an interesting aside, we also show that this time-homogeneous, low-parametric, Markovian PDV model is able to fit the whole surface of S&P 500 implied volatilities remarkably well.",
  "year": 2025,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "9a93d2b3e3c635b4b18f0fddf08a045c",
  "timestamp": "2025-05-15T01:29:09.007018"
}