{
  "id": 204,
  "title": "Pricing options with dual volatility input to modular neural networks",
  "abstract": "Tested is the choice of the volatility input to the artificial neural networks in the process of pricing options. Numerous studies concluded the weaknesses of Black-Scholes model use as a pricing tool in the market. For the last two decades, various studies were done analyzing the alternate tools to price options. Among the alternates is the use of artificial neural networks. While Gradojevic, Gencay, and Kukolj (2009) use Modular back-propagation neural networks (BPNN) without any volatility related inputs, others like Y.H. Wang (2009a, 2009b), Lin and Yeh (2009), Wang, Lin, Huang, Wu (2012), and Chang, Wang and Yeh (2013) test different options of a volatility input and compare the final artificial neural network (ANN) outcome. This paper provides volatility input to the BPNN, first the selected historical volatility estimate followed by the implied volatility as single volatility input to ANN. Finally, trained is the ANN with input inclusive of the combination of the two volatility measures. Accordingly, dual-volatility model outperformance suggests that each of the volatility inputs provides some exclusive information to the ANN to price options. Copyright (C) 2020, Borsa Istanbul Anonim Sirketi. Production and hosting by Elsevier B.V.",
  "year": 2020,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "83765cb8b0bc5ecb319dccacb935796e",
  "timestamp": "2025-05-15T01:29:44.143518"
}