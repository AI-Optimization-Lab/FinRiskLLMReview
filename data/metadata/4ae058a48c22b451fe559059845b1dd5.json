{
  "id": 15,
  "title": "Gold Price Forecast based on LSTM-CNN Model",
  "abstract": "An accurate prediction is certainly significant in financial data analysis. Investors have used a series of econometric techniques on pricing, stock selection and risk management but few of them have found great success due to the fact that most of them only are purely based on a single scheme. Recent advances in deep learning methods have also demonstrated the outstanding performance in the fields of image recognition and sentiment analysis. In this paper, we originally propose a novel gold price forecast method based on the integration of Long Short-Term Memory Neural Networks (LSTM) and Convolutional Neural Networks (CNN) with Attention Mechanism (denoted to LSTM-Attention-CNN model). Particularly, the LSTM-Attention-CNN model consists of three components: the LSTM component, Attention Mechanism and the CNN component. The LSTM component enables to harness the sequential order of daily gold price. Meanwhile, the Attention Mechanism assigns different attention weights on the new encoding method from LSTM component to enhance the extraction of the temporal and spatial features. In addition, the CNN component enables to capture the local patterns and abstract the spatial features. Extensive experiments on real dataset collected from World Gold Council show that our proposed approach outperforms other conventional financial forecast methods.",
  "year": 2019,
  "source": "WOS",
  "area": "financial_risk",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "4ae058a48c22b451fe559059845b1dd5",
  "timestamp": "2025-05-15T01:32:30.237099"
}