{
  "id": 1410,
  "title": "Partially egalitarian portfolio selection",
  "abstract": "We propose a new portfolio optimization framework, partially egalitarian portfolio selection (PEPS). Inspired by the celebrated LASSO regression and its recent variant partially egalitarian LASSO (PELASSO) developed in [1] in the context of the forecast combinations problem in econometrics in [1], we regularize the mean-variance portfolio optimization of Markowitz by adding two regularizing terms that essentially zero out portfolio weights of some of the assets in the portfolio and select and shrink portfolio weights of the remaining assets towards equal weights to hedge against parameter estimation risk. We solve our PEPS formulations by applying Gurobi 9.0 mixed integer optimization (MIO) solver that allow us to tackle large-scale portfolio problems. We test our PEPS portfolios against an array of classical portfolio optimization strategies on a number of datasets in the US equity markets. The PEPS portfolios exhibit the highest out-of-sample Sharpe ratios in all instances considered.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8b8aeeb31bf2176e9846ce7920d1a5ac",
  "timestamp": "2025-05-15T00:55:28.469467"
}