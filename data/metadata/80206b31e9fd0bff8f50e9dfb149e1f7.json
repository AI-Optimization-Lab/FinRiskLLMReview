{
  "id": 170,
  "title": "大所审计能抑制商誉减值异常吗？",
  "abstract": "审计师在资本市场中对企业会计异常的识别发挥至关重要作用。本文以2007-2019年我国A股上市公司为样本，探讨大所审计能否对商誉减值异常产生抑制作用。实证结果发现，相比经过小所审计的公司，经大所审计的公司商誉减值异常水平较低。经过Heckman两阶段回归、随机样本匹配等一系列方法的稳健性检验，该结果未发生改变，说明大所审计能有效约束客户公司商誉减值异常行为。区分不同类型的商誉减值异常行为，研究结果显示，相比商誉减值激进行为，大所审计对商誉减值规避行为的约束作用更加显著。进一步研究还发现，大所审计对商誉减值异常的抑制效应在信息环境较差的公司更加显著；大所审计可作为机构投资者、内部审计委员会的替代机制，对商誉减值异常产生抑制作用。这些结论拓展了对商誉减值和审计师的研究，对加强商誉减值监管、防范化解金融风险提供了决策参考。",
  "year": 2023,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "80206b31e9fd0bff8f50e9dfb149e1f7",
  "timestamp": "2025-05-14T22:27:22.019673"
}