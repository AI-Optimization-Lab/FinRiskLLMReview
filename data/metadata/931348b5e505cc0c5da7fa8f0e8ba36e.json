{
  "id": 5222,
  "title": "The drivers of the great bull stock market of 2015 in China: evidence and policy implications",
  "abstract": "This paper investigates what drove the great bull stock market of 2015 in China. Multiple regression models based on the Arbitrage Pricing Theory (APT) theory are developed to describe the variation in stock returns using economic fundamentals. The results indicate that during the normal period, the Chinese stock market was sensitive to economic conditions. However, during the bull market, fundamentals could not justify the variation in the stock returns which are significantly different from the conditional predictions based on the multiple regression model which is robust for the normal period. Margin trading was the main driver of the speculative bubble during the bull market from May 2014 to June 2015. As commercial banks are becoming more exposed to the stock market, the volatility of stock prices may have the potential to increase the risk of the financial system and limit the freedom of China to use monetary policy to deal with economic fundamentals.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "931348b5e505cc0c5da7fa8f0e8ba36e",
  "timestamp": "2025-05-15T02:45:47.323795"
}