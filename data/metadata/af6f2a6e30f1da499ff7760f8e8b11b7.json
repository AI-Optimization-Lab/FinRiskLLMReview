{
  "id": 1555,
  "title": "Takeover prediction using forecast combinations",
  "abstract": "The ability to identify likely takeover targets at an early stage should provide investors with valuable information, enabling them to profit by investing in potential target firms. In this paper we contribute to the takeover forecasting literature by suggesting the combination of probability forecasts as an alternative method of improving the forecast accuracy in takeover prediction and realizing improved economic returns from portfolios made up of predicted targets. Forecasts from several non-linear forecasting models, such as logistic and neural network models and a combination of them, are used to determine the methodology that best reduces the out-of-sample misclassification error. We draw two general conclusions from our results. First, the forecast combination method outperforms the single models, and should therefore be used to improve the accuracy of takeover target predictions. Second, we demonstrate that an investment in a portfolio of the combined predicted targets results in significant abnormal returns being made by an investor, in the order of up to double the market benchmark return when using a portfolio of manageable size. (C) 2013 Published by Elsevier B.V. on behalf of International Institute of Forecasters.",
  "year": 2013,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "af6f2a6e30f1da499ff7760f8e8b11b7",
  "timestamp": "2025-05-15T00:57:12.629995"
}