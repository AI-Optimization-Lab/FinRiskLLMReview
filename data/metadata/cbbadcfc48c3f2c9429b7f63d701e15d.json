{
  "id": 3091,
  "title": "Understanding tourists' leisure expenditure at the destination: a social network analysis",
  "abstract": "The aim of this study is to identify spending patterns of tourists in relation to the leisure activities performed throughout their day-by-day stay at the destination. Using the methodology of social network analysis (SNA), a tourists-activities bipartite network was identified following a pattern known as core-periphery. The effect of this structure (including typology, number, and timing of performing the activities) on tourism expenditure is analysed using a multiple regression model, to which were added different sociodemographic variables and other variables related to travel. In order to better understand the portfolio of activities, four examples of networks are studied and visually represented. This study reveals that through SNA between tourists and activities, we can study the behaviour of tourists in a novel way.",
  "year": 2018,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "cbbadcfc48c3f2c9429b7f63d701e15d",
  "timestamp": "2025-05-15T01:13:45.077949"
}