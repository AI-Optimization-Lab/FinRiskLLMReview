{
  "id": 705,
  "title": "Nonlinear modeling of financial state variables and multiscale numerical analysis",
  "abstract": "The aim of this study is to explore the nonlinear modeling of financial state variables and multiscale numerical analysis to better understand the complex dynamic behavior of financial markets. Traditional financial theories are limited by their reliance on linear indicators, failing to adequately capture nonlinear risks in the market. This article first employs Agent-Based Models (ABM) and manifold learning. ABM simulates the heterogeneous behaviors and interactions of market participants, revealing the market's nonlinear characteristics; manifold learning is used for dimensionality reduction of high-dimensional data while preserving the intrinsic geometric structure. Additionally, we utilize multiscale analysis methods to reveal short-term fluctuations and long-term trends in the market. Finally, by calculating the weighted mean escape time and the escape time distribution, we quantify nonlinear phenomena in the market, providing new perspectives for understanding market volatility and systemic risk.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "ce51cc67960a02e27a37d3f5a852868c",
  "timestamp": "2025-05-15T01:53:59.477231"
}