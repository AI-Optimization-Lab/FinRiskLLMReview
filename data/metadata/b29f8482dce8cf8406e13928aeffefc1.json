{
  "id": 39,
  "title": "Deep learning of optimal exercise boundaries for American options",
  "abstract": "Efficiently determining a price and optimal exercise boundary for an American option is a critical subject in the financial sector. This study introduces a novel application of long short-term memory neural networks to solve a relevant Volterra equation, enhancing the accuracy and efficiency of American option pricing. The proposed approach outperforms traditional numerical techniques, including finite difference methods, binomial trees, and Monte Carlo methods, delivering an impressive speed improvement by a factor of thousands while maintaining industry-accepted accuracy levels. It exhibits computational speeds up to about a hundred times faster than the state-of-the-art method used by Andersen et al. [High-performance American option pricing, J. Comput. Finance 20(1) (2016), pp. 39-87] when evaluating numerous options. The proposed network, trained on a reasonable range of parameters related to the Black-Scholes model, swiftly determines option prices and exercise boundaries, serving as a practical closed-form solution.",
  "year": 2025,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b29f8482dce8cf8406e13928aeffefc1",
  "timestamp": "2025-05-15T01:26:54.897741"
}