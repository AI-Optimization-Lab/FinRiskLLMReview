{
  "id": 3652,
  "title": "Does Aid for Malaria Increase with Exposure to Malaria Risk? Evidence from Mining Sites in the DRCongo*",
  "abstract": "I examine the ability of donors to target the highest exposure to malaria risk when the health information structure is fragmented. I exploit local variations in the risk of malaria transmission induced by mining activities in the Democratic Republic of Congo as well as financial and epidemiological data from health facilities to estimate how local aid is matching the local malaria burden. Using fine-grained data on mines and health infrastructure in a regression discontinuity design, I find no evidence that local populations exposed to the highest risk of malaria transmission receive a proportionately higher share of aid compared to neighbouring areas with reduced exposure to malaria risk.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "43260ffda5a048a1483b00867cefc2b3",
  "timestamp": "2025-05-15T02:28:29.419463"
}