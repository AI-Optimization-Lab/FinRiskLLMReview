{
  "id": 1071,
  "title": "Evolutionary Extreme Learning Machine with novel activation function for credit scoring",
  "abstract": "The term credit scoring is extensively used in credit industries for decision making and measuring the risk associated with an applicant. It uses applicants' historical data for credit risk evaluation by applying machine learning or statistical techniques. Credit risk evaluation has become progressively important field in financial risk management for credit industries. In this study, Extreme Learning Machine (ELM) is utilized as a classification tool for credit risk evaluation model. ELM requires more number of hidden neurons and random determination of the input weights and hidden biases. Moreover, ELM performance depends on activation function, weights and biases assigned to hidden neurons. An appropriate approach for selection of activation function, weights and biases may improve the performance of ELM. Hence, we have proposed a novel activation function and an evolutionary approach to get optimized weights and biases by utilizing Bat optimization algorithm. Further, the simulations are performed on four bench-marked credit scoring datasets with various activation functions. Simulation results demonstrate that proposed Evolutionary ELM (EELM) is more suitable for credit risk evaluation.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d1f969073913addd2d858df219d210f7",
  "timestamp": "2025-05-15T01:58:43.350851"
}