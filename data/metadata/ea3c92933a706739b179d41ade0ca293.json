{
  "id": 3148,
  "title": "Which return regime induces overconfidence behavior? Artificial intelligence and a nonlinear approach",
  "abstract": "Overconfidence behavior, one form of positive illusion, has drawn considerable attention throughout history because it is viewed as the main reason for many crises. Investors' overconfidence, which can be observed as overtrading following positive returns, may lead to inefficiencies in stock markets. To the best of our knowledge, this is the first study to examine the presence of investor overconfidence by employing an artificial intelligence technique and a nonlinear approach to impulse responses to analyze the impact of different return regimes on the overconfidence attitude. We examine whether investors in an emerging stock market (Borsa Istanbul) exhibit overconfidence behavior using a feed-forward, neural network, nonlinear Granger causality test and nonlinear impulse-response functions based on local projections. These are the first applications in the relevant literature due to the novelty of these models in forecasting high-dimensional, multivariate time series. The results obtained from distinguishing between the different market regimes to analyze the responses of trading volume to return shocks contradict those in the literature, which is the key contribution of the study. The empirical findings imply that overconfidence behavior exhibits asymmetries in different return regimes and is persistent during the 20-day forecasting horizon. Overconfidence is more persistent in the low- than in the high-return regime. In the negative interest-rate period, a high-return regime induces overconfidence behavior, whereas in the positive interest-rate period, a low-return regime induces overconfidence behavior. Based on the empirical findings, investors should be aware that portfolio gains may result in losses depending on aggressive and excessive trading strategies, particularly in low-return regimes.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "ea3c92933a706739b179d41ade0ca293",
  "timestamp": "2025-05-15T01:14:16.154530"
}