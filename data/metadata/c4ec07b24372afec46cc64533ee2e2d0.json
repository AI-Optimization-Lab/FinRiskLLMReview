{
  "id": 3196,
  "title": "Every Corporation Owns Its Structure: Corporate Credit Rating via Graph Neural Networks",
  "abstract": "Credit rating is an analysis of the credit risks associated with a corporation, which reflects the level of the riskiness and reliability in investing, and plays a vital role in financial risk. There have emerged many studies that implement machine learning and deep learning techniques which are based on vector space to deal with corporate credit rating. Recently, considering the relations among enterprises such as loan guarantee network, some graph-based models are applied in this field with the advent of graph neural networks. But these existing models build networks between corporations without taking the internal feature interactions into account. In this paper, to overcome such problems, we propose a novel model, Corporate Credit Rating via Graph Neural Networks, CCR-GNN for brevity. We firstly construct individual graphs for each corporation based on self-outer product and then use GNN to model the feature interaction explicitly, which includes both local and global information. Extensive experiments conducted on the Chinese public-listed corporate rating dataset, prove that CCR-GNN outperforms the state-of-the-art methods consistently.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c4ec07b24372afec46cc64533ee2e2d0",
  "timestamp": "2025-05-15T02:23:33.570103"
}