{
  "id": 1526,
  "title": "Transparent Neural based Expert System for Credit Risk (TNESCR): An Automated Credit Risk Evaluation System",
  "abstract": "Nowadays credit risk evaluation is very crucial in financial domain. Whenever it is processed by an individual, it becomes controversial as the assessment may be prone to human error. Recently, to overcome this issue, some automated systems have been developed for credit risk evaluation. Most of the developed systems focused on the credit decision only and neglected the transparency of the systems; however, many cases require transparency of the credit decision to benefit financial organization as well as the potential customers. Therefore, this paper proposes an expert system named Transparent Neural based Expert System for Credit Risk (TNESCR) evaluation which uses a white box neural model Rule Extraction from Neural Network using Classified and Misclassified data (RxNCM) to generate rules from financial data. The generated rules are so transparent to justify the explanations for why applications are granted/rejected with a significant predictive accuracy. The proposed TNESCR is validated using 10 fold cross validation with 3 credit risk datasets. The experimental results show the proposed TNESCR can perform significantly with great transparency and accuracy.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "3acf67527b498d6fb4cc8f2b260b2d8f",
  "timestamp": "2025-05-15T02:04:20.043986"
}