{
  "id": 1096,
  "title": "Polytope Fraud Theory",
  "abstract": "Polytope Fraud Theory (PFT) extends the existing triangle and diamond theories of accounting fraud with ten abnormal financial practice alarms that a fraudulent firm might trigger. These warning signals are identified through evaluation of the shorting behavior of sophisticated activist short sellers, which are used to train several supervised machine learning methods in detecting financial statement fraud using published accounting data. Our contributions include a systematic manual collection and labeling of companies that are shorted by professional activist short sellers. We also combine well-known asset pricing factors with accounting red flags in financial features selections. Using 80 % of the data for training and the remaining 20 % for out-of-sample test and performance assessment, we find that the best method is XGBoost, with a Recall of 72 % and F1-score of 82 %. Other methods have relatively lower performance, demonstrating the robustness of our results. This shows that the sophisticated activist short sellers, from whom the algorithms are learning, have excellent accounting insights, tremendous forensic analytical knowledge, and sharp business acumen. Our feature importance analysis indicates that potential short-selling targets share many similar financial characteristics, such as bankruptcy or financial distress risk, clustering in some industries, inconsistency of profitability, high accrual, and unreasonable business operations. Our results imply the possible automation of advanced financial statement analysis, which can both improve auditing processes and effectively enhance investment performance. Finally, we propose the Unified Investor Protection Framework, summarizing and categorizing investor-protection related theories from the macro-level to the micro-level.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "0cc6c459f3aae8a122bb2196f9604b44",
  "timestamp": "2025-05-15T01:58:43.451300"
}