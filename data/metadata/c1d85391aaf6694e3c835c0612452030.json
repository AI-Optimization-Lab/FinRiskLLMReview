{
  "id": 1598,
  "title": "Credit Risk Assessment Using BP Neural Network with Dempster-Shafer Theory",
  "abstract": "In latest decades credit risk assessment has been a heavy problem in the society especially in the financial system. Credit risk assessment is a decision level decision problem. Information fusion in multi-sensor system is a very complex process, especially in the decision level fusion process. Presently some useful and representative methods, such as neural networks and Dempster-Shafer evidence theory, which can solve some decision level fusion problems. But neural network has some faults, such as bad stability, long-time training time, and bad convergence rate et al. Dempster-Shafer evidence theory needs known evidence of every objective. Aiming at theses faults of neural networks and Dempster-Shafer evidence theory, we propose a novel decision level fusion algorithm based on back-propagation neural network and Dempster-Shafer Theory to overcome the above mentioned problems of present decision level fusion methods. Meanwhile, introduce the unknown degree for all objectives in this paper. At last, some experiments show the validity and feasibility.",
  "year": 2009,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c1d85391aaf6694e3c835c0612452030",
  "timestamp": "2025-05-15T02:05:08.221868"
}