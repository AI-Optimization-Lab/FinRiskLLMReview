{
  "id": 1111,
  "title": "Product family concept generation and validation through predictive decision tree data mining and multi-level optimization",
  "abstract": "The formulation of a product family requires extensive knowledge about the product market space and also the technical limitations of a company's engineering design and manufacturing processes. We present a methodology to significantly reduce the computational time required to achieve an optimal product portfolio by eliminating the need for an exhaustive search of all possible product concepts. This is achieved through a data mining decision tree technique that generates a set of product concepts that are subsequently validated in the engineering design level using multi-level optimization techniques. The final optimal product portfolio evaluates products based on the following three criteria: 1) The ability to satisfy customer's price and performance expectations (based on predictive model) defined here as the feasibility criterion. 2) The feasible set of products/variants validated at the engineering level must generate positive profit that we define as the optimality criterion. 3) The optimal set of products/variants should be a manageable size as defined by the enterprise decisions makers and should therefore not exceed the product portfolio limit. The strength of our work is to reveal the tremendous savings in time and resources that exist when data mining predictive techniques are applied to the formulation of an optimal product portfolio. Using data mining tree generation techniques, a customer response data set of 40,000 individual product preferences is narrowed down to 46 product family concepts and then validated through the multilevel engineering design response of feasible architectures. A cell phone example is presented and an optimal product portfolio solution is achieved that maximizes company profit, while concurrently satisfying customer product performance expectations.",
  "year": 2008,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1e9c76967b9aa9fc55e4320f813802fb",
  "timestamp": "2025-05-15T00:52:00.348942"
}