{
  "id": 2423,
  "title": "Tractable Compensation Plan under Asymmetric Information",
  "abstract": "In an elegant study on salesforce incentive design, Steenburgh and Ahearne (2012) have argued that a multi-faceted portfolio approach, based on the classification of workers into laggards, core, and star performers, can induce better result from the salesforce, compared to traditional approaches used in companies. In this paper, we construct a portfolio of incentive contracts with a three-piece linear-quadratic-linear structure and study their incentive effects. It is well known that such contracts can extract 100% of the incremental benefits (i.e., optimal) when the performance levels of the agents are exponentially or uniformly distributed, but its effect is still unknown in the more natural case when performance levels are normally distributed. We show that the proposed three-piece contract can capture more than 95.32% of the incremental benefits, obtained from the optimal incentive contract over fixed salary contract, when the cost functions of efforts are quadratic, and the performance levels are normally distributed. In this case, the more traditional three-piece linear contract has a corresponding tight lower bound of 82.64%. Interestingly this is the same as the tight lower bound from a two-piece linear contract, and thus adding more linear pieces to the contract does not help to improve the lower bound when the performance levels follow the normal distributions. This provides a partial theoretical explanation for the superiority of the portfolio approach advocated by Steenburgh and Ahearne (2012).",
  "year": 2020,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c83657bafe760775ae7e86cf6f52e7fb",
  "timestamp": "2025-05-15T01:06:38.102033"
}