{
  "id": 1182,
  "title": "Deep learning for efficient frontier calculation in finance",
  "abstract": "We propose deep neural network algorithms to calculate the efficient frontier in mean-variance and mean-conditional value-at-risk (mean-CVaR) portfolio optimization problems. Starting with the mean-variance portfolio optimization problem in the Black-Scholes framework, we first compare the analytical solution with the computed one, and we show the efficiency of the methodology in high dimensions. Adding additional constraints, we compare different formulations and, obtaining the same frontier, show that the no short selling and no borrowing problem can be solved with all formulations. Then, a new projected feedforward network is shown to be able to deal with some local and global constraints on the weights of the portfolio while outperforming classical penalization methods. We extend our numerical results to assets following the Heston model, and we show that the results obtained in the Black-Scholes method still hold. Finally, we present numerical results for the more difficult mean-CVaR optimization problem, which we show are realistic only for algorithms with a global resolution of the problem.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "2f17334014f2915447017a3e64834e95",
  "timestamp": "2025-05-15T00:52:33.926473"
}