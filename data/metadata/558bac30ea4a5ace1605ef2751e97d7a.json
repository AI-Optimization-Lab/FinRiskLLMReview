{
  "id": 3309,
  "title": "Good for the firm, good for the society? Causal evidence of the impact of equity incentives on a firm's green investment",
  "abstract": "Green innovation can assist firms in achieving corporate social responsibility legitimacy among their stakeholders. However, we have limited knowledge about how to encourage firms toward it. Using a sample of Chinese firms, we examine the effect of executive equity incentive plans (EEIPs) on green innovation. Our baseline results indicate that EEIPs promote firms' green innovation and the importance of green patents in their patent portfolio. This positive effect mainly exists in restricted stocks, rather than stock options. After addressing potential endogeneity problems by adopting instrumental variable regression method, difference-in-difference method and an entropy-balanced sample research design, we find a causal effect of EEIPs on green innovation. This positive effect is pronounced in firms facing greater environmental risks. Further analysis suggests that green innovation helps in promoting the firm's environmental outcomes, without an adverse effect on performance.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "558bac30ea4a5ace1605ef2751e97d7a",
  "timestamp": "2025-05-15T01:15:54.732516"
}