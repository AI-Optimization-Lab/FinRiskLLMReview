{
  "id": 828,
  "title": "A Hybrid CNN and LSTM based Model for Financial Crisis Prediction",
  "abstract": "The detection and prediction of financial crises in listed companies are crucial for investors to mitigate potential losses. Traditional prediction methods primarily rely on financial indicators, yet they often overlook valuable insights hidden in financial text. To address this limitation, our study explores the integration of financial indicators and financial text from annual reports to enhance financial crisis prediction. We propose a two-step approach, leveraging a Convolutional Neural Network (CNN) model to extract features from financial indicators and utilizing a Long Short-Term Memory (LSTM) network with attention mechanism to capture the underlying semantics in financial text. Subsequently, we combine the extracted features from both sources for effective classification. Through extensive experiments with various models, we demonstrate the efficacy of our combined approach in achieving optimal prediction results. Our findings highlight the importance of considering financial text alongside traditional financial indicators for enhanced financial crisis detection and prediction. The proposed methodology contributes to the existing literature and offers valuable insights for investors and financial analysts seeking more accurate and comprehensive risk assessment tools.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "dd42d876d44ba8a129039a49932d3251",
  "timestamp": "2025-05-15T01:55:41.551847"
}