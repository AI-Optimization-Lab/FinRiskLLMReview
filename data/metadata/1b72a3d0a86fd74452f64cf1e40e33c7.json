{
  "id": 598,
  "title": "商业银行风险溢出的网络关联效应研究",
  "abstract": "选取2011～2018中国16家上市银行作为研究对象,利用分位数回归ΔCoVaR模型构建银行风险溢出矩阵,并通过社会网络分析法构建风险溢出关联网络研究银行风险溢出的网络关联效应,研究发现:银行风险溢出具有非对称性和方向性,相对于国有银行,股份制银行和城市发展银行对其它银行风险溢出以及遭受其它银行风险溢出程度更显著;银行风险溢出网络具有\"小世界\"现象,也具有时变特征,中国系统性金融风险近几年在不断增加;同时银行网络关联度与风险溢出效应呈正比,银行自身财务指标能够影响风险溢出效应,宏观经济状况良好时,银行间的风险溢出程度减少。建议金融监管当局建立健全风险预警和防范体系,关注银行间风险溢出的网络关联性,着重管理风险溢出中占重要地位的银行,防范风险溢出网络关联性上升引发系统风险。",
  "year": 2019,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1b72a3d0a86fd74452f64cf1e40e33c7",
  "timestamp": "2025-05-14T22:31:30.162597"
}