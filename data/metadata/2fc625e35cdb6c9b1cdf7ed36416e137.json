{
  "id": 33,
  "title": "Deep learning in stock portfolio selection and predictions",
  "abstract": "Deep learning (DL) has made its way into many disciplines ranging from health care to self-driving cars. In financial markets, we see a rich literature for DL applications. Particularly, investors require robust algorithms that can navigate and make sense of extremely noisy and volatile markets. In this work, we use deep learning to select a portfolio of stocks and use a genetic algorithm to optimize the hyperparameters of DL. The work analyzes the improvement in using genetic-based hyperparameter optimization over grid searches. The Genetic Algorithm brings 40% improvements in prediction when compared to a random-grid search. Novelty-wise, the work couples a genetic-based hyperparameter optimization with multiple Deep RankNet models to predict the behavior of financial assets. Our results show promising portfolio returns 20% better than the general market. In the highly volatile COVID 19 period, the models exceed market returns by more than double. Overall, this paper brings a comprehensive work that integrates hyperparameter optimization, Deep RankNet, LSTM, period size variations, input variable transformation, feature selection, training/evaluation ratio analysis, and multiple portfolio selection strategies.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "2fc625e35cdb6c9b1cdf7ed36416e137",
  "timestamp": "2025-05-15T00:31:16.879868"
}