{
  "id": 4274,
  "title": "Balanced Funds in India Amid COVID-19 Crisis: Spreader of Financial Contagion?",
  "abstract": "In its latest financial stability report, dated 11 January 2021, the Reserve Bank of India (RBI) emphasised the significance of balanced mutual funds in risk transmission. We investigate the transmission of volatility and contagion effect from Indian balanced funds to representative indices-Bank, PSU Bank, Private Bank, Financial Services, Broader Market, Services Sector and Fixed Income-using three established models: Diagonal BEKK (1995), Dynamic Conditional Correlation (DCC GARCH (2002)) and network model. In analyses of financial time series data, the COVID-19 pandemic has been widely regarded as a structural break. We may better understand the dynamism and scale of spillover before and during a crisis by dividing the study into two periods: pre-COVID-19 (January 2011-29 December 2019) and during COVID-19 (30 December 2019-20 April 2021). The results of all three models support our hypothesis of statistically significant spillover from balanced funds to chosen indices, with strong persistence and a marked increase in long-term volatility spillover, showing the presence of contagion effects. The findings of this paper can assist fund managers in diversifying their portfolios while also benefiting investors educationally. JEL Classification: C23, G12, G23",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "140cac69a44955eb052178f1befbd26e",
  "timestamp": "2025-05-15T02:35:26.246565"
}