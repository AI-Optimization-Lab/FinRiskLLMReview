{
  "id": 527,
  "title": "Quantitative Portfolio Management: Review and Outlook",
  "abstract": "This survey aims to provide insightful and objective perspectives on the research history of quantitative portfolio management strategies with suggestions for the future of research. The relevant literature can be clustered into four broad themes: portfolio optimization, risk-parity, style integration, and machine learning. Portfolio optimization attempts to find the optimal trade-off of future returns per unit of risk. Risk-parity attempts to match the exposure of various asset classes such that no single asset class dominates portfolio risk. Style integration combines risk factors on a security level such that rebalancing differences cancel out. Finally, machine learning utilizes large arrays of tunable parameters to predict future asset behavior and solve non-convex optimization problems. We conclude that machine learning will likely be the focus of future research.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8055121f14a7c2f583cd09db7e055849",
  "timestamp": "2025-05-15T00:44:21.081642"
}