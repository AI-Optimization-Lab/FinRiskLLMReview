{
  "id": 2682,
  "title": "CLUSTERING ROMANIAN STOCK FUNDS BY RETURN AND RISK",
  "abstract": "Mutual funds are classified at an international level, according to specific criteria, by the rating agencies, and the results are presented in a simple form. Morningstar groups the funds with the help of a system of stars indicating the performance of the funds during different periods. This classification does not apply to Romanian mutual funds. The Romanian Association of Asset Managers publishes only information about risk and return. In this paper, we used cluster analysis (hierarchical classification) and the AT-GARCH model in order to classify the mutual stock funds in Romania. The variables taken into consideration for the cluster analysis are represented by minimum constant risk, time-varying standard risk, turmoil risk and average of the returns. The estimation of the components risk will enable us to take into account the stochastic nature of the financial time series. The classification thus obtained is useful for the investors who want to diversify their investments via the purchase of units of mutual stock funds that have a different market behavior from the perspective of return and risk.",
  "year": 2010,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "ec1a84657ee7df60e90ce3634c7d07cf",
  "timestamp": "2025-05-15T02:18:06.165321"
}