{
  "id": 1970,
  "title": "Estimating credit risk parameters using ensemble learning methods: an empirical study on loss given default",
  "abstract": "In credit risk modeling, banks and insurance companies routinely use a single model for estimating key risk parameters. Combining several models to make a final prediction is not often considered. Using an ensemble or a collection of models rather than a single model can improve the accuracy and robustness of prediction results. In this study, we investigate two well-established ensemble learning methods (stochastic gradient boosting and random forest) and propose two new ensembles (ensemble by partial least squares and bag-boosting) in the application of predicting the loss given default. We demonstrate that an ensemble approach significantly increases the discriminatory power of the model compared with a single decision tree. In addition, the ensemble learning methods can be applied directly to predicting the exposure at default and probability of default with some simple modifications. The proposed approaches introduce a novel modeling framework that banks and other financial institutions can use to estimate and validate credit risk parameters based on the internal data of different portfolios. Moreover, the proposed approaches can be readily extended to general portfolio risk modeling in the areas of regulatory capital and economic capital management, loss forecasting, stress testing and pre-provision net revenue projections.",
  "year": 2016,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "21581647b86e829f0c996797b0e88b30",
  "timestamp": "2025-05-15T02:09:48.276750"
}