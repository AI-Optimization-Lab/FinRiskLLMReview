{
  "id": 147,
  "title": "Research on Financial Risk Prediction Method of Listed Companies Based on GA-RBF Neural Network",
  "abstract": "Research on the problem shows that it is difficult to form a normalized risk forecast for listed companies, which makes it difficult for company management to keep up with risk changes. The radial basis neural network model is used to construct listed companies' financial risk prediction models. At the same time, according to the shortcomings of the difficulty in determining the parameters of the radial basis neural network model, the genetic algorithm is used to improve it, and the parameter determination steps are optimized to enhance the overall performance of the model. The results of the study show that the prediction error of the GA-RBF (Genetic Algorithm-radial basis function) neural network model designed in the study has increased overall, and finally dropped to 10-2. At the same time, only one sample of the intercepted prediction samples is in the abnormal state of prediction, and the prediction effect is significantly stronger than in Traditional forecasting models. It can be seen that the GA-RBF neural network model designed by the research can achieve more accurate and stable forecasting effects in practical applications and lay the foundation for the normalized forecasting of listed companies.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "99ba0292780f2a9e5b1be31d14027cf7",
  "timestamp": "2025-05-15T01:47:14.136498"
}