{
  "id": 4310,
  "title": "ANN prediction model of final construction cost at an early stage",
  "abstract": "Previous studies developed models to predict final construction cost (FCC) values based on many inputs, which makes them difficult to use. However, relying on models with relatively few inputs will reduce the accuracy of the prediction results. This paper aims to develop an artificial neural network (ANN) model to predict the FCC based on contract cost (CC), contract duration, and project sector at an early stage of a project. The data collected and used for the ANN model was 135 Saudi Arabian construction projects. The Zavadskas and Turskis logarithmic approaches, and the Pasini method were utilized to overcome the limited data. Then, the ANN model was developed through two stages. The purpose of the first stage was to enhance the data by identifying the abnormal data using absolute percentage errors (APE). The enhanced data was used to develop the ANN in the second stage. The finding showed that the ANN model provided an average MAPE (mean absolute percentage error) of 18.7%. The MAPE of the ANN model is decreased to 8.7% on average by deleting data with an APE higher than 35%. The model allows stakeholders to evaluate the financial importance of potential risks and develop appropriate risk management strategies.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c84c69c14baf3d3c44e2601043add5da",
  "timestamp": "2025-05-15T02:35:26.368572"
}