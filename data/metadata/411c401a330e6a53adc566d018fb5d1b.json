{
  "id": 7113,
  "title": "Monitoring Liquidity Management of Banks With Recurrent Neural Networks",
  "abstract": "Monitoring liquidity management of banks is one of the prime tasks of central banks. A bank that manages its liquidity inadequately can severely harm its liquidity position and potentially threaten the stability of the entire financial system. Central banks try to anticipate these risks by carefully monitoring the liquidity management of banks in large-value payment systems (LVPSs). Typically, they do this based on statistical methods in which various risk indicators related to the liquidity usage of banks are calculated from the transaction log of an LVPS. These indicators need to be manually analyzed by payment experts to find irregularities that could signal potential risks. Although statistical methods provide much insight into the liquidity management of banks, they do not scale well to the large number of banks that are subject to risk monitoring and the high velocity by which payments are nowadays settled. In this paper, we investigate whether the liquidity management of banks can be monitored more efficiently by anomaly detection. We construct different probabilistic classifiers that classify delta sequences of banks by the corresponding bank. A delta sequence captures the change in the liquidity position of a bank in an LVPS throughout a given day. Accordingly, anomalies in the intraday liquidity usage of banks are detected by determining whether the classifiers misclassify recent delta sequences that were not used to train the classifiers. Our results show that recurrent neural networks are well suited to perform this classification task and detect many irregularities in payment behavior that are interesting for the supervisors and operators of an LVPS.",
  "year": 2021,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "411c401a330e6a53adc566d018fb5d1b",
  "timestamp": "2025-05-15T03:05:31.993905"
}