{
  "id": 2892,
  "title": "Tail event driven networks of SIFIs",
  "abstract": "The interdependence, dynamics and riskiness of financial institutions are the key features frequently tackled in financial econometrics. We propose a Tail Event driven Network Quantile Regression (TENQR) model which addresses these three aspects. More precisely, our framework captures the risk propagation and dynamics in terms of a panel quantile autoregression involving network effects that are quantified through a time-varying adjacency matrix. To reflect the risk content in stress situations the construction of the adjacency matrix is suggested to include tail events. More precisely we employ the conditional expected shortfall as risk profile. Based on the similarity of the risk profiles we create a positive and a negative network factor, which capture the effects of risk contagion and risk diversification respectively. The developed joint spacings variance ratio test supports the suggested methodology. The TENQR technique is evaluated using the SIFIs (systemically important financial institutions) identified by the Financial Stability Board (FSB). The risk decomposition of the resulting network identifies the systemic importance of SIFIs and thus provides measures for the required level of additional loss absorbency. It is discovered that the positive network effect, as a function of the tail probability level, becomes more profound in stress situations and varies in its impact to SIFIs located in different geographic regions. (C) 2018 Elsevier B.V. All rights reserved.",
  "year": 2019,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "075326dadbb7754f72c06f2cddcfd13b",
  "timestamp": "2025-05-15T02:20:16.917206"
}