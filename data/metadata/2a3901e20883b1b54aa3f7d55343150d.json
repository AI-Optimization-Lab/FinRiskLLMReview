{
  "id": 769,
  "title": "金融业需要控制“体脂率”",
  "abstract": "<正>从金融部门自身的角度,需要认识到任何脱离实体经济的\"自娱自乐\"、过度膨胀最终只能自食其果,金融只有回归本源、做回主业,才能在\"倒U型\"的上升阶段形成金融深化效果。学界研究显示,金融发展对应实体经济存在\"最优边界\"。近几年我国金融业脱实向虚、\"自娱自乐\",导致结构失衡问题突出,违法违规乱象丛生,潜在风险和隐患正在积累,脆弱性明显上升。为防止金融部门的风险被传递到经济体的各个组成部分,产生经济危机,除了管理部门管住货币供给总闸门,通过强监管、去杠杆,守住不发生系统性金融风险的底线;更重要的,金融部门尤其是商业银行要以实体经济、国家政策为遵循,多措并举控制\"体脂率\",促进金融与实体经济良性循环。",
  "year": 2018,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "2a3901e20883b1b54aa3f7d55343150d",
  "timestamp": "2025-05-14T22:33:14.914453"
}