{
  "id": 165,
  "title": "Heston-GA Hybrid Option Pricing Model Based on ResNet50",
  "abstract": "(1) Background. This study aims to improve the accuracy of the pricing model. (2) Methods. Heston model is combined with ResNet50 convolutional neural network model. Based on the optimization of Heston model parameters by genetic algorithm (GA), ResNet50 model is used to correct the deviation between market option price and Heston price, so a new hybrid option pricing model is established based on the empirical research on the European call options of Huatai-PB CSI 300ETF (code 510300), Harvest CSI 300ETF (code 159919), and SSE 50ETF (code 510050). (3) Results. The pricing result of the hybrid model is better than other single models and hybrid models. The model is applicable to the pricing of options with short and long remaining terms. (4) Conclusions. It is shown that the combination of Heston model and ResNet50 model with optimized parameters can ensure the interpretability of the model and enhance the nonlinear fitting ability of the model, which confirms the effectiveness of the hybrid model and provides a reference for investors and institutions to make scientific decisions.",
  "year": 2022,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "397363cae293ef60d4abeff0ad459f6b",
  "timestamp": "2025-05-15T01:29:09.036033"
}