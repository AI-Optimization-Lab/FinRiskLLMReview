{
  "id": 5361,
  "title": "Risk Modelling of Energy Futures: A Comparison of RiskMetrics, Historical Simulation, Filtered Historical Simulation, and Quantile Regression",
  "abstract": "Prices of energy commodity futures often display high volatility and changes in return distribution over time, making accurate risk modelling both important and challenging. Non-complex risk measuring methods that work quite well for financial assets perform worse when applied to energy commodities. More advanced approaches have been developed to deal with these issues, but either are too complex for practitioners or do not perform consistently as they work for one commodity but not for another. The goal of this paper is to examine, from the viewpoint of a European energy practitioner, whether some non-estimation complex methods for calculating Value-at-Risk can be found to provide consistent results for different energy commodity futures. We compare Risklvletrics (TM), historical simulation, filtered historical simulation and quantile regression applied to crude oil, gas oil, natural gas, coal, carbon and electricity futures. We find that historical simulation filtered with an exponential weighted moving average (EWMA) for recent trends and volatility performs best and most consistent among the commodities in this paper.",
  "year": 2015,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "bf9289d78a6a7c8e1738c9f8ab202190",
  "timestamp": "2025-05-15T02:46:45.050353"
}