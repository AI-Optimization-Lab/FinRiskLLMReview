{
  "id": 3606,
  "title": "The impact of bank liquidity, monetary policy and global crises on bank risk-taking: evidence from Vietnam",
  "abstract": "PurposeThis paper aims to examine the impact of bank liquidity, monetary policy and global crises on bank risk-taking behavior of Vietnamese banks. It provides evidence for a risk-taking channel of monetary policy through bank liquidity and global crises.Design/methodology/approachThe study uses the data set of 572 observations from 35 banks operating in Vietnam between 2005 and 2022, using the GMM regression technique.FindingsThe findings indicate that banks with higher liquidity tend to take more risks in the long run. Additionally, expansionary monetary policies encourage banks to take on more risk. Bank liquidity and global crises, such as the global financial crisis and the COVID-19 pandemic, not only directly affect bank risk-taking but also indirectly through monetary policy.Originality/valueThis paper expands the existing literature by examining the effect of bank liquidity, monetary policy and global crises on bank risk-taking by using the GMM and two models of which the authors regress the impact with and without bank liquidity and global crises. New factors affecting risk-taking, including operating cost, financial crisis and the COVID-19 pandemic are added into the model.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "00c0a455d64c627dd1877ef8f3a97ab7",
  "timestamp": "2025-05-15T02:27:54.122494"
}