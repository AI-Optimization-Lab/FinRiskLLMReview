{
  "id": 4413,
  "title": "What Information Variables Predict Bitcoin Returns? A Dimension- Reduction Approach",
  "abstract": "This article investigates the determinants of Bitcoin returns. The authors consider a comprehensive set of information variables under five categories: macroeconomics, blockchain technology, other assets, stress level, and investor sentiment. Their approach toward this large dataset is built upon dimension-reduction models such as Backward Elimination, least absolute shrinkage and selection operator (LASSO), principal component regression (PCR), and three-pass regression filter (3PRF). The empirical results show that blockchain technology, stress level, and investor sentiment have positive, negative, and positive predicting power on Bitcoin returns, respectively. Macroeconomic variables exhibit insignificant impacts on Bitcoin returns. Other asset variables show little predicting power until 2019, but some become a significant predictor during the COVID-19 pandemic. Overall, the authors caution against using Bitcoin as a risk-hedging device in financial portfolios. They also find that, consistent with other financial assets such as equities, Bitcoin shows increased predictability with a longer return horizon. Due to their empirical results, they also advocate the use of 3PRF; relative to other dimension-reduction methods under consideration, they observe superior performance of 3PRF in predicting both the level and the direction of future Bitcoin returns across all return horizons.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5e2454f4321b9d5d773c0ef572664470",
  "timestamp": "2025-05-15T02:37:16.717307"
}