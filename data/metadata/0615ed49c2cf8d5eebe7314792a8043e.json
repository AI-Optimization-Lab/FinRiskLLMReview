{
  "id": 999,
  "title": "A Tool for Predicting Regulatory Approval After Phase II Testing of New Oncology Compounds",
  "abstract": "We developed an algorithm (ANDI) for predicting regulatory marketing approval for new cancer drugs after phase II testing has been conducted, with the objective of providing a tool to improve drug portfolio decision-making. We examined 98 oncology drugs from the top 50 pharmaceutical companies (2006 sales) that first entered clinical development from 1999 to 2007, had been taken to at least phase II development, and had a known final outcome (research abandonment or regulatory marketing approval). Data on safety, efficacy, operational, market, and company characteristics were obtained from public sources. Logistic regression and machine-learning methods were used to provide an unbiased approach to assess overall predictability and to identify the most important individual predictors. We found that a simple four-factor model (activity, number of patients in the pivotal phase II trial, phase II duration, and a prevalence-related measure) had high sensitivity and specificity for predicting regulatory marketing approval.",
  "year": 2015,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "0615ed49c2cf8d5eebe7314792a8043e",
  "timestamp": "2025-05-15T00:50:40.743792"
}