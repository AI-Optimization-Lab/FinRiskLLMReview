{
  "id": 2145,
  "title": "A Distributed Algorithm for the Cooperative Prediction of Power Production in PV Plants",
  "abstract": "Forecasting the energy production of photovoltaic plants is today an essential tool for asset owners because it has direct economic implications on the net operating income of the plants whose generated energy is sold in competitive electricity markets. In this paper, we propose an innovative distributed decentralized prediction technique for the forecasting of power generated by several PV plants. The prediction technique is based on the Echo State Networks, which are recurrent neural network models very promising in terms of prediction performance and model accuracy. They will be used in conjunction with a distributed learning algorithm and a distributed consensus protocol that makes unnecessary any central coordinator. The technique has been properly conceived for asset owners that hold a wide portfolio of PV systems that are geographically spread out over large areas. The algorithm reveals very efficient, accurate, and scalable performance to any number of plants and it requires only a simple reliable communication channel. Through a real-world example we assess the applicability of such methodology and show its strength.",
  "year": 2019,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "494894da246f5233bb7cc32ab066bc41",
  "timestamp": "2025-05-15T01:03:36.613547"
}