{
  "id": 3471,
  "title": "Antecedents of project managers' voice behavior: The moderating effect of organization-based self-esteem and affective organizational commitment",
  "abstract": "Theory and research stress that employee voice behavior (VB; discretionary communication of ideas, suggestions, or concerns with the intent to improve organizational functioning) positively influences decision making, improvement, and innovation. However, the VB construct has rarely been studied in the specific context of project management. Using a sample of 618 project managers and 154 project portfolio coordinators nested in 154 firms, the main purpose of this study was to analyze a moderated model, in which specific contextual factors interact with individual-level variables to predict project managers' VB. Consistent with our hypotheses derived from self-consistency theory, moderated hierarchical regression analysis revealed that idea encouragement, career perspectives, qualification opportunities, and peer collaboration related more positively to VB for project managers with a high level of organisation-based self-esteem. For project managers high in affective organizational commitment, we found stronger positive relationships of peer collaboration and idea encouragement with project managers' VB. (C) 2015 Elsevier Ltd. APM and IPMA. All rights reserved.",
  "year": 2016,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "3339c9c312d8a8ef9652cf1c743f7453",
  "timestamp": "2025-05-15T01:17:25.528804"
}