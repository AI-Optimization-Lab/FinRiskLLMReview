{
  "id": 16,
  "title": "ChatGPT-Related Risk Patterns and Students' Creative Thinking Toward Tourism Statistics Course: Pretest and Posttest Quasi-Experimentation",
  "abstract": "The existing research highlights the pivotal role of ChatGPT usage-related risk patterns in higher education students' creative thinking. Data was obtained from 1443 students at seven tourism colleges in Egypt. Statistical analysis tools (i.e., SPSS v.26 and ADANCO v.2.4) were employed for path testing. PLS-SEM findings proved that students' privacy, performance, financial, and psychological risks towards ChatGPT usage significantly decreased their creative thinking towards tourism statistics courses. Besides, students' inherent creative abilities positively affected creative thinking. Further, SPSS-based quasi-experimental findings confirmed that students who use ChatGPT apps have several risks that influence their creative thinking. Accordingly, the existing paper provides keen insights for tourism education policymakers.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "LLMs",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6e7cccd0206ab1dfceed32d9586ce9df",
  "timestamp": "2025-05-15T01:45:16.331427"
}