{
  "id": 34,
  "title": "基于非线性预测模型的行业轮动策略研究",
  "abstract": "相对于线性模型，非线性模型可以更好地处理变量间的非线性关系，得到更准确的预测结果。选择中信一级行业月度数据作为研究对象，采用基本面和技术面因子作为预测指标，利用分位数回归、广义可加模型以及随机森林三种非线性预测模型对我国股市行业收益率进行预测并构造投资组合。研究发现：相对于线性模型，非线性模型的预测准确度更高，随机森林模型的表现最优，构建的投资组合表现最好；对随机森林模型的改进研究发现，应尽可能往模型中增加更多的因子，而不必考虑变量间的共线性问题，但是加入的因子必须要包含有预测信息，如果加入因子携带的预测信息过少，很可能会拖累模型的表现。研究结论是对投资组合理论以及人工智能理论的有益补充，对于投资者的投资实践也具有一定的参考价值。",
  "year": 2024,
  "source": "CNKI",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5a1c7b278221e7b4f1071d371eca5c7f",
  "timestamp": "2025-05-14T22:07:42.484138"
}