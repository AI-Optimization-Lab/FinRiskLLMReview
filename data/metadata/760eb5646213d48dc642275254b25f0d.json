{
  "id": 1103,
  "title": "On Machine Learning models explainability in the banking sector: the case of SHAP",
  "abstract": "Machine Learning models explainability has recently become a very popular topic in the banking sector. We apply Shapley values and the Python library SHAP to a real credit risk database and show that the two available SHAP types (interventional and path-dependent) provide very similar results even under correlated features. The main drawback of SHAP is that it is not portfolio invariant, this is, the explanation for the prediction provided for each observation depends on the portfolio distribution of the features. This can be a serious problem for customers and banking regulators, who expect that explanations will stay stable as long as the clients characteristics do not change. We conduct several tests and show that the SHAP explanation of an observation may considerably change depending on the rest of the portfolio distribution. As a consequence, the explanation of a client may vary over time even if her characteristics do not change and banks using the same model (for ex. commercial models) may provide different explanations to the same client.",
  "year": 2025,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "760eb5646213d48dc642275254b25f0d",
  "timestamp": "2025-05-15T00:52:00.334893"
}