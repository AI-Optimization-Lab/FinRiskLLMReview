{
  "id": 2234,
  "title": "Searching hedging instruments against diverse global risks and uncertainties",
  "abstract": "We evaluate the influence of five major risk and uncertainty factors on four asset classes. Our time-varying findings suggest that each asset hedges only a particular uncertainty factor, whereas gold does more than one factor, especially during COVID-19. Our frequency-based quantile regression (QR) results show that in the raw frequency, gold and Islamic stock can better hedge various uncertainty factors than Bitcoin and crude oil, depending on the market conditions. Additionally, using the frequency bands (e.g., short, medium, and long term) data, we further notice that, depending on the market circumstances and investment horizons, gold and Islamic stock returns are still better hedges for the various risks and uncertainties than Bitcoin and crude oil returns. Our findings have crucial risk and portfolio management implications for investors, portfolio managers, and policymakers.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "3c75b3d03f4bc09eccc71368b1a51936",
  "timestamp": "2025-05-15T01:04:27.498480"
}