{
  "id": 5238,
  "title": "Quantile-based detecting the day of the week effect on market risk in Chinese stock markets",
  "abstract": "In past decades calendric effects on the mean and volatility of stock returns have been studied by many scholars. The paper takes a new insight into the day of the week effect on market risk and finds its significant existence in Chinese stock markets. A conditional quantile regression model with dummy week explanatory variables is constructed to estimate value-at-risk of return time series in order to measure market risk. For both Shanghai and Shenzhen stock markets, it is found that the dummy week variables from Monday to Friday cause various quantities of impact on VaR(the biggest impacts come from Friday in Shanghai market, and from Wednesday in Shenzhen market), however in the same market the patterns of calendric impact on VaR at different confidence levels are similar. It is also indicated that market risk reaches the peak on Friday in Shanghai market and on Wednesday in Shenzhen market, whereas arrives at the bottom on Wednesday in Shanghai market and on Friday in Shenzhen market in average. The week anomaly of market risk in Chinese stock markets firstly found in the paper will benefit Chinese financial institutions and investors by adjusting the positions of asset portfolios to disperse risk and strengthen risk supervision in future.",
  "year": 2007,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d7be9c9f269ea9bf6cbd4aeff875a093",
  "timestamp": "2025-05-15T02:45:47.410439"
}