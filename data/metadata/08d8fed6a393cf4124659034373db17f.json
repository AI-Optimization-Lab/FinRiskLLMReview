{
  "id": 3718,
  "title": "On the robustness of week-day effect to error distributional assumption: International evidence",
  "abstract": "We examine the robustness of the week-day effect both in the mean and conditional volatility using 51 stock market indices while controlling for volatility clustering and using three specifications of the error distributions. We show that the evidence of week-day effect in mean and conditional volatility is sensitive to the choice of the underlying distribution. Our results are not limited to the classic setting of examining week-day effect but also extend to settings that account for conditional and unconditional market risk. We extend our analysis to wandering week-day effect, and find that it also varies with the error distributional assumptions. Moreover, we document that the 2008 financial crisis lessened the week-day effect in the mean but at the same time magnified such effect in the conditional volatility. Our findings are robust to the presence of outliers, to different model specifications, and to the presence of structural breaks. Our study suggests that empirical regularity in financial series may be econometrically fragile in the sense of Leamer (1985). It also corroborates the calls that followed the recent financial crisis about the hazard of using models that are based on unrealistic assumptions. (C) 2016 Elsevier B.V. All rights reserved.",
  "year": 2017,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "08d8fed6a393cf4124659034373db17f",
  "timestamp": "2025-05-15T02:29:27.940314"
}