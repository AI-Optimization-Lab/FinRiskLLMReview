{
  "id": 540,
  "title": "IMPROVING FRACTALS FINANCIAL CREDIT RISK EVALUATION BASED ON DEEP LEARNING TECHNIQUES AND BLOCKCHAIN-BASED ENCRYPTION",
  "abstract": "Predicting a client's affluence is essential in financial services. This task is the unity of the most important danger factors in groups and additional economic institutions. Typically, credit risk evaluation relies on black box models. However, these models often need to clarify the hidden information within the data. Moreover, few clear models focus on being easy to understand and accessible. This paper proposes a fractal credit risk assessment model that uses deep techniques like self-attention generative adversarial networks (SA-GAN) and deep multi-layer perceptron (DMLP). We use blockchain technology with the Brakerski-Gentry-Vaikuntanathan (BGV) encryption method to bolster safekeeping. Additionally, the scheme is designed for the Edge-of-things network, enabling communication through a LoRaWAN server. The proposed solution was tested on the German retail credit dataset. We assessed its performance using accuracy, F1 score, precision, and recall as metrics. Notably, our hybrid deep model, which combines SA-GAN with DMLP, achieved an impressive accuracy of 97.8% - outperforming existing methods in works.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "2a5657b91edac1c31a588a4ba934d273",
  "timestamp": "2025-05-15T01:39:38.277114"
}