{
  "id": 2668,
  "title": "Do ESG Risk Scores Influence Financial Distress? Evidence from a Dynamic NDEA Approach",
  "abstract": "Financial distress is a research topic in finance that has attracted attention from academia following past financial crises. Although previous studies associate financial distress with several elements, the relationship between distress and ESG has not been broadly explored. This paper investigates these issues by elaborating a Dynamic Network DEA model to address the underlying connections between accounting and financial indicators. Thus, a model that includes profit and loss, balance sheet, and capital and operating expenditures indicators is demonstrated under the dynamic network structure to compute financial-distress efficiency scores. Then, the impact of carryovers is considered for the accurate calculation of efficiency scores for the three substructures. The influence of contextual variables, such as socioeconomic and macroeconomic variables, and whether the firm owns an ESG Risk Score or not, is assessed through a stochastic non-linear model that combines three distinct regression types: Simplex, Tobit, and Beta. The results indicate that firms that hold an ESG Risk Score are less prone to be in financial distress, and Governance Score is negatively associated with financial distress efficiency.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "32640f7b8786eaa23ce0c91384701f7b",
  "timestamp": "2025-05-15T02:18:06.130269"
}