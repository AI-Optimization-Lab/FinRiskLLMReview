{
  "id": 134,
  "title": "《中国金融报告2022》",
  "abstract": "<正>《中国金融报告2022》以“金融助力经济回归潜在增长水平”开篇，分为14个部分，从全球变局下的汇率决定和汇率制度、资本属性与银行风险、国有上市公司估值的典型特征与提升路径、房地产金融新变化与房地产发展新模式、房地产金融新变化与房地产发展新模式、系统性金融风险与现代金融监管、发展账户制个人养老金、基本养老保险全国统筹制度、引导数字金融支持实体经济的路径、数字人民币促进中小微金融服务、资本市场支持创新性企业发展、金融支持创新研究、促进科技产业金融良性循环、新市民普惠金融、双碳目标与转型金融发展等角度，指出货币金融政策坚持“以我为主、稳字当头”总基调，助力稳住了经济基本盘，经济增长有望回归潜在增长水平。报告回顾了2022年中国金融形势并展望2023年发展调整以及金融工作重点，提出了金融工作中存在的问题以及相应的对策，对于我国制定金融发展政策具有一定的参考价值和指导意义。",
  "year": 2023,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "ffdd678c6c3eec2ed0867063e8469910",
  "timestamp": "2025-05-14T22:26:58.976905"
}