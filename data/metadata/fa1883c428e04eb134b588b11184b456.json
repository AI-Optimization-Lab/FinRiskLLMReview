{
  "id": 2768,
  "title": "A Coupled Mathematical Model of the Dissemination Route of Short-Term Fund-Raising Fraud",
  "abstract": "To effectively protect citizens' property from the infringement of fund-raising fraud, it is necessary to investigate the dissemination, identification, and causation of fund-raising fraud. In this study, the Susceptible Infected Recovered (SIR) model, Back-Propagation (BP) neural network, Fault tree, and Bayesian network were used to analyze the dissemination, identification, and causation of fund-raising fraud. Firstly, relevant data about fund-raising fraud were collected from residents in the same area via a questionnaire survey. Secondly, the SIR model was used to simulate the dissemination of victims, susceptibles, alerts, and fraud amount; the BP neural network was used to identify the data of financial fraud and change the accuracy of the number analysis of neurons and hidden layers; the fault-tree model and the Bayesian network model were employed to analyze the causation and importance of basic events. Finally, the security measures of fund-raising fraud were simulated by changing the dissemination parameters. The results show that (1) for the spread of the scam, the scale of the victims expands sharply with the increase of the fraud cycle, and the victims of the final fraud cycle account for 12.5% of people in the region; (2) for the source of infection of the scam, the initial recognition rate of fraud by the BP neural network varies from 90.9% to 93.9%; (3) for the victims of the scam, reducing fraud publicity, improving risk awareness, and strengthening fraud supervision can effectively reduce the probability of fraud; and (4) reducing the fraud rate can reduce the number of victims and delay the outbreak time. Improving the alert rate can reduce victims on a large scale. Strengthening supervision can restrict the scale of victims and prolong the duration of fraud.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "fa1883c428e04eb134b588b11184b456",
  "timestamp": "2025-05-15T02:19:08.349291"
}