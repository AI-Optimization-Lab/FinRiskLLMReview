{
  "id": 2183,
  "title": "Evolving Hybrid Neural Fuzzy Network for Realized Volatility Forecasting with Jumps",
  "abstract": "Equity assets volatility modeling and forecasting are fundamental in risk management, portfolio construction, financial decision making and derivative pricing. The use of realized volatility models outperforms GARCH and related stochastic volatility models in out-of-sample forecasting. Gains in performance can be achieved by separately considering volatility jump components. This paper suggests an evolving hybrid neural fuzzy network (eHFN) modeling approach for realized volatility forecasting with jumps. The eHFN model is nonlinear, timeraying, and uses neurons based on uninorms and sigmoidal activation functions in a feedforward network topology. The approach simultaneously chooses the number of hidden layer neurons and corresponding neural networks weights. This is of outmost importance in dynamic environments such as in volatility forecasting using data streams. Computational experiments were performed to evaluate and to compare the performance of eHFN with multilayer feedforward neural network, linear regression, and evolving fuzzy models representative of the current state of the art. The experiments use actual data from the main equity market indexes in global markets, namely, S&P 500 and Nasdaq (United States), FTSE (United Kingdom), DAX (Germany), IBEX (Spain) and Ibovespa (Brazil). The results show that the evolving hybrid neural fuzzy network is highly capable to model timevarying realized volatility with jumps.",
  "year": 2014,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a1c81532ac5afc5fefd50f4011bae41a",
  "timestamp": "2025-05-15T02:12:17.390828"
}