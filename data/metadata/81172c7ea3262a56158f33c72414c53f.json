{
  "id": 1600,
  "title": "Comparing the Effectiveness of Multiple Quantitative Trading Strategies",
  "abstract": "Investment in stock has drawn worldwide attention from individuals and investment companies. There are many common practices of trading strategies. An easy but effective one is the buy and hold strategy strongly advocated by Warren Buffett, where investigators would buy one or a group of stocks and let time make money. A common strategy for individual investors was by reading the stock chart, based on their personal judgement, which often was not quite different from random guesses due to the lack of information and experience. Another recent strategy is to use machine-learning techniques to predict the stock market. I am interested in investigating which of the above strategies were more effective in the current stock market. To gain an up-to-date view, I applied these strategies on 4 different popular stocks and observed their performance for 100 randomly chosen time frame in 2017 and 2018. By evaluating the return and risk of each strategy, my results provide guidance for quantitative trading for general investors. Specifically, if the stock market is stably increasing, the optimal strategy is to use the buy-and-hold strategy. If the stock market is comparatively stable, using a good machine learning strategy is expected to help. Overall, individual investors should devote more efforts in selecting a promising stock or portfolio than focusing too closely on daily price changes.",
  "year": 2019,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "81172c7ea3262a56158f33c72414c53f",
  "timestamp": "2025-05-15T00:57:46.754601"
}