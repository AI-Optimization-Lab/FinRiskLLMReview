{
  "id": 4830,
  "title": "Share-loan pledging and relaxation of share-repurchase restrictions in China",
  "abstract": "We examine a period in which the in-principle prohibition of share repurchases was relaxed in 2018 to allow for the repurchase of shares whose prices dropped materially or were below book value. We find that share-loan pledges by controlling shareholders are significantly and positively associated with share repurchases for a sample of 3,531 Chinese firms. This finding is robust using entropy and propensity score matched samples, 2SLS IV regressions, regression discontinuity design (RDD), and two exogenous shocks (the China-US trade war in 2018 and the COVID-19 pandemic in 2020). The association remains robust but becomes less strong with state ownership and with above industry average firm agency problems, leverage ratios and financial constraints/distress (i.e., other share repurchase motives). Our findings highlight the importance of financial market regulations on share-loan pledging and share repurchases in emerging markets during periods of heightened firm-specific and systemic margin call risk and impending liquidation of share-loan pledges.",
  "year": 2021,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "f8656e52ba010d38a88a706badc8128d",
  "timestamp": "2025-05-15T02:41:32.719976"
}