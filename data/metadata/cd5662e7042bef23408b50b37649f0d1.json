{
  "id": 520,
  "title": "MF-Informer for long-term QoS prediction in edge-cloud collaboration environments",
  "abstract": "In Service-Oriented Architecture (SOA) systems, continuously stabilizing web services' quality of service (QoS) is critical to maintaining system performance. Dynamic changes in edge-cloud collaborative computing environments lead to fluctuations in QoS values, and the original service portfolio design will no longer fulfill the Service Level Agreement (SLA), resulting in performance degradation of SOA systems. To ensure the efficiency of SOA systems, long time-series prediction of services' QoS is an effective method, which can warn of SLA violations and recommend optimal candidate services. In this paper, we propose a prediction algorithm, MF-Informer, which combines matrix factorization and the Informer model to solve the sparsity problem of QoS historical data, and the self-attention mechanism of the Informer model realizes the prediction of service QoS over N steps ahead. In this paper, experiments are conducted based on real-world web service QoS datasets, and the results show that this paper's method improves the efficiency and accuracy of service QoS long-term prediction, which is significantly better than existing methods in several evaluation metrics.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "cd5662e7042bef23408b50b37649f0d1",
  "timestamp": "2025-05-15T00:37:01.723223"
}