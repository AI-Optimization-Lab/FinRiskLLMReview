{
  "id": 3249,
  "title": "Estimating Tail Risk in Ultra-High-Frequency Cryptocurrency Data",
  "abstract": "Understanding the density of possible prices in one-minute intervals provides traders, investors, and financial institutions with the data necessary for making informed decisions, managing risk, optimizing trading strategies, and enhancing the overall efficiency of the cryptocurrency market. While high accuracy is critical for researchers and investors, market nonlinearity and hidden dependencies pose challenges. In this study, the filtered historical simulation is used to generate pathways for the next hour on the one-minute step for Bitcoin and Ethereum quotes. The innovations in the simulation are standardized historical returns resampled with the method of block bootstrapping, which helps to capture any hidden dependencies in the residuals of a conditional parameterization in the mean and variance. Ordinary bootstrapping requires the feed innovations to be free of any dependencies. To deal with complex data structures and dependencies found in ultra-high-frequency data, this study employs block bootstrap to resample contiguous segments, thereby preserving the sequential dependencies and sectoral clustering within the market. These techniques enhance decision-making and risk measures in investment strategies despite the complexities inherent in financial data. This offers a new dimension in measuring the market risk of cryptocurrency prices and can help market participants price these assets, as well as improve the timing of their entry and exit trades.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "9af3fa70d351bc0eb1040e6a34d0e144",
  "timestamp": "2025-05-15T02:24:05.238990"
}