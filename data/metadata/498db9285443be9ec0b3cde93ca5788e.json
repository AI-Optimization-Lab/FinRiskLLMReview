{
  "id": 2155,
  "title": "Developing a scoring model for managing money laundering transactions using machine learning",
  "abstract": "PurposeThe purpose of this study is twofold. Firstly, this study outlines the creation of an ML bolt on transaction monitoring risk scoring model. This ML model uses predictive classification to score the likelihood of an alert being a false or true positive based on historical data. Secondly, this study explores the results of implementing the model in a real-world environment. This is valuable, as it explores the potential to reduce the workload on human analysts responsible for reviewing alerts, by hibernating low-risk alerts and auto-escalating high-risk alerts.Design/methodology/approachMachine learning is used to create a bolt on model that sits on top of existing rule-based transaction monitoring systems to improve their effectiveness and efficiency. This was achieved by developing a model to mimic the analysts alert review process with the aim of improving efficiency, reducing investigation timeliness and ultimately reducing time-to-SAR duration. The model did so by scoring anti-money laundering (AML) alerts to help conduct three actions: automatic hibernation of low-risk alerts; review of medium-risk alerts by the level 1 team; and auto-escalation of high-risk alerts to the level 2 team for detailed investigation.FindingsThe model was successful in consistently identifying low-risk alerts correctly, significantly reducing the volume of false positives that needed manual review. Prior to implementation, 100% of alerts had to be reviewed, by the end of the examined period, 19% of alerts were hibernated and 18% of alerts were auto-escalated. Time taken to investigate and submit SARs was reduced by 61%.Practical implicationsThe practical implications of the study lie in its contributions to helping banking institutions effectively keep pace with the increasing volume of transactions, in a cost effective and efficient manner, which has a positive effect on their reputation through enhancing their AML response.Social implicationsThe model outlined greatly enhances the timeliness of investigations, which is crucial for money laundering prevention and enables timely responses by institutions and law enforcement agencies to make better use of the investigation timeframe after an offence is identified, enabling them to more rapidly address threats, freeze assets when necessary, and secure vital evidence before it is lost.Originality/valueThis study provides a blueprint for other financial institutions to consider similar approaches to AML. This is significant because previous studies of machine learning applications in the domain of AML have not explored this type of use before, particularly in the context of machine learning ensembled techniques. It also addressed several cited limitations of previous research by increasing the depth of information in the datasets used and providing a formal evaluation. Importantly, the blueprint and evaluation metrics used in this study ensure its reproducibility, addressing another previously identified academic issue.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "498db9285443be9ec0b3cde93ca5788e",
  "timestamp": "2025-05-15T02:11:40.635222"
}