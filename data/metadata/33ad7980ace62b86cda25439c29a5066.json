{
  "id": 507,
  "title": "Effects of Temperature Rise on Clean Energy-Based Capital Market Investments: Neural Network-Based Granger Causality Analysis",
  "abstract": "During the past 20 years, due to climate change, the government and the private sector have significantly focused on relying on non-fossil fuel-based methods for their energy needs. Climate change-related events, such as unusual weather conditions, abnormal temperature spikes, etc., have an adverse influence on clean energy-based investments. In the given study, we intend to focus on how an incremental temperature rise could affect investors' perceptions of clean energy assets. To understand the investor-based sentiment on climate change, we utilize prominent clean energy ETFs (exchange traded funds) and consider the temperature's effect on them. The daily average temperatures of the three most dynamic international financial centers: New York, London and Tokyo, are taken as predictors. Deep learning-based neural networks are applied to understand both the linear and non-linear relationships between the desired variables and identify the causal effects. The results indicate that in almost all the cases with desired lags, there is some sort of non-linear causality, irrespective of linear causality effects. We hope this occurrence can help portfolio managers and environmental professionals in identifying novel climate change-related factors when considering the temperature-related risks.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "33ad7980ace62b86cda25439c29a5066",
  "timestamp": "2025-05-15T00:37:01.675774"
}