{
  "id": 1135,
  "title": "Earnings Per Share Forecast Using Extracted Rules from Trained Neural Network by Genetic Algorithm",
  "abstract": "Earnings per share (EPS) is one of the main financial ratio that is considering by managers, investors and financial analysts. It is usually using in investment decisions, profitability evaluation, profit risk, and stock price estimation. Therefore, EPS forecasting is a valuable and attractive task for managers and investors. This paper examines EPS forecasting using multi-layer perceptron (MLP) neural network and rule extraction from neural network by genetic algorithm technique and determined an optimal model between MLP and RE technique by evaluating their forecasting accuracy. For this purpose, we use 990 listed firms in Tehran Stock Exchange in the period of 2000-2010. The results show that the RE technique is significantly more accurate than the MLP model.",
  "year": 2015,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b52b861a48e36285db1e13508a3cb813",
  "timestamp": "2025-05-15T01:59:21.621848"
}