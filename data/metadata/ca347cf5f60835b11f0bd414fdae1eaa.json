{
  "id": 298,
  "title": "Application of eXtreme gradient boosting trees in the construction of credit risk assessment models for financial institutions",
  "abstract": "The majority of the studies on credit risk assessment models for financial institutions during recent years focus on the improvement of imbalanced data or on the enhancement of classification accuracy with multistage modeling. Whilst multistage modeling and data pre-processing can boost accuracy somewhat, the heterogeneous nature of data may affects the classification accuracy of classifiers. This paper intends to use the classifier, eXtreme gradient boosting tree (XGBoost), to construct a credit risk assessment model for financial institutions. Cluster-based under-sampling is deployed to process imbalanced data. Finally, the area under the receiver operative curve and the accuracy of classifications are the assessment indicators, in the comparison with other frequently used single-stage classifiers such as logistic regression, self-organizing algorithms and support vector machine. The results indicate that the XGBoost classifier used by this paper achieve better results than the other three and can serve as a superior tool for the development of credit risk models for financial institutions. (C) 2018 Elsevier B.V. All rights reserved.",
  "year": 2018,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "ca347cf5f60835b11f0bd414fdae1eaa",
  "timestamp": "2025-05-15T01:49:04.667144"
}