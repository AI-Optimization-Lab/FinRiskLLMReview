{
  "id": 455,
  "title": "A Variables Clustering based Differential Evolution Algorithm to Solve Multistage Goal Programming Model in Defense Projects Portfolio",
  "abstract": "The multistage goal programming model is popular to model the defense projects portfolio optimization problem in recent years. However, as its high-dimensional variables and large-scale solution space, the addressed model is hard to be solved in an acceptable time. To deal with this challenge, we propose an improved differential evolution algorithm which combines three novel strategies i. e. the variables clustering based evolution, the whole randomized parameters, and the child-individual based selection. The simulation results show that this algorithm has the fastest convergence and the best global searching capability in 6 test instances with different scales of solution space, compared with classical differential evolution algorithm (CDE), genetic algorithm (GA) and particle swarm optimization (PSO) algorithm.",
  "year": 2014,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "23b7b88a110cf2530ba22deee1009637",
  "timestamp": "2025-05-15T00:43:47.314972"
}