{
  "id": 260,
  "title": "Measurement of Project Portfolio Benefits With a GA-BP Neural Network Group",
  "abstract": "To facilitate the project portfolio benefits (PPB) management and realize the maximization of the benefits, a PPB measurement model based on the genetic algorithm (GA)-BP neural network group (GA-BPNNG) is proposed in current research. Unlike traditional benefits management approaches, the proposed model takes full cooperation and information sharing advantages of group learning to measure PPB more accurately, which considers both the financial and nonfinancial benefits and synergy benefits generated from the interrelationships among project portfolio components. To ascertain the priority of the PPB measurement model, the GA-BPNNG model is compared with BPNN and GA-BPNN, two common models in the literature. The mean square error of the GA-BPNNG model reduced by 94% and 83%, respectively, when compared to the BPNN and GA-BPNN models. The results suggest that the PPB measurement model performs more effectively. Therefore, it could be concluded that the proposed model has a better nonlinear fitting effect for PPB measurement. This article can support managers, decision-makers, and management in realizing strategy by providing a practical and scalable tool for PPB measurement.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6af71999ac16106837b5be6ebfd31fe0",
  "timestamp": "2025-05-15T00:41:04.759573"
}