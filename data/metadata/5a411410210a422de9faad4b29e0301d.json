{
  "id": 316,
  "title": "An Optimal Least Square Support Vector Machine Based Earnings Prediction of Blockchain Financial Products",
  "abstract": "The booming applications of bitcoin Blockchain technologies made investors concerned about the return and risk of financial products. So, the return rate of bitcoin must be foreseen in prior. This research article devises an effective return rate prediction technique for Blockchain financial products based on Optimal Least Square Support Vector Machine (OLS-SVM) model. The parameter optimization of the LS-SVM model was performed using hybridization of Grey Wolf Optimization (GWO) with Differential Evolution (DE), called optimal GWO (OGWO) algorithm. The hybridization process is performed to eliminate the local optima problem of GWO and enhance the diversity of the population. To verify the goodness of the proposed model, the Ethereum (ETH) return rate was chosen as the target and experimental analysis was performed on it to verify the predictive results on the time series. The experimental outcome was analyzed in terms of two performance measures namely Mean Squared Error (MSE) and Mean Absolute Percentage Error (MAPE). The obtained simulation outcome infers that the OLS-SVM model yielded better predictive outcome of the return rate of financial products.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5a411410210a422de9faad4b29e0301d",
  "timestamp": "2025-05-15T01:49:40.952595"
}