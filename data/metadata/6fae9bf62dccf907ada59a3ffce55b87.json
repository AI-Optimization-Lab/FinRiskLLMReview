{
  "id": 3506,
  "title": "Strict sensitivity analysis in fuzzy quadratic programming",
  "abstract": "Quadratic programming can be seen both as a general approach to linear programming and a special class of non-linear programming. Moreover, quadratic programming problems are of utmost importance in an increasing variety of practical fields, such as, regression, efficient production and portfolio selection. As ambiguity and vagueness are natural and ever-present in real-life situations requiring solutions, it makes perfect sense to attempt to address them using fuzzy quadratic programming problems. The fxmain main purpose of this paper is to study the strictly sensitivity analysis for fuzzy quadratic programming when simultaneously and independently variations occur in the right-hand-side of the constraints and the coefficients of the objective function. One presents computable auxiliary problems to identify the invariance intervals and give a fuzzy quadratic form of the optimal value function too. Some numerical examples are presented to illustrate the proposed method. (c) 2011 Elsevier B.V. All rights reserved.",
  "year": 2012,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6fae9bf62dccf907ada59a3ffce55b87",
  "timestamp": "2025-05-15T01:17:54.094103"
}