{
  "id": 396,
  "title": "The Non-Linear Regression Model to Estimate the Part of NPLS in the Whole Loan Portfolio of Ukrainian Banks",
  "abstract": "The non-linear regression model for estimating the part of non-performing loans (NPLs) in the whole loan portfolio of Ukrainian banks is constructed on the basis of the Johnson normalizing transformation for the four-dimensional non-Gaussian data: the part of NPLs in the whole loan portfolio of Ukrainian banks, the official exchange rate of the US dollar to the national currency UAH, the part of foreign currency loans and the part of loans for legal entities in the loan portfolio. The equation, confidence and prediction intervals of non-linear regression on the basis of normalizing transformations for the non-Gaussian data are also built. Comparison of the constructed model with the linear regression model and a nonlinear regression model based on the decimal logarithm is performed.",
  "year": 2018,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a55d93ebd96cc23bc88d0b547be51704",
  "timestamp": "2025-05-15T00:43:10.476764"
}