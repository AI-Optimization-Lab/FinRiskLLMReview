{
  "id": 1942,
  "title": "The investment value of the value premium",
  "abstract": "Value investment strategies are premised on research that value stocks outperform growth stocks. However, the research findings are dependent on the portfolio classification method that is used to sort stocks using the attributes of size and book-to-market ratios. Different stock markets contain different distributions of stocks, and in many markets, illiquidity concerns combined with a lack of investment scale, effectively create barriers to practical portfolio formations that align with the research. This study conducts a case study on one such market (Australia) and demonstrates that different methods of portfolio formation lead to different conclusions. For example, previous studies in Australia find evidence of the value premium only being present in the largest stocks, in contrast to the results from the US market. However, we find a value premium that is systematic across all size categories and generally increases inversely with size. Further, we find the well-documented size premium largely disappears once portfolios are formed that better represent feasible investment sets and once 'penny dreadfuls' are removed. Finally, asset pricing tests support the existence of a value premium in Australian stock returns when a more appropriate portfolio formation method is employed. (C) 2011 Elsevier B.V. All rights reserved.",
  "year": 2012,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c636db800b758879bf8c15779cca9643",
  "timestamp": "2025-05-15T01:01:41.570911"
}