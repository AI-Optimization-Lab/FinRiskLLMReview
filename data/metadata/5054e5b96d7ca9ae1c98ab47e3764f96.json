{
  "id": 5148,
  "title": "Smartphone Use by Caregivers for Patients With Heart Failure During Hospitalization: An Investigation",
  "abstract": "This study investigated the use of smartphones by family caregivers for hospitalized patients with chronic heart failure (CHF). In total, 120 patients and their unpaid family caregivers participated in this study. The caregivers were divided into two groups based on the perceived importance of smartphones in patient care. Both groups completed the General Demographic Information Survey, Problematic Mobile Phone Use Questionnaire, Barthel Index Scale, Modified Early Warning Score (MEWS), Johns Hopkins Fall Risk Assessment Tool (JH-FRAT), and Family Burden Scale of Diseases Survey. Moreover, left ventricular ejection fraction (LVEF) and stroke volume (SV) were measured in all participants. The age of hospitalized patients with CHF was correlated with the Barthel Index Scale, MEWS, and JH-FRAT, whereas LVEF and SV were correlated with MEWS. The important group had a much higher financial burden than the nonimportant group. Linear regression analysis revealed that financial burden and mental health had a remarkable impact on the content of mobile calls about treatment. Furthermore, the economic status of family caregivers determined the importance of smartphone calls in the care of patients with CHF during hospitalization.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5054e5b96d7ca9ae1c98ab47e3764f96",
  "timestamp": "2025-05-15T02:44:43.960706"
}