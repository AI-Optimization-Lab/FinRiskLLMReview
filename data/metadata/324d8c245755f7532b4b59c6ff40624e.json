{
  "id": 2940,
  "title": "Perceived risks and restaurant visit intentions in China: Do online customer reviews matter?",
  "abstract": "Drawing on risk and communication theory, this study examines the moderating effects of online customer reviews in the Chinese restaurant context. In particular, we examine how review trustworthiness may moderate the relationship between two types of risk (performance risk and financial risk) and restaurant visit intention. After reviewing the sample criteria and excluding surveys with missing values, the final sample comprised 520 respondents from the context of Chinese restaurants. We tested the proposed hypotheses using hierarchical moderated regression and found that financial risk negatively impacts both restaurant visit intention and responses to two- and three-way interactions. More specifically, the negative effects diminish when positive tradeoff effects increase. This analysis strongly supports the two-way interaction effects of review trustworthiness while showing that the three-way interactions effects of review trustworthiness depend significantly on different levels of review skepticism.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "324d8c245755f7532b4b59c6ff40624e",
  "timestamp": "2025-05-15T02:20:48.237209"
}