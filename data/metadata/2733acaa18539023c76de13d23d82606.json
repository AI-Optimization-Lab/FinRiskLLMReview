{
  "id": 3984,
  "title": "Family firms and their participation in cross-border acquisition waves: evidence from India",
  "abstract": "Purpose From the socioemotional wealth (SEW) perspective, family firms prioritize non-financial goals and show risk averse behaviour towards conducting acquisitions. In this paper, we study family firms' acquisitive behaviour while participating in CBA waves. Scholars have largely treated the cross border acquisition (CBA) wave and non-wave environments as homogeneous. We theorize that these two environments differ in their uncertainty and risk profiles on account of temporal clustering of acquisition deals. Accordingly, based on the SEW perspective, we examine the preference of family firms to participate in CBA waves. Design/methodology/approach The paper is based on CBAs conducted by Indian family firms between 2000 and 2018. These waves are identified by conducting a simulation based methodology. Findings Our findings suggest that foreign institutional ownership, firm age and acquisition relatedness moderate the relationship between family control and participation in CBA waves. Originality/value Our paper contributes towards the acquisitive behavior of family firms and their participation in CBA waves.",
  "year": 2021,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "2733acaa18539023c76de13d23d82606",
  "timestamp": "2025-05-15T02:31:58.636312"
}