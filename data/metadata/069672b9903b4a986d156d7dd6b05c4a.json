{
  "id": 3315,
  "title": "Monetary policy uncertainty, monetary policy surprises and stock returns",
  "abstract": "We study the effects of monetary policy surprises on stock returns under low and high monetary policy uncertainty in the U.S. using the Panel Smooth Transition Regression (PSTR) model to identify the uncertainty regimes. Monetary policy surprises are unexpected changes in the Federal Funds Rate (FFR) on Federal Open Market Committee (FOMC) announcement days, where the mimicking portfolio method is used to obtain a regular time series with surprises since the an-nouncements occur on an irregular basis. Using data for the period 1994-2008, we find a negative relationship between monetary policy surprises and stock returns under both uncertainty regimes but a less pronounced relationship between surprises and returns when uncertainty is low. Hence, it is more important to hedge against unexpected stock market volatility when the uncertainty in monetary policy is high compared to when uncertainty is low.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "069672b9903b4a986d156d7dd6b05c4a",
  "timestamp": "2025-05-15T01:15:54.752336"
}