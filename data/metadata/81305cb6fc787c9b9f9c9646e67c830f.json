{
  "id": 3581,
  "title": "Performance persistence and style consistency of Indian fixed income mutual funds-A longitudinal study",
  "abstract": "In this study, we evaluate the performance of Indian fixed-income mutual funds using a comprehensive sample over a ten-year period from April 2010 to March 2020. We examine performance persistence of 190 fixed income funds across 16 fund categories and analyze investment style of the most persistent and top performing funds. We assess performance persistence using recursive portfolio formation test, and analyze investment style using Sharpe's (1992) asset class factor model supplemented with Lobosco and diBartolomeo (1997) approach for statistical robustness. We also study the correlation between performance persistence and style consistency and find persistent funds to be less consistent in style. Our findings indicate that a substantial proportion (73%) of the funds considered were under-performers. Our results pertaining to style analysis indicate substantial drift in investment style from regulator-mandated investment objectives. Further, the study nudges regulators to revisit the prevailing practice of fund classification based on Macaulay's duration. In light of the growing prominence of Indian fixed income securities, the findings of this study are all the more pertinent to investors, asset management companies and policy makers.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "81305cb6fc787c9b9f9c9646e67c830f",
  "timestamp": "2025-05-15T01:18:20.612650"
}