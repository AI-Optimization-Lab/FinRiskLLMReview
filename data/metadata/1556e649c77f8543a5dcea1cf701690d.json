{
  "id": 3305,
  "title": "Optimal spatial allocation of enzymes as an investment problem",
  "abstract": "Cells face various allocation problems demanding decisions on how to distribute their finite resources. They decide which enzymes to produce at what quantity, but also where to position them. Here we focus on the spatial allocation problem of arranging enzymes such as to maximize the total reaction flux produced by them in a system with given geometry and boundary conditions. We derive an optimal allocation principle demanding that the available enzymes are distributed such that the marginal flux returns at each occupied position are equal. This 'homogeneous marginal returns' (HMR) criterion corresponds to a portfolio optimization of investments that globally feed back onto all payoffs. The HMR criterion allows us to analytically understand and characterize a localization-delocalization transition in the optimal enzyme distribution. Our analysis reveals the generality of the transition, and produces a practical test for the optimality of enzyme clustering by comparing the reaction flux to the influx of substrate. Based on these results, we devise an additive construction scheme, which builds up optimal enzyme arrangements systematically rather than by trial and error. Taken together, we identify a common principle in allocation problems from biology and economics, which also serves as a design principle for synthetic biomolecular systems.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1556e649c77f8543a5dcea1cf701690d",
  "timestamp": "2025-05-15T01:15:54.723371"
}