{
  "id": 675,
  "title": "Stable Stock Market Prediction Using NARX Algorithm",
  "abstract": "Computational technologies have offered faster and efficient solutions to many diverse areas including the financial sector. In the financial market, the advancements in computational field have been mainly achieved through the use of neural networks and machine learning tools that delivered a number of financial applications. These applications include: stock market prediction, bankruptcy prediction, risk assessment etc. Thus, in this paper, we are developing a technique to predict the stock market index for the Dow Jones using deep learning algorithms. We propose a model based on an adaptive NARX neural network that can predict the closing price of a moderately stable market. In our model, non-linear auto regressive exogenous input model inserts delays into the input as well as the output acting as memory slots thereby raising the accuracy of the prediction. This model uses a time series analysis to improve the prediction accuracy. In addition, Levenberg-Marquardt algorithm has been used for training the network. The accuracy of the model is determined by the mean squared error between the predicted and the actual prices.",
  "year": 2018,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1d6d419c6ccc484c0dea5447f525123c",
  "timestamp": "2025-05-15T01:53:59.315857"
}