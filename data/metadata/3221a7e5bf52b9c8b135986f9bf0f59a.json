{
  "id": 94,
  "title": "Forecasting the high-frequency volatility based on the LSTM-HIT model",
  "abstract": "Volatility forecasting from high-frequency data plays a crucial role in many financial fields, such as risk management, option pricing, and portfolio management. Many existing statistical models could better describe and forecast the characteristics of volatility, whereas they do not simultaneously account for the long-term memory of volatility, the nonlinear characteristics of high-frequency data, and technical index information during the modeling phase. The purpose of this paper is to use the prediction advantage of deep learning long short-term memory (LSTM) model to predict the volatility fusing three classes of information, that is, high frequency realized volatility (H), technical indicators (I), and the parameters of generalized autoregression conditional heteroskedasticity(GARCH), heterogeneous autoregressive (HAR), and c, resulting in a novel LSTM-HIT model to forecast realized volatility. We employ the extreme value theory (EVT) of a semiparametric method to estimate the quantile of standardized return and construct the LSTM-HIT-EVT model to forecast the value at risk (VaR). Empirical results show that the LSTM-HIT model provides the most accurate volatility forecast among the various considered models and that the LSTM-HIT-EVT model yields forecasts more accurate than other VaR models.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "3221a7e5bf52b9c8b135986f9bf0f59a",
  "timestamp": "2025-05-15T01:33:49.043727"
}