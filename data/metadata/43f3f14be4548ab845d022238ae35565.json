{
  "id": 2385,
  "title": "A nature inspired Ying-Yang approach for intelligent decision support in bank solvency analysis",
  "abstract": "Since the collapse or failure of a bank could trigger an adverse financial repercussion and generate negative impacts, it is desirable to have an early warning system (EWS) that identifies potential bank failures or high-risk banks through the traits of financial distress. This research is aimed to construct a novel fuzzy neural CMAC as an alternative to analyze bank solvency, in which a nature inspiration motivated from the famous Chinese ancient Ying-Yang philosophy is introduced to find the optimal fuzzy sets, and truth value restriction (TVR) inference scheme is employed to derive the truth-values of the rule weights. The proposed model functions as an early warning system and is able to identify the inherent traits of financial distress based on financial covariates (features) derived from publicly available financial statements. Our experiments are conducted on a benchmark dataset of a population of 3635 US banks observed over a 21 years period. Three sets of experiments are performed - bank failure classification based on the last available financial record and prediction using financial records one and two years prior to the last available financial statements. The performance of the proposed Ying-Yang FCMAC network as a bank failure classification and early warning system is very encouraging. (c) 2007 Elsevier Ltd. All rights reserved.",
  "year": 2008,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "43f3f14be4548ab845d022238ae35565",
  "timestamp": "2025-05-15T02:14:50.304402"
}