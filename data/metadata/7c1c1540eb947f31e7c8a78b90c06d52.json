{
  "id": 3649,
  "title": "Fear and perceived risk of cyber fraud victimization among Chinese University students",
  "abstract": "Cyber fraud has surfaced as a serious social problem in China, resulting in billions of Chinese yuan worth of financial losses in recent years. The high prevalence and large quantity financial losses from cyber fraud have sparked widespread public concerns about online safety. Based on survey data from over 1000 university students in China, this study explores the prevalence of fear and perceived risk of cyber fraud and its correlates among university students. The results showed that although only 10% of the respondents believed they would likely experience cyber fraud victimization in the next 12 months, approximately 50% reported feeling fearful of cyber fraud in the past 3 months. The logistic regression results show that both fear and perceived risk are influenced by different domains of risk factors, with higher self-control and deviant online behaviors explaining greater odds of fear. In contrast, the perceived risk of crime is linked to vicarious victimization experiences, perceived crime seriousness, and satisfaction with the police. Implications for future research and policy are discussed.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7c1c1540eb947f31e7c8a78b90c06d52",
  "timestamp": "2025-05-15T02:28:29.401376"
}