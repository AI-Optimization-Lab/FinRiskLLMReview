{
  "id": 2378,
  "title": "FORECASTING HIGH FREQUENCY FINANCIAL DATA: STATISTICAL AND FUZZY LOGIC RBF ANN APPROACH",
  "abstract": "Forecast accuracy of economic and financial processes is a popular measure for quantifying the risk in multi-criteria decision making. In this paper, we develop forecasting models based on the statistical (stochastic) methods, sometimes called as hard computing, and on the soft methods using granular computing. To illustrate the forecasting performance of these approaches the learning aspects of RBF networks are presented and an application is included. We show a new approach of function estimation for nonlinear time series model by means of a granular fuzzy logic neural network based on Gaussian activation function with cloud concept. In a comparative study is shown that the presented approach is able to model and predict the high frequency data with reasonable accuracy and more efficient than the statistical methods.",
  "year": 2012,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7c90b66c216acebe183ece0ab1ec6eb2",
  "timestamp": "2025-05-15T02:14:50.285731"
}