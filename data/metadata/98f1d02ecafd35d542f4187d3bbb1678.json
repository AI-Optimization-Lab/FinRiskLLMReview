{
  "id": 3751,
  "title": "Path-wise estimators and cross-path regressions: An application to evaluating portfolio strategies",
  "abstract": "Recently developed dual techniques allow us to evaluate a given sub-optimal dynamic portfolio policy by using the policy to construct an upper bound on the optimal value function. Moreover, when the policy is in fact optimal, the upper bound coincides with the optimal value function. Since it is easy to construct a lower bound by simulating the given policy, we may use the distance from the lower bound to the upper bound to assess the quality of the policy. One of the difficulties that arises when computing the upper bound, however, is that we need to know the suboptimal policy's value function and its partial derivatives with respect to all state variables. If these quantities are not available analytically, then an alternative upper bound can still be computed but it is less satisfying from a theoretical perspective. In this paper we show how path-wise Monte Carlo estimators together with the cross-path regression approach can be used used to estimate the sub-optimal value function and its derivatives, thereby enabling us to compute the more theoretically satisfying upper bound on the optimal value function.",
  "year": 2007,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "98f1d02ecafd35d542f4187d3bbb1678",
  "timestamp": "2025-05-15T01:20:35.972688"
}