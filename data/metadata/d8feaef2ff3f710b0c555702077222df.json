{
  "id": 2686,
  "title": "Extracting Science Traceability Graphs from Mission Concept Documentation using Natural Language Processing",
  "abstract": "Representing end-to-end science traceability from high-level scientific goals or questions all the way to instrument and platform requirements is of key importance, especially in the early phases of mission development. In the context of program formulation and mission portfolio selection, decision makers use science traceability information to understand the overall merit of a proposal, including coverage and consistency of requirements at various levels, relevance of the mission to strategic program priorities, and overall excellence. This helps decision makers develop the 'best' set of candidate missions to meet the needs of the scientific community. However, extracting scientific traceability information from mission concept proposals is a challenging, time-consuming, and somewhat subjective process for reviewers because the information is often scattered throughout the proposal and different proposals use slightly different nomenclature. With recent advancements in computing power and machine learning, particularly in the area of natural language processing, there exists an opportunity in applying semantic-based, computer-powered approaches to support the proposal evaluation process. This paper proposes a natural language processing system, called AstroNLP, capable of automatically extracting and visualizing a mission concept proposal's science traceability information in the form of a directed graph. Specifically, the proposed approach automatically extracts science goals, objectives, requirements, and relations between them and maps those onto a defined science traceability ontology. Preliminary results are shown for four example use cases relevant to the Astrophysics Decadal Survey conducted by the National Academies of Science, Engineering, and Medicine.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d8feaef2ff3f710b0c555702077222df",
  "timestamp": "2025-05-15T01:09:14.990143"
}