{
  "id": 1179,
  "title": "An Intelligent Parallel Hybrid Algorithm for Multi-Objective Multi-Period Portfolio Selection Models with Fuzzy Random Returns",
  "abstract": "Describing future security returns as fuzzy random variables, we present a multi-objective multi-period portfolio model by considering multiple decision criteria and real-world constraints. An intelligent hybrid algorithm is then proposed to solve the presented model. In this algorithm, we devise a novel way of searching the Pareto-optimal solutions, train a Simulated Annealing Resilient Back Propagation (SARPROP) neural network for objectives approximation, and use fuzzy random simulation to generate the training dataset. The proposed algorithm is compared with the one generated by integrating NSGA-II, SARPROP neural network and fuzzy random simulation. The results demonstrate that our algorithm significantly outperforms the compared one in terms of the running time and the quality of obtained efficient frontier. To improve computational efficiency, we adopt MPI to parallelize our algorithm. The parallel algorithm is tested on different processors and its scalability is verified.",
  "year": 2019,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "709694bf675f822ec07ea59f5502f8c9",
  "timestamp": "2025-05-15T00:52:33.898334"
}