{
  "id": 3905,
  "title": "Forecasting shipping index using CEEMD-PSO-BiLSTM model",
  "abstract": "Shipping indices are extremely volatile, non-stationary, unstructured and non-linear, and more difficult to forecast than other common financial time series. Based on the idea of decomposition-reconstruction-integration, this article puts forward a combined forecasting model CEEMD-PSO-BiLSTM for shipping index, which overcomes the linearity limitation of traditional models. CEEMD is used to decompose the original sequence into several IMF components and RES sequences, and the IMF components are recombined by reconstruction. Each sub-sequence is predicted and analyzed by PSO-BiLSTM neural network, and finally the predicted value of the original sequence is obtained by summing up the predicted values of each sub-sequence. Using six major shipping indices in China's shipping market such as FDI and BDI as test data, a systematic comparison test is conducted between the CEEMD-PSO-BiLSTM model and other mainstream time-series models in terms of forecasting effects. The results show that the model outperforms other models in all indicators, indicating its universality in different shipping markets. The research results of this article can deepen and improve the understanding of shipping indices, and also have important implications for risk management and decision management in the shipping market.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "ad259fe1a2747ffc2c3cc2559dcbd05c",
  "timestamp": "2025-05-15T02:30:58.386873"
}