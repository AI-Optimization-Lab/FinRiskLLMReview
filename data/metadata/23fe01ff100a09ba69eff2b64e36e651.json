{
  "id": 1935,
  "title": "A taxonomy of literature reviews and experimental study of deepreinforcement learning in portfolio management",
  "abstract": "Portfolio management involves choosing and actively overseeing various investment assets to meet an investor's long-term financial goals, considering their risk tolerance and desired return potential. Traditional methods, like mean-variance analysis, often lack the flexibility needed to navigate the complexities of today's financial markets. Recently, Deep Reinforcement Learning (DRL) has emerged as a promising approach, enabling continuous adjustments to investment strategies based on market feedback without explicit price predictions. This paper presents a comprehensive literature review of DRL applications in portfolio management, aimed at finance researchers, data scientists, AI experts, FinTech engineers, and students seeking advanced portfolio optimization methodologies. We also conducted an experimental study to evaluate five DRL algorithms-Advantage Actor-Critic (A2C), Deep Deterministic Policy Gradient (DDPG), Proximal Policy Optimization (PPO), Soft Actor-Critic (SAC), and Twin Delayed DDPG (TD3)-in managing a portfolio of 30 Dow Jones Industrial Average (DJIA) stocks. Their performance is compared with the DJIA index and traditional strategies, demonstrating DRL's potential to improve portfolio outcomes while effectively managing risk. Das Portfoliomanagement umfasst die Auswahl und aktive & Uuml;berwachung verschiedener Anlageklassen, um dielangfristigen finanziellen Ziele eines Investors unter Ber & uuml;cksichtigung seiner Risikotoleranz und Renditeerwartungenzu erreichen. Traditionelle Methoden wie die Mittel-Varianz-Analyse bieten oft nicht die n & ouml;tige Flexibilit & auml;t, um dieKomplexit & auml;t moderner Finanzm & auml;rkte zu bew & auml;ltigen. In j & uuml;ngster Zeit hat sich Deep Reinforcement Learning (DRL) alsvielversprechender Ansatz etabliert, der kontinuierliche Anpassungen von Anlagestrategien basierend aufMarktfeedback erm & ouml;glicht, ohne explizite Preisprognosen zu ben & ouml;tigen.Diese Arbeit bietet einen umfassenden Literatur & uuml;berblick & uuml;ber DRL-Anwendungen im Portfoliomanagement undrichtet sich an Finanzforscher, Datenwissenschaftler, KI-Experten, FinTech-Ingenieure und Studierende, diefortschrittliche Methoden der Portfoliooptimierung suchen. Dar & uuml;ber hinaus wurde eine experimentelle Studiedurchgef & uuml;hrt, um f & uuml;nf DRL-Algorithmen - Advantage Actor-Critic (A2C), Deep Deterministic Policy Gradient (DDPG),Proximal Policy Optimization (PPO), Soft Actor-Critic (SAC) und Twin Delayed DDPG (TD3) - bei der Verwaltung einesPortfolios von 30 Dow Jones Industrial Average (DJIA)-Aktien zu bewerten.Die Ergebnisse zeigen, dass DRL das Potenzial hat, die Portfolioergebnisse zu verbessern und Risiken effektiv zumanagen, wobei die Leistung mit dem DJIA-Index und traditionellen Strategien verglichen wurde.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "23fe01ff100a09ba69eff2b64e36e651",
  "timestamp": "2025-05-15T02:09:14.370339"
}