{
  "id": 1798,
  "title": "Excessive Volatility is Also a Feature of Individual Level Forecasts",
  "abstract": "The excessive volatility of prices in financial markets is one of the most pressing puzzles in social science. It has led many to question economic theory, which attributes beneficial effects to markets in the allocation of risks and the aggregation of information. In exploring its causes, we investigated to what extent excessive volatility can be observed at the individual level. Economists claim that securities prices are forecasts of future outcomes. Here, we report on a simple experiment in which participants were rewarded to make the most accurate possible forecast of a canonical financial time series. We discovered excessive volatility in individual-level forecasts, paralleling the finding at the market level. Assuming that participants updated their beliefs based on reinforcement learning, we show that excess volatility emerged because of a combination of three factors. First, we found that submitted forecasts were noisy perturbations of participants' revealed beliefs. Second, beliefs were updated using a prediction error based on submitted forecast rather than revealed past beliefs. Third, in updating beliefs, participants maladaptively decreased learning speed with prediction risk. Our results reveal formerly undocumented features in individual-level forecasting that may be critical to understand the inherent instability of financial markets and inform regulatory policy.",
  "year": 2014,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "dc7672db6d833fca02f9453091e780d1",
  "timestamp": "2025-05-15T02:07:25.756614"
}