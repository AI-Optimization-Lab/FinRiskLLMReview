{
  "id": 657,
  "title": "Cardiovascular and renal risk assessment as a guide for treatment in primary hypertension",
  "abstract": "BP levels per se may be an unreliable indicator of risk in the individual patient. In fact, the global cardiovascular profile, including the presence and degree of target organ damage, is a better predictor of future events and, therefore, should be used to choose both treatment and BP goals. However, the prevalence of target organ damage and therefore the percentage of patients who are at risk very much depends on the diagnostic techniques used. However, as a result of the high prevalence of hypertension and its financial impact on public health systems, limiting unnecessary and extensive diagnostic tests also should be a priority. The routine search for microalbuminuria may lead to the detection of a significantly greater percentage of patients who are at high risk while contributing the optimization of the cost-effectiveness of diagnostic workup in hypertensive patients.",
  "year": 2004,
  "source": "WOS",
  "area": "financial_risk",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6c85a51380e5d1ea5458e8b7bf9b6a82",
  "timestamp": "2025-05-15T01:40:51.209324"
}