{
  "id": 3316,
  "title": "Optimal Portfolio Allocation between Global Stock Indexes and Safe Haven Assets: Gold versus the Swiss Franc (1999-2021)",
  "abstract": "This paper contributes to the literature on safe haven assets, analyzing gold and the Swiss Franc's defensive properties inside various global stocks portfolios. The analysis relies on monthly data extending over the last two decades. Drawing on Multivariate Garch DCC models, the hedging effectiveness of bivariate Swiss Franc-hedged portfolios is found to be notably higher than that of gold-hedged portfolios. Value-at-Risk simulations, assuming equal or optimal portfolio weights, confirm these results inside a multivariate asset framework, while a regression approach with quantile dummies provides further support in this regard. Since the better hedge and safe haven properties of the Swiss Franc are likely to persist in the future, the main policy implication of the paper concerns asset allocation strategies giving relatively more weight to the Swiss currency in global stock portfolios.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "9854c1690c6d54ea8479befff6d87fb1",
  "timestamp": "2025-05-15T01:15:54.757335"
}