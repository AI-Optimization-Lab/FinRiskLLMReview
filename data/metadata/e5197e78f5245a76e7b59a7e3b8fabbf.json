{
  "id": 95,
  "title": "Enterprise Bankruptcy Prediction Using Noisy-tolerant Support Vector Machine",
  "abstract": "Enterprise bankruptcy forecasting is very important to manage credit risk and a lot of scholars applied themselves to study how to increase the accuracy of bankruptcy forecast which requires a powerful learning machine algorithm capable of good generalization on financial data. Therefore, classification algorithms like Support Vector Machine (SVM) are popular for modeling and predicting corporate distress. However, making inferences and choosing appropriate responses based on incomplete, uncertainty and noisy data is challenging in financial settings particularly in bankruptcy prediction. In this paper, we propose a new approach for enterprise bankruptcy prediction, which uses a novel Support Vector Machine and K-nearest neighbor (KNN-SVM) to remove noisy training examples. The experimental results show that the generalization performance and the accuracy of classification are improved significantly compared to that of the traditional SVM classifier, and adapt to engineering applications.",
  "year": 2008,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "e5197e78f5245a76e7b59a7e3b8fabbf",
  "timestamp": "2025-05-17T10:37:00.347500"
}