{
  "id": 1765,
  "title": "Measuring risk in environmental finance",
  "abstract": "Environmental sustainability indices, such as the Dow Jones Sustainability Indexes and the Ethibel Sustainability Index, quantify the development and promotion of sustainable social, ethical and environmental values in the community. Moreover, such indices provide a benchmark for managing sustainability portfolios, and developing financial products and services that are linked to sustainable economic, environmental, social and ethical criteria. This paper reviews the existing data and risk indices in environmental finance. The main purpose of the paper is to analyse existing sustainability and ethical indices in environmental finance, and evaluate empirical environmental risk by estimating conditional volatility clustering that is inherent in these indices. Financial volatility models are estimated to analyse the underlying conditional volatility or time-varying risk that is inherent in alternative environmental sustainability indices. Volatility clustering is observed for most series, but some extreme observations are also evident. The log- and second-moment conditions suggest that valid inferences can be drawn for purposes of sensible empirical analysis.",
  "year": 2007,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c9b389484b2e6795fca757725e90a9a6",
  "timestamp": "2025-05-15T02:07:25.636832"
}