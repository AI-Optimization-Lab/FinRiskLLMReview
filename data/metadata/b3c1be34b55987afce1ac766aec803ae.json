{
  "id": 7586,
  "title": "Does Medicare Reduce Medical Debt?",
  "abstract": "We study the effect of Medicare on financial strain, measured by annual changes in medical debt in collections, using credit bureau data. We exploit the program's eligibility age at 65 and compare the experiences of those just under and over age 65 using a regression discontinuity design. We find that during our baseline study period Medicare reduced the annual probability of large medical collections, above $1,000, by 0.31 percentage points, a 19 percent reduction relative to the probability for those aged 60-64, and reduced new medical collections by approximately $380 at the 99th percentile, a 23 percent decrease. We hypothesize that Medicare mainly decreases medical collections among those who transition from uninsured to Medicare. Under that hypothesis we estimate a treatment on the treated average reduction of about $250 in new medical collections. We find support for our hypothesis by comparing discontinuities for those in zip codes with different uninsured rates pre-age 65, and comparing discontinuities before and after implementation of the main health insurance provisions of the Affordable Care Act. Our findings complement recent work on the role of Medicare in reducing risk of out-of-pocket medical expenditures and of health insurance in reducing medical collections.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b3c1be34b55987afce1ac766aec803ae",
  "timestamp": "2025-05-15T03:10:05.556557"
}