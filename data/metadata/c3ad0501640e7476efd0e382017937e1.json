{
  "id": 166,
  "title": "Enhancing stock market predictions via hybrid external trend and internal components analysis and long short term memory model",
  "abstract": "When it comes to financial decision-making, stock market predictability is extremely important since it offers valuable information that may guide investment strategies, risk management, and portfolio allocation overall. Traditional methods often fail to accurately predict stock prices due to their complexity and inability to handle non-linear and non-stationary patterns in market data. To address these issues, this study introduces an innovative model that combines the External Trend and Internal Components Analysis decomposition method (ETICA) with the Long Short-Term Memory (LSTM) model, aiming to enhance stock market predictions for S&P 500, NASDAQ, Dow Jones, SSE and SZSE indices. Through rigorous testing across various training data proportions and epoch settings, our findings reveal that the proposed hybrid model outperforms the single LSTM model, delivering significantly lower Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) values. This enhanced precision reduces prediction errors, underscoring the model's robustness and reliability. The superior performance of the ETICA-LSTM model highlights its potential as a powerful financial forecasting tool, promising to transform investment strategies, optimize risk management, and enhance portfolio performance.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c3ad0501640e7476efd0e382017937e1",
  "timestamp": "2025-05-15T01:35:04.350968"
}