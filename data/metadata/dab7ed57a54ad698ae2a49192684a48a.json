{
  "id": 3123,
  "title": "Evaluating the Default Risk of Bond Portfolios with Extreme Value Theory",
  "abstract": "Credit risk management is important for the investors in practical risk management. This paper aims to discuss how to evaluate the default risk of bond portfolios by applying extreme value theory. Based on Black and Cox default approach, we propose a novel threshold default model and use extreme value theory to derive the distribution functions of the state variables. To some extent, our model can be regarded as the counterpart of CreditMetrics, which is based on Merton approach. According to multivariate extreme value theory, extreme value copula is applicable to build the dependence between the state variables; on the other hand, it is more probable that default clustering occurs in the same region or sector in reality. Taking these into account, we adopt hierarchical Gumbel copulas, which are tail-dependent extreme value copulas and can group the bonds by regions or sectors, to link the state variables. An empirical bond portfolio is used to illustrate the model. The results show that, compared with CreditMetrics and the simple Gumbel copula model, the extremal tail of the distribution of loss from default in the proposed model is heavier. Consequently, the proposed model seems relatively conservative in terms of stress testing.",
  "year": 2015,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "dab7ed57a54ad698ae2a49192684a48a",
  "timestamp": "2025-05-15T01:13:45.253650"
}