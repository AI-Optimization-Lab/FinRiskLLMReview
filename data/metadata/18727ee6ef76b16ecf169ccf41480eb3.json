{
  "id": 6506,
  "title": "Determinants of idiosyncratic volatility: Evidence from the Indian stock market",
  "abstract": "This paper investigates whether firm-specific characteristics explain idiosyncratic volatility in the stocks of non-financial firms traded in the Indian stock market. It employs the linear time series five-factor model, augmented with a liquidity factor and the conditional EGARCH model, to extract yearly idiosyncratic volatility. We estimate a panel data regression to quantify the relationship between firm-specific characteristics and the volatility of individual securities. The results show that idiosyncratic volatility is significant in emerging markets such as India, and that cross-sectional return variations of firms are associated with firm-specific characteristics such as firm size, book-to-market ratio, momentum, liquidity, cash flow-to-price ratio, and returns on assets. We find that the idiosyncratic risk documented in this study is associated with smaller size of company, higher liquidity, low momentum, high book-to-market ratio, and low cash flow-to-price ratio. The findings suggest need to develop alternative tools to make investment decisions in emerging markets.",
  "year": 2017,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "18727ee6ef76b16ecf169ccf41480eb3",
  "timestamp": "2025-05-15T02:58:34.302227"
}