{
  "id": 1075,
  "title": "中国加息对国际热钱流入规模的实证分析",
  "abstract": "热钱的流入加剧了资本市场的不稳定性和投机性,经济表现虚假繁荣,迫使中国央行被动增加货币投放,不仅抵消了货币政策的效应,还增大了国内通货膨胀的压力。而国际热钱的流出则会给中国经济与社会带来更大的危害,当逐利的条件消失,热钱会连本带利回到境外,极容易诱发金融市场的动荡,加大中国金融风险。本研究改进和修正了热钱流入规模回归模型,构建了自适应预期模型,利用1995～2009年的年度数据对热钱规模进行最小二乘估计,认为资本市场对热钱规模的影响起决定性作用。并在实证分析的基础上,中国应该加强资本市场的监管,防止股票市场泡沫化;放开资本项目步伐应谨慎,资本管制是应对国际热钱投机的屏障;对资本利得征收所得税与托宾税,形成抑制国际热钱进入的有效手段。",
  "year": 2011,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "04e4aef41dfe28ad4c1cd969f7d9fa20",
  "timestamp": "2025-05-14T22:35:44.439948"
}