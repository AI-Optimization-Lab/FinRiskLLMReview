{
  "id": 271,
  "title": "“双循环”新发展格局下的金融市场稳定性研究——基于大宗商品金融化视角",
  "abstract": "近年来“大宗商品金融化”现象受到学界广泛关注，在“双循环”新发展格局下的金融市场稳定性面临诸多挑战，探究商品金融化视角下的金融市场风险防范对维持经济稳定运行具有重要意义。文章首先系统梳理“双循环”新发展格局下大宗商品金融化对中国金融市场稳定性的影响机理，同时基于改进的商品期货定价模型，从金融化视角详细剖析金融市场稳定性受商品价格、供给和需求冲击的边际效应，比较其在长短期和市场波动环境方面的异质性特征。其次，利用2000—2020年一季度美国金融市场和2010—2019四季度中国金融市场样本，分别构建金融化指标和金融市场稳定性指标，通过结构向量自回归模型实证考察金融市场稳定性、商品价格以及金融化程度之间的结构化关系。最后考虑市场波动差异，特别是金融危机或新冠疫情这类不确定性“黑天鹅”事件的冲击，实证检验商品金融化程度对金融市场稳定性的影响在不同市场环境下的门限效应。研究结果表明：在短期内，中美两国商品指数市场中，金融化对大宗商品价格的短期冲击影响程度最大，各个市场受冲击后的1至2年内价格水平均能恢复均衡状态；金融市场稳定性受大宗商品金融化影响显著，特别是在商品指数市场；相较于大宗商品供给、需求和价格，金融市场稳定性在短期内由大宗商品金融化程度主导；商品金融化程度在短期内对金融市场稳定性的负面影响较长期更显著，影响程度也更深；从长期看，金融市场稳定性由大宗商品价格主导，而大宗商品金融化的影响则较弱；进一步通过门限模型证实，相对于金融市场低波动环境，在高波动环境中大宗商品金融化程度对金融市场稳定性的短期影响力更强。据此，对尚处发展阶段的中国大宗商品期货市场，文章提出以下政策建议：第一，优化大宗商品期货市场持仓报告制度体系，强化对金融交易者持仓识别与金融化程度监测；第二，分市场环境监管机构投资者持仓，避免“一刀切”持仓限制，因人施策差异化管理市场金融投机行为；第三，建立金融市场联动应急响应机制，提高金融市场风险识别效率，防范金融风险跨市场蔓延，合理应对大宗商品金融化现象，维护金融市场长期稳定。",
  "year": 2022,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a3c244b8a4ced6cd9f6813e023ffe6e2",
  "timestamp": "2025-05-14T22:28:44.128404"
}