{
  "id": 3561,
  "title": "The Consumption-Structure-Analysis - A simple and quick method for the evaluation of energy consumption in existing non-residential buildings.",
  "abstract": "Only little is known about both the energy demand and the energy consumption of existing nonresidential buildings. Further, the collection of those building-specific energy data is laborious, which makes the full coverage of whole building stocks difficult. So far there are no benchmarks available which are suitable for the classification of the energy status of a non-residential building, compared to others of a portfolio and for the determination of building-individual saving potentials. The method presented here targets precisely these issues. The Consumption-Structure-Analysis of an existing non-residential building enables a quick estimation of its energy use. For this purpose, classified characteristic energy values regarding the existing purposes will be specified separately for different usage profiles. Generally, a building analysis within half a day is achievable by applying this method. Within the research project a test application of the developed Consumption-Structure-Analysis-tool at ten office and administrative buildings showed good accordance between measured energy consumption data and demand calculation. The method determines object-specific benchmarks for the current state as well as for two different refurbishment standards of a building.",
  "year": 2016,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6c932643785789677f81c5bba743cc1c",
  "timestamp": "2025-05-15T01:18:20.550291"
}