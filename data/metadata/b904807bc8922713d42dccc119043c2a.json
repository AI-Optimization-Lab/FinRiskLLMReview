{
  "id": 427,
  "title": "A Cost-sensitive Active Learning for Imbalance Data with Uncertainty and Diversity Combination",
  "abstract": "The class distributions of real-world classification datasets are usually imbalanced because many applications, such as network intrusion detection, tumor classification, financial risk identification, etc., exhibit imbalance natures that positive examples are rare. When labeling such data to create training sets for supervised learning, too many examples belonging to the majority class will be labeled, which dramatically increase the labeling cost and usually is unnecessary, because balanced datasets are more suitable for inducing good learners. To deal with this problem, this paper proposes a novel cost-sensitive active learning algorithm that combines the uncertainty and diversity measures to select training examples for an unlabeled sample pool. We use the proportions of the majority and the minority against the whole examples in the training dataset as the weights of the majority class and the minority class, respectively. With the class weights, the minor examples can obtain more emphasis when building learning models. Experimental results show that our proposed method can significantly reduce the label cost while improving the performance of learning models.",
  "year": 2018,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b904807bc8922713d42dccc119043c2a",
  "timestamp": "2025-05-15T01:50:52.619804"
}