{
  "id": 958,
  "title": "Improving Portfolio Optimization Using Weighted Link Prediction in Dynamic Stock Networks",
  "abstract": "Portfolio optimization in stock markets has been investigated by many researchers. It looks for a subset of assets able to maintain a good trade-off control between risk and return. Several algorithms have been proposed to portfolio management. These algorithms use known return and correlation data to build subset of recommended assets. Dynamic stock correlation networks, whose vertices represent stocks and edges represent the correlation between them, can also be used as input by these algorithms. This study proposes the definition of constants of the classical mean-variance analysis using machine learning and weighted link prediction in stock networks (method named as MLink). To assess the performance of MLink, experiments were performed using real data from the Brazilian Stock Exchange. In these experiments, MLink was compared with mean-variance analysis (MVA), a popular method to portfolio optimization. According to the experimental results, using weighted link prediction in stock networks as input considerably increases the performance in portfolio optimization task, resulting in a gross capital increase of 41% in 84 days.",
  "year": 2019,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "31c4704acba91fd722fa816550f81c2b",
  "timestamp": "2025-05-15T00:50:08.718920"
}