{
  "id": 679,
  "title": "Practicable optimization for portfolios that contain nonfungible tokens",
  "abstract": "Non-fungible tokens (NFT) constitute a novel asset class that has the potential to diversify portfolios. Scant research supports that hypothesis at a collection level, yet it remains an open question how to leverage the potential in practice. Owing to their non-fungible nature, liquidity of the asset that leads to a mathematically optimal portfolio does not always exist. This letter introduces a practicable portfolio optimization strategy for NFTs based on machine learning, more specifically robust hierarchical risk parity. When applied to portfolios that contain high valued NFT collections, the latter's inclusion into the portfolio is shown to improve overall portfolio return.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "11542c7f5d844e7f11c5580bb9cfe350",
  "timestamp": "2025-05-15T00:46:24.518296"
}