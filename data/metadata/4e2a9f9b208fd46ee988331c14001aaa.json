{
  "id": 95,
  "title": "我国融资融券机制的研究态势——基于近30年CNKI数据库的文献计量分析",
  "abstract": "本文通过对CNKI数据库收录的1989-2019年间的相关文献进行了发文量、主要期刊来源等方面的统计分析,同时利用Bibexcel、Ucinet6.0等计量软件对关键词进行了共现频次分析、社会网络分析、聚类分析。结果表明:自2010年我国实行融资融券机制以来,有关融资融券关联话题的发文量总体呈现上升趋势,相关研究主要集中在股票市场上,也涉及到金融衍生品市场领域,研究问题聚焦股市风险控制、波动性、定价效率等方面;通过聚类分析发现,在研究方法上多采用GARCH模型、VAR模型、DID模型;对近5年的文献做进一步细化分析后发现,将融资融券与行为金融学和公司金融学的相关理论结合的研究逐渐增多,从投资者与标的上市公司的视角进一步丰富了融资融券机制实施效果研究的内容。",
  "year": 2019,
  "source": "CNKI",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "4e2a9f9b208fd46ee988331c14001aaa",
  "timestamp": "2025-05-14T22:13:53.070119"
}