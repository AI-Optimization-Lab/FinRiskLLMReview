{
  "id": 2203,
  "title": "Improving realised volatility forecast for emerging markets",
  "abstract": "Accurate forecasting of realised volatility is essential for financial risk management and investment decision-making in emerging markets, taking the South African financial market as a benchmark. This study examines the predictive performance of four prominent models: HAR (Heterogeneous AutoRegressive), realised GARCH (Generalized AutoRegressive Conditional Heteroscedasticity), Recurrent Conditional Heteroskedasticity (RECH), and the Rough Fractional Stochastic Volatility (RFSV) models. These models are specifically tailored to capture the complex dynamics and long-range dependence observed in financial time series. We illustrate the challenges and limitations of these models outside the context of established markets. Our empirical findings reveal unique strengths for each model. The HAR model excels in capturing long-term volatility patterns, while realised GARCH models effectively capture volatility clustering and persistence. RECH model showcases their ability to forecast Value-at-Risk, while the RFSV model successfully captures irregular and long-memory characteristics. We provide empirical evidence that the South African financial market is rough. Moreover, this study provides valuable insights into forecasting realised volatility in the South African market, and the findings can assist practitioners and investors in making informed decisions and developing robust risk management strategies.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a1f0acd6e161bfb8defb558c59946208",
  "timestamp": "2025-05-15T02:12:17.462460"
}