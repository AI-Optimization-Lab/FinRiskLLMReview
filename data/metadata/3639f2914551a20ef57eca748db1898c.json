{
  "id": 8172,
  "title": "Interpretable artificial intelligence to optimise use of imatinib after resection in patients with localised gastrointestinal stromal tumours: an observational cohort study",
  "abstract": "Background Current guidelines recommend use of adjuvant imatinib therapy for many patients with gastrointestinal stromal tumours (GISTs); however, its optimal treatment duration is unknown and some patient groups benefit from the therapy. We aimed to apply state-of-the-art, interpretable artificial intelligence (ie, predictions prescription logic that can be easily understood) methods on real-world data to establish which groups of with GISTs should receive adjuvant imatinib, its optimal treatment duration, and the benefits conferred this therapy. Methods In this observational cohort study, we considered for inclusion all patients who underwent resection primary, non-metastatic GISTs at the Memorial Sloan Kettering Cancer Center (MSKCC; New York, NY, USA) Oct 1, 1982, and Dec 31, 2017, and who were classified as intermediate or high risk according to the Armed Institute of Pathology Miettinen criteria and had complete follow-up data with no missing entries. A counterfactual random forest model, which used predictors of recurrence (mitotic count, tumour size, and tumour site) and duration to infer the probability of recurrence at 7 years for a given patient under each duration of imatinib treatment, was trained in the MSKCC cohort. Optimal policy trees (OPTs), a state-of-the-art interpretable AI-based method, used to read the counterfactual random forest model by training a decision tree with the counterfactual predictions. The OPT recommendations were externally validated in two cohorts of patients from Poland (the Polish Clinical Registry), who underwent GIST resection between Dec 1, 1981, and Dec 31, 2011, and from Spain (the Spanish for Research in Sarcomas), who underwent resection between Oct 1, 1987, and Jan 30, 2011. Findings Among 1007 patients who underwent GIST surgery in MSKCC, 117 were included in the internal cohort; the external cohorts, the Polish cohort comprised 363 patients and the Spanish cohort comprised 239 patients. OPT did not recommend imatinib for patients with GISTs of gastric origin measuring less than 159 cm mitotic count of less than 115 mitoses per 5 mm2 2 or for those with small GISTs (<54 cm) of any site with a less than 115 mitoses per 5 mm2. 2 . In this cohort, the OPT cutoffs had a sensitivity of 927% (95% CI 824-980) a specificity of 339% (223-470). The application of these cutoffs in the two external cohorts would have 38 (29%) of 131 patients in the Spanish cohort and 44 (35%) of 126 patients in the Polish cohort from unnecessary treatment with imatinib. Meanwhile, the risk of undertreating patients in these cohorts was minimal (sensitivity 954% [95% CI 895-985] in the Spanish cohort and 924% [883-954] in the Polish cohort). The OPT 33 different durations of imatinib treatment (<5 years) and found that 5 years of treatment conferred the most benefit. Interpretation If the identified patient subgroups were applied in clinical practice, as many as a third of the cohort of candidates who do not benefit from adjuvant imatinib would be encouraged to not receive subsequently avoiding unnecessary toxicity on patients and financial strain on health-care systems. Our finding 5 years is the optimal duration of imatinib treatment could be the best source of evidence to inform clinical until 2028, when a randomised controlled trial with the same aims is expected to report its findings.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "3639f2914551a20ef57eca748db1898c",
  "timestamp": "2025-05-15T03:16:17.359886"
}