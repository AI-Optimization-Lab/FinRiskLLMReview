{
  "id": 5467,
  "title": "The transformation and survival of fortune 500 industrial corporations through mergers and acquisitions, 1981-1995",
  "abstract": "The 1980s leveraged buyouts followed by the 1990s stock swap mergers represent the most dynamic period in U.S. business history. Using Cox regression with time-varying covariates, we examine the relationships among changes in corporate mergers and acquisitions, changes in corporate diversification strategies, and the transition from the multidivisional form (MDF) to the multisubsidiary form (MSF) of the largest Fortune 500 U.S. parent corporations. Consistent with the political economy contingency theory of accumulation (PECTA), our findings show that acquisition risk is reduced as a function of size, product and industry diversification, and percentages of shares held by institutional investors. Acquisition risk: is increased by holding units in a multidivisional rather than a multisubsidiary form, higher returns to shareholders, higher divestitures, higher production to administrative intensity, and surviving previous takeover attempts. The political-legal institutions of the state have increasingly engaged in activities that are supportive and profitable for industrial and financial corporations. The actions of the state are increasingly aligned with the interests of capital.",
  "year": 2001,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "3012563e197c39d16b6600effcecfcfd",
  "timestamp": "2025-05-15T02:48:23.560778"
}