{
  "id": 4635,
  "title": "Structural equation model of construction contract dispute potential",
  "abstract": "This paper presents the results of a structural equation model (SEM) for describing and quantifying the fundamental factors that affect contract disputes between owners and contractors in the construction industry. Through this example, the potential impact of SEM analysis in construction engineering and management research is illustrated. The purpose of the specific model developed in this research is to explain how and why contract related construction problems occur. This study builds upon earlier work, which developed a disputes potential index, and the likelihood of construction disputes was modeled using logistic regression. In this earlier study, questionnaires were completed on 159 construction projects, which measured both qualitative and quantitative aspects of contract disputes, management ability, financial planning, risk allocation, and project scope definition for both owners and contractors. The SEM approach offers several advantages over the previously employed logistic regression methodology. The final set of structural equations provides insight into the interaction of the variables that was not apparent in the original logistic regression modeling methodology.",
  "year": 2000,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7b4d501534fc33fc936322eaa00ac20f",
  "timestamp": "2025-05-15T02:39:26.981310"
}