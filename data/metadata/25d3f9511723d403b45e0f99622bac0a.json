{
  "id": 4965,
  "title": "Patient Length of Stay Under the Two-Midnight Rule: Assessing the Accuracy of Providers' Predictions",
  "abstract": "EXECUTIVE SUMMARY We sought to determine emergency medicine physicians' accuracy in designating patients' disposition status as inpatient or observation at the time of hospital admission in the context of Medicare's Two-Midnight rule and to identify characteristics that may improve the providers' predictions. We conducted a 90-day observational study of emergency department (ED) admissions involving adults aged 65 years and older and assessed the accuracy of physicians' disposition decisions. Logistic regression models were fit to explore associations and predictors of disposition. A total of 2,257 patients 65 and older were admitted through the ED. The overall error rate in physician designation of observation or inpatient was 36%. Diagnoses most strongly associated with stays lasting less than two midnights included diverticulitis, syncope, and nonspecific chest pain. Diagnoses most strongly associated with stays lasting two or more midnights included orthopedic fractures, biliary tract disease, and back pain. ED physicians inaccurately predicted patient length of stay in more than one third of all patients. Under the Two-Midnight rule, these inaccurate predictions place hospitals at risk of underpayment and patients at risk of significant financial liability. Further work is needed to increase providers' awareness of the financial repercussions of their admission designations and to identify interventions that can improve prediction accuracy.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "25d3f9511723d403b45e0f99622bac0a",
  "timestamp": "2025-05-15T02:43:06.673908"
}