{
  "id": 2032,
  "title": "Fine-Grained Financial News Sentiment Analysis",
  "abstract": "The 24-hour news cycle and barrage of online media is a constant drum beat. The flow of positive and negative news is always in flux, influencing our current perspective and reassessing our future outlook. Nowhere is this more true than in the capital markets where assets are priced and risk assessed based on future expectations. While many factors influence a trader's decision to buy or sell an asset it can be argued that the sentiment from the 24-hour news cycle greatly impacts their outlook on the future value of an asset. In this paper we propose new methods to predict the positive or negative sentiment of financial news. Our analysis has found that contemporary document level sentiment analysis methods break down at fine-grained levels. Fine-grained analysis methods are vitally important as the velocity and impact of small texts, such as tweets and news flashes, increase their influence over the decision process. Using Natural Language Processing methods we extract syntactic sentence patterns from financial news headlines. From these patterns we conduct experiments using both lexicon and machine learning sentiment analysis approaches to predict sentiment. We find that our sentiment prediction methods are able to consistently out perform lexicon methods. Our robust techniques give the financial practitioner a method to fold a fine-grained news sentiment factor into their pricing or risk prediction models.",
  "year": 2017,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "eb054851a9d5d6e6cf470cf6cbb26c9a",
  "timestamp": "2025-05-15T02:10:25.741636"
}