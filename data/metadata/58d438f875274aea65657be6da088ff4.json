{
  "id": 1661,
  "title": "Leveraging Cloud Computing to Convert the Non-Intrusive Load Monitor into a Powerful Framework for Grid-Responsive Buildings",
  "abstract": "This paper describes how the non-intrusive load monitoring technique can be applied to develop a powerful framework for grid-responsive buildings, particularly in the small commercial and residential sector. Specifically, recent advances have made it cost-effective to monitor a number of electrical circuits in a building using low-cost embedded platforms that can send their data to cloud-computing and data-storage services. This approach significantly reduces the effort required to deploy and commission monitoring solutions, specifically because the cloud allows one to create a large library of load patterns and it provides a powerful platform for computation. This approach thus solves one of the major challenges in power monitoring and energy management, which has been the development of robust unsupervised learning algorithms that eliminate the need for costly human involvement. The cloud also provides an opportunity to learn fault patterns and to predict the performance of individual building systems. This paper describes the unsupervised training that can be performed in the cloud using intuition about the underlying physics of major load devices. It also describes how load on-off patterns can be used for fault detection as well as load prediction and control and the deployment of powerful algorithms for a large data set obtained across a large portfolio is discussed.",
  "year": 2016,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "58d438f875274aea65657be6da088ff4",
  "timestamp": "2025-05-15T00:58:18.326661"
}