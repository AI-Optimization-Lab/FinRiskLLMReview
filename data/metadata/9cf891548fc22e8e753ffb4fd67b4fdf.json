{
  "id": 1855,
  "title": "Learning to Rank Firms with Annual Reports",
  "abstract": "The textual content of company annual reports has proven to contain predictive indicators for the company future performance. This paper addresses the general research question of evaluating the effectiveness of applying machine learning and text mining techniques to building predictive models with annual reports. More specifically, we focus on these two questions: 1) can the advantages of the ranking algorithm help achieve better predictive performance with annual reports? and 2) can we integrate meta semantic features to help support our prediction? We compare models built with different ranking algorithms and document models. We evaluate our models with a simulated investment portfolio. Our results show significantly positive average returns over 5 years with a power law trend as we increase the ranking threshold. Adding meta features to document model has shown to improve ranking performance. The SVR & Meta-augemented model outperforms the others and provides potential for explaining the textual factors behind the prediction.",
  "year": 2009,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "9cf891548fc22e8e753ffb4fd67b4fdf",
  "timestamp": "2025-05-15T01:00:27.329122"
}