{
  "id": 1827,
  "title": "FCMAC-EWS: A bank failure early warning system based on a novel localized pattern learning and semantically associative fuzzy neural network",
  "abstract": "In the banking industry, it is highly desirable to identify potential bank failure or high-risk banks. Successful early warning systems (EWS) would provide capabilities to avoid adverse financial repercussions and a massive bail out costs for the failing banks. Very often, these failures are due to financial distress. Various traditional statistical models have been used to study failures of financial institutions (Sinkey, J., Jr. (1975). A multivariate statistical analysis of the characteristics of problem banks. Journal of Finance, 1, 21-36; Martin, D. (1977). Early warning of bank failure: A logit regression approach. Journal of Banking and Finance, 1(3), 249-276; Lane, W., Looney, S., & Wansley, J. (1986). An application of the Cox proportional hazards model to bank failure. Journal of Banking and Finance, 10, 51153 1; Cole, R., & Gunther, J. (1995). Separating the likelihood and timing of bank failure. Journal of Banking and Finance, 19, 1073-1089.). However, these models do not have the capability to identify the characteristics of financial distress and thus function as black boxes. This paper proposes a novel fuzzy CMAC (cerebellar model articulation controller) model based on compositional rule of inference, named FCMAC-CRI(S), as a new approach to tackle the problem using localized learning. The CRI-based FCMAC network, based on localized training, is able to identify the inherent traits and patterns of financial distress based on financial covariates derived from publicly available financial statements. The use of localized learning is akin to the neocortex semantic associative memory which is superior to the hippocampal form of global learning. The reason is that the hippocampal memory system rapidly learns arbitrary patterns of activity, whereas the neocortical system learns slowly. The slow learning of the neocortex is a requirement for any system that is able to eventually extract and model the similarity structure in its environment. The rapid learning of the hippocampal system, in contrast, sacrifices the ability to generalize. When both systems are intact, the hippocampal memory system trains the neocortical learning system through a process of repeated patterns, allowing for the gradual extraction of the similarity structure that is central to generalization. In FCMAC-CRI(S), its interactive relations among the selected pattern features are captured in the form of highly intuitive fuzzy IF-THEN rules, which form the knowledge base of the early warning system and provide insights into the characteristics of financial distress. The performance of the FCMAC-CRI(S) is benchmarked against that of the Cox's proportional hazard model and GenSoFNN-CRI(S) network, a functional hippocampal fuzzy semantic learning memory structure, in predicting bank failures based on a population of 3635 US banks observed over 21 years. The localized models and learning yield superior results and interpretation to fuzzy neural network such as GenSoFNN-CRI(S) that are based on global learning. The performance of the new approach as a bank failure classification and early warning system is highly encouraging. (c) 2006 Elsevier Ltd. All rights reserved.",
  "year": 2008,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "45312c5534281d09d29fb56237dfb3cd",
  "timestamp": "2025-05-15T02:08:03.915911"
}