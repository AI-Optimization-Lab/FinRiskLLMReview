{
  "id": 7190,
  "title": "Does Market Performance (Tobin's Q) Have A Negative Effect On Credit Ratings? Evidence From South Korea",
  "abstract": "Tobin's Q is an established measure of firm performance, based on investor confidence. However, the association between Tobin's Q and credit ratings is not well-established in the literature. Using a sample of Korean listed firms over the 2001-2016 sample period, Probit regression analysis shows that overall, Tobin's Q is positively associated with credit ratings. However, for firms with a > 1 (1 <) Tobin's Q ratio, a negative (positive) relationship exists. Moreover, in independent regressions, a threshold level if found where the effect of Tobin's Q on credit ratings changes from being positive (0.2), to negative (0.3). To the best of our knowledge, we are the first to demonstrate that credit rating agencies are nuanced when making default risk assessments. Specifically, that in South Korea, a threshold level exists, at which increasing Tobin's Q values reduce credit ratings. Empirical evidence of the different association between Tobin's Q (market confidence) and credit ratings can extend the literature and offer insights to market participants. Furthermore, because Tobin's Q is a commonly used proxy for financial performance in accounting lectures, the study has practical implications for academics in classrooms.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "920affb40d77b14ef10266f2409496e2",
  "timestamp": "2025-05-15T03:06:01.244789"
}