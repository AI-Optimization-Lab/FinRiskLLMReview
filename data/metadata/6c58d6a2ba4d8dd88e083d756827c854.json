{
  "id": 3574,
  "title": "Robust min-max portfolio strategies for rival forecast and risk scenarios",
  "abstract": "We consider an extension of the Markowitz mean-variance optimization framework to multiple return and risk scenarios, It is well known that asset return forecasts and risk estimates ale inherently inaccurate. The method proposed provides a means for considering rival representations of the future. The optimal portfolio is computed, simultaneously with the worst case, to take account of all rival scenarios. This is a min-max strategy which is essentially equivalent to a robust pooling of the scenarios. Robustness is ensured by the noninferiority of min-max. For example, a basic worst-case optimal return is guaranteed in view of multiple return scenarios. If robustness happens to have too high a cost, guided by the min-max pooling, it is also possible to explore other pooling alternatives. A min-max algorithm is used to solve the problem and illustrate the robust character of min-max with return and risk scenarios. We study the properties of the min-max risk-return frontier and compare with the potentially suboptimal worst-case where the investment strategy and the worst case are computed separately. (C) 2000 Elsevier Science B.V. All rights reserved. JEL classification: C44: C61; C63; G11.",
  "year": 2000,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6c58d6a2ba4d8dd88e083d756827c854",
  "timestamp": "2025-05-15T01:18:20.599612"
}