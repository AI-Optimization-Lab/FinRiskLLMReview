{
  "id": 2642,
  "title": "Support vector machines based on convex risk functions and general norms",
  "abstract": "This paper studies unified formulations of support vector machines (SVMs) for binary classification on the basis of convex analysis, especially, convex risk functions theory, which is recently developed in the context of financial optimization. Using the notions of convex empirical risk and convex regularizer, a pair of primal and dual formulations of the SVMs are described in a general manner. With the generalized formulations, we discuss reasonable choices for the empirical risk and the regularizer on the basis of the risk function's properties, which are well-known in the financial context. In particular, we use the properties of the risk function's dual representations to derive multiple interpretations. We provide two perspectives on robust optimization modeling, enhancing the known facts: (1) the primal formulation can be viewed as a robust empirical risk minimization; (2) the dual formulation is compatible with the distributionally robust modeling.",
  "year": 2017,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "ef74d63911716e2fc61137b42b18c51a",
  "timestamp": "2025-05-15T02:17:32.227778"
}