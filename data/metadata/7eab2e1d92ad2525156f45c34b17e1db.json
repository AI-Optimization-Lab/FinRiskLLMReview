{
  "id": 3487,
  "title": "Fatigue residual life estimation of jib structure based on improved v-SVR algorithm obtaining equivalent load spectrum",
  "abstract": "Fatigue tests of truck crane jib structure have great difficulty, long testing cycle, and high cost. Therefore, with the portfolio strategy for collection, prediction, measurement and simulation being introduced, an improved support vector regression (v-SVR) algorithm is proposed to predict the equivalent load spectrum based on the small measured load spectrum and the fatigue residual life evaluation model is built. First, the v-SVR algorithm corrected in kernel function, decision function, and parameter optimization is utilized to acquire the equivalent load spectrum. Second, the distribution of critical points is determined by the case-based reasoning technique. The simulation model of first main stress-time histories for critical points is established, and the two-dimensional stress spectrum is obtained by the rain-flow counting method. Finally, the fatigue residual life of jib structure is estimated by the Forman formula. Taking ZLJ5551JQZ110V truck crane jib structure as an example, the effectiveness of the above method is validated.",
  "year": 2020,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7eab2e1d92ad2525156f45c34b17e1db",
  "timestamp": "2025-05-15T01:17:25.596781"
}