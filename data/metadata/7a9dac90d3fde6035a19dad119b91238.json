{
  "id": 3640,
  "title": "EFFICIENT INTENSITY MEASURES FOR PROBABILISTIC SEISMIC RESPONSE ANALYSIS OF ANCHORED ABOVE-GROUND LIQUID STEEL STORAGE TANKS",
  "abstract": "Liquid storage tanks are vital lifeline structures and have been widely used in industries and nuclear power plants. In performance-based earthquake engineering, the assessment of probabilistic seismic risk of structural components at a site is significantly affected by the choice of ground motion intensity measures (IMs). However, at present there is no specific widely accepted procedure to evaluate the efficiency of IMs used in assessing the seismic performance of steel storage tanks. The study presented herein concerns the probabilistic seismic analysis of anchored above-ground steel storage tanks subjected to several sets of ground motion records. The engineering demand parameters for the analysis are the compressive meridional stress in the tank wall and the sloshing wave height of the liquid free surface. The efficiency and sufficiency of each alternative IM are quantified by results of time history analyses for the structural response and a proper regression analysis. According to the comparative study results, this paper proposes the most efficient and sufficient IMs with respect to the above demand parameters for a portfolio of anchored steel storage tanks.",
  "year": 2017,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7a9dac90d3fde6035a19dad119b91238",
  "timestamp": "2025-05-15T01:19:26.073665"
}