{
  "id": 2741,
  "title": "Public attitudes towards electricity decarbonization and meeting 2035 goals",
  "abstract": "Varying levels of public acceptance of different low-carbon energy technologies can pose a barrier to progress on decarbonizing the electricity grid in the U.S. This study developed a survey system that allowed respondents to design their ideal 100 % low-carbon mix for 2035 by allocating generation across seven low-carbon technologies. Using data from 532 respondents, the authors analyzed overall public preferences and how demographics affect technology preferences. Contrary to what is often assumed, the authors found that approximately 75 % of respondents' ideal portfolios are diverse (5+ technologies), and many included novel technologies, with approximately 90 % including CCS or offshore wind. Regression analysis found that demographic factors affect the amount of a technology that a respondent chose to deploy in their portfolio. Demonstrating the public's willingness to accept a diverse electricity portfolio that includes novel technologies opens the door for energy analysts and energy developers to investigate diverse and creative solutions to achieve electricity decarbonization. Additionally, demographic factors that affect technology preferences create a new layer of consideration for project siting to increase the likelihood of acceptance. Engaging with the public and considering public preferences will be integral to achieving the U.S.'s decarbonization goals.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c555fe08a1deba27401afb8e46f9e9a2",
  "timestamp": "2025-05-15T01:10:16.413179"
}