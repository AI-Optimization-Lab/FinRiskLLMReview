{
  "id": 1152,
  "title": "A Default Prediction Method using XGBoost and LightGBM",
  "abstract": "With the rapid development of the global economy, loans have been used to promote consumption, promote currency circulation, and help individuals deal with economic problems. However, the formation of people's concept of ahead of time consumption and the high-yield business of commercial banks are accompanied by an increase in the number of financial risk events. The personal credit risk prediction problem can be regarded as a binary classification problem, and it is a common method to solve the problem by using machine learning algorithms to build a credit evaluation model. This paper uses the match data published by American Express in Kaggle to conduct a study of default prediction. To evaluate our experiment's performance, we do comparative competitions. We define the new experimental metrics. The result shows our hybrid model owns the highest metric 0.800 among these models, which is 0.002, 0.01, 0.013 higher than XGBoost, LightgGBM, DNN respectively.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "493914602d2e40c65db4092aed833e3e",
  "timestamp": "2025-05-15T01:59:21.720833"
}