{
  "id": 3110,
  "title": "Sensitivity of US sectoral returns to energy commodities under different investment horizons and market conditions",
  "abstract": "This study investigates relationships between US equity sector returns and energy commodity- crude oil, natural gas, gasoline, and gas oil-prices over short-run and long-run investment horizons. We decompose 22 years of daily raw return series on sampled US sectors and energy commodities into short-run and long-run components using variational mode decomposition (VMD). We employ quantile regression to observe US sector return behaviours under differing market conditions. Our results identify important differences in these behaviours by energy commodity, timeframe, and market condition. This includes, on average, differences in the sign and magnitude of quantile regression coefficients on energy commodities by investment horizon. While remaining susceptible to energy market changes in the short run, US sectors are recipients of greater volatility spillovers over the long run. Our results suggest a greater potential to achieve diversification benefits in the short run, and greater homogeneity in the effect of energy commodity on US sector returns across all quantiles in the long run. Our results have implications for investors, portfolio managers, and policy makers.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a9703a9598f4957aacb40a35ba450067",
  "timestamp": "2025-05-15T01:13:45.191379"
}