{
  "id": 873,
  "title": "Integration of incremental filter-wrapper selection strategy with artificial intelligence for enterprise risk management",
  "abstract": "The deterioration in enterprises' profitability not only threatens the interests of those firms, but also means related parties (investors, bankers, and stakeholders) could encounter tremendous financial losses, which could also impact the circulation of limited economic resources. Thus, an enterprise risk forecasting mechanism is urgently needed to assist decision-makers in adjusting their operating strategies so as to survive under any highly turbulent economic climate. This research introduces a novel hybrid model that incorporates an incremental filter-wrapper feature subset selection with the statistical examination and twin support vector machine (IFWTSVM) for enterprise operating performance forecasting. To promote a hybrid model's real-life application, the knowledge visualization extracted from IFWTSVM is represented in an easy-to-grasp style. The experimental results reveal that IFWTSVM's forecasting quality is very promising for financial risk mining, relative to other forecasting techniques examined in this study.",
  "year": 2018,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8ac01f664c87d1f82ae6fc23149264e4",
  "timestamp": "2025-05-15T01:56:17.481078"
}