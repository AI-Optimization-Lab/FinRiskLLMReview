{
  "id": 3875,
  "title": "Investor Sentiment Timing Ability of Mutual Fund Managers: A Comparative Study and Some Extensions",
  "abstract": "Purpose: This study aims to explore an ability to time market-wide investor sentiment of mutual fund managers in an emerging market. Research design, data, and methodology: Based on data of Thai mutual fund market over the period of 2000-2019, our sample includes 283 equity funds, consisting of 204 bank-related funds and 79 nonbank-related funds. We perform our regression analyses at the aggregate and portfolio levels. Results: Under the non-normal distribution of return, we find different behaviors between the best- and worst-performing funds in an ability to time market-wide investor sentiment in Thailand, which is dissimilar to the findings in the U.S. Bottom fund managers act as sentiment hedgers, who decrease (increase) an exposure of investment portfolios when the investor sentiment is high (low). Oppositely, top fund managers are likely to chase investor sentiment. Conclusion: We find that only the worst-performing fund managers, especially for bank-related funds are able to time the market-wide investor sentiment. An advantage of gaining information from their bank's clients is a key success. A competition in the mutual fund industry, an ability to predict fundamentals, and financial literacy are possible reasons to explain the main findings found in this study.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8473567a7921d7d284cb0d2f592d0d15",
  "timestamp": "2025-05-15T01:21:41.392361"
}