{
  "id": 1102,
  "title": "Portfolio optimization with a neural network implementation of the coherent market hypothesis",
  "abstract": "Capital market research seems to be widely governed by traditional static linear models like arbitrage pricing theory and capital asset pricing model, though there is some evidence that better results can be achieved using nonlinear approaches. In this study we described a portfolio optimization model based on artificial neural networks embedded in the framework of a nonlinear dynamic capital market model, the coherent market hypothesis. The main advantage of this theory is that it drops the premise of rational investors and therefore relaxes the precondition of approximately normally distributed stock returns. Neural networks are used to estimate the return distributions in order to forecast the fundamental situation and the level of group behavior of the specific stocks. On the basis of these forecasts the relative stock performance is predicted and used to manage stock portfolios. In a simulation with out-of-sample data from 1991-1994 a portfolio constructed from the eight best ranked stocks achieved an annual return rate about 25% higher than that of the market portfolio and one built from the eight worst ranked stocks attained a return about 25% lower than the market portfolio's return rate. A hedging strategy based on the two aforementioned portfolios leads to a consistently positive annual return of about 25% regardless of the movements of the market portfolio with only 41% of the risk of a buy and hold strategy in the market portfolio. (C) 1997 Elsevier Science B.V.",
  "year": 1997,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "222f82d50dd95c4801fd49504115b1aa",
  "timestamp": "2025-05-15T00:52:00.333914"
}