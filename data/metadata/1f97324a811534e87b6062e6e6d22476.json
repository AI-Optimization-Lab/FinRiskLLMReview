{
  "id": 4275,
  "title": "Penalized quasi-likelihood estimation of generalized Pareto regression-consistent identification of risk factors for extreme losses",
  "abstract": "In the financial industry, including insurance, a pressing problem is to identify risk factors for extreme losses. Penalized estimation of the generalized Pareto regression model provides a general framework for solving this problem via selecting risk factors associated with the (threshold) exceedance loss. However, the validity of postulating the generalized Pareto distribution as the conditional distribution of the exceedance loss predicates on a sufficiently high threshold. In the case of high feature dimension and high threshold, the feature dimension could well increase with the exceedance sample size, at a non-polynomial (NP) rate. We introduce a novel penalized quasi-maximum likelihood estimation method for feature selection within the framework of the generalized Pareto regression and derive the consistency of tuning parameter selection via a modified generalized information criterion, for the NP setting, under some mild regularity conditions. We illustrate the efficacy and the robustness of the proposed method with simulations and a real automobile insurance claim analysis, which reveals significant risk factors for large claims.(c) 2022 Elsevier B.V. All rights reserved.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1f97324a811534e87b6062e6e6d22476",
  "timestamp": "2025-05-15T02:35:26.249073"
}