{
  "id": 2815,
  "title": "Automated Trading System for Stock Index Using LSTM Neural Networks and Risk Management",
  "abstract": "Financial time series predictions are a challenge due to their nonlinear and chaotic nature. In recent decades, many researchers and investors have studied methods to improve quantitative analysis. In the field of artificial intelligence, sophisticated machine learning techniques, such as deep learning showed better performance. In this paper, an automated trading system is built to predict future trends of stock index prices. Using an LSTM-based agent to learn temporal patterns in the data, the algorithm triggers automatic trades according to the historical data, technical analysis indicators, and risk management. The results demonstrate that the proposed method, called LSTM-RMODV, shows better performance when compared with other methods, including the buy-and-hold technique. The proposed method also works in bear or bull market conditions, showing a rate over net income based on invested capital of 228.94%. That is, despite the low accuracy, the algorithm is capable of generating consistent profits when all the transaction costs are considered.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6c5b30e3565cefd1c96b5d8fcf25990f",
  "timestamp": "2025-05-15T02:19:46.578731"
}