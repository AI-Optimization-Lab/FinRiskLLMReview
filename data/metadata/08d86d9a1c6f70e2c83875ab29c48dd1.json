{
  "id": 5172,
  "title": "Portfolio management and dependence structure between cryptocurrencies and traditional assets: evidence from FIEGARCH-EVT-Copula",
  "abstract": "The purpose of this paper is twofold. Firstly, it discusses the relationship between five cryptocurrencies, oil prices, and US indices. Secondly, it focuses on determining the best portfolio hedging strategy. Using daily data relevant to the period ranging from January 4, 2016, to November 29, 2019, this study applies the FIEGARCH-EVT-Copula and Hedge ratios analysis. The findings obtained have shown that the crude oil (WTI) and the US indices return highlights the persistence of a negative and significant leverage effect while the cryptocurrency markets present a positive asymmetric volatility effect. Moreover, this paper show evidence of very weak dependence between all the different pairs considered before and after the introduction of Bitcoin Futures. Based on the Hedging ratio and mean-variance approach, this article suggests that to minimize the risk while keeping the same expected returns of the digital-conventional financial asset portfolio, the investor should hold more conventional financial assets than digital assets except for WTI-Bitcoin, WTI- Dash and WTI-Ethereum pairs which the values of their hedge ratios are rather important with respect to OLS regression.",
  "year": 2021,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "08d86d9a1c6f70e2c83875ab29c48dd1",
  "timestamp": "2025-05-15T02:45:17.010979"
}