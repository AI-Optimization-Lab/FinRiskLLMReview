{
  "id": 4110,
  "title": "Ukrainian financial markets: an examination of calendar anomalies",
  "abstract": "Purpose-This study aims to examine the market returns of the Ukrainian stock and bond markets to determine whether they exhibit calendar anomalies including the January effect, weekend effect, and turn-of-the-month ( TOM) effect. Ukraine provides an opportunity to examine the efficiency of an emerging market, adding to the extensive body of research on calendar anomalies. Design/methodology/approach-Regression analysis is used to examine the relationship between January returns vs non-January returns, Monday returns vs non-Monday returns, and TOM returns vs non-TOM returns. Non-parametric t-tests and Wilcoxon signed rank tests are also used to examine TOM returns vs the rest of the month returns. Findings -There is no evidence of a January effect or a weekend effect in the Ukrainian stock and bond markets. However, our results support a TOM effect in the Ukrainian stock market. The mean daily TOM return is 0.35 vs 0.24 per cent for the rest of the month. Additionally, in 63 per cent of the months, the mean daily TOM return exceeds the return for the rest of the month. Research limitations/implications -The data are limited to five-years of daily returns and two different Ukrainian indexes. Thus, the results could be biased by the time period analyzed. The results are important for portfolio managers and investors as they can benefit from the TOM effect, but not the January effect and weekend effect. Originality/value -This is the first study to our knowledge that has extensively examined the calendar anomalies in the Ukrainian stock and bond markets.",
  "year": 2010,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b8fd514929246413151540054a067be7",
  "timestamp": "2025-05-15T01:23:58.055035"
}