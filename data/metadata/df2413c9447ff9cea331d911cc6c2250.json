{
  "id": 6037,
  "title": "Oil market volatility: comparison of COVID-19 crisis with the SARS outbreak of 2002 and the global financial crisis of 2008",
  "abstract": "During the recent COVID-19 outbreak, the crude oil market experienced enormous price fluctuations. A large number of researchers contended the volatility observed in oil market as unprecedented and it was immediately attributed to the pandemic owing to its globally devastating nature. Whether or not this attribution is justified, is the major question we have raised in this paper. We perform the comparative analysis of the volatility spasms of oil market during the COVID-19 pandemic (COVID-19), the Global financial crisis of 2008 (GFC) and the SARS outbreak of 2002-2004 (SARS). Preliminary investigation is conducted using two proxies of market sentiment which are oil price returns and oil price spread. For further investigations we apply symmetric GARCH (1,1) and the asymmetric GJR-GARCH (1,1) models. Our results based on skewness and kurtosis, indicate an extremely high degree of fat tail risk implying COVID-19 crisis as low probability yet high severity event a.k.a. black swan event. Our results further confirm the presence of volatility clustering (GARCH effect) along with the highest degree of asymmetry during COVID-19. These facts collectively make COVID-19 crisis more uncertain and pessimistic compared to the GFC and SARS.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "df2413c9447ff9cea331d911cc6c2250",
  "timestamp": "2025-05-15T02:54:03.428751"
}