{
  "id": 1853,
  "title": "Artificial intelligence and machine learning in finance: Identifying foundations, themes, and research clusters from bibliometric analysis",
  "abstract": "Artificial intelligence (AI) and machine learning (ML) are two related technologies that are emergent in financial scholarship. However, no review, to date, has offered a wholistic retrospection of this research. To address this gap, we provide an overview of AI and ML research in finance. Using both co-citation and bibliometric-coupling analyses, we infer the thematic structure of AI and ML research in finance for 1986-April 2021. By uncovering nine (co-citation) and eight (bibliometric coupling) specific clusters of finance that apply AI and ML, we further identify three overarching groups of finance scholarship that are roughly equivalent for both forms of analysis: (1) portfolio construction, valuation, and investor behavior; (2) financial fraud and distress; and (3) sentiment inference, forecasting, and planning. Additionally, using co-occurrence and confluence analyses, we highlight trends and research directions regarding AI and ML in finance research. Our results provide assessment of AI and ML in finance research. (C) 2021 Elsevier B.V. All rights reserved.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "f18d3426bc3ac43337f4df19d7189984",
  "timestamp": "2025-05-15T01:00:27.323126"
}