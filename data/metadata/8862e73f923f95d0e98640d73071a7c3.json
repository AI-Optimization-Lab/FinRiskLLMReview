{
  "id": 3631,
  "title": "The Predictive Power of Financial Stress on the Financial Markets Dynamics: Hidden Markov Model",
  "abstract": "This study investigates the predictive power of the financial stress on the dynamic of the Middle East and North Africa (MENA) financial market returns from 2007 to 2021. Based on a Quantile Regression, we show that financial stress has highest predictive abilities at the lower quantiles when the market is bearish. Then, we propose a Hidden Markov Model (HMM) based on the transition matrix to understand the relationship between financial stress index and the MENA stock market dynamics. We find that the effect of financial stress on stock market return reveals the persistence of regimes: Bullish state exists and persists, and has the longest conditional expected duration for the majority of MENA markets, except Bahrain, Qatar and Jordan. However, the transition probability from the bullish to the calm regime is too low for the financial market of Bahrain, United Arab Emirates and Egypt. Besides, the estimated mean returns for each regime divulge that the bearish and calm states are more attractive destination for both portfolio managers and investors.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8862e73f923f95d0e98640d73071a7c3",
  "timestamp": "2025-05-15T01:19:00.800029"
}