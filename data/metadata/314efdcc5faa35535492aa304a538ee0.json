{
  "id": 2202,
  "title": "SPCM: A Machine Learning Approach for Sentiment-Based Stock Recommendation System",
  "abstract": "Recommendation systems play a pivotal role in delivering user preference information. However, they often face the challenge of information cocoons due to repeated content delivery, particularly prevalent in stock recommendations that are susceptible to investor sentiment. In response to the information cocoons, we propose the Sentiment and Price Combined Model (SPCM), which leverages sentiment features and price factors to predict stock price movements. This novel framework combines collective sentiment analysis with state-of-the-art BERT transformer models and advanced machine learning techniques. Over a three-year period, we collected 40 million stock comments from the Guba platform, extracting investor sentiment conveyed in text information and investigating the impact of metrics such as homophily on stock recommendations. Experimental results indicate that both the volume of posts and the agreement index affect the effectiveness of investor sentiment, while homophily reduces the accuracy of participants' stock price judgments. The recognition accuracy of the BERT-based sentiment analysis model reaches an impressive 84.12%, and the portfolio constructed by SPCM yields a cumulative return four times that of the industry benchmark. Furthermore, homogeneous quantitative metrics also enhance diversification in stock selection.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "314efdcc5faa35535492aa304a538ee0",
  "timestamp": "2025-05-15T01:04:27.407850"
}