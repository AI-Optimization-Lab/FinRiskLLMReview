{
  "id": 189,
  "title": "国际冲击下系统性风险的影响因素与传染渠道研究",
  "abstract": "本文基于区分宏观审慎与微观审慎这一崭新视角，采用前沿的系统性风险分解方法与相对重要性分析技术，准确测度国际输入性风险冲击下，全球49个主要金融市场的系统关联及尾部风险，精准识别我国金融市场的薄弱环节。同时，就不同市场冲击下各影响因素对系统性风险及其子成分的作用方向、影响力度等展开深入研究，剖析输入性金融风险的传染渠道。此外，对发达市场、新兴市场风险的影响因素与传染渠道展开对比分析。最后，本文采用条件分位数回归模型，探究各因素在不同风险分位数区间的异质性影响，并考察它们在各时期的渐进演变。在此基础上，为有效应对输入性风险冲击提出了相关政策建议，从而为健全国际金融风险防范机制、“守住不发生系统性风险底线”提供参考依据。",
  "year": 2023,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "4283442d89dd9369acd7de13bc02effb",
  "timestamp": "2025-05-14T22:27:22.033599"
}