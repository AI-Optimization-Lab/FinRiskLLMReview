{
  "id": 6055,
  "title": "orr Network formation in the interbank money market: An application of the actor-oriented model",
  "abstract": "This paper investigates the driving forces behind banks' link formation in the interbank market by applying the stochastic actor oriented model (SAOM). Our data consists of quarterly networks constructed from the transactions on an electronic trading platform (e-MID) for interbank credit over the period from 2001 to 2010. The analysis strongly supports the hypothesis that the existence and extent of past credit relationships is a major determinant of credit provision (i.e., link formation) in subsequent periods. We also find explanatory power of size-related characteristics, but little influence of past interest rates. The actor based analysis, thus, confirms the prevalent view that interbank credit is mainly determined by lasting business relationships and less so by competition for the best price (interest rate). Our findings also show that topological features exert a certain influence on the network formation process. The major changes found for the period after the onset of the financial crisis are that: (1) large banks and those identified as 'core' intermediaries became even more sought of as counterparties and (2) indirect counterparty risk appeared to be more of a concern as we find a higher tendency to avoid indirect exposure as indicated by clustering effects. (C) 2016 Elsevier B.V. All rights reserved.",
  "year": 2017,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b8f25287476cbd2895fa36225efbcc3d",
  "timestamp": "2025-05-15T02:54:03.514496"
}