{
  "id": 348,
  "title": "我国金融“脱实向虚”的综合判断与分析",
  "abstract": "本文界定了金融\"脱实向虚\"的内涵,设计了研判金融\"脱实向虚\"的挂钩变量和标准。本文以1990—2019年78个国家为样本的实证研究显示:2012年我国金融出现\"脱实向虚\",2012—2014年处于低度\"脱实向虚\"状态,2015—2018年出现了中度\"脱实向虚\",2019年又回落到低度\"脱实向虚\",但未来5年金融杠杆会回升。这意味着未来经济运行仍将面临高杠杆带来的系统性金融风险,以及金融杠杆波动性不断加剧给经济增长带来更大的负面冲击。宏观调控的政策取向和首要任务仍是\"降杠杆\"和\"稳增长\"。针对该形势,本文提出:一是亟须建立金融\"脱实向虚\"的审慎监管机制,将金融杠杆作为金融\"脱实向虚\"的审慎监管政策工具,将均衡金融杠杆作为研判金融\"脱实向虚\"的标准,前瞻性地引导金融回归服务实体经济的本位职能。二是改革现有存款基准利率的\"双轨制\",实施货币政策\"锁短放长\"的创新性操作来消除导致金融\"脱实向虚\"的政策诱因。",
  "year": 2021,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "136742ac3a015aea987a65dc99a1820a",
  "timestamp": "2025-05-14T22:29:10.705570"
}