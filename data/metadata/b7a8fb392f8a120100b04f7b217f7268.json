{
  "id": 1786,
  "title": "COMPARATIVE STUDY ON THE MODELS OF OPTIMAL HEDGE RATIO WITH APPLICATIONS TO CHINESE FUEL FUTURES",
  "abstract": "This paper investigates the problem of optimal hedge ratio and hedge efficiency of Chinese fuel futures. For this we use the data of Chinese fuel futures prices and spot prices to examine the performance of various models for hedge ratios, such as traditional regression model, VAR, EC, CC GARCH, and EC-GARCH model. We find that the latter four models provide better hedge efficiency than traditional regression model. VAR slightly improves the hedge performance. EC and CC GARCH models deduce the hedged portfolio risk by 10%. EC-GARCH model brings out the best hedge efficiency of 0.8524. Consequently, hedge strategies constructed from EC-GARCH model can significantly deduce the variance of the hedged portfolio and evade the price risk.",
  "year": 2010,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b7a8fb392f8a120100b04f7b217f7268",
  "timestamp": "2025-05-15T00:59:23.061577"
}