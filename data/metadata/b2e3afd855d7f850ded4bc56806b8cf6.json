{
  "id": 2655,
  "title": "A rule extraction based approach in predicting derivative use for financial risk hedging by construction companies",
  "abstract": "Prevention of financial risk is one of the major tasks that construction companies have to pay attention to. Using derivatives to avoid such risks is a practical strategy, but is heavily dependent on the traders' skills and accuracy of predictions. The purpose of this study is to develop an automatic expert model using a rule extraction based approach that provides practitioners with a prediction tool for the hedging of financial risks through the use of derivatives. Data for the study include 780 quarterly financial statements collected from 2002 to 2006, based on public information from 39 listed construction companies in Taiwan. Statements with incomplete and missing data are eliminated, leaving 672 with which to construct the rule extraction based model, the Hyper Rectangular Composite Neural Networks (HRCNNs). After factor dimension reduction, only 16 financial ratios out of all revealed ratios are left to be used as input variables. The HRCNNs yield an 80.6% successful classification rate. With these 16 financial ratios and the proposed model, derivative use to hedge financial risk can be established for the benefit of the construction practitioners. (C) 2010 Elsevier Ltd. All rights reserved.",
  "year": 2010,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b2e3afd855d7f850ded4bc56806b8cf6",
  "timestamp": "2025-05-15T02:17:32.289198"
}