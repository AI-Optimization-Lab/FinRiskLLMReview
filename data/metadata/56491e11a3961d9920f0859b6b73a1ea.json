{
  "id": 98,
  "title": "Credit default swap pricing with counterparty risk in a reduced form model with Hawkes process",
  "abstract": "In this article, we investigate the pricing of credit default swaps (CDS) while taking into account counterparty risk. We adopt a reduced form model with a self-exciting Hawkes process that allows for clustering in the default intensity. By solving the partial differential equations, we derive semi-analytical formulas for the joint survival probability density and the first default probability density. To obtain the numerical solutions for CDS pricing, we use the Runge-Kutta numerical method. Through our numerical analysis, by comparing the CDS pricing under the Poisson process, we find that the CDS pricing model under the Hawkes process provides a more general and richer structure and better describes the default risk of contagion.",
  "year": 2025,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "56491e11a3961d9920f0859b6b73a1ea",
  "timestamp": "2025-05-15T01:28:35.304555"
}