{
  "id": 1020,
  "title": "Enhancing Portfolio Optimization: A Two-Stage Approach with Deep Learning and Portfolio Optimization",
  "abstract": "The portfolio selection problem has been a central focus in financial research. A complete portfolio selection process includes two stages: stock pre-selection and portfolio optimization. However, most existing studies focus on portfolio optimization, often overlooking stock pre-selection. To address this problem, this paper presents a novel two-stage approach that integrates deep learning with portfolio optimization. In the first stage, we develop a stock trend prediction model for stock pre-selection called the AGC-CNN model, which leverages a convolutional neural network (CNN), self-attention mechanism, Graph Convolutional Network (GCN), and k-reciprocal nearest neighbors (k-reciprocal NN). Specifically, we utilize a CNN to capture individual stock information and a GCN to capture relationships among stocks. Moreover, we incorporate the self-attention mechanism into the GCN to extract deeper data features and employ k-reciprocal NN to enhance the accuracy and robustness of the graph structure in the GCN. In the second stage, we employ the Global Minimum Variance (GMV) model for portfolio optimization, culminating in the AGC-CNN+GMV two-stage approach. We empirically validate the proposed two-stage approach using real-world data through numerical studies, achieving a roughly 35% increase in Cumulative Returns compared to portfolio optimization models without stock pre-selection, demonstrating its robust performance in the Average Return, Sharp Ratio, Turnover-adjusted Sharp Ratio, and Sortino Ratio.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "ba6d0b2b76c8551d9a41ffc1cf90190f",
  "timestamp": "2025-05-15T00:50:40.815189"
}