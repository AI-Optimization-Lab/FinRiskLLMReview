{
  "id": 4625,
  "title": "Comparing the learning effectiveness of BP, ELM, I-ELM, and SVM for corporate credit ratings",
  "abstract": "Corporate credit ratings are one of the key problems of the credit risk management, which has attracted much research attention since the credit crisis in 2007. Scorecards are the most widely used approaches for corporate credit ratings nowadays. However, they have heavy dependency on the involvement of users. Al technologies, such as Artificial Neural Networks (ANNs) and Support Vector Machines (SVMs) have demonstrated their remarkable performance on automatic corporate credit ratings. Corporate credit ratings involve various rating models, and their outputs can scale to multiple levels and be used for various applications. Such inherent complexity gives rise to the requirement of higher demands on the effectiveness of learning algorithms regarding the accuracy, overfitness, error distribution, and output distribution. Most research works show that SVMs have better performance than ANNs on accuracy. This paper carries out a comprehensive experimental comparison study over the effectiveness of four learning algorithms, i.e., BP, ELM, I-ELM, and SVM over a data set consisting of real financial data for corporate credit ratings. The results are presented and discussed in the paper. (C) 2013 Elsevier B.V. All rights reserved.",
  "year": 2014,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b9aac2b5ce5296c19686b67f07c390cc",
  "timestamp": "2025-05-15T02:39:26.939679"
}