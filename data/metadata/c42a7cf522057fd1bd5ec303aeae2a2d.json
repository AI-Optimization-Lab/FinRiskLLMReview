{
  "id": 442,
  "title": "QUANTILE CLOCKS",
  "abstract": "Quantile clocks are defined as convolutions of subordinators L, with quantile functions of positive random variables. We show that quantile clocks can be chosen to be strictly increasing and continuous and discuss their practical modeling advantages as business activity times in models for asset prices. We show that the marginal distributions of a quantile clock, at each fixed time, equate with the marginal distribution of a single subordinator. Moreover, we show that there are many quantile clocks where one can specify L, such that their marginal distributions have a desired law in the class of generalized s-self decomposable distributions, and in particular the class of self-decomposable distributions. The development of these results involves elements of distribution theory for specific classes of infinitely divisible random variables and also decompositions of a gamma subordinator, that is of independent interest. As applications, we construct many price models that have continuous trajectories, exhibit volatility clustering and have marginal distributions that are equivalent to those of quite general exponential Levy price models. In particular, we provide explicit details for continuous processes whose marginals equate with the popular VG, CGMY and NIG price models. We also show how to perfectly sample the marginal distributions of more general classes of convoluted subordinators when L is in a sub-class of generalized gamma convolutions, which is relevant for pricing of European style options.",
  "year": 2011,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c42a7cf522057fd1bd5ec303aeae2a2d",
  "timestamp": "2025-05-15T01:31:50.794502"
}