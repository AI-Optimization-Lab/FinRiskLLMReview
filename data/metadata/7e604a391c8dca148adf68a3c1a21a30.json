{
  "id": 3230,
  "title": "A Review on Complex System Engineering",
  "abstract": "Complexity is commonly summarized as 'the actions of the whole are more than the sum of the actions of the parts'. Understanding how the coherence emerges from these natural and artificial systems provides a radical shift in the process of thought, and brings huge promises for controlling and fostering this emergence. The authors define the term 'Complex System Engineering' to denote this approach, which aims at transferring the radical insights from Complex System Science to the pragmatic world of engineering, especially in the Computing System Engineering domain. A theoretical framework for Complex System Engineering is built by the morphogenetic engineering framework, which identifies a graduation of models, in growing order of generative power. The implementation of Complex System Engineering requires a portfolio of operational solutions: The authors therefore provide a classification of Complex System application approaches to answer this challenge and support the emergence of Complex System Engineers capable of addressing the issues of an ever more connected world.",
  "year": 2020,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7e604a391c8dca148adf68a3c1a21a30",
  "timestamp": "2025-05-15T01:14:55.028180"
}