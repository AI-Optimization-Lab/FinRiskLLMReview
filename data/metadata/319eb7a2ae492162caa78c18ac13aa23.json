{
  "id": 633,
  "title": "Factors that Impact the Accuracy of Clustering Based Load Forecasting",
  "abstract": "Due to the deregulation of the power system, the electric power industry is undergoing a transformation in terms of its planning and operation strategies. Because of the importance in reducing financial and operational risk, improving load forecasting accuracy is paramount. In some load forecasting applications, K-means clustering is used to group customers prior to forecasting. This method has been shown to improve the accuracy of load predictions. However, there are situations where K-means clustering reduces load forecasting accuracy. This paper studies the factors that affect the performance of K-means clustering. Additionally, several strategies have been proposed to tackle the lower estimation accuracy problems for this clustering algorithm. The data used for validating the proposed strategies associated with the factors is from Consolidated Edison Company of New York, Inc. (ConEdison). The mean absolute percent error (MAPE) and relative mean square error (RMSE) are utilized to evaluate the forecasting results of K-means based least squares support vector machines (LS-SVM) and preprocessed K-means based LS-SVM. Additionally, the outperformance of preprocessed K-means based LS-SVM is demonstrated via the data results.",
  "year": 2015,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "319eb7a2ae492162caa78c18ac13aa23",
  "timestamp": "2025-05-15T01:53:24.839500"
}