{
  "id": 1086,
  "title": "DIFFERENT STATISTICAL METHODS FOR PREDICTING NASDAQ 100 USING UNIVARIATE TIME SERIES APPROACHES",
  "abstract": "Stock price prediction is the process by which future stock prices are predicted using historical prices. The prediction of stock prices is vital for traders and investors to increase their profits from stock trading and for risk managers to manage the risk of their portfolio. This article aims to compare the performance of a wide range of statistical methods for stock price prediction. The statistical methods considered in this article include autoregressive integrated moving average (ARIMA), exponential smoothing with errors term (ETS), Holt-Winters exponential smoothing (HW), and neural network auto-regression (NNETAR). Additionally, hybrid methods which combine multiple models for prediction are also considered. Then, the prediction capability of these models are compared under mean absolute error (MAE), root mean square error (RMSE), mean absolute percentage error (MAPE), mean absolute square error (MASE) and Theil's statistics (Theil U). Empirical analysis shows that the hybrid method performs best among all methods.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c7591af8a8460c6a0dbe7a8e9336f074",
  "timestamp": "2025-05-15T00:51:25.967592"
}