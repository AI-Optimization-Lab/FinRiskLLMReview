{
  "id": 6297,
  "title": "AUSTRALIAN NATIONAL DIAGNOSIS RELATED GROUPS AND ABDOMINAL-SURGERY",
  "abstract": "This study compares the declared splits for abdominal surgery within the Australian National Diagnosis Related Groups (AN-DRG) with age-based strata. Data were derived from two clinical trials involving 2114 adults. The patients tended to be elderly (25% > 71 years) and had significant co-morbidity, that is, 57% with an American Society of Anesthesia (ASA) classification > 1. Adverse events after surgery included pulmonary complications (16%), urinary tract infections (10%), wound infection (6%), and death (4.5%). Only 27% of the patients could be classified into a 'non-complicated' AN-DRG partition; these patients had a median age of 25 years and 88% had either appendicectomy or cholecystectomy. In contrast, analysis of six age-based strata revealed a stepwise increase in the incidence of adverse events after surgery (Friedman ANOVA, P < 0.001). It might therefore be wise to consider the inclusion of age-strata in the abdominal surgery component of the AN-DRG. Failure to do so may result in financial penalties for hospitals that care for patients at high risk of an adverse outcome after abdominal surgery.",
  "year": 1994,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "04468292422e4b388d660caa80e7128b",
  "timestamp": "2025-05-15T02:56:37.505765"
}