{
  "id": 901,
  "title": "A Genetic Algorithm Model for Financial Asset Diversification",
  "abstract": "Machine learning models can produce balanced financial portfolios through a variety of methods. Genetic algorithms are one such method that can optimally combine different funds that may occupy a portfolio. This study introduces a genetic algorithm model that finds optimal combinations of funds for a portfolio through a new approach to fitness formula calculation. Each fund in a given population has a base fitness score consisting of the sum of several technical analysis indicators. Each indicator chosen measures a different performance aspect of a fund, allowing for a balanced fitness score. Additionally, each fund has multiple category variables that determine diversity when combined into a portfolio. The base fitness score for each portfolio is the sum of its funds' individual fitness scores. Portfolio fitness scores adjust based on the included funds' category variable diversity. Portfolios that consist of funds with largely similar categories receive lower adjusted fitness scores and do not cross over. This process encourages strong and diversified portfolios to reproduce. This model creates diverse portfolios that outperform market benchmarks and demonstrates future potential as a diversification-aware investment strategy.",
  "year": 2019,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c52728b81418ebce97f2c1bb38884f12",
  "timestamp": "2025-05-15T00:49:36.263350"
}