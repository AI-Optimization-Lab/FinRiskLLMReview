{
  "id": 1776,
  "title": "Portfolio Strategies to Track and Outperform a Benchmark",
  "abstract": "I investigate the question of how to construct a benchmark replicating portfolio consisting of a subset of the benchmark's components. I consider two approaches: a sequential stepwise regression and another method based on factor models of security returns' first and second moments. The first approach produces the standard hedge portfolio that has the maximum feasible correlation with the benchmark. The second approach produces weights that are proportional to a signal-to-noise ratio of factor beta to idiosyncratic volatility. Using a factor model of securities returns allows the use of a larger number of securities than the number of time periods used to estimate the parameters of the factor model. I also consider a second objective that maximizes expected returns subject to a target tracking error variance. The security selection criterion naturally extends to the product of the information ratio and the signal-to-noise ratio. The optimal tracking portfolio is either a one-fund or a two-fund portfolio rule consisting of the optimal hedging portfolio, the tangent portfolio or the global minimum variance portfolio, depending on what constraints are imposed on the objective function. I construct buy-and-hold replicating portfolios using the algorithms presented in the paper to track a widely followed stock index with very good results both in-sampleandout-of-sample.",
  "year": 2020,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "37a08c04950ae72413da1d1dc497bca8",
  "timestamp": "2025-05-15T00:59:23.030612"
}