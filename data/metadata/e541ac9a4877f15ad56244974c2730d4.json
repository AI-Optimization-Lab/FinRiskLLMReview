{
  "id": 669,
  "title": "News Sentiment and the Risk of a Stock Price Crash Risk: Based on Financial Dictionary Combined BERT-DCA",
  "abstract": "This study combines a financial knowledge dictionary and pretraining method based on BERT (Bidirectional Encoder Representation from Transformers) to construct a deep learning model for identifying stock news sentiments. The study then calculates the sentiment metrics of all stocks and analyzes the impact of news sentiment on the risk of a stock price crash and its heterogeneity. The results show that stocks with more positive sentiment metrics have a higher risk of crash in the following year. We also investigate the information intermediation and investor sentiment channels by which news sentiment affects the risk of a crash. The results show that more net insider sales, lower information transparency, and less analyst coverage amplify the impact of news sentiment on future crash risk, which is consistent with the information intermediation channel. Additionally, more retail investor positions, more active investor sentiment, and divergence between analysts' opinions and news amplify the impact of news sentiment on the risk of a future stock price crash, which is consistent with the investor sentiment channel.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "e541ac9a4877f15ad56244974c2730d4",
  "timestamp": "2025-05-15T01:41:29.772941"
}