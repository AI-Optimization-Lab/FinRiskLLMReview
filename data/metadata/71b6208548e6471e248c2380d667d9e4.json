{
  "id": 46,
  "title": "Twin-system recurrent reinforcement learning for optimizing portfolio strategy",
  "abstract": "Portfolio management is important for sequential investment decisions in response to fluctuating financial markets. As portfolio management can be formulated as a sequential decision -making problem, it has been addressed using reinforcement learning in recent years. However, reinforcement learning methods face challenges in addressing portfolio management problems considering practical constraints. To overcome the limitations, this study proposes a twin -system approach, establishing a tractable twin that mirrors the original problem but with more manageable constraints and system dynamics. Once an optimized portfolio strategy is achieved within the tractable twin, the proposed mapping function translates it back to the original problem, ensuring the retention of optimized performance. Unlike the previous study, the proposed recurrent reinforcement learning method optimizes the portfolio strategy for a single agent managing all candidate assets. This method allows for comprehensive investment decisions by incorporating the features of candidate assets, leading to a more globally optimized portfolio strategy. Experimental studies demonstrate that the proposed method consistently outperforms benchmark strategies on the US sector and foreign exchange portfolios.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "71b6208548e6471e248c2380d667d9e4",
  "timestamp": "2025-05-15T00:38:56.906339"
}