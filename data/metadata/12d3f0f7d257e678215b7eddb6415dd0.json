{
  "id": 228,
  "title": "An Empirical Study on the Effectiveness of Bi-LSTM-Based Industry Rotation Strategies in Thai Equity Portfolios",
  "abstract": "Portfolio optimization poses a significant challenge due to asset price volatility caused by various economic factors. Portfolio optimization typically aims to achieve a high risk-adjusted return through asset allocation. However, high-volatility assets such as equities can lead to significant losses in the event of crises, such as trade wars. An industry rotation strategy can reduce portfolio risk by investing in industry indexes. This research aims to develop industry rotation strategies for Thailand by analyzing previous consecutive months of economic variables with the goal of maximizing the portfolio's Sharpe ratio in the following period. Two strategies are proposed in this paper, one with cash and the other without, both of which include eight Thai industry indexes in their portfolios. Both strategies are developed using Bidirectional Long Short-term Memory (BiLSTM) models, which generate the allocation ratio based on historical economic variable data. The models then optimize the allocation ratio by using a modified loss function to maximize the Sharpe ratio. In addition to the Sharpe ratio, the return on investment and the Calmar ratio are used to assess the performance of the strategies. The results showed that our strategies outperformed the baseline buy-and-hold SET50 and equal-weight strategies.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "12d3f0f7d257e678215b7eddb6415dd0",
  "timestamp": "2025-05-15T00:33:39.482539"
}