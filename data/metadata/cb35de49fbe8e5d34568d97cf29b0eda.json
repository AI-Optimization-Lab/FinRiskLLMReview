{
  "id": 608,
  "title": "SELF-FTS: A SELF-SUPERVISED LEARNING METHOD FOR FINANCIAL TIME SERIES REPRESENTATION IN STOCK INTRADAY TRADING",
  "abstract": "The stock price's highly unstable fluctuation pattern makes learning efficient representation challenging to model the stock movement. The common deep learning often overfits after a few epochs of training and performs poorly in the validation set because the optimization objective is insufficient to characterize the stock adequately. In this paper, we propose Self-FTS, a self-supervised learning framework for financial time series representation, to learn the underlying representation and use in stock trading, affected by the fact that self-supervised learning is a promising technique for learning representation for extracting high dimensional features from unlabeled financial data to overcome the bias caused by handcrafted features. Specifically, we design several auxiliary tasks to generate samples with pseudo labels from the A-share stock price data sets and build a weight-sharing feature extraction backbone combined with a classification head to learn the pseudo labels based on the samples. Finally, We evaluate the learned representations extracted from the backbone by fine-tuning data sets labelled with stock returns to build an investment portfolio. Experimental analysis results on the Chinese stock market data show that our method significantly improves the stock trend forecasting performances and the actual investment income through backtesting compared to the current SOTA method, which strongly demonstrates our effective approach.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "cb35de49fbe8e5d34568d97cf29b0eda",
  "timestamp": "2025-05-15T00:45:39.111123"
}