{
  "id": 11,
  "title": "A novel prediction based portfolio optimization model using deep learning",
  "abstract": "Portfolio optimization is an important part of portfolio management. It realizes the trade-off between maximizing expected return and minimizing risk. A better portfolio optimization model helps investors achieve higher expected returns under the same risk level. This paper proposes a novel prediction based portfolio optimization model. This model uses autoencoder (AE) for feature extraction and long short term memory (LSTM) network to predict stock return, then predicted and historical returns are utilized to build a portfolio optimization model by advancing worst-case omega model. In order to show the effect of AE, the LSTM network without any feature extraction methods is used as a benchmark in stock prediction. Also, an equally weighted portfolio is considered as a comparison to reveal the advantage of the worst-case omega model. Empirical results show that the proposed model significantly outperforms the equally weighted portfolio, and a high risk-return preference is more suitable to this model. In addition, even after deducting transaction fees, this model still achieves a satisfying return and performs better than the state-of-art prediction based portfolio optimization models. Thus, this paper recommends applying this model in practical investment.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d7ec1df284ae3aa69e9380d3737cc8ee",
  "timestamp": "2025-05-15T00:31:16.732897"
}