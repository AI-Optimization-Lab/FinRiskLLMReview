{
  "id": 3722,
  "title": "Divestiture of prior acquisitions: competing explanations of performance",
  "abstract": "Purpose There are multiple perspectives of divestiture and its performance that require reconciliation. While research finds a positive market response to divestment announcement, divestiture of prior acquisitions are generally viewed negatively. The purpose of this paper is to develop and empirically test different explanations for the divestment of prior acquisitions. Design/methodology/approach This research employs event study to capture market reaction at acquisition announcement and subsequent divestments in a sample of 69 public US high-technology acquisitions between 2003 and 2008 that were divested by 2015. Only initial acquisitions involving public firms were included from the Thomson One Banker SDC database. Public press releases and companies' SEC filings were reviewed to track divestitures back to prior acquisitions. Ordinary least squared regression was used to estimate coefficients. Findings Results indicate a positive relation between acquisition and divestiture performance around announcement dates. This finding rejects the correction of mistake explanation, suggesting that a negative stigma surrounding divestments is largely unwarranted and that investors reward capable acquirer's divestiture decisions. Originality/value This study finds that investors view divestiture as a proactive strategy, suggesting firms can improve performance by actively managing acquisitions and divestments to optimize their portfolio of businesses.",
  "year": 2020,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "e83f0d096dd1463c87bcd4e679f392c1",
  "timestamp": "2025-05-15T01:20:03.488990"
}