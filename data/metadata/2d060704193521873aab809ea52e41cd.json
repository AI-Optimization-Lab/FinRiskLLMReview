{
  "id": 2450,
  "title": "Energy Resource Scheduling with Multiple Iterations for the Validation of Demand Response Aggregation",
  "abstract": "Flexibility aggregators are becoming a trend in European energy markets, joining several consumers and small-size distributed generators to their portfolio, enabling market participation. Also, the interest growth in clean energy resources and in smart grid concepts such as demand response and communication infrastructures, has led to a facilitation in the integration of these flexibility resources. In this paper, it is proposed a methodology that supports the aggregator in its energy management and resources scheduling. The work focuses on a rescheduling method that uses aggregation and remuneration processes to define new tariffs for consumers participating in a load curtailment demand response program. Aggregation is performed using the clustering algorithm, k-means, while the remuneration process defines a tariff per group formed by computing the arithmetic average of the consumer's prices belonging to each group.",
  "year": 2018,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "2d060704193521873aab809ea52e41cd",
  "timestamp": "2025-05-15T01:07:02.975908"
}