{
  "id": 22,
  "title": "我国金融风险传染机制与防控策略研究——基于复杂网络下非连续治疗策略的SIRS模型",
  "abstract": "本文以我国42家上市银行2011—2021年财务报表数据为样本，构建复杂网络下非连续治疗策略的SIRS模型，通过Copula函数、门槛回归等方法对模型参数进行估计，分析系统内的风险传播过程，进一步探讨当前我国政府对于银行救助策略的合理性，仿真模拟不同救助策略并提出相应的优化方案。研究表明：(1)在银行救助过程中应当优先救助市场参与集中度高的银行，重要的银行网络节点处于风险不可感染状态是达到风险稳态的关键；(2)目前我国采取的银行救助策略可以解决当前银行风险高位问题；(3)在实现银行救助目标的前提下，当前的救助策略可降低强度57.55%。研究结果带来的启示：(1)完善金融市场监管的法律法规体系，强化应对突发危险的能力；(2)加强对市场参与集中度高的机构的监管；(3)根据市场风险结构的变化不断调整风险应对策略。",
  "year": 2024,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8c39d899943f401fac15410dd154a42c",
  "timestamp": "2025-05-14T22:26:03.563766"
}