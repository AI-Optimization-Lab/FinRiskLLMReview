{
  "id": 591,
  "title": "Systemic risk prediction based on Savitzky-Golay smoothing and temporal convolutional networks",
  "abstract": "Based on the data from January 2007 to December 2021, this paper selects 14 representatives from four levels of the extreme risk of financial institutions, the contagion effect between financial systems, volatility and instability of financial markets, liquidity, and credit risk systemic risk. By constructing a Savitzky-Golay-TCN deep convolutional neural network, the systemic risk indicators of China's financial market are predicted, and their accuracy and reliability are analyzed. The research found that: 1) Savitzky-Golay-TCN deep convolutional neural network has a strong generalization ability, and the prediction effect on all indices is stable. 2) Compared with the three control models (time-series convolutional network (TCN), convolutional neural network (CNN), and long short-term memory (LSTM)), the Savitzky-Golay-TCN deep convolutional neural network has excellent prediction accuracy, and its average prediction accuracy for all indices has increased. 3) Savitzky-Golay-TCN deep convolutional neural network can better monitor financial market changes and effectively predict systemic risk.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "59f67c23c168fd65adb9efd5feebdce4",
  "timestamp": "2025-05-15T01:52:49.487068"
}