{
  "id": 7616,
  "title": "Site-Adaptation of Modeled Solar Radiation Data: The SiteAdapt Procedure",
  "abstract": "The adaptation of modeled solar radiation data with coincident ground measurements has become a standard practice of the industry, typically requested by financial institutions in the detailed solar resource assessments of solar projects. This practice mitigates the risk of solar projects, enhancing the adequate solar plant design and reducing the uncertainty of its yield estimates. This work presents a procedure for improving the accuracy of modeled solar irradiance series through site-adaptation with coincident ground-based measurements relying on the use of a regression preprocessing followed by an empirical quantile mapping (eQM) correction. It was tested at nine sites in a wide range of latitudes and climates, resulting in significant improvements of statistical indicators of dispersion, distribution similarity and overall performance: relative bias is reduced on average from -1.8% and -2.3% to 0.1% and 0.3% for GHI and DNI, respectively; relative root mean square deviation is reduced on average from 17.9% and 34.9% to 14.6% and 29.8% for GHI and DNI, respectively; the distribution similarity is also improved after the site-adaptation (KSIis 3.5 and 3.9 times lower for GHI and DNI at hourly scale, respectively). The methodology is freely available as supplementary material and downloadable as R-package from SiteAdapt.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "730ccbc71b121562ac40f903cd924292",
  "timestamp": "2025-05-15T03:10:32.976235"
}