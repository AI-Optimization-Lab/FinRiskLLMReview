{
  "id": 1519,
  "title": "Predictions of Loan Defaulter - A Data Science Perspective",
  "abstract": "With the progress of technology and implementation of Data Science in banking, changes the face of banking industry. Most of the banking, financial sectors and social lending platforms are actively investing on lending. But financial institutions might face huge capital loss if they approved the loan without having any prior assessment of default risk. Financial institutions always need a more accurate predictive system for various purposes. Predicting loan defaulters is a crucial task for the banking industry. Banks have immensely large amount of data like customer's data, transaction behavior, etc. Data Science is a promising area to process the data and extract the hidden patterns using machine learning techniques. This paper uses statistical measures to preprocess the data and build an effective model that will predicts the loan defaulter accurately.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "4b1ded33c153b5da906c46fc9ae30ad2",
  "timestamp": "2025-05-15T02:04:20.009320"
}