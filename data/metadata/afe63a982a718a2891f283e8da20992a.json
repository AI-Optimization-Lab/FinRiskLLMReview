{
  "id": 879,
  "title": "'What matters is what works': Labour's journey from 'national superannuation' to 'personal accounts'",
  "abstract": "A key element of Labour's response to the Pensions Commission's recommendations for 'a new pension settlement for the twenty-first century' is a system of 'personal accounts' that will be administered and invested by the private sector. The contrast with 50 years ago, when Britain faced similar pressures, is striking. Then, Labour presented to the British public proposals for a state-run scheme embodying redistribution between higher and lower-paid workers and the accumulation of a very large fund that would be directly invested in stock markets by the state to promote faster growth. Today's scheme embodies neither redistribution nor collective control of the scheme's assets, and investment and risk-taking will be the responsibility of individuals rather than the state. This article explores the differences between Labour's proposals in 1957 and the scheme it proposes today. It considers what these differences tell us about the party's changing conception of social democracy, and highlights the irony that, with consumers' faith in financial markets shattered by the most severe financial crisis since 1929, New Labour's embrace of a private sector solution on the grounds that 'what matters is what works' now seems badly mistaken. British Politics (2010) 5, 41-64. doi:10.1057/bp.2009.27",
  "year": 2010,
  "source": "WOS",
  "area": "financial_risk",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "afe63a982a718a2891f283e8da20992a",
  "timestamp": "2025-05-15T01:43:54.561869"
}