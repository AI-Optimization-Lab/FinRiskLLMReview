{
  "id": 903,
  "title": "Geopolitical Risk in Investment Research: Allies, Adversaries, and Algorithms",
  "abstract": "Geopolitical risk is a driver of just about every type of investment portfolio. However, in practice, most geopolitical research published by investment firms is not informed by international relations theory, giving it a less rigorous, editorial flavor. This article is an attempt to address the latter shortcoming by providing a theoretically grounded framework for analyzing geopolitical risk in an investment context. The first half of the article presents a qualitative framework for analyzing geopolitical risk. The framework uses conceptual tools from international relations theory that can be easily adapted to portfolio management. The second half of the article explores the analysis of geopolitical risk from a quantitative standpoint. The focus of this section is the application of game-theoretic, machine learning, and algorithmic techniques to the study of international relations. The last section of the article briefly addresses the topic of portfolio construction and provides a simple framework for incorporating geopolitical views into the portfolio selection process.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a5ae07bc66345e8b2f3612681fda8511",
  "timestamp": "2025-05-15T00:49:36.284769"
}