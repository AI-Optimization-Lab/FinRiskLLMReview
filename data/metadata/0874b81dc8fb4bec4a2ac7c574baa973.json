{
  "id": 5544,
  "title": "Modern approaches to efficient market hypothesis of FOREX the central European case",
  "abstract": "In this article the main goal is to verify the efficiency hypothesis of FOREX market in the sample of panel dataset of the Central European countries. Traditionally there are many approaches for testing the market efficiency hypothesis. We should briefly mention the regression analysis, time series analysis, vector autoregression or linear co-integration. For recent years there are modern approaches that change the technical way of testing. Pedroni's panel co-integration method is a modern method for verification conclusions of pure economic theory. It's innovation is in analyzing short time series but on a great range of panel data. The other way is to include non-linear co-integration into non-stationary time series. The FOREX market is market with the greater trading volumes of financial traded assets. Either the rejection or the confirmation of the market efficiency hypothesis highly influence the regulation or liberalization of financial services. More we have discussed the influence of the risk premium, the influence of transaction costs and its response to equilibrium readjustment. We have shown the empirical evidence, which results in the strong tendency of nominal convergence in EU countries. (C) 2014 The Authors. Published by Elsevier B.V.",
  "year": 2014,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "0874b81dc8fb4bec4a2ac7c574baa973",
  "timestamp": "2025-05-15T02:48:51.350597"
}