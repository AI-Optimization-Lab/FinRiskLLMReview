{
  "id": 1322,
  "title": "STABILITY OF SSD EFFICIENCY - MONTHLY VERSUS YEARLY RETURNS",
  "abstract": "This paper deals with second-order stochastic dominance portfolio efficiency. In existing portfolio efficiency tests with respect to the second-order stochastic dominance (SSD) criterion, the scenario approach for random returns is assumed. We analyse the stability of SSD portfolio efficient classification with respect to two possible set of historical scenarios: monthly returns and yearly returns. In both cases, 20 years history is considered. For both sets of scenarios we test SSD efficiency of almost one hundred thousand portfolios that can be formed from ten US industry representative portfolios. For each portfolio, we compare the monthly returns results with yearly return results.",
  "year": 2009,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "2cc0f2e1d46d1f27ff97520cafe9809f",
  "timestamp": "2025-05-15T00:54:24.666601"
}