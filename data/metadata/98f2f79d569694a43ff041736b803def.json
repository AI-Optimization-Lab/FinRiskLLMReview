{
  "id": 2824,
  "title": "Defining phonosurgery: a proposal for classification and nomenclature by the Phonosurgery Committee of the European Laryngological Society (ELS)",
  "abstract": "The term phonosurgery (PS) refers to any operation designed primarily for the improvement or restoration of voice. It is defined by the intended operative goal, which pertains to quality of life rather than its preservation, and informed consent needs to account for this emphasis. Since the aim is improvement or maintenance of vocal function, it is essential to document voice accurately pre-operatively. As important as the surgery itself is a team approach to perioperative care and rehabilitation. Although not a new concept, the PS portfolio of operations continues to grow rapidly, making this one of the most dynamic field in Laryngology. However, this has also led to confusion regarding terminology and classification, with the result that it is presently difficult to compare results between institutions. The aim of this paper is to establish a practical classification system for PS and to thereby establish a common language for reporting results. We propose four groups of operation: vocal fold surgery (VFS), laryngeal framework surgery (LFS), neuromuscular surgery (NHS) and reconstructive surgery (RCS) (for either partial or total laryngeal replacement).",
  "year": 2007,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "98f2f79d569694a43ff041736b803def",
  "timestamp": "2025-05-15T01:10:49.556735"
}