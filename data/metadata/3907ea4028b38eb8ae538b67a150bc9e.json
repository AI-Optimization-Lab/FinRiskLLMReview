{
  "id": 484,
  "title": "Forecasting Financial Time Series with Support Vector Machines Based on Dynamic Kernels",
  "abstract": "The technical analysis of financial time series and in particular the prediction of future developments is a challenging problem that has been addressed by many researchers and practitioners due to the possible profit We provide a forecasting technique based on a certain machine learning paradigm, namely support vector machines (SVM). SVM gained more and more importance for practical applications in the past years as they have excellent generalization abilities due to the principle of structural risk minimization. However, standard kernel functions for SVM are not able to compare time series of variable length appropriately, i.e., when we assume that these time series must be scaled in a non-linear way. Therefore, we use the dynamic time warping (DTW) technique as a kernel function. We demonstrate for two financial time series (FDAX and FGBL futures) that excellent results can be obtained with this approach.",
  "year": 2009,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "3907ea4028b38eb8ae538b67a150bc9e",
  "timestamp": "2025-05-15T01:51:31.267407"
}