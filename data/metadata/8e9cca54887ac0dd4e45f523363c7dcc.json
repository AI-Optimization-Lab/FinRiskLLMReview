{
  "id": 3598,
  "title": "Shortability and asset pricing model: Evidence from the Hong Kong stock market",
  "abstract": "This study explores how the violation of free short selling assumption affects the performance of CAPM and the Fama-French three-factor model, as existing studies show that short-sales constraints affect asset pricing of the stocks. Using data from the Hong Kong Stock Market which has unique regulations on short selling, we conduct both time-series and cross-sectional regression analyses to evaluate the performance of the two models under the short-sales-constraints and the no-constraints market environment. The two models perform much worse in the former environment than in the latter, indicating a significant impact of the short sales constraints on the explanatory power of the models. We then augment the two models with a shortability-mimicking factor. Our results show that the factor has a significant power in explaining both time-series and cross-sectional variation in the size-B/M portfolio returns. The addition of the factor to the two models considerably increases their overall performance. (C) 2017 Elsevier B.V. All rights reserved.",
  "year": 2017,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8e9cca54887ac0dd4e45f523363c7dcc",
  "timestamp": "2025-05-15T01:19:00.630196"
}