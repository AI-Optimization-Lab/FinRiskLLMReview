{
  "id": 3450,
  "title": "A Study of Data Management in Hybrid Cloud Configuration",
  "abstract": "Cloud computing is currently spreading with the further implementation of IT infrastructure. Clouds involve certain negative factors, however, which must be addressed to promote further cloud utilization. As a means of addressing some of these negative factors, a hybrid cloud configuration combining public and private clouds has attracted attention. This configuration stores personal and confidential information in a private cloud and other data in a public cloud. Unfortunately, no detailed classification of where various kinds of data should be stored has yet been fully established. Hence, this paper proposes an enterprise data management method for a hybrid cloud configuration. Specifically, enterprise data was subdivided into 28 categories through a work breakdown structure (WBS) method. Then, the subdivided data was classified in terms of whether it did or did not consist of personal or confidential information. The resulting data portfolio required storing only about 18% of data in a private cloud, with the remaining 82% in a public cloud. In accordance with this basic guideline, a fundamental data management proposal is developed for the hybrid cloud configuration.",
  "year": 2013,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "e6dbaa23c4391d16d895c13d872059bc",
  "timestamp": "2025-05-15T01:17:25.426163"
}