{
  "id": 206,
  "title": "Application of Dynamic Financial Time-Series Prediction on the Interval Artificial Neural Network Approach with Value-at-Risk Model",
  "abstract": "Artificial Neural Networks (ANNs) are promising approaches for financial time-series prediction. This study adopts a hybrid approach, called a Fuzzy BPN, consisting of a Back-Propagation Neural Network (BPN) and a fuzzy membership function which takes advantage of the ANNs' nonlinear features and interval values instead of the shortcoming of ANNs' single-point estimation. To employ the two characteristics mentioned above, a dynamic intelligent time-series forecasting system will be built more efficiently for practical financial predictions. Additionally, with the liberalization and opening of financial markets, the relationships among financial commodities became much closer and complicated. Hence, establishing a perfect measure approach to evaluate investment risk has become a critical issue. The objective of this study is not only to achieve higher efficiency in dynamic financial time-series predictions but also a more effective financial risk control with Value-at-Risk methodology, which is called Fuzzy-VaR BPN model in this study. By extending to the financial market environment, it is expected that wider and more suitable applications in financial time-series and risk management problems would be covered. Moreover, the Fuzzy-VaR BPN model would be applied to the Taiwan Top50 Tracker Fund to demonstrate the capability of our study.",
  "year": 2008,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6d9f4039bdad542d1c99ed0966f811c6",
  "timestamp": "2025-05-15T01:47:53.086385"
}