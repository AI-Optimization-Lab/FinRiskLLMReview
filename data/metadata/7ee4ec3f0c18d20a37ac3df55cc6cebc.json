{
  "id": 1652,
  "title": "The Optimal Re-sampling Strategy for a Risk Assessment Model",
  "abstract": "The global economic environment is changing rapidly. Consequently, the financial risks of banks or financial institutions are also increased. Banks or financial institutions often utilize various classification methods to construct risk assessment models to determine whether to grant loans to a corporation or an individual. It is often found that the data used to construct a risk assessment model are imbalanced. That is, the number of default is significantly smaller than the number of non-default. In this case, most classification methods fail to construct an accurate risk assessment model since the classification methods are subjected to the imbalanced data. The try-and-error method is often utilized to balance the sample sizes for default and non-default classes. However, the try-and error method is costly and the sampling strategy determined by the try-and-error method may not effectively classify the imbalanced data. Therefore, this study aims to develop an optimal re-sampling strategy using design of experiments (DOE) and dual response surface methodology (DRS). The proposed method can be employed for any classification method to develop a risk assessment model. The effectiveness of the proposed procedure is verified using a real case from a Taiwanese financial institution.",
  "year": 2012,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7ee4ec3f0c18d20a37ac3df55cc6cebc",
  "timestamp": "2025-05-15T02:05:42.617901"
}