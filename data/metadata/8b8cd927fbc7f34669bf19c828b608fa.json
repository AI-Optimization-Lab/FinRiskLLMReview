{
  "id": 3592,
  "title": "On Forecasting Realized Volatility for Bitcoin Based on Deep Learning PSO-GRU Model",
  "abstract": "As the trendsetter of the digital currency market, Bitcoin fluctuates dramatically in a short period of time and has received increasing attention from investors. However, its high volatility has brought great uncertainty to the financial market. In this paper, we focus on forecasting the realized volatility of Bitcoin by using an optimized deep learning model. Firstly, we construct a more comprehensive system of factor indicators and employ different methods for feature selection, and find that the Random Forest-based feature selection fits better on the deep learning model. Then, we use the particle swarm optimization (PSO) algorithm to optimize the parameters of gated recurrent unit (GRU) model to improve the prediction accuracy, and the results show that the prediction accuracy of PSO-GRU model is 10.47%, 15.28%, 21.73%, 34.79% better than the GRU model, long-short term memory model, machine learning models and the generalized autoregressive conditional heteroscedasticity model on the mean absolute error, respectively. Finally, we establish an early risk warning scheme for Bitcoin volatility and a butterfly option arbitrage strategy, that provide investors with a reference for reasonable arrangement of trading strategies.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8b8cd927fbc7f34669bf19c828b608fa",
  "timestamp": "2025-05-15T02:27:54.086409"
}