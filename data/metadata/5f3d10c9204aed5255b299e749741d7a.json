{
  "id": 104,
  "title": "Portfolio dynamic trading strategies using deep reinforcement learning",
  "abstract": "Using the constituent stocks of the iShares MSCI US ESG Select Index ETF, a matrix of technical indicators, returns, and covariance is incorporated to represent the inherent information characteristics of the stock market. In this study, based on the proposed Deep Reinforcement Learning for Portfolio Management on Environmental, Social, and Governance (DRLPMESG) architecture model, investors who use active portfolio management reap the greatest rewards, as the portfolio with 5 stocks performing the best, with an annualized return of 46.58%, a Sharpe ratio of 1.37, and a cumulative return of 115.18%, indicating that the results have the potential to win the market and generate excess profits. In contrast to the efficient market hypothesis, this new understanding of proven effectiveness in obtaining satisfactory rewards would help improve investment strategies for portfolio management. Furthermore, this study proposed that holding 5 stocks in a portfolio can lead to higher returns, laying the foundation for future research on the number of holdings. Moreover, when compared to previous static strategies, this model offering a dynamic strategy may generate a more stable return in the face of market fluctuations.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5f3d10c9204aed5255b299e749741d7a",
  "timestamp": "2025-05-15T00:39:32.523764"
}