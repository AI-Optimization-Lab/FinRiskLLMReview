{
  "id": 576,
  "title": "金融产品去刚性兑付:掣肘解析与对策建议",
  "abstract": "金融产品刚性兑付是我国金融组织体系不断健全过程中部分金融业态形成的金融现象和结果,是一种过渡型状态和产物。金融产品去刚性兑付已经成为当前金融强监管、严监管、防范化解金融风险的重要举措。而打破刚性兑付不是一蹴而就的,根本的掣肘问题在于金融本源的\"缺位\"、市场机制的\"混乱\"以及基础设施的\"欠缺\"。金融产品去刚性兑付是一项系统性工程,在宏观层面、中观层面、微观层面都具有必要性,破除掣肘的对策需要回归金融服务实体本源,理顺金融市场机制(契约机制、定价机制、业务机制),健全金融基础设施(法律法规、金融信用、金融文化),从根本上为金融产品去刚性兑付奠定好基础,以促进资管行业回归\"卖者尽责、买者自负\"的正常轨道。",
  "year": 2019,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "ef7f872c28e384aeb7308f4e7691a391",
  "timestamp": "2025-05-14T22:31:30.144149"
}