{
  "id": 119,
  "title": "Portfolio Allocation with Dynamic Risk Preferences via Reinforcement Learning",
  "abstract": "In the realm of investment, the mean-variance model serves as an efficacious method for constructing investment portfolios, as it is underpinned by a robust economic theory and is ubiquitously employed in both academia and practice. Nevertheless, there is currently no satisfactory approach for ascertaining the risk preference parameters within the model for investors. This paper proposes a novel reinforcement learning (RL) framework integrated with the mean-variance model, designed to dynamically adjust investors' risk preference parameters during the portfolio construction process. Our RL portfolio is not only readily implementable but also exhibits strong economic interpretability. In our empirical analysis employing Taiwan 50 Index market data, our designed RL portfolio outperforms both the buy-and-hold strategy and portfolios with static risk preference parameters. Concurrently, through our meticulously crafted reward function, RL demonstrates heightened accuracy in selecting suitable risk preferences when market return differences are more pronounced, underscoring the effectiveness of RL methods in dynamically adjusting risk preference parameters during periods of elevated market volatility.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "72cb4995de72724401be5b1eac652647",
  "timestamp": "2025-05-15T00:39:32.580954"
}