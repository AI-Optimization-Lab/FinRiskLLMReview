{
  "id": 4181,
  "title": "Market-specific and currency-specific risk during the global financial crisis: Evidence from the interbank markets in Tokyo and London",
  "abstract": "This paper investigates how international money markets reflected credit and liquidity risk during the global financial crisis. After matching the currency denomination, we examine how the Tokyo Interbank Offered Rate (TIBOR) was synchronized with the London Interbank Offered Rate (LIBOR). We find remarkably asymmetric responses in market-specific and currency-specific risk during the crisis. The regression results suggest that market-specific credit risk increased the difference across markets, whereas liquidity risk caused the difference across currency denominations. They also support the view that liquidity shortage of the US dollar occurred in international money markets during the crisis. Coordinated central bank liquidity provisions were useful in reducing the liquidity shortage of the US dollar, but their effectiveness was asymmetric across markets. (C) 2012 Elsevier B.V. All rights reserved.",
  "year": 2012,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "acf4d47f3774744ce9e4ed6786a7cf6a",
  "timestamp": "2025-05-15T02:34:13.402689"
}