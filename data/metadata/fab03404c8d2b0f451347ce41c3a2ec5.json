{
  "id": 536,
  "title": "Methodology for Constructing an Experimental Investment Strategy Formed in Crisis Conditions",
  "abstract": "This article proposes a neoclassical stock market portfolio based on the principles of dynamic response and constant adaptation to the market. The construction of a neoclassical investment portfolio begins with the conceptual development of an adaptive investment strategy. We suggest an algorithm for creating an adaptive investment portfolio. The conceptual model of the investment strategy is presented including the following mandatory components: evaluation, forecasting, investment, and adaptation. This model has the ability to adapt both in normal and in crisis periods of the market. As a description of the forecasting component, an additive mathematical model of the predictive ensemble is used, including seasonal, regression, and shock elements as well as a neural network.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "fab03404c8d2b0f451347ce41c3a2ec5",
  "timestamp": "2025-05-15T00:44:21.136226"
}