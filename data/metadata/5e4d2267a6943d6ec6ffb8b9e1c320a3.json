{
  "id": 3344,
  "title": "Predicting domain-specific risk-taking attitudes of mainland China university students: a hyper core self-evaluation approach",
  "abstract": "This study applied the framework of hyper core self-evaluation to examine the risk-taking attitudes, in the ethical, financial, health/safety, recreational, and social domains, of 437 university students from Harbin, China. Under the hyper core self-evaluation approach, overconfidence and hubristic pride were found to be significant predictors of risk-taking attitudes in the ethical, financial, and health/safety domains. The control variable of sensation seeking found in the Impulsive Behavior Scale was also significant in predicting risk-taking attitudes in certain domains. Different regression analysis models were run to generate these results. Limited studies have focused on Chinese university students' risk taking attitudes in different domains, and most studies have merely applied sensation seeking and impulsivity in understanding risk-taking. However, this empirical study contributes to finding out whether a particular group of Chinese students had high levels of overconfidence and hubristic pride (as many young people do) and whether these common characteristics could contribute to the understanding of risk-taking attitudes in the five domains.",
  "year": 2016,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5e4d2267a6943d6ec6ffb8b9e1c320a3",
  "timestamp": "2025-05-15T02:25:13.742453"
}