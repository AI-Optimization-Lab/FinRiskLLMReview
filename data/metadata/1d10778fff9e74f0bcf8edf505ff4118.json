{
  "id": 2233,
  "title": "Analysing technological specificities of industrial sectors using corporate patent profiles with a gravity center modelling",
  "abstract": "This paper investigates the possibility of developing a correspondence between the industrial sector (based on ICB classification) which is attributed to a corporation and the technological composition of this corporation's patent portfolio (based on WIPO technological fields) using a mathematical model based on gravity center. Exploiting data characterising 1288 large corporations from the Corporate Invention Board database, we carry out a two steps analysis. In the first place we compute average patent profiles for different industrial sectors. Then, we test the discriminating power of these average patent profiles by checking to what extent the analysis of a given corporate patent portfolio makes it possible to correctly predict the industrial sector to which this corporation actually belongs. The results show that this modelling, although providing quite precise predictive information for some industrial sectors (e.g. Healthcare, Automobiles or Chemical), does not fit for some industrial sectors which produce mainly very generic (i.e. not specific) technologies (e.g. Consumer Services or Support Services).",
  "year": 2019,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1d10778fff9e74f0bcf8edf505ff4118",
  "timestamp": "2025-05-15T01:04:27.494474"
}