{
  "id": 1967,
  "title": "Reverse stress testing: Scenario design for macroprudential stress tests",
  "abstract": "We propose a systematic algorithmic reverse-stress testing methodology to create worst case scenarios for regulatory stress tests by accounting for losses that arise from distressed portfolio liquidations. First, we derive the optimal bank response for any given shock. Then, we introduce an algorithm which systematically generates scenarios that exploit the key vulnerabilities in banks' portfolio holdings and thus maximize contagion despite banks' optimal response to the shock. We apply our methodology to data of the 2016 European Banking Authority (EBA) stress test, and design worst case scenarios for the portfolio holdings of European banks at the time. Using spectral clustering techniques, we group 10,000 worst-case scenarios into twelve geographically concentrated families. Our results show that even though there is a wide range of different scenarios within these 12 families, each cluster tends to affect the same banks. An Anna Karenina principle of stress testing emerges: Not all stressful scenarios are alike, but every stressful scenario stresses the same banks. These findings suggest that the precise specification of a scenario is not of primal importance as long as the most vulnerable banks are targeted and sufficiently stressed. Finally, our methodology can be used to uncover the weakest links in the financial system and thereby focus supervisory attention on these, thus building a bridge between macroprudential and microprudential stress tests.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "cfa2c93eecbc34d0116629701005c15c",
  "timestamp": "2025-05-15T01:01:41.617529"
}