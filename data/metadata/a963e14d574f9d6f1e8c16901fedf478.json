{
  "id": 397,
  "title": "Developing a dynamic carbon benchmarking method for large building property estates",
  "abstract": "As supermarkets are known to be energy intensive, improvements made to their efficiency can enable operators to reduce not only carbon emissions but also costs, in line with corporate and legislative targets. This study presents a novel benchmarking method to appraise emission and cost performances across a portfolio, enabling building managers to identify sites that are underperforming, taking as a case study a large number of food retail stores. Multiple layers, detailed variable selection including weather features and regression technique comparisons (Multivariate Linear Regression (MLR), Artificial Neural Network (ANN) and Decision Tree (DT)), are considered in model construction. Efficiency is evaluated on multiple bases with a focus on emissions. These are clustered together to produce a benchmark to inform investment decision-making across a portfolio. The DT technique was found to be the most effective, producing a benchmark with low average error (1.5 kgCO(2) m(-2) period(-1)) and high maximum error (21 kgCO(2) m(-2) period(-1)) indicating high accuracy and high discernment respectively. This model also correctly classified buildings known to perform poorly into the worst 30% of buildings in the portfolio. This work highlights the need for further research into natural gas consumption benchmarking and particularly the use of humidity data to better understand the issues in decarbonising heat. (C) 2021 Elsevier B.V. All rights reserved.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a963e14d574f9d6f1e8c16901fedf478",
  "timestamp": "2025-05-15T00:43:10.478259"
}