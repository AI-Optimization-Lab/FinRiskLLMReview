{
  "id": 1718,
  "title": "Foreign Policy Specificity: An Analysis of Ministerial Survival in Latin America, 1945-2020",
  "abstract": "This research note analyzes the incentives of different types of policy areas for a president to keep or dismiss a minister. It uses ministerial survival analysis to compare foreign and domestic policy areas, focusing on comparable and analogous presidential decisions among countries and portfolios. The research utilizes ministerial survival data for education, finance, health, and foreign policy between 1945 and 2020 in Argentina, Brazil, Chile, Mexico, Paraguay, Peru, and Uruguay. Using Cox regression models, we find that a foreign policy portfolio has a positive effect on ministerial survival, but the specificity of this portfolio does not hold for autocratic governments. Autocracies show higher levels of ministerial survival in all four portfolios, but a foreign policy portfolio is no more stable than domestic portfolios. Democratic presidents have the incentive to signal stability to the international audience, preserving the foreign policy portfolio from the frequent ministerial changes in domestic portfolios.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "3fdf3f5345adc9067ad46462db8d3148",
  "timestamp": "2025-05-15T00:58:50.653625"
}