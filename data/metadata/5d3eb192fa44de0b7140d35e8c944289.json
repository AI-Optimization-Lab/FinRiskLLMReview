{
  "id": 5896,
  "title": "Stress Testing for Retail Mortgages Based on Probability Analysis",
  "abstract": "One big problem with stress testing used by banks, regulators, and international financial organization is that the test does not predict occurrence probabilities of certain pre-specified stress scenarios and their consequent loss to be expected, which is, however, the real purpose of stress testing in the first place. As a result, institutes lack information sufficient enough for preserving appropriate resources to hedge risks prompted by these scenarios. In this study we use real life retail mortgages from a Chinese commercial bank and propose a stress testing approach based on probability analysis of different scenarios. This method would provide not only the amount of expected loss, but also that of the loan distributed over the loan classification states: Standard, Special Mention, Substandard, Doubtful, Loss, and Paid-off. Consequently, the bank management would have useful information when making credit operation policy decisions. In addition, the models and algorithms, providing practical risk management tools for banks and regulators, could be implemented on other commercial credit products as well.",
  "year": 2019,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5d3eb192fa44de0b7140d35e8c944289",
  "timestamp": "2025-05-15T02:52:31.487943"
}