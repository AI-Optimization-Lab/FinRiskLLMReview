{
  "id": 7267,
  "title": "Size-threshold effect in debt-firm performance nexus in the sub-Saharan region: A Panel Smooth Transition Regression approach",
  "abstract": "This paper formally tests the presence of threshold effect on debt-firm performance nexus with respect to firm size. To do this, we use sub-Saharian-5 countries over the period 2006-2016. To deal with problems of endogeneity and heterogeneity, we use the Panel Smooth Transition Regression (PSTR) method developed by Gonzalez, Terasvirta, and van Dijk (2005). This technique further estimates the smoothness of the transition from a small size to a large size regime. These findings reveal a threshold level of 5.531 (about 252 million dollars), below (above) which performance of small (large) firms decreases (increases) when debt increases. Consequently, predictions of pecking order, trade-off, and signal theories are admitted. These results may yield important policy implications. These findings show that small (large) firms are more (less) vulnerable in terms of financial risk. In this case, they must rely on internal funds (credit access) to maximize their performance. This should be achieved through the optimization of their capital structures. Policymakers may take these different effects into account.. (C) 2019 Board of Trustees of the University of Illinois. Published by Elsevier Inc. All rights reserved.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "082a82bb9fba00bfcab7fffde6b322b9",
  "timestamp": "2025-05-15T03:07:02.529784"
}