{
  "id": 1374,
  "title": "Transfer learning-based default prediction model for consumer credit in China",
  "abstract": "Financial institutions in China, such as banks, are encountering competitive impacts from Internet financial businesses. To address these impacts, financial institutions are seeking business innovations, such as an automatic credit evaluation system that is based on machine learning. Abundant new credit data are required in the implementation of new businesses to establish related risk evaluation models; however, new businesses lack data. Based on these insights, this paper innovatively proposes the idea of transfer learning, determines the similarity between traditional businesses and new businesses and transfers the data of traditional bank businesses to new business data to construct new training sets and to train small data sets. The reconstructed training data sets are used to train default risk prediction models, compare them with the benchmark models in the tests and validate the performance and adaptation of the default prediction model based on transfer learning technique. Our study highlights the commercial value of the transfer learning concept in the financial risk field and provides practitioners and management personnel with a decision basis.",
  "year": 2019,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5272308b2532bd6b3396e7465647ab77",
  "timestamp": "2025-05-15T02:02:22.677157"
}