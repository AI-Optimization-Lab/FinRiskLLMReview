{
  "id": 766,
  "title": "Advanced Fraud Detection: Leveraging K-SMOTEENN and Stacking Ensemble to Tackle Data Imbalance and Extract Insights",
  "abstract": "This study proposes an innovative solution for credit card fraud detection, utilizing a stacking ensemble of machine learning classifiers enhanced with sophisticated data resampling techniques. The model demonstrates exceptional performance, achieving an F1-score of 0.92, precision of 0.95, recall of 0.88, an AUPRC of 0.96, and a perfect ROC-AUC of 1.00. These results significantly outperform standalone models like XGBoost and Decision Tree, showcasing the strength of the proposed approach. The study addresses two critical challenges, class imbalance and overfitting, by employing K-means SMOTEENN to balance minority class representation while reducing synthetic data noise, thus lowering the risk of overfitting. Additionally, the stacking ensemble's integration of diverse classifiers produces a generalized decision boundary, enhancing model robustness in real-world scenarios. This ensures a precise fraud detection mechanism without compromising sensitivity. Furthermore, the proposed model incorporates Explainable AI (XAI) techniques to enhance interpretability and trust. The study identifies key features driving model predictions by leveraging Local Interpretable Model-Agnostic Explanations (LIME), illustrating how base learners and the meta-learner contribute to the final decision. This transparency bolsters stakeholder confidence and provides actionable insights for financial institutions. Overall, the proposed approach marks a notable step in protecting financial transactions from fraud.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7aa6ef03b4b72c63515b298e610a0237",
  "timestamp": "2025-05-15T01:55:07.980295"
}