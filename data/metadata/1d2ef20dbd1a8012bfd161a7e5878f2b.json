{
  "id": 2826,
  "title": "The color of FinTech: FinTech and corporate green transformation in China",
  "abstract": "How to drive the transformation toward a green economy has become an urgent topic of concern around the world under the pressure of global warming. This study sheds light on the effect of FinTech on corporate green transformation. Based on machine learning and text analysis methods to construct the two key metrics, our findings show that FinTech promotes corporate green transformation, which is mainly achieved by alleviating information asymmetry, relaxing financial constraints and increasing risk-taking. The above conclusions remain unchanged after a series of robustness tests, such as instrumental variable and difference-in-difference methods, etc. Additionally, this positive effect is more pronounced in high-tech, non-state-owned and heavily-polluting companies, and it is amplified by the peer groups' green transformation strategies. Overall, our study reveals the green nature of FinTech and provides creative insights into the achievement of the goal of carbon emission peak and neutrality in China.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1d2ef20dbd1a8012bfd161a7e5878f2b",
  "timestamp": "2025-05-15T02:19:46.624038"
}