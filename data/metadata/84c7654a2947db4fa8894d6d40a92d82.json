{
  "id": 1952,
  "title": "The Performance and Diversification Potential of Non-Listed Value-Add Real Estate Funds in Japan",
  "abstract": "In the aftermath of the COVID-19 pandemic, non-core investments are gaining traction amongst institutional investors due to the shifting preference towards investment vehicles that position higher on the risk-return curve. Non-listed value-add real estate funds in Japan are one such vehicle. This research develops a comprehensive bespoke benchmark total return index using the ANREV database to reflect the performance of Japan-focussed non-listed value-add real estate funds. We compare the performance of such funds with that of other asset classes and perform portfolio and regression analyses. We conclude that there are several advantages to investing in those funds, including: (1) strong absolute total return performance, (2) competitive risk-adjusted performance, and (3) significant portfolio diversification potential in a mixed-asset portfolio context. The strategic implications for real estate investors are also assessed.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "84c7654a2947db4fa8894d6d40a92d82",
  "timestamp": "2025-05-15T01:01:41.592816"
}