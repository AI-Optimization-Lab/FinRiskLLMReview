{
  "id": 485,
  "title": "Emerging and Potential Opportunities for 2D Flexible Nanoelectronics",
  "abstract": "The last 10 years have seen the emergence of two-dimensional (2D) nanomaterials such as graphene, transition metal dichalcogenides (TMDs), and black phosphorus (BP) among the growing portfolio of layered van der Waals thin films. Graphene, the prototypical 2D material has advanced rapidly in device, circuit and system studies that has resulted in commercial large-area applications. In this work, we provide a perspective of the emerging and potential translational applications of 2D materials including semiconductors, semimetals, and insulators that comprise the basic material set for diverse nanosystems. Applications include RF transceivers, smart systems, the so-called internet of things, and neurotechnology. We will review the DC and RF electronic performance of graphene and BP thin film transistors. 2D materials at sub-um channel length have so far enabled cut-off frequencies from baseband to 100GHz suitable for low-power RF and sub-THz concepts.",
  "year": 2016,
  "source": "WOS",
  "area": "portfolio",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "085f01ba579bd9a88b6df51186e9e4f7",
  "timestamp": "2025-05-15T00:36:26.592366"
}