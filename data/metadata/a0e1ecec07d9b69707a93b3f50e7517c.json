{
  "id": 1833,
  "title": "A Study of a Hybrid Evolutionary Fuzzy Model for Stock Selection",
  "abstract": "Stock selection has long been a challenging and important task in finance. Recent advances in machine learning and data mining are leading to significant opportunities to solve these problems more effectively. In this study, we aim at developing a methodology for effective stock selection using fuzzy models as well as genetic algorithms (GA). We first devise a stock scoring mechanism using fundamental variables and apply fuzzy membership functions to re-scale the scores properly. The scores are then used to obtain the relative rankings of stocks. Top-ranked stocks can thus be selected to form a portfolio. Furthermore, we employ GA for optimization of model parameters and feature selection for input variables to the stock scoring model. We will show that the investment returns provided by our proposed methodology significantly outperform the benchmark return. Based upon the promising results obtained, we expect this hybrid fuzzy-GA methodology to advance the research in soft computing for finance and provide an effective solution to stock selection in practice.",
  "year": 2011,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a0e1ecec07d9b69707a93b3f50e7517c",
  "timestamp": "2025-05-15T00:59:53.307349"
}