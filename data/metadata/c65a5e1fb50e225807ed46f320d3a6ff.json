{
  "id": 8,
  "title": "Gridifying Classification-Monte Carlo algorithm for pricing high-dimensional Bermudan-American options",
  "abstract": "Among derivative financial contracts, the widely traded in the financial markets are the Bermudan-American options. However, pricing high-dimensional Bermudan-American options is quite computationally intensive and using traditional computing infrastructures may take up to hours for these computations. This can result in potential financial losses, further weakening the competitiveness of an organization. Several parallel approaches for pricing have been practiced utilizing parallel or cluster computing techniques. We aim to address this problem in the context of grid computing, relying on the ProActive Java distributed computing platform. We parallelize the Classification-Monte Carlo algorithm, which relies on classification techniques front the machine learning domain, for pricing Bermudan-American options. Consequently, we evaluate the performance of two machine learning techniques, Boosting and Support Vector Machines, and compare the numerical results with respect to accuracy, speed up and their applicability in the grid settings. Furthermore, the paper also contributes to the numerical experiments of a high-dimensional Bermudan-American option with 40 underlying assets.",
  "year": 2008,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c65a5e1fb50e225807ed46f320d3a6ff",
  "timestamp": "2025-05-15T01:27:29.428755"
}