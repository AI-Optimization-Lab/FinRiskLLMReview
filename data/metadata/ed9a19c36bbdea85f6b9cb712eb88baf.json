{
  "id": 210,
  "title": "Stock market network based on bi-dimensional histogram and autoencoder",
  "abstract": "In this study, we propose a deep learning related framework to analyze S&P500 stocks using bi-dimensional histogram and autoencoder. The bi-dimensional histogram consisting of daily returns of stock price and stock trading volume is plotted for each stock. Autoencoder is applied to the bi-dimensional histogram to reduce data dimension and extract meaningful features of a stock. The histogram distance matrix for stocks are made of the extracted features of stocks, and stock market network is built by applying Planar Maximally Filtered Graph(PMFG) algorithm to the histogram distance matrix. The constructed stock market network represents the latent space of bi-dimensional histogram, and network analysis is performed to investigate the structural properties of the stock market. we discover that the structural properties of stock market network are related to the dispersion of bi-dimensional histogram. Also, we confirm that the autoencoder is effective in extracting the latent feature of the bi-dimensional histogram. Portfolios using the features of bi-dimensional histogram network are constructed and their investment performance is evaluated in comparison with other benchmark portfolios. We observe that the portfolio consisting of stocks corresponding to the peripheral nodes of bi-dimensional histogram network shows better investment performance than other benchmark stock portfolios.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "ed9a19c36bbdea85f6b9cb712eb88baf",
  "timestamp": "2025-05-15T00:33:39.425238"
}