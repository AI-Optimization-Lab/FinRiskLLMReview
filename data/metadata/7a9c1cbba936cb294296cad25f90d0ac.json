{
  "id": 8862,
  "title": "The discrepancy between objective and subjective assessments of catastrophic health expenditure: evidence from China",
  "abstract": "The pro-rich nature of catastrophic health expenditure (CHE) indicators has garnered criticism, inspiring the exploration of the subjective approach as a complementary method. However, no studies have examined the discrepancy between subjective and objective approaches. Employing data from the Chinese Social Survey (CSS) 2013-2021 waves, we analysed the discrepancy between objective and subjective CHE and its associated socioeconomic factors using logit regression modelling. Overall, self-rating generated higher CHE incidence (28.35% to 33.72%) compared to objective indicators (9.92% to 21.97%). Objective indicators did not support 17.57% to 23.90% of self-rated cases of household CHE, while 2.73% to 8.42% of households classified with CHE by objective indicators did not self-rate with CHE. The normative subsistence spending indicator showed the least consistency with self-rating (70.66% to 74.28%), while the budget share method produced the most consistent estimation (72.73% to 76.10%). Living with elderly and young children [adjusted odds ratios (AOR): 1.069 to 1.169, P < 0.1], lower educational attainment (AOR: 1.106 to 1.225, P < 0.1), lower income (AOR: 1.394 to 2.062, P < 0.01), and lower perceived social class (AOR: 1.537 to 2.801, P < 0.05) were associated with higher odds of self-rated CHE without support from objective indicators. Conversely, low socioeconomic status (AOR: 0.324 to 0.819, P < 0.1) was associated with lower odds of missing CHE cases classified by objective indicators in self-rating. The commonly used objective indicators for assessing CHE may attract doubts about their fairness from socioeconomically disadvantaged people. The CHE subjective approach can be adopted as a complementary measure to monitor financial risk protection.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7a9c1cbba936cb294296cad25f90d0ac",
  "timestamp": "2025-05-15T03:22:57.967349"
}