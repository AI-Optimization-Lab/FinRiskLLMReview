{
  "id": 1637,
  "title": "Evolving Deep Neural Networks for Movie Box-office Revenues Prediction",
  "abstract": "Reliable prediction of movie box-office revenues can greatly reduce the financial risk in the film industry, but accurate prediction is not easy to obtain. Recently, deep neural networks has been applied on movie box-office revenues prediction problems as a promising solution. However, the architecture has a significant impact on its performance, and generally involves a heavy burden of manually designing which is unable to traverse the space of possible architectures efficiently. As a result, the applicability and performance of deep neural networks are severely limited. This paper proposes a new evolutionary algorithm for evolving deep neural networks for movie box-office revenues prediction. In particular, a deep neural network that fuses features extracted from movie posters by a convolutional neural network is introduced first, then a set of novel genetic operators are designed correspondingly. The proposed method can automate the deep neural network architecture designing and aim to search the optimal architecture for movie box-office revenues prediction. Experiments carried out on the Internet Movie Database (IMDB) dataset show that the proposed algorithm achieves superior performance compare to other competitive approaches.",
  "year": 2018,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "cda3aa0987e6629363f64d6bb843d8a1",
  "timestamp": "2025-05-15T02:05:42.585408"
}