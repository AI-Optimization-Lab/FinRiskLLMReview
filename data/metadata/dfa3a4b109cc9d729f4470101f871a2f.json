{
  "id": 395,
  "title": "A Simple Approach to Pricing American Options Under the Heston Stochastic Volatility Model",
  "abstract": "In a recent study, Nawalkha, Beliaeva, and Zreik (NBZ) [2010] presented a multidimensional transform for generating path-independent trees for pricing American options under low-dimensional stochastic volatility models. For this class of models, this approach has higher accuracy than the GARCH tree method of Ritchken and Trevor [1999] and is computationally more efficient than the Monte Carlo regression method of Longstaff and Schwartz [2001] as well as the lattice method of Leisen [2000]. In this article, the authors give an explicit demonstration of the NBZ transform using the specific example of the Heston [1993] stochastic volatility model. Using the control variate method, this approach obtains highly accurate American option prices within a fraction of a second.",
  "year": 2010,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "dfa3a4b109cc9d729f4470101f871a2f",
  "timestamp": "2025-05-15T01:31:13.218448"
}