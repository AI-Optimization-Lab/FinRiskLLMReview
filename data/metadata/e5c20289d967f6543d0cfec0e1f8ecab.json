{
  "id": 1390,
  "title": "The optimal portfolio size in Shanghai stock market",
  "abstract": "By denoting the portfolio risk with portfolio variance, this paper empirically analyzes the tendency of the reduction of portfolio variances with the increase of sizes of portfolios selected from Shanghai stock market. Using the sample of December 1996 to May 1998 monthly closing prices of 208 stocks in Shanghai Stock Exchange, the computer simulates the simple random sampling and calculates the variance of every portfolio. With regression and marginal analyses on above data, it is concluded: 1)in order to diminish the risk, the portfolio size must be no less than eight stocks; 2) according to relevant regulations and the level of costs resulting from diversification in securities investment funds companies, the portfolio size can be fourteen or more.",
  "year": 1998,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "e5c20289d967f6543d0cfec0e1f8ecab",
  "timestamp": "2025-05-15T00:55:28.405892"
}