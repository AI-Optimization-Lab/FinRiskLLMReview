{
  "id": 3923,
  "title": "Do firm-level factors play forward-looking role for financial systemic risk: Evidence from China",
  "abstract": "This paper examines the firm-level driving factors of the systemic risk in the Chinese banking system. To more accurately estimate the systemic risk, we take asymmetric and fat-tailed financial returns into consideration. Our empirical results reveal that the Chinese banks' systemic risk contribution reached the highest level during the stock market crash in 2015. The panel regression results imply that banks' size, leverage, loans, non-performing loans and demand deposits positively drive their systemic risk contribution, and ROA, loan-loss provisions and time deposits shows a negative relationship. Moreover, individual banks VaR increase its systemic risk contribution, which means that the riskier individual bank contributes more to the systemic risk. The forward-looking role of the firm-level factors can potentially be used for macro-prudential regulation.",
  "year": 2019,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5bcdfeec0960d4c70d361ecff808795a",
  "timestamp": "2025-05-15T02:31:28.343859"
}