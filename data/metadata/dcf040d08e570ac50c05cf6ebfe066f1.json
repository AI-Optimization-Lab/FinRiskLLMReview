{
  "id": 2864,
  "title": "Financial distress and commodity hedging: Evidence from Canadian oil firms",
  "abstract": "Properly implemented risk management practices can help maximize shareholder value by reducing the expected cost of financial distress, and as such firms in deeper financial distress are expected to hedge more. However, empirical studies on such relationship have yielded mixed results. This paper documents the main determinant of hedging decisions using a newly assembled dataset for 92 Canadian-based, publicly traded oil extraction companies between 2005 and 2015. We adopt empirical techniques -Honore's semiparametric model and simultaneous equations with the minimum distance estimator-that explicitly deal with issues that frequently arise when studying hedging decisions, namely a clustering of firms that choose to not hedge at all and the endogeneity associated with concurrent determination of hedging and borrowing decisions. Even after controlling for endogeneity and other possible drivers of hedging, we still detect a positive and statistically significant relationship between a firm's perceived financial distress and the degree to which it hedges. (C) 2021 Elsevier B.V. All rights reserved.",
  "year": 2021,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "dcf040d08e570ac50c05cf6ebfe066f1",
  "timestamp": "2025-05-15T02:20:16.786159"
}