{
  "id": 2595,
  "title": "Gold, inflation and exchange rate in dollarized economies - A comparative study of Turkey, Peru and the United States",
  "abstract": "This paper conducts a comprehensive empirical study on gold's hedging potential against adverse movements of inflation and exchange rates for three countries: Turkey (highly dollarized), Peru (low dollarized) and United States (benchmark). With the use of quantile-on-quantile regression (QQR) and quantile-on-quantile correlation (QQCOR) models, we find that gold can offer protection against currency movements and inflation fluctuation at all times for Turkey and the United States, but fail to do so during Turkey's hyperinflationary period; in Peru, gold is a good hedge if the change of CPI is above 3.29% or currency depreciation rate is above 3.24%. We reveal that the conclusion of gold acting as a hedge (safe haven) against inflation or exchange rate volatility conjoin to both the gold market condition and the nature of macroeconomic shocks. Moreover, we use the QQCOR results into a portfolio hedging strategy and further confirm gold's usefulness in portfolio risk management in terms of return accumulation and risk reduction with respect to a currency only investment.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "f1be8a7cd4afd12f30ad0dffed606be0",
  "timestamp": "2025-05-15T01:08:41.826674"
}