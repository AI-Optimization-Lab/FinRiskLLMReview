{
  "id": 2266,
  "title": "Assessing systemic risk spillovers from FinTech to China's financial system",
  "abstract": "Today, the potential of FinTech in China is immense. After a prolonged period of dormancy, a blazing trail in finance surges. This study estimates the extent to which risk is transmitted from FinTech to various sub-industries within the Chinese financial sector, employing the GARCH copula quantile regression model. Our empirical findings indicate that FinTech exerts significant risk spillover effects on these financial sub-industries. Notably, at lower risk levels of 0.1 and 0.05, the securities and state-owned commercial banks sub-industries demonstrate the most substantial and least significant risk spillovers, respectively. Conversely, at the highest risk level of 0.01, the joint-stock commercial banks and securities exhibit the largest and smallest risk spillovers, respectively. Additionally, our analysis reveals that the dynamic risk spillovers for each financial sub-industry differ and reflect the influences of the stock market crash that occurred during 2015-2016. The implications of our study extend to portfolio managers and financial authorities, highlighting the importance of enhancing supervision and regulation of FinTech companies to uphold financial stability.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "9ee903705632e9e2590e2a1a997350e5",
  "timestamp": "2025-05-15T02:13:31.721704"
}