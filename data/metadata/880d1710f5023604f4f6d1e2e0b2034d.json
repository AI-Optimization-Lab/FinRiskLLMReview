{
  "id": 2347,
  "title": "Financial Literacy, Behavioral Biases and Participation in Crypto Asset Markets",
  "abstract": "We have conducted a survey to determine the relationship between financial literacy and crypto market participation. Furthermore, we have included overconfidence and risk lover tendency, which are considered behavioral biases, in our models along with financial literacy. Logistic regression results revealed striking findings on financial literacy and crypto market participation. Our analysis shows that financial literacy has a positive significant impact on crypto market participation. Specifically, advanced financial literates are more likely to engage in crypto markets than basic financial literates. Confidence in financial decisions and risk - lover tendency also positively affect crypto investments, however these effects are insignificant. Apart from this, we determined a relationship between participation behavior and other control variables such as age, gender and investing in traditional assets. Lastly, we focus on Turkish crypto investors and find significant differences in respect of demographic factors in financial literacy and behavioral biases",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "880d1710f5023604f4f6d1e2e0b2034d",
  "timestamp": "2025-05-15T02:14:19.653553"
}