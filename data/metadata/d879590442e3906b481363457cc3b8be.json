{
  "id": 5016,
  "title": "A clustering approach and a rule of thumb for risk aggregation",
  "abstract": "The problem of establishing reliable estimates or bounds for the (T)VaR of a joint risk portfolio is a relevant subject in connection with the computation of total economic capital in the Basel regulatory framework for the finance sector as well as with the Solvency regulations for the insurance sector. In the computation of total economic capital, a financial institution faces a considerable amount of model uncertainty related to the estimation of the interdependence amongst the marginal risks. In this paper, we propose to apply a clustering procedure in order to partition a risk portfolio into independent subgroups of positively dependent risks. Based on available data, the portfolio partition so obtained can be statistically validated and allows for a reduction of capital and the corresponding model uncertainty. We illustrate the proposed methodology in a simulation study and two case studies considering an Operational and a Market Risk portfolio. A rule of thumb stems from the various examples proposed: in a mathematical model where the risk portfolio is split into independent subsets with comonotonic dependence within, the smallest VaR-based capital estimate (at the high regulatory probability levels typically used) is produced by assuming that the infinite-mean risks are comonotonic and the finite-mean risks are independent. The largest VaR estimate is instead generated by obtaining the maximum number of independent infinite-mean sums. (C) 2018 Elsevier B.V. All rights reserved.",
  "year": 2018,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d879590442e3906b481363457cc3b8be",
  "timestamp": "2025-05-15T02:43:40.091485"
}