{
  "id": 2366,
  "title": "Fractal-Based Robotic Trading Strategies Using Detrended Fluctuation Analysis and Fractional Derivatives: A Case Study in the Energy Market",
  "abstract": "This paper presents an integrated robotic trading strategy developed for the day-ahead energy market that includes different methods for time series analysis and forecasting, such as Detrended Fluctuation Analysis (DFA), Rescaled Range Analysis (R/S analysis), fractional derivatives, Long Short-Term Memory (LSTM) Networks, and Seasonal Autoregressive Integrated Moving Average (SARIMA) models. DFA and R/S analysis may capture the long-range dependencies and fractal features inherited by the nature of the electricity price time series and give information about persistence and variability in their behavior. Given this, fractional derivatives can be used to analyze price movements concerning the minor changes in price and time acceleration for that change, which makes the proposed framework more flexible for quickly changing market conditions. LSTM, from their perspective, may capture complex and non-linear dependencies, while SARIMA models may help handle seasonal trends. This integrated approach improves market signal interpretation and optimizes the market risk through adjustable stop-loss and take-profit levels which could lead to better portfolio performance. The proposed integrated strategy is based on actual data from the Bulgarian electricity market for the years 2017-2024. Findings from this research show how the combination of fractals with statistical and machine learning models can improve complex trading strategies implementation for the energy markets.",
  "year": 2025,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d61972b3b4de11038235d43601266ffa",
  "timestamp": "2025-05-15T01:06:10.743053"
}