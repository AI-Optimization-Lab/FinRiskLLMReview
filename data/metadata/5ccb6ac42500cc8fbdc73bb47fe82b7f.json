{
  "id": 3070,
  "title": "Fear of Missing out on Financial Gains: Associations Between Fear of Missing Out, Problem Gambling, and Speculative Trading in College Students",
  "abstract": "In recent years a fear of missing out (FOMO) on short-term monetary gains through speculative trading has been highlighted as a driving force of financial behaviors. Additionally, increasing evidence has likened speculative trading to gambling. The current study sought to determine whether financial FOMO is linked to stock market and cryptocurrency trading activities and problem gambling severity in both traditional gambling and financial trading domains, among a sample of 258 college students. Results of binomial regression and hurdle model analyses found that financial FOMO was linked to participation in stock market and cryptocurrency trading. Financial FOMO was also associated with problem gambling severity in traditional gambling and the presence of gambling problems in the stock market trading domain. Our results suggest that financial FOMO may be a salient risk factor of problem gambling in traditional gambling domains and, to a smaller degree, in the speculative trading domain among young adults.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5ccb6ac42500cc8fbdc73bb47fe82b7f",
  "timestamp": "2025-05-15T02:22:25.059618"
}