{
  "id": 2531,
  "title": "Clustering with Bregman divergence in factoring business",
  "abstract": "In this contribution we characterize the customers of factoring company (in the factoring business there are two types of subject - client (supplier) who sells his receivables and customer (he is the primary debtor)). While the factoring company has enough information about its clients (credit report based on financial and non-financial data), about customers there are only few characteristics. But the risk of non-payment lies on the customers. Thereby, it is important to find some common similarities among the customers. This is done here by clustering with Bregman divergence. In the second section we describe shortly the principle of factoring business and in Section 4 possible customers' characteristics (turnover through factoring, pay morale, yield, per cent of offsets, etc.) The third section introduces Bregman divergence (definition and basic properties). Then we describe the procedure for clustering and apply it to the data about customers. The procedure was written in VBA MS Excel. We used data form the year 2007 and 2009 to answer additional question: is the structure of factoring customers same in the economic boom and in the depression?",
  "year": 2010,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6d06ac25bbfcd2155288f8c1f272ebc7",
  "timestamp": "2025-05-15T02:16:32.635192"
}