{
  "id": 3610,
  "title": "Assessing the impacts of tourism events on city development in China: a perspective of event system",
  "abstract": "Events boost the economy and generate tourist interest in host cities. Organizations involved in tourism will benefit from understanding how best to implement events which impact host cities' development. This paper explores the impact on host cities of sponsoring an event portfolio, comprising many different types of events. An empirical study analysed 230 tourism events hosted in mainland China. A multiple regression analysis was performed to test various hypotheses. The findings show that event 'strength' (i.e. the level of internationalization, number of participants, and continuity of events) can increase event attractiveness. Consequently, such events promote economic development in host cities. However, levels of government support were found to have negative impacts on host cities' economies. It is worth mentioning that the duration of tourism events has an inverted U-shaped relationship to economic development. As for spatial distribution of events, we found that locating them in provincial capitals had stronger positive impacts on host cities' economic development and attractiveness. Marketing strategies are proposed to meet target goals.",
  "year": 2020,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "f3d623bd2f63a78eee2c842062d96c4d",
  "timestamp": "2025-05-15T01:19:00.686497"
}