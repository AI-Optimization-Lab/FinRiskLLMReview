{
  "id": 1563,
  "title": "Dynamic Return Scenario Generation Approach for Large-Scale Portfolio Optimisation Framework",
  "abstract": "In this paper, we propose a complex return scenario generation process that can be incorporated into portfolio selection problems. In particular, we assume that returns follow the ARMA-GARCH model with stable-distributed and skewed t-copula dependent residuals. Since the portfolio selection problem is large-scale, we apply the multifactor model with a parametric regression and a nonparametric regression approaches to reduce the complexity of the problem. To do this, the recently proposed trend-dependent correlation matrix is used to obtain the main factors of the asset dependency structure by applying principal component analysis (PCA). However, when a few main factors are assumed, the obtained residuals of the returns still explain a non-negligible part of the portfolio variability. Therefore, we propose the application of a novel approach involving a second PCA to the Pearson correlation to obtain additional factors of residual components leading to the refinement of the final prediction. Future return scenarios are predicted using Monte Carlo simulations. Finally, the impact of the proposed approaches on the portfolio selection problem is evaluated in an empirical analysis of the application of a classical mean-variance model to a dynamic dataset of stock returns from the US market. The results show that the proposed scenario generation approach with nonparametric regression outperforms the traditional approach for out-of-sample portfolios.",
  "year": 2025,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "fbc46dab4c2b416625672b727604c6c4",
  "timestamp": "2025-05-15T00:57:12.646056"
}