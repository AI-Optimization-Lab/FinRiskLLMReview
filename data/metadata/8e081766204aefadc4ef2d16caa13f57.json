{
  "id": 358,
  "title": "会计-税收差异、未来盈余增长与投资者认知偏差——基于我国上市公司的经验证据",
  "abstract": "基于会计制度和税收法规两套体系而产生的会计-税收差异普遍存在且不可消除,本文以2008-2012年我国A股上市公司为研究样本,首先研究了会计-税收差异、暂时性会计-税收差异及永久性会计-税收差异与公司未来盈余增长的关系,再采用Fama-Mac Beth回归等方法观察投资者对会计-税收差异的反应,最后构建投资组合,运用长窗口事件研究法,计算购买并持有超额收益,观察投资者能否利用会计-税收差异所蕴含的信息获得超额收益。研究结果表明会计-税收差异、暂时性会计-税收差异与公司未来盈余增长显著相关,本文构建的投资组合能获得显著超额收益,市场对会计-税收差异信息存在误定价,这种投资者认知偏差是资本市场存在的一个\"市场异象\"。",
  "year": 2015,
  "source": "CNKI",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8e081766204aefadc4ef2d16caa13f57",
  "timestamp": "2025-05-14T22:11:50.068698"
}