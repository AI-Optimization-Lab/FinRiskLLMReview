{
  "id": 2051,
  "title": "Technology portfolio options for NASA missions using decision trees",
  "abstract": "The portfolio allocation problem is pervasive to all R&D endeavors (i.e. all basic research sponsors need to be able to justify the anticipated incremental benefit/cost/ratios). The approach suggested is to utilize decision tree(s) that capitalize on past experience of probabilistic fault/event tree analysis developed in nuclear industry. A mission concept is formalized in terms of a sequence of event trees linkages and alternatives with probabilities/figures of merit of success and associated R&D costs ascribed at each link. For example, a search for life mission on Europa would involve site reconnaissance, site selection, landing, deep drilling through ice, small autonomous submersibles traversing the purported sea under ice, and in-situ life detection. Many advanced technologies not currently available would be required including long duration survivable systems (power, thermal, radiation), minimal mass autonomous systems (systems-on-a-chip, autonomous safe precision landing), life detection (including planetary protection) and communication of science data (ocean/ice/surface/orbiter/earth). For the Europa case, as an example, an event tree has been prepared in software (which means it is easily manipulated) with a variety of alternative technologies expressed. Mission objectives have been iterated with science teams; technology probabilities and costs at each link have been deduced and documented using information from Office of Space Science databases. These numbers are assumed to be the best estimates at present, which need to be reviewed and updated by NASA domain experts. Once the decision tree has been formulated with associated probabilities/figures of merit and costs at each link, it is easy to show that the proper metric for prioritization per dollar is the derivative which represents the relative change in probability of success at a given link, per change in investment dollar at that link, then divided by the current probability/figure of merit of that link. This is intuitively plausible since one seeks to maximize the change in probability for a unit change in R&D investment, and the smaller the probability of a given link, the more room there is to improve. In this model wherein the mission probability is multiplicative of the probability of all links (i.e. uncorrelated events), the percentage change in any one link propagates linearly to the percentage change in the overall mission probability. Using this metric, one can then prioritize and explain the technology investment strategy to potential R&D sponsors, and have a systematic method for continuing to improve the overall database and gain community consensus. The decision tree approach described, developed for an example long term (e.g. 2025) mission, is amenable to the introduction of time dependence if one is to consider investment strategies for nearer term endeavors, or Programs comprised of time sequences of several projects.",
  "year": 2002,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a7154c94f808956dfed246d95a778f45",
  "timestamp": "2025-05-15T01:02:32.811808"
}