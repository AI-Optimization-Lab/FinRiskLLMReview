{
  "id": 1666,
  "title": "Combining Multiple Algorithms for Portfolio Management using Combinatorial Fusion",
  "abstract": "Several financial indicators or attributes are used to evaluate the performance of stocks when constructing and managing a portfolio. It is advantageous to utilize multiple algorithms for analyzing and combining these financial indicators, instead of using and optimizing a single algorithm. In this paper, we use the recently developed Combinatorial Fusion Analysis (CFA) to improve portfolio performance at both the attribute level and at the algorithm level. The first phase employs the following algorithms for attribute selection and combination: multiple regression, random forest, support vector machines, and neural networks, and combinatorial fusion according to either diversity strength or performance strength. The second phase involves combining the outputs from these multiple algorithms, using both score and rank combination. Our results suggest that different systems may be preferable for different portfolio sizes. Our results also directly demonstrate that combinatorial fusion can improve portfolio performance.",
  "year": 2017,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "0ddb1d4b2e6b6115e9d092e29b95a3b3",
  "timestamp": "2025-05-15T00:58:18.354889"
}