{
  "id": 6220,
  "title": "Decision-Making of Discretionary Goodwill Impairments-Evidence from Publicly Listed Firms in China",
  "abstract": "With the wave of M&A, total amount of goodwill balances has been accumulated to an enormous number in Chinese capital market. This study uses new independent variables to examine the determinants of goodwill impairments and to study the decision-making of discretionary goodwill impairments. First, this study investigates short-term and long-term market reaction of goodwill impairment announcements from 2019 to 2021 by using the event study method. Results indicate that goodwill impairments are only significantly associated with short-term cumulative abnormal return, on average. Then, based on the panel data of companies with goodwill balance from 2007 to 2020, logistic regression findings indicate that the companies without risk of financial loss have a higher probability of withdrawing goodwill impairments, on average; companies with stable operation have a higher probability of withdrawing goodwill impairments, on average. Result shows the discretion was used in goodwill impairments decision-making.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "970fa74b2b8bb8b9c74e7a6d0575d1b3",
  "timestamp": "2025-05-15T02:56:10.580519"
}