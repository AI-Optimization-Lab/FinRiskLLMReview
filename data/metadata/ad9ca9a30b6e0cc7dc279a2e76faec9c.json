{
  "id": 1715,
  "title": "Price delay and post-earnings announcement drift anomalies: The role of option-implied betas",
  "abstract": "In this study, we used informational advantage in the options market to investigate whether the option-implied equity risk developed by Chen, Chung, and Tsai (2016) - viewed as a type of time-varying beta - can help explain both the Hou and Moskowitz (2005) price delay premium and post-earnings announcement drift (PEAD). Our empirical results revealed a clear association between quintile portfolios with greater price delay premiums and higher option-implied betas, while the Fama-MacBeth regressions showed that the implied betas are positively related to future delay-based portfolio returns. Regarding the PEAD, we discerned a general increase in the mean of portfolio option-implied betas with standardized unexpected earnings portfolio drift. Our regression results support the notion that a portfolio's PEAD can be viewed as compensation for the variations in option-implied betas.",
  "year": 2020,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "ad9ca9a30b6e0cc7dc279a2e76faec9c",
  "timestamp": "2025-05-15T00:58:50.648421"
}