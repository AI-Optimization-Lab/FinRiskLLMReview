{
  "id": 14,
  "title": "A systematic approach to predicting NFT prices using time series forecasting and macroeconomic factors in digital assets",
  "abstract": "Non-fungible tokens (NFTs) have gained mainstream attention in the fintech community, but there is little research on their statistical properties. This study investigates the long-memory characteristics of NFT returns and volatility, focusing on their potential for predicting price movements. As NFTs do not conform to traditional models, understanding their unique features is crucial for comprehending complex market dynamics. This study aims to reveal the impact of macroeconomic factors on NFT prices, understand their correlation and develop predictive models using autoregression and artificial intelligence (AI) technology. This research utilized datasets from the Centers for Disease Control and Prevention (CDC), U.S. Bureau of Labor Statistics, Bureau of Economic Analysis, Christie's, Dune, and Google Trends. Correlation and p value tests revealed strong relationships between NFT prices and variables such as weekly volume, pandemics, inflation and security. The Baseline Model using autoregression with NFT volume, security and technology factors outperformed all other models demonstrating the speculative volatility of NFTs. The Transformer Model using transformers, an architecture used by ChatGPT, Gemini and Stable Diffusion, showed high accuracy with less feature selection and preprocessing efforts. This study provides a novelty using a systematic approach for researchers to perform financial forecasting and contributes to the scarce literature on NFTs. This research offers valuable insights to investors and private agents regarding the right economic conditions for NFT investments by reducing portfolio risks and making informed decisions. To the authors' best knowledge, this is the first study to utilize time-series transformers for forecasting NFTs based on macroeconomic factors.",
  "year": 2025,
  "source": "WOS",
  "area": "portfolio",
  "method": "LLMs",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "9883f5584069ad5fbb0998e7469c3ddc",
  "timestamp": "2025-05-15T00:38:16.187843"
}