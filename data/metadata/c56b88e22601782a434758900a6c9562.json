{
  "id": 2085,
  "title": "Wealth and risk implications of the Dodd-Frank Act on the US financial intermediaries",
  "abstract": "We contribute to the current regulatory debate by examining the wealth and risk effects of the Dodd Frank Act on U.S. financial institutions. We measure the effects of key legislative events of the Act by means of a multivariate regression model using the seemingly unrelated regression (SUR) framework. Our results indicate a mixed reaction by financial institutions during the various stages of the Act's legislative process. Further tests reveal that any positive reactions are driven by small and/or low risk institutions, while negative ones are consistent across subsets; except for investment banks. We also find market risk increases for most financial institutions that are dominated by small and/or low risk firms. The cross-section results reveal that large institutions fare better than their smaller counterparts and that large investment banks gain value at the expense of others. Overall, the Dodd-Frank Act may have redistributed value among financial institutions, while not necessarily reducing the industry's riskiness. (C) 2016 Elsevier B.V. All rights reserved.",
  "year": 2017,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c56b88e22601782a434758900a6c9562",
  "timestamp": "2025-05-15T02:10:59.032116"
}