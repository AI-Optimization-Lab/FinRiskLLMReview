{
  "id": 3625,
  "title": "Feed-In Forecasts for Photovoltaic Systems and Economic Implications of Enhanced Forecast Accuracy",
  "abstract": "The combination of governmental incentives and falling module prices has led to a rapid increase of globally installed solar photovoltaic (PV) capacity. Consequently, solar power becomes more and more important for the electricity system. One main challenge is the volatility of solar irradiance and variable renewable energy sources in general. In this context, accurate and reliable forecasts of power generation are required for both electricity trading and grid operation. This study builds and evaluates models for day-ahead forecasting of PV electricity feed-in. Different state-of-the-art forecasting models are implemented and applied to a portfolio of ten PV systems. More specifically, a linear model and an autoregressive model with exogenous input are used. Both models include inputs from numerical weather prediction and are combined with a statistical clear sky model using the method of weighted quantile regression. Forecasting-related economic implications are analyzed by means of a two-dimensional mean-variance approach. It is shown that enhanced forecast accuracy does not necessarily imply an economic gain.",
  "year": 2017,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "41a4a03657db4e82ab0a9d50c71a305f",
  "timestamp": "2025-05-15T01:19:00.754374"
}