{
  "id": 42,
  "title": "管理层股权激励对应计误定价的影响——来自中国A股市场的证据",
  "abstract": "利用2009-2020年中国A股上市公司数据，检验了管理层股权激励对应计误定价的影响。通过Mishkin检验发现低股权激励组应计误定价存在而高股权激励组应计误定价消失，同时，OLS回归结果发现股权激励减弱了自由裁量应计被市场高估的程度，说明股权激励缓解了应计误定价。进一步研究表明，股票型激励有助于缓解应计误定价，而股票期权激励会加剧应计误定价。上述结果说明中国A股上市公司股权激励整体表现出“利益趋同”效应，能够激励管理层通过信息传递动机的盈余管理提高应计盈余的估值有用性，从而缓解投资者对应计盈余的错误定价，但不同模式股权激励具有差异性作用。文章拓展了应计误定价影响因素的研究范围，同时为管理层盈余管理的信息传递动机提供了经验证据。",
  "year": 2022,
  "source": "CNKI",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "abc228c128490a4d73d3d872c3ef0b57",
  "timestamp": "2025-05-14T20:36:18.870584"
}