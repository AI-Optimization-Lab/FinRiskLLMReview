{
  "id": 4986,
  "title": "Quantifying longevity gaps using micro-level lifetime data",
  "abstract": "Using flexible Poisson regressions, we analyse a huge micro-level lifetime dataset from a Dutch pension fund, including categorical, continuous and spatial risk factors collected on participants in the fund. The availability of granular lifetime data allows us to quantify the longevity gap between the national population and the fund on the one hand, and between participants within the fund on the other hand. We identify the most important risk factors using statistical criteria that measure the in- and out-of sample performance of the regression models. We evaluate the financial performance of the models by introducing a novel type of backtest, which selects the risk factors that contribute most to an accurate prediction of future pension liabilities. For this portfolio, the most relevant risk factors (next to age and gender) are the salary, the time spent in disability and working at irregular hours. The resulting personalized mortality risk profiles show substantial differences between the remaining life expectancies for the most-favourable and least-favourable risk profiles. Our method to estimate these longevity gaps will help policy makers to assess wanted and unwanted consequences of longevity risk sharing in pension schemes.",
  "year": 2021,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "953941be1d922d353370c7d340c246ae",
  "timestamp": "2025-05-15T02:43:06.772501"
}