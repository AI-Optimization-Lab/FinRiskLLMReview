{
  "id": 74,
  "title": "Application of Support Vector Machines in debt to GDP ratio forecasting",
  "abstract": "This paper deals with the application of a novel neural network technique, Support Vector Machine (SVM), in financial time series forecasting. This study applies SVM to predict the debt to GDP ratio index. The objective of this paper is to examine the feasibility of SVM in foreign debt risk forecasting by comparing it with a back-propagation (BP) neural network. We choose Gaussian function as its Kernel function. The experiment shows that SVM outperforms the BP neural network based on the criteria of mean absolute error (MAE), mean absolute percent error (MAPE), mean squared error (MSE) and root mean square error (RMSE). Analysis of the experimental results proved that it is advantageous to apply SVMs to forecast debt to GDP ratio.",
  "year": 2006,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "041979c24942c5e61202cd3f15783ff0",
  "timestamp": "2025-05-15T01:46:39.508950"
}