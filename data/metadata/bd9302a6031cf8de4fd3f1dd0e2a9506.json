{
  "id": 3105,
  "title": "The Influence of Confidence and Social Networks on an Agent-Based Model of Stock Exchange",
  "abstract": "This paper aims to investigate the influence of investors' confidence in their portfolio holding relative to their social group and of various social network topologies on the dynamics of an artificial stock exchange. An investor's confidence depends on the growth rate of his or her wealth relative to his or her social group's average wealth. If the investor's confidence is low, the agent will change his or her asset allocation; otherwise, he or she will maintain it. We consider three types of social networks: Barabasi, small-world, and random. The actual stock markets' properties are recovered by this model: high excess kurtosis, skewness, volatility clustering, random walk prices, and stationary return rates. The networks' topologies are found to impact both the structuration of investors in the space of strategies and their performance. Among other characteristics, we find that (i) the small-world networks show the highest degree of homophily; (ii) as investors can switch to more profitable strategies, the best approach to make profitable investments is the chartist one in Barabasi and small-world topologies; and (iii) an unequal distribution and more significant relative wealth gains occur in the Barabasi network.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "bd9302a6031cf8de4fd3f1dd0e2a9506",
  "timestamp": "2025-05-15T01:13:45.166620"
}