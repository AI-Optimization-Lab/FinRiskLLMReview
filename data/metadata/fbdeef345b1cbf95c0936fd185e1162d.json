{
  "id": 2639,
  "title": "Improving the Prediction of Asset Returns With Machine Learning by Using a Custom Loss Function",
  "abstract": "Not all errors from models predicting asset returns are equal in terms of impact on the efficiency of the algorithm: a small error could trigger poor investment decisions while a significant error has no financial consequences. This economic asymmetry, critical for assessing the performance of algorithms, can usefully be replicated within the machine learning algorithms itself through the loss function to improve its prediction capability. . In this article: (a) we analyze symmetric and asymmetric loss functions for deep learning algorithms. We develop custom loss functions that mimic the asymmetry in economic consequences of prediction errors. (b) We compare the efficiency of these custom loss functions with MSE and the linear- exponential loss LinEx. (c) We present an efficient custom loss function that significantly improves the prediction of asset returns with improved risk-return metrics (like Sharpe ratio twice better), and which we confirm to be robust.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "fbdeef345b1cbf95c0936fd185e1162d",
  "timestamp": "2025-05-15T02:17:32.206947"
}