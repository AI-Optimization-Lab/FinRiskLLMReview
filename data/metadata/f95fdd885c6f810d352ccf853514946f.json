{
  "id": 5218,
  "title": "New Definition of Default-Recalibration of Credit Risk Models Using Bayesian Approach",
  "abstract": "After the financial crisis, the European Banking Authority (EBA) has established tighter standards around the definition of default (Capital Requirements Regulation CRR Article 178, EBA/GL/2017/16) to increase the degree of comparability and consistency in credit risk measurement and capital frameworks across banks and financial institutions. Requirements of the new definition of default (DoD) concern how banks recognize credit defaults for prudential purposes and include quantitative impact analysis and new rules of materiality. In this approach, the number and timing of defaults affect the validity of currently used risk models and processes. The recommendation presented in this paper is to address current gaps by considering a Bayesian approach for PD recalibration based on insights derived from both simulated and empirical data (e.g., a priori and a posteriori distributions). A Bayesian approach was used in two steps: to calculate the Long Run Average (LRA) on both simulated and empirical data and for the final model calibration to the posterior LRA. The Bayesian approach result for the PD LRA was slightly lower than the one calculated based on classical logistic regression. It also decreased for the historically observed LRA that included the most recent empirical data. The Bayesian methodology was used to make the LRA more objective, but it also helps to better align the LRA not only with the empirical data but also with the most recent ones.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "f95fdd885c6f810d352ccf853514946f",
  "timestamp": "2025-05-15T02:45:47.318303"
}