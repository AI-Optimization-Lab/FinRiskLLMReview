{
  "id": 3774,
  "title": "Predicting High Frequency Prices: New Evidence from the E-mini S&P 500 Futures Market",
  "abstract": "This paper develops and employs a robust and computationally efficient predictive model for forecasting high-frequency E-mini-S&P 500 Index futures prices. Four categories of stock prices are considered, namely Open, Low, High, and Closing prices. Utilizing Elastic Net Regression, we address key challenges inherent in high frequency financial time-series data, including noise and the risk of overfitting. A two-step methodological approach is employed: firstly, the optimal number of time-series lags is determined, thus transforming the time series to autoregressive, and secondly, the Elastic Net Regression model is trained and tested for predictive accuracy. The results reveal that three optimal time-series lags contribute significantly to the model, with the first lag being the most influential. Exceptional forecasting accuracy is achieved on the test set, resulting in Mean Absolute Percentage Errors (MAPE) ranging from 0.01 to 0.02%. The study opens avenues for future research, including the incorporation of additional financial indicators and adaptability to market shocks and volatility.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "ed5d9dbbf1ca359795700326ca090966",
  "timestamp": "2025-05-15T02:29:59.132670"
}