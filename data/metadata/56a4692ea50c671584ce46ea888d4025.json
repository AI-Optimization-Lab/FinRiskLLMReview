{
  "id": 47,
  "title": "Detecting and modelling the jump risk of CO2 emission allowances and their impact on the valuation of option on futures contracts",
  "abstract": "Modelling CO2 emission allowance prices is important for pricing CO2 emission allowance linked assets in the emissions trading scheme (ETS). Some statistical properties of CO2 emission allowance prices have been discovered in the literature ignoring price jumps. By employing real data from the ETS, this research first detects the jump risk using a jump test and then verifies jump effects in modelling CO2 emission allowance prices by comparing the in-sample and out-of-sample model performance. We suggest a model which can capture the statistical properties of autocorrelation, volatility clustering and jump effects is more appropriate for modelling CO2 emission allowance prices. We establish a general framework for pricing CO2 emission allowance options on futures contracts with these properties and find that the jump risk significantly affects the value of the CO2 emission allowance option on futures contracts. More importantly, we demonstrate that the dynamic jump ARMA-GARCH model can provide more accurate valuations of the CO2 emission allowance options on futures than other models in terms of pricing error.",
  "year": 2016,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "56a4692ea50c671584ce46ea888d4025",
  "timestamp": "2025-05-15T01:28:03.798750"
}