{
  "id": 2386,
  "title": "We choose what we like - Affect as a driver of electricity portfolio choice",
  "abstract": "Numerous countries are restructuring their electricity systems. Transitioning to electricity systems that are considered acceptable by the public requires that the public's preferences be taken into account. In this study, we investigate the type of energy technology portfolio that people prefer for Switzerland, and why they prefer it, when they are faced with two realistic constraints: (i) the limited domestic potential for the expansion of power plants and (ii) the requirement to not dismantle existing infrastructure. We find that the affect evoked by particular energy technologies is consistently the most important driver of the proportion of those technologies included in an energy portfolio. The regression models for the investigated technologies explain between 14% and 54% of the variance, providing strong support for the affect heuristic. We further find that concerns regarding environmental impacts, costs or climate change play an additional role for portfolio preferences. This is reflected in four different clusters we identified for the German-speaking Swiss population who potentially hold opposing views as to what they consider the best electricity mix. For policymakers, our findings suggest that positive affective reactions towards energy technologies are necessary, although concerns must also be considered if the implementation is to be widely accepted.",
  "year": 2018,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "f17db23a733cdd880fd8b772683efe50",
  "timestamp": "2025-05-15T01:06:10.822065"
}