{
  "id": 2517,
  "title": "Neural network based multiagent system for simulation for investing strategies",
  "abstract": "Recent years of empirical research have collected enough evidences that for efficient markets the process of lower-wealth accumulation by capital investment is approximated by log-normal and high-wealth range by Pareto wealth distribution. This research aims to construct a simple neural network (NN) based multiagent system of heterogeneous agents' targeted to get on the efficiency frontier by combining investments to the real life index funds and nonrisky financial assets, diversifying the risk and maximizing the profits. Each agent is represented by the different stock trading strategy according to his portfolio, saving and risk aversion preferences. The goal is, following empirical evidences from the real investment markets, to find enough proofs that NN-based multiagent system, in principle, has the same fundamental properties of real investment markets described by the log-normal, Pareto wealth and Levy stock returns distributions and can be used further to simulate even more complex social phenomena.",
  "year": 2007,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "144d35b0cd6fd4a81443689fd7b2beea",
  "timestamp": "2025-05-15T02:16:32.564358"
}