{
  "id": 3580,
  "title": "Management's tone change, post earnings announcement drift and accruals",
  "abstract": "This study explores whether the management discussion and analysis (MD&A) section of Forms 10-Q and 10-K has incremental information content beyond financial measures such as earnings surprises and accruals. It uses a classification scheme of words into positive and negative categories to measure the tone change in the MD&A section relative to prior periodic SEC filings. Our results indicate that short window market reactions around the SEC filing are significantly associated with the tone change of the MD&A section, even after controlling for accruals and earnings surprises. We show that management's tone change adds significantly to portfolio drift returns in the window of 2 days after the SEC filing date through 1 day after the subsequent quarter's preliminary earnings announcement, beyond financial information conveyed by accruals and earnings surprises. The drift returns are affected by the ability of the tone change signals to help predict the subsequent quarter's earnings surprise but cannot be completely attributed to this ability. We also find that the incremental information of management's tone change depends on the strength of the firm's information environment.",
  "year": 2010,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c42b19e1d6d8000974e8a9d8b34777e6",
  "timestamp": "2025-05-15T01:18:20.611652"
}