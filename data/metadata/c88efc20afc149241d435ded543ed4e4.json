{
  "id": 5268,
  "title": "Understanding sovereign credit ratings: Text-based evidence from the credit rating reports",
  "abstract": "We apply a novel approach to identifying the qualitative judgment of the rating committee in sovereign credit ratings by extending the traditional regression with new measures - sentiment and subjectivity scores - obtained by textual sentiment analysis methods. Using an ordered logit with random effects for 98 countries from 1995 to 2018, we find evidence that the subjectivity score provides additional information not captured by previously identified determinants of sovereign credit ratings, even after controlling for political risk, institutional strength, and potential bias. The results from the bivariate and multivariate analysis confirm differences in textual sentiment and subjectivity between emerging markets and advanced economies, as well as before and after the 2008 global financial crisis.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c88efc20afc149241d435ded543ed4e4",
  "timestamp": "2025-05-15T02:46:16.120773"
}