{
  "id": 3909,
  "title": "Financial Fraud Among Older Americans: Evidence and Implications",
  "abstract": "Objectives: The consequences of poor financial capability at older ages are serious and include making mistakes with credit, spending retirement assets too quickly, and being defrauded by financial predators. Because older persons are at or past the peak of their wealth accumulation, they are often the targets of fraud. Methods: Our project analyzes a module we developed and fielded on people aged 50 an older years in the 2016 Health and Retirement Study (HRS). Using this data set, we evaluated the incidence and prospective risk factors (measured in 2010) for investment fraud and prize/lottery fraud using logistic regression (N = 1,220). Results: Relatively few HRS respondents mentioned any single form of fraud over the prior 5 years, but 5.0% reported at least one form of investment fraud and 4.4% recounted prize/lottery fraud. Greater wealth (nonhousing) was associated with investment fraud, whereas lower housing wealth and symptoms of depression were associated with prize/lottery fraud. Hispanics were significantly less likely to report either type of fraud. Other suspected risk factors-low social integration and financial literacy-were not significant. Discussion: Fraud is a complex phenomenon and no single factor uniquely predicts victimization across different types, even within the category of investment fraud. Prevention programs should educate consumers about various types of fraud and increase awareness among financial services professionals.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "80cc7d3c47ea343b272502477787e52f",
  "timestamp": "2025-05-15T02:30:58.390341"
}