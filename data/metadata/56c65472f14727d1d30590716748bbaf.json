{
  "id": 1061,
  "title": "Credit Risk Scoring Using a Data Fusion Approach",
  "abstract": "Credit scoring is a vital task in the financial industry for assessing the creditworthiness of companies and mitigating credit risks. In recent years, machine learning algorithms have shown promising results in credit scoring by leveraging large amounts of tabular data. However, the traditional tabular data alone may not capture all the information relevant to credit scoring that is typically used by credit risk analysts. In this paper, we propose a novel approach for company credit scoring that integrates text and tabular data. Our method uses natural language processing techniques to extract key features from risk assessments made by credit risk experts which are then combined with financial data to predict the likelihood of default within a one-year horizon. We compare different Machine Learning based models for different text embedding techniques. Our results show that the fact of adding a textual feature improves the ability of the model to capture defaulted companies. More concretely, adding a categorical feature generated by the application of sentiment analysis over text risk assessments yields the best results.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "56c65472f14727d1d30590716748bbaf",
  "timestamp": "2025-05-15T01:58:08.688690"
}