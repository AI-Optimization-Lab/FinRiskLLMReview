{
  "id": 1395,
  "title": "Evaluation of Deep Learning Algorithms for Quadratic Hedging",
  "abstract": "We solve the quadratic hedging problem by deep learning in discrete time. We consider three deep learning algorithms corresponding to three architectures of neural network approximation: approximating controls of different periods by different feedforward neural networks (FNNs) as proposed by Han and Weinan (2016), using a single FNN with decision time as an input to approximate controls of different periods, and using a recursive neural network (RNN) to utilize historical information. We evaluate these algorithms under the discrete-time Black-Scholes model and the DCC-GARCH model for hedging basket options on portfolios of up to 100 assets with time to maturity up to one year. We compare them in terms of their hedging error on the test data, extent of overlearning, learned hedging strategy, training speed, and scalability. Our results favor the single FNN and RNN approximations overall; the multiple FNN approximation can fail for a large portfolio and a long maturity. We also evaluate the performance of the single FNN and RNN algorithms in a data-driven framework, where data is generated by resampling without assuming any parametric model.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "823bc98391c970cfb456fcea9dee467d",
  "timestamp": "2025-05-15T00:55:28.430667"
}