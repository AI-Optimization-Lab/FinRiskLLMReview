{
  "id": 1512,
  "title": "Applying Game Theory Rules to Enhance Decision Support Systems in Credit and Financial Applications",
  "abstract": "This paper examines the potential of applying Game Theory to Data Mining mechanisms to enhance the accuracy of predicting risk in financial settings. There have been many attempts made in the past to enhance Data Mining results using different methods including Game Theory principles. Despite the promising results of previous work in integrating Game Theory and Data Mining, further research is needed to explore the potential of creating a combined model that can be applied to a range of datasets to successfully enhance risk prediction. We use the German credit dataset using a variety of different data mining mechanisms then we propose a combined model to enhance the results using Game Theory principles and the decision tree J48 algorithm as a data mining mechanism.",
  "year": 2014,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7da52c5be93b7704fff345b6c96e6222",
  "timestamp": "2025-05-15T02:03:39.862495"
}