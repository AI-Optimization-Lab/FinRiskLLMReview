{
  "id": 3836,
  "title": "Blockchain Research and Development Activities Sponsored by the US Department of Energy and Utility Sector",
  "abstract": "This article provides an in-depth analysis of blockchain research in the energy sector, focusing on projects funded by the U.S. Department of Energy (DOE) and comparing them with industry-funded initiatives. A total of 110 funded activities within the U.S. power industry were successfully tracked and mapped into a newly developed categorization framework. This framework is designed to help research agencies to systematically understand their funded portfolio. Such characterization is expected to help them make effective investments, identify research gaps, measure impact, and advance technological progress to meet national goals. In line with this need, the proposed framework proposes a 2-D categorization matrix to systematically classify blockchain efforts within the energy sector.Under the proposed framework, the Energy System Domain serves as the primary classification dimension, categorizing use cases into 30 distinct applications. The second dimension, Blockchain Properties, captures the specific needs and functionalities provided by Blockchain technology. The aim was to capture blockchain's applicability and functionality: where and why blockchain? Principles behind the selection of the viewpoint dimensions were carefully defined based on consensus obtained through the Blockchain for Optimized Security and Energy Management (BLOSEM) project. The mapped results show that activities within the Grid Automation, Coordination, and Control (31.8%), Marketplaces and Trading (25.5%), Foundational Blockchain Research (19.1%), and Supply Chain Management (17.3%) domains have been actively pursued to date. The three leading specific use case applications were identified as Transactive Energy Management for Marketplaces and Trading, Asset Management for Supply Chain Management, and Fundamental Blockchain for Foundational Blockchain Research. The Marketplaces and Trading and Retail Services Enablement domains stood out as being favored by industry by a factor greater than 2 (2.3 and 2.6, respectively), yet there seemed to be little to zero investment from DOE. Approximately 76% of the total projects prioritized Immutability, Identity Management, and Decentralization and/or Disintermediation compared to Asset Digitization and/or Tokenization, Automation, and Privacy and/or Anonymity. The greatest discrepancies between DOE and industry were in Asset Digitization and/or Tokenization and Automation. The industry efforts (36% in Asset Digitization/Tokenization and 22% in Automation) was 14 times and 2.4 times, respectively, more intensive than the DOE-sponsored efforts, indicating a significant discrepancy in industry versus government priorities. Overall, quantifying DOE-sponsored projects and industry activities through mapping provides clarity on portfolio investments and opportunities for future research.",
  "year": 2025,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "22936e29077d4c746bd3ceae477a97ec",
  "timestamp": "2025-05-15T01:21:08.331255"
}