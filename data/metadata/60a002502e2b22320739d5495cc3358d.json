{
  "id": 4148,
  "title": "An evolving possibilistic fuzzy modeling approach for Value-at-Risk estimation",
  "abstract": "Market risk exposure plays a key role in risk management. A way to measure risk exposure is to evaluate the losses likely to incur when the assets prices of a portfolio decline. Most financial institutions rely on Value-at-Risk (VaR) estimates to measure downside market risk. This paper suggests an evolving possibilistic fuzzy modeling (ePFM) approach to estimate VaR. The approach is an extension of the possibilistic fuzzy c-means clustering and functional fuzzy rule-based modeling within the framework of incremental learning. Evolving possibilistic modeling employs memberships and typicalities to update the cluster structure and corresponding fuzzy rules using a statistical control distance-based criterion. A utility measure evaluates the quality of the current cluster structure and associated model. Data from the main global equity market indexes of United States, United Kingdom, Germany, Spain, and Brazil from January 2000 to December 2012 are used to estimate VaR using ePFM. The performance of ePFM is evaluated and compared with traditional VaR benchmarks such as Historical Simulation, GARCH, EWMA, and Extreme Value Theory based VaR, as well as with state of the art evolving approaches. The results suggest that ePFM is a potential candidate for VaR modeling because it achieves better results than the alternative approaches. (C) 2017 Elsevier B.V. All rights reserved.",
  "year": 2017,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "60a002502e2b22320739d5495cc3358d",
  "timestamp": "2025-05-15T02:33:42.100223"
}