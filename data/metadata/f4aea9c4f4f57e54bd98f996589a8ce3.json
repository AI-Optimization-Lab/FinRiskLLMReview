{
  "id": 2765,
  "title": "The challenge in managing new financial risks: adopting an heuristic or theoretical approach",
  "abstract": "The financial crisis began with the collapse of Lehman Brothers and the subprime asset backed securities debacle. Credit risk was turned into liquidity risk, resulting in a lack of confidence among financial institutions. In this article, we will propose a way to model liquidity risk and the credit risk in best practices. We will show that liquidity risk is a new type of risk and the current way to deal with it is based solely on observed variables without any theoretical link. We propose an heuristic approach to combine the numerous liquidity risk indicators with a logistic regression for the first time. In regards to credit risk, several articles prove that the best practice is to use an option model to appreciate this risk. We will present our methodology using stochastic diffusion for the interest rate because currently the yield curves aren't liquid. This approach is more relevant because the basis model in prior publications has a constant interest rate or a forward rate. Both models allow a better understanding of liquidity and credit risks and the further development of research deals with the link between these two financial risks.",
  "year": 2016,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "f4aea9c4f4f57e54bd98f996589a8ce3",
  "timestamp": "2025-05-15T02:19:08.333856"
}