{
  "id": 698,
  "title": "Intelligent Asset Allocation via Market Sentiment Views",
  "abstract": "The sentiment index of market participants has been extensively used for stock market prediction in recent years. Many financial information vendors also provide it as a service. However, utilizing market sentiment under the asset allocation framework has been rarely discussed. In this article, we investigate the role of market sentiment in an asset allocation problem. We propose to compute sentiment time series from social media with the help of sentiment analysis and text mining techniques. A novel neural network design, built upon an ensemble of evolving clustering and long short-term memory, is used to formalize sentiment information into market views. These views are later integrated into modern portfolio theory through a Bayesian approach. We analyze the performance of this asset allocation model from many aspects, such as stability of portfolios, computing of sentiment time series, and profitability in our simulations. Experimental results show that our model outperforms some of the most successful forecasting techniques. Thanks to the introduction of the evolving clustering method, the estimation accuracy of market views is significantly improved.",
  "year": 2018,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a60c8c616b5997e5d18c201cdff8f985",
  "timestamp": "2025-05-15T00:47:18.459751"
}