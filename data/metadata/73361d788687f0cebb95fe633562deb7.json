{
  "id": 5206,
  "title": "Predicting the Australian equity risk premium",
  "abstract": "This paper examines the predictive performance of a range of financial, economic, and sentiment variables that may predict the Australian All Ordinaries index equity risk premium using data for the last 28 years (1992-2020). The methods employed address a range of potential econometric biases that affect inference based on the predictive regression. Results show consistent in-sample and out-of-sample predictability evidence for various predictors, including the dividend yield, interest rates, and sentiment at selected forecasting horizons ranging from one month to one year. The analysis reveals new insights about time-varying predictability patterns in the Australian stock market and identifies phases of predictability in the time series. For several predictors, results show that mean-variance investors may rely on forecasts generated by the predictive regression to derive significant utility gains. Additional tests indicate that the predictability evidence is robust to the microstructure bias and variable selection bias for several predictors used in the analysis.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "73361d788687f0cebb95fe633562deb7",
  "timestamp": "2025-05-15T02:45:17.133207"
}