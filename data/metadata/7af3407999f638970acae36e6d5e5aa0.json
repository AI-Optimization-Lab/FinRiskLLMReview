{
  "id": 1285,
  "title": "Modified support vector machines in financial time series forecasting",
  "abstract": "This paper proposes a modified version of support vector machines, called C-ascending support vector machine, to model non-stationary financial time series. The C-ascending support vector machines are obtained by a simple modification of the regularized risk function in support vector machines, whereby the recent e-insensitive errors are penalized more heavily than the distant epsilon-insensitive errors. This procedure is based on the prior knowledge that in the non-stationary financial time series the dependency between input variables and output variable gradually changes over the time, specifically, the recent past data could provide more important information than the distant past data. In the experiment, C-ascending support vector machines are tested using three real futures collected from the Chicago Mercantile Market. It is shown that the C-ascending support vector machines with the actually ordered sample data consistently forecast better than the standard support vector machines, with the worst performance when the reversely ordered sample data are used. Furthermore, the C-ascending support vector machines use fewer support vectors than those of the standard support vector machines, resulting in a sparser representation of solution. (C) 2002 Elsevier Science B.V. All rights reserved.",
  "year": 2002,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7af3407999f638970acae36e6d5e5aa0",
  "timestamp": "2025-05-15T02:01:11.850625"
}