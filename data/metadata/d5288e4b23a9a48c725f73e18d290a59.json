{
  "id": 868,
  "title": "COVID-19: the impact of the pandemic fear on IPO underpricing",
  "abstract": "Purpose The purpose of this study is to assess how the information disclosed in prospectuses impacted the initial public offering (IPO) underpricing at a time of high government interference amid the ongoing pandemic. Design/methodology/approach The design of this study has several tracks, namely, a macro-level track, which is represented by the government measures to halt the pandemic; a micro-level track, which is followed by textual analysis of IPO prospectuses; and, finally, a machine learning track, in which the authors use state-of-the-art tools to improve their linear regression model. Findings The authors found that strict government anti-COVID-19 measures indeed contribute to the reduction of the IPO underpricing. Interestingly, the mere fact of such measures taking place is enough to take effect on financial markets, regardless of the resulting efficiency of such measures. At the micro-level, the authors show that prospectus sentiments and their significance differ across prospectus sections. Using linear regression and machine learning models, the authors find robust evidence that such sections as Risk factors, Prospectus summary, Financial Information and Business play a crucial role in explaining the underpricing. Their effect is different, namely, it turns out that the more negative Risk factors and Financial Information sentiment, the higher the resulting underpricing. Conversely, the more positive Prospectus summary and Business sentiments appear, the lower the resulting underpricing is. In addition, we used machine learning methods. Consisting of more than 580 IPO prospectuses, the study sample required modern and powerful machine learning tools like Isolation Forest for pre-processing or Random Forest Regressor and Light Gradient Boosting Model for modelling purposes, which enabled the authors to gain better results compared to the classic linear regression model. Originality/value At the micro level, this study is not confined to 2020, but also embraces 2021, the year of the record number of IPOs held. Moreover, in this paper, these were prospectuses that served as a source of management sentiment. In addition, the authors used a tailor-made government stringency index. At the micro level, basing the study on behavioural finance hypotheses, the authors conducted both separate and holistic analysis of prospectuses to assess investors' reaction to different aspects of IPO companies as well as to the characteristics of the IPOs themselves. Lastly, the authors introduced a few innovations to the research methodology. Textual analysis was conducted on a corpus of prospectuses included in a study sample. However, the authors did not use pre-trained dictionaries, but instead opted for FLAIR, a modern open-source framework for natural language processing.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d5288e4b23a9a48c725f73e18d290a59",
  "timestamp": "2025-05-15T01:56:17.467883"
}