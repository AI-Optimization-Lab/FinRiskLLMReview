{
  "id": 232,
  "title": "基于加权最小二乘拟蒙特卡罗的美式期权定价",
  "abstract": "美式期权定价具有后向迭代搜索特征,在最小二乘拟蒙特卡罗模拟(least-squares quasi-Monte Carlo,LSM)方法的基础上,本文通过随机 Faure 序列以及对偶变数法增加抽样数目,达到减小模拟方差的目的,用其计算标的资产价格,然后用加权最小二乘法进行回归,得到了加权最小二乘拟蒙特卡罗(weighted least-squares quasi-Monte Carlo,WLSQM)方法.从期权价值、标准差、运行时间几个方面比较方法的优劣,得出WLSQM 方法比 LSM 方法估计效果更优的结果,验证了 WLSQM 方法在美式期权定价上的有效性.",
  "year": 2008,
  "source": "CNKI",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6c92875f0da220db9b63f72b5dec3c2e",
  "timestamp": "2025-05-14T22:13:31.319224"
}