{
  "id": 2227,
  "title": "Neural networks vs logistic regression: a comparative study on a large data set",
  "abstract": "Neural networks and logistic regression have been among the most widely used AI techniques in applications of pattern classification. Much has been discussed about if there is any significant difference in between them but much less has been actually done with real-world applications data (large scale) to help settle this matter, with a few exceptions. This paper presents a performance comparison between these two techniques on the market application of credit risk assessment, making use of a large database from an outstanding credit bureau and financial institution (a sample of 180,000 examples). The comparison was carried out through a 30-fold stratified cross-validation process to define the confidence intervals for the performance evaluation. Several metrics were applied both on the optimal decision point and along the continuous output domain. The statistical tests showed that multilayer perceptrons perform better than logistic regression at 95% confidence level, for all the metrics used.",
  "year": 2004,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "fb4df664fc812eae4597c5a6d7391c08",
  "timestamp": "2025-05-15T02:12:50.980408"
}