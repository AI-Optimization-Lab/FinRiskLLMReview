{
  "id": 1,
  "title": "AI大模型赋能金融市场量化投资?基于另类数据与传统金融数据的研究",
  "abstract": "当前,以ChatGPT (chat generative pre-trained transformer)为代表的大语言模型迅速发展,被广泛用于股市投资算法交易、风险管理等多个领域.这为金融投资者提供了新的决策工具和投资途径.本文基于BERT (bidirectional encoder representation from transformers)模型和ChatGPT构建了适用于中国股票市场的投资交易模型,实现从财经新闻文本数据以及传统金融数据中获取交易信号.对于文本数据,首先抓取每日的财经新闻将其与对应的股票代码相匹配.其次将新闻文本数据输入至训练好的FTBERT (fine-tuning BERT)模型中,得到每条新闻的情感倾向,选择积极情感的财经新闻作为正的投资交易信号.对于传统金融数据,借助ChatGPT的高级解析能力,对中国股票市场的历史数据进行深入分析.通过调整prompt读取数据,从而构造出用于股票投资的关键因子,输出每日各股票的得分.最终根据不同数据类型得到每日各股票的投资交易信号,并将其作为构建投资组合的依据,构建有效的投资策略.实证结果表明, ChatGPT能有效判断文本情感倾向,且经过微调后的大语言模型能有效助力量化投资,为投资者带来超额收益.本研究尝试将大语言模型运用于金融投资领域,展现了其在生成股票投资信号方面的潜在价值.随着技术的不断发展和市场环境的变化,这种基于人工智能的投资策略将不断演进,为投资者创造更多价值.",
  "year": 2024,
  "source": "CNKI",
  "area": "portfolio",
  "method": "LLMs",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "59e3ef39a7cd2a29bae432fcc3cae9a0",
  "timestamp": "2025-05-14T22:20:52.546815"
}