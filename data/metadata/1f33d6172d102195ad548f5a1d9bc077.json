{
  "id": 3445,
  "title": "Bonus-Malus Systems in Vehicle Insurance",
  "abstract": "Actuaries in insurance companies try to design a tariff structure that will fairly distribute the burden of claims among policyholders. Therefore they try to find the best model for an estimation of the insurance premium. The paper deals with an estimate of a priori annual claim frequency and application of bonus-malus system in the vehicle insurance. In this paper, analysis of the portfolio of vehicle insurance data using generalized linear model (GLM) is performed. Based on large real-world sample of data from 67 857 vehicles, the present study proposes a classification analysis approach addressing the selection of predictor variables. The models with different predictor variables are compared by the analysis of deviance. Based on this comparison, the model for the best estimate of annual claim frequency is chosen. Then the bonus-malus (BM) system is used for each class of drivers and Bayesian relative premium is calculated. Finally a fairer premium for different groups of drivers is proposed. (C) 2015 The Authors. Published by Elsevier B.V.",
  "year": 2015,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1f33d6172d102195ad548f5a1d9bc077",
  "timestamp": "2025-05-15T01:17:25.414165"
}