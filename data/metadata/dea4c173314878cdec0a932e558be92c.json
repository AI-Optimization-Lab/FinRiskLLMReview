{
  "id": 5190,
  "title": "Improving the Business Plan Evaluation Process: the Role of Intangibles",
  "abstract": "One of the main objectives of the European MUSING project is to design and test software tools in order to support the activities of small and medium sized businesses. In this paper we examine financial risk management and, more specifically, the self-assessment of business plans. The role of intangible assets is discussed, and we report on how intangible assets can be collected, how they can be represented, taking into account their semantic relationships, and how they can be used to build an analytical tool for business plans. The basic technology embedded in the tool is the construction of classification trees, a well-known technique in inductive learning. We show how using knowledge of intangible assets can improve the construction of the classifier, as proved by the testing carried out so far.",
  "year": 2010,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "dea4c173314878cdec0a932e558be92c",
  "timestamp": "2025-05-15T02:45:17.102401"
}