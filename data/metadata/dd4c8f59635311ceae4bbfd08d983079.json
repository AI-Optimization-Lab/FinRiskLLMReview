{
  "id": 5836,
  "title": "Risk taking of Czech banks",
  "abstract": "Present study has focused on riskiness of providing loans as well as loans and reserves policies of banks in the Czech Republic. The paper shows how Czech banks are taking more credit risk due to dissolution of credit provisions to their incomes even in global financial crisis times. Higher concentration level of credit market and foreign owners of banks are typical for this small country. Estimated period is from 2002 to 2011. Methodologically it is used panel GMM regression, but on the other hand it is also used basic calculations from annual reports data of Czech major banks in this article. The author has argued that Czech banking sector is more risky, which is affected by foreign parent companies. Higher level of banks' earnings at the expense of the credit risk then could affect whole Czech economy, if the quality of debtors will decrease. There are also some policy implications based on results of the work. These implications are addressed to commercial banks, but also to the central bank of the Czech Republic. (C) 2013 The Authors. Published by Elsevier B.V.",
  "year": 2013,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "dd4c8f59635311ceae4bbfd08d983079",
  "timestamp": "2025-05-15T02:51:58.586746"
}