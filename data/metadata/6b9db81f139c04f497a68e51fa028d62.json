{
  "id": 304,
  "title": "Parallel lattice implementation for option pricing under mixed state-dependent volatility models",
  "abstract": "With the principal goal of developing an alternative, relatively simple and tractable pricing framework for accurately reproducing a market implied volatility surface, this paper presents two new asset price return models for option pricing and calibration. We consider a class of hidden Markov models based on Markov switching and a mixture model that embeds two diffusion processes whereby the underlying asset price dynamics obeys a mixed state-dependent non-linear volatility model. In particular, we study the so-called two-state mixture CEV diffusion model. Among possible nonlinear mixed state-dependent models, this proposed model offers a good balance between computational tractability and multiple parameter flexibility in the calibration process. The model also captures most of the empirical features such as leptokurtosis and volatility clustering of asset price returns. We present efficient higher order multinomial lattice methods for calibrating our model and for pricing European and American style equity options. Finally, we discuss two parallel algorithms for implementing the lattice methods: the shared memory and distributed memory algorithms.",
  "year": 2005,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6b9db81f139c04f497a68e51fa028d62",
  "timestamp": "2025-05-15T01:30:46.262042"
}