{
  "id": 5884,
  "title": "Factor affecting technical efficiency of the banking sector: Evidence from Ethiopia",
  "abstract": "An efficient bank is more robust to shocks, fosters competitiveness, and promotes stability of the financial system. This study estimates Ethiopia's commercial banks' level of efficiency and its determinants during the period 2014-2020. Data Envelopment Analysis (DEA), Malmquist DEA, and Tobit regression were employed to analyze the data. The result indicated that the average efficiency score of banks in the constant returns to scale (CRS), variable returns to scale (VRS), and scale efficiency (SE) models were 95.5%, 99.85%, and 96.95% , respectively. Furthermore, in the VRS model, a state bank is more efficient than private banks. During the study period, the Total Factor Productivity (TFP) of Banks improved by 1%. According to the Tobit model, the efficiency of banks grows with an increment in the number of branches, bank size, and credit risk. However, when, liquidity risk and the log of the fixed asset increase, bank efficiency will decrease. The level of capitalization, log of GDP, and inflation, on the other hand, do not influence bank efficiency. Therefore, banks should pay close attention to aspects that influence technical efficiency.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7712ece226a86bbaddd05fbbfccd7bf8",
  "timestamp": "2025-05-15T02:52:31.433332"
}