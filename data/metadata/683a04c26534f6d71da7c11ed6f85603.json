{
  "id": 2495,
  "title": "The Effect of COVID-19 on the Relationship between Idiosyncratic Volatility and Expected Stock Returns",
  "abstract": "This study examines the effect of the COVID-19 pandemic on the relationship between idiosyncratic volatility and expected stock returns. Using daily stock return data in the US market from the Center for Research in Security Prices (CRSP), we estimate monthly idiosyncratic volatility and investigate the effect of the COVID-19 pandemic at the portfolio and firm level. The results of portfolio analysis and cross-sectional regression show that the relationship between idiosyncratic volatility and subsequent stock returns switches from negative to positive during the pandemic period. Furthermore, we find that the relationship is robust to skewness for the before the pandemic and after pandemic periods. On the contrary, when we control for the one-month return reversal, the effect of idiosyncratic volatility on the subsequent stock returns becomes insignificant in both periods. Therefore, the short-term return reversal effect is the underlying reason for the relationship switching from negative to positive in the pandemic period. Our results are beneficial for investors and researchers.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "683a04c26534f6d71da7c11ed6f85603",
  "timestamp": "2025-05-15T01:07:35.663747"
}