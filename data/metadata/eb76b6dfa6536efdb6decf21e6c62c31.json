{
  "id": 158,
  "title": "稀疏网络下核范数回归的连续时间Smart Beta策略",
  "abstract": "大数据环境下,通过建立关联关系、网络关系可挖掘隐含在数据背后的深刻规律.文章通过图网络结构表征资产组合内部的稀疏与聚类关系,采用带网络结构和低秩稀疏的最小一乘策略有效盯住目标指数,深度发掘有效特征因子并优化连续时间资产组合,从而获得非完备市场下更优的Smart Beta性能和绩效.研究发现基于链路预测的稀疏网络结构能够更好地捕捉资产之间的非线性相依特性并实现有效的资产分类结果;稀疏分散回归和网络结构的特征提取方法能够深刻揭示资产潜含的内在特性;基于最小一乘法的核范数回归策略能够自适应地优化跟踪策略,从Alpha和Beta分离的角度有效地提升了投资组合的整体业绩,对非完备市场下资产配置优化和指数型投资组合管理具有重要的指导意义.",
  "year": 2021,
  "source": "CNKI",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "eb76b6dfa6536efdb6decf21e6c62c31",
  "timestamp": "2025-05-14T22:21:50.477990"
}