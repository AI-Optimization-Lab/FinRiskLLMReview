{
  "id": 2658,
  "title": "Enhancing Auto Insurance Risk Evaluation With Transformer and SHAP",
  "abstract": "The evaluation of auto insurance risks is a fundamental task for financial institutions, crucial for setting equitable premiums and managing risks effectively. Traditional machine learning algorithms often struggle to capture the intricate relationships necessary for accurate risk assessment. In contrast, deep learning methods, while capable of processing complex data structures, lack the ability to model feature interactions and provide interpretability, which are essential for transparent decision-making in the insurance industry. To address these challenges, we introduce the Actuarial Transformer (AT)-a pioneering model that leverages the self-attention mechanism of the Transformer architecture to meticulously map feature interactions. The AT integrates advanced residual models with tree-based methods, enhancing its predictive accuracy. Additionally, it incorporates the SHAP (SHapley Additive exPlanations) model, which uses Shapley values from cooperative game theory to ensure interpretability and transparency in its risk assessments. Our empirical analysis, conducted on a representative dataset of auto insurance risks, demonstrates the AT's superior performance in risk prediction. The SHAP analysis further validates the model's ability to prioritize features logically, providing clear insights into the decision-making process. The AT not only improves the precision of auto insurance risk evaluations but also enhances the interpretability of these evaluations, making it a valuable tool for both industry practitioners and clients.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "327a1a72946360b04c8d23c7226ece2a",
  "timestamp": "2025-05-15T02:17:32.300726"
}