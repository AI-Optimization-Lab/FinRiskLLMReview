{
  "id": 618,
  "title": "What do the AI methods tell us about predicting price volatility of key natural resources: Evidence from hyperparameter tuning",
  "abstract": "Volatility plays a significant role in pricing derivatives, managing portfolio risk, and using hedging strategies in the financial markets. As a result, it is imperative to precisely estimate the volatility of key natural resources, including crude oil, gold, copper, natural gas, and silver. The likelihood of some countries' budget deficits exceeding permissible levels increased due to recent uncertainties brought on by geo-political threats. This article employs a hybrid model of LSTM-GJR-GARCH (1,1) with hyperparameter tuning to forecast the volatility of the prices of significant natural resources using daily closing prices for crude oil, natural gas, silver, copper, and gold from January 2012 to July 2022. Our results demonstrate that, compared to utilising standard LSTM-GJR-GARCH, employing hyperparameter adjustment increases volatility predictions by an average of 40%-70%. We also looked at the connection between the geo-political risk index and the overall connectedness of natural resources. Our findings suggest that geo-political risk uncertainty does not account for the overall intercon-nectedness of natural resources' prices. Because they may better understand future volatility and manage their portfolios and budgets by estimating the price volatility of natural resources, our findings are important for politicians, governments, and investors.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "80a44dc099254a8bc441e7e6b303eeef",
  "timestamp": "2025-05-15T01:40:51.075083"
}