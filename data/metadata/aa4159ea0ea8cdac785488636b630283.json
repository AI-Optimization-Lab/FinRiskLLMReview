{
  "id": 1741,
  "title": "Efficient valuation of variable annuity portfolios with dynamic programming",
  "abstract": "The valuation of variable annuity portfolios presents major challenges for US life insurers. Recent studies propose machine learning and metamodeling techniques based on selecting a few representative guarantees. However, these methods face a critical trade-off between speed and accuracy. In contrast, I propose a recursive dynamic programming approach and demonstrate its ability to value a large and highly heterogeneous variable annuity portfolio with a high degree of accuracy and within a few seconds-even under stochastic interest rates and volatility-since the heavy computational burden can be fully front-loaded (in a one-time effort at the guarantee's pricing stage). This makes the dynamic programming approach ideally suited for all variable annuity applications, including the computation of reserves and capital requirements and to determine the insurer's hedging position. Moreover, dynamic programming can naturally incorporate optimal policyholder behavior into the insurer's valuation.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "aa4159ea0ea8cdac785488636b630283",
  "timestamp": "2025-05-15T00:59:22.887704"
}