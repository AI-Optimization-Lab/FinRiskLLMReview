{
  "id": 2977,
  "title": "The CEFR for Languages: Research Perspectives in Foreign Language Teaching in Engineering University",
  "abstract": "The European educational standards for foreign language teaching proved to be effective in the world. The article discusses the ways of integrating European educational standards for foreign language teaching into Russian educational system. The purpose of the work is to prove the effectiveness of adapting the CEFR for foreign languages in Russian federal educational standards. The research was conducted by analysis and comparison of the CEFR and the Federal State Educational Standards in Russia. In article we used the recourses and official materials of Council of Europe, European Language Portfolio and Federal educational standards. The CEFR classification of language proficiency includes six levels (from A1 to C2) and groups them into: Basic User, Independent User and Proficient User. In the article we have illustrated the activities and strategies for better understanding and conclusions of the two different approaches of educational standards for foreign languages. Based on the official materials, we have tried to prove the relevance in adopting the CEFR classification to help language teachers further raise the quality and effectiveness of language learning and teaching in first and foremost in real-world communicative needs for future engineers.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "87d5e4c68552887a4276c71396f58fad",
  "timestamp": "2025-05-15T01:12:09.226938"
}