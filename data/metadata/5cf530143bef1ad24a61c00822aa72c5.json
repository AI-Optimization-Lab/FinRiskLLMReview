{
  "id": 7604,
  "title": "Cytomegalovirus in Australian blood donors: seroepidemiology and seronegative red blood cell component inventories",
  "abstract": "BACKGROUND: Cytomegalovirus (CMV) can lead to severe disease in high-risk subpopulations. To prevent transfusion-transmitted CMV in these patient groups, the Australian Red Cross Blood Service maintains inventories of CMV-seronegative fresh blood components. STUDY DESIGN AND METHODS: Donor demographic data and CMV seroscreening results for all blood donations and blood components issued in Australia between financial years (FYs) 2008/09 to 2012/13 inclusive were obtained. Population estimates were also extracted for the calculation of age-weighted seroprevalence estimates. Linear regression was used to model trends in red blood cell (RBC) component acquisition and demand. RESULTS: The estimated age-weighted seroprevalence of CMV in 20- to 69-year old Australians was 76.12 +/- 0.13%, with higher seroprevalence in females and older age groups. Seroprevalence decreased over the study period, while the demand for CMV-seronegative RBC components increased. It was predicted that component acquisition may be insufficient by FY 2017/18 if current trends persist. CONCLUSION: These findings represent an evaluation of CMV seroepidemiology in Australia and form a basis to predict the future status of CMV-seronegative RBC component inventories. The results will serve to guide Blood Service operations and inform current international debate on CMV-safe blood components.",
  "year": 2016,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5cf530143bef1ad24a61c00822aa72c5",
  "timestamp": "2025-05-15T03:10:05.663201"
}