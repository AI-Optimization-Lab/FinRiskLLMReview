{
  "id": 426,
  "title": "A dynamic equilibrium model for U-shaped pricing kernels",
  "abstract": "This paper proposes a dynamic equilibrium model that can provide a unified explanation for the stylized facts observed in stock index markets such as the fat tails of the risk-neutral return distribution relative to the physical distribution, negative expected returns on deep OTM call options and negative realized variance risk premiums. In particular, we focus on the U-shaped pricing kernel against the stock index return, which is closely related to the negative call returns. We assume that the stock index return follows a time-changed Levy process and that a representative investor has power utility over the aggregate consumption that forms a linear regression of the stock index return and its stochastic activity rate. This model offers a macroeconomic interpretation of the stylized facts from the perspective of the sensitivity of the activity rate and stock index return on aggregate consumption as well as the investor's risk aversion.",
  "year": 2018,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "0e8a2e89865e7d969d878cd7adf002cf",
  "timestamp": "2025-05-15T01:31:50.748970"
}