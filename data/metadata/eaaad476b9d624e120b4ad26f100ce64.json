{
  "id": 140,
  "title": "Deep time series forecasting for enhanced index tracking",
  "abstract": "We consider the problem of enhanced index tracking whose objective is to construct a portfolio that maximizes the excess return and minimizes the tracking error between the returns of the tracking portfolio and a benchmark index. This problem is of considerable importance in the field of asset management as beating the market is known to be a notoriously difficult problem. We first identify the shortcomings inherent in the existing approaches to the problem, and then propose a general methodology to enhanced index tracking portfolio construction that moderates the degree of the shortcomings. Then, we present explicit construction schemes that utilize the latest advancements of the deep learning technology, and in particular, of long short-term memory networks that are designed to be efficacious for time series forecasting. Our proposed enhanced index tracking portfolios are empirically compared and contrasted with those of previously known proficient enhanced index tracking schemes over the benchmark of S&P 500. It is presented that our proposed portfolios outperform all other portfolios considered in this paper, and in particular, can beat the benchmark index substantially for a variety of cardinality constraint values tested.",
  "year": 2021,
  "source": "WOS",
  "area": "portfolio",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "eaaad476b9d624e120b4ad26f100ce64",
  "timestamp": "2025-05-15T00:32:31.574519"
}