{
  "id": 2191,
  "title": "A perspective on data-driven screening and discovery of polymer membranes for gas separation, from the molecular structure to the industrial performance",
  "abstract": "In the portfolio of technologies available for net zero-enabling solutions, such as carbon capture and low-carbon production of hydrogen, membrane-based gas separation is a sustainable alternative to energy-intensive processes, such as solvent-based absorption or cryogenic distillation. Detailed knowledge of membrane materials performance in wide operative ranges is a necessary prerequisite for the design of efficient membrane processes. With the increasing popularization of data-driven methods in natural sciences and engineering, the investigation of their potential to support materials and process design for gas separation with membranes has received increasing attention, as it can help compact the lab-to-market cycle. In this work we review several machine learning (ML) strategies for the estimation of the gas separation performance of polymer membranes. New hybrid modelling strategies, in which ML complements physics-based models and simulation methods, are also discussed. Such strategies can enable the fast screening of large databases of existing materials for a specific separation, as well as assist in de-novo materials design. We conclude by highlighting the challenges and future directions envisioned for the ML-assisted design and optimization of membrane materials and processes for traditional, as well as new, membrane separations.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a9366465af9c98bb2896fca1e9cb477e",
  "timestamp": "2025-05-15T01:04:27.355762"
}