{
  "id": 3233,
  "title": "CRISPR-Cas13 technology portfolio and alliance with other genetic tools",
  "abstract": "The exploitation of CRISPR-Cas systems especially CRISPR-Cas9 has led to radical advances in genome editing, gene activation, gene repression, protein imaging, and beyond. However, these applications are limited to tar-geting of DNA rather than RNA. CRISPR-Cas13 is the first reported CRISPR system targeting RNA and thus opens a new avenue for transcription regulation. While a plethora of reviews have systematically documented CRISPR-Cas9 toolbox, this review focuses on CRISPR-Cas13 family, covering aspects of classification, structures, response to foreign invaders, and genetic toolbox. In particular, we compare CRISPR-Cas13 with other RNA regulation tools such as RNA interference and antisense RNA technology to ponder the possibility of combining them to engineer hierarchical regulatory networks fulfilling novel functions. Lastly, we summarize the wide applications of CRISPR-Cas13 toolbox and the status quo that requires amelioration. Overall, this review charts a landscape of CRISPR-Cas13 technology portfolio to provide insights for gene regulation, metabolic engineering and synthetic biology.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8506577982e0ba109fad5dfe009be07b",
  "timestamp": "2025-05-15T01:14:55.055006"
}