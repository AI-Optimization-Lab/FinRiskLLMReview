{
  "id": 417,
  "title": "Six-factor asset pricing and portfolio investment via deep learning: Evidence from Chinese stock market",
  "abstract": "This paper proposes a long short-term memory (LSTM) neural network model to predict daily stock price movements based on asset pricing factors (i.e., the five factors proposed by Fama and French, and the short-term momentum factor). Based on three independent experiments, we systematically evaluate the explanatory power and the predictive power of the LSTM model by employing 3316 A-share listed companies in the Shanghai and Shenzhen stock exchanges from the in-sample period January 1, 2008 to December 31, 2019. Furthermore, we propose a four-step approach to dynamically update the underlying stocks in different portfolios based on the empirical findings. All portfolios are simulated using out-of-sample data (i.e., from January 1, 2020, to May 31, 2021) to avoid look-ahead bias. The trading results suggest that our dynamic investment strategies are superior to the benchmark index and are able to generate significant returns with relatively low risks.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "95fe76b06ad32a1f99a119876fbfa757",
  "timestamp": "2025-05-15T00:35:49.696718"
}