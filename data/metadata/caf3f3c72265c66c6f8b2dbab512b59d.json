{
  "id": 966,
  "title": "Efficiency of corporate debt financing based on machine learning and convolutional neural network",
  "abstract": "For the digital age today, the attack of financial data has a great risk, so it is necessary to establish several specific procedures to ensure the security and privacy of our financial data. To consider the security and reliability of financial data, we should consider the security of financial data transaction. Using the form of nodes to retain the copy data of financial accounting, in this way to prevent the failure of the network. At present, a new type of network data backup method is proposed, which can be applied to financial transactions at the present stage. Using machines to classify and distribute financial accounts and backup data on each node, assuming that one node's backup fails, it will not affect the failure of adjacent nodes. No longer afraid of losing transaction data and other problems. The system is backed up by convolution neural network (CNN) and ledger. It also includes backup of credit and debit transactions and backup of transaction ID mode in timestamp and simulation.It is used to ensure the classification of accounts, including block information of chain area, hash value of previous block and latter block, etc.",
  "year": 2021,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "caf3f3c72265c66c6f8b2dbab512b59d",
  "timestamp": "2025-05-15T01:57:29.807169"
}