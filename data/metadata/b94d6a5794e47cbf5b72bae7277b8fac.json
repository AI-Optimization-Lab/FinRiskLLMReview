{
  "id": 3679,
  "title": "Giving Unto Others: Private Financial Transfers and Hardship Among Families With Children",
  "abstract": "Prior research shows that financial assistance from family and friends is an important source of support for families with children. Research on financial transfers has largely focused on the recipients of transfers, however. In this study, using longitudinal data from the Fragile Families and Child Wellbeing Study (n similar to 16,000 person-waves), the authors examine the association between the provision of financial assistance to family and friends and material hardship. The results from pooled regression and fixed effects models indicate that providing financial transfers is associated with an increased risk of hardship. The most economically disadvantaged groups, single mothers, those in the bottom income tertile, and Black mothers are the most likely to experience hardship after giving a transfer. These findings have important implications for understanding why families may have difficulty meeting basic and essential needs and how social networks may exacerbate the challenges of escaping poverty and establishing economic self-sufficiency.",
  "year": 2017,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b94d6a5794e47cbf5b72bae7277b8fac",
  "timestamp": "2025-05-15T02:29:00.084759"
}