{
  "id": 3865,
  "title": "Risk Spillover Effect of Chinese Commercial Banks: Based on Indicator Method and CoVaR Approach",
  "abstract": "This paper took the thirteen listed commercial banks in China as the research objects, and used the financial risk measurement method CoVaR to study the risk spillover effect of commercial banks. Firstly, we employed an indicator-method to study the systemic importance changes of the listed banks in the normal and risk periods. It is found that the systemic importance is always closely related to the size of bank's assets. The application of Cluster Analysis on the indicator score showed that they were divided into two part: four state-owned banks and nine joint-stock banks groups. From the perspective of financial market risk spillover effect caused by relevance, the risk contributions of each bank to the bank groups were calculated by using the quantile regression and CoVaR approaches in two time periods. The results showed that not only the systemically important banks with big asset scale had great risk spillover effect, in the risk period, some of the smaller scale banks had a significant increase in the risk contribution, which would also become an important source of risk. From the normal period to risk period, the risk spillover effects of each bank were obviously enhanced, and the risk contagion between banks rose generally. Therefore, regulators should not only focus on large-scale banks, but also pay attention to those banks with high risk contributions. (C) 2017 The Authors. Published by Elsevier B.V.",
  "year": 2017,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "85723539dfcba4b1d5391fd5d1bc38a8",
  "timestamp": "2025-05-15T02:30:58.173824"
}