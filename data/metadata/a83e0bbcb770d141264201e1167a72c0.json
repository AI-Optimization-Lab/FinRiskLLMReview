{
  "id": 2059,
  "title": "Exploring the Generalizability of Deep Convolutional Neural Networks for Post-Hurricane Damage Assessment",
  "abstract": "Research on artificial intelligence (AI) and aerial imaging technologies has led to new opportunities in large-scale damage assessment for disaster management. As in other domains, the quality of AI predictions in disaster damage assessment primarily depends on the size, quality, and heterogeneity of training data. However, each disaster leaves behind a unique visual pattern of destruction that is influenced by both the intrinsic properties of the event (e.g., wind speed of a hurricane, ground acceleration of an earthquake) and the characteristics of the location it is taking place (e.g., building portfolio, terrain, vegetation cover). This makes the development and assessment of AI models for universal damage assessment extremely challenging, as the size and feature space of data collected from each disaster is distinctive. This study aims to evaluate and benchmark the generalizability of a damage assessment AI model across different hurricane events. The model is a stacked convolutional neural network (CNN) that is initially trained on aerial videos from Hurricane Dorian (2019) but is tested without retraining on unseen videos of several hurricanes in the 2017 season, including Harvey, Maria, and Irma. The testing accuracy and the square of Earth Mover's Distance (EMD2) values are used to evaluate the model generalizability. Overall, the model achieves 36.7% precision in detecting buildings and 43.1% accuracy in damage level classification. Additionally, EMD2 is found to be negatively correlated with accuracy. Results also indicate that the model generally has a better performance in predicting extreme ground truth labels (i.e., no damaged or destroyed buildings). This behavior is expected and consistent with how human annotators label buildings for damage since humans find these extreme cases more straightforward to label than cases where buildings have suffered intermediate damage levels.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a83e0bbcb770d141264201e1167a72c0",
  "timestamp": "2025-05-15T01:02:32.851213"
}