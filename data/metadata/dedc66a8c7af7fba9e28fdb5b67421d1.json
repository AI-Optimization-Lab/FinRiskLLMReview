{
  "id": 3776,
  "title": "Heterogeneity and fine wine prices: application of the quantile regression approach",
  "abstract": "This study addresses the price heterogeneity of the five first growths of Bordeaux. We apply the quantile regression (QR) approach with market segmentation based on wine bottle price quantiles. We compute the hedonic price of wine attributes for various price segments in the market. This approach is applied to a major dataset comprising approximately 50,000 transactions over the 2003-2017 period. The findings indicate that the relative hedonic prices of several wine attributes differ significantly among deciles. The implications of our results are manifold. Vintage and Parker grades have a strong impact on the variation in wine prices, and there is a hierarchy among the five first growths of Bordeaux. There is also a premium commanded by the reputation and experience of an auction house. Since the financial crisis of 2012-2013, investors have considered that the five first growths are overrated, save for the most expensive wines; for those most expensive ones, investors prefer scarcity to liquidity. These results are of import to several actors in the fine wine market: investors, for example, could use the findings herein to better diversify their wine portfolio, while auction houses could better anticipate their future sales based on consumers' expectation.",
  "year": 2020,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "dedc66a8c7af7fba9e28fdb5b67421d1",
  "timestamp": "2025-05-15T01:20:36.108333"
}