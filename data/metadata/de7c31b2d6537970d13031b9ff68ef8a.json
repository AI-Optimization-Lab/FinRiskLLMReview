{
  "id": 1128,
  "title": "Online Mining in Unstructured Financial Information: An Empirical Study in Bulletin News",
  "abstract": "The Internet produces massive financial unstructured textual information every day. How to utilize these unstructured data effectively is a challenging topic. In the background of A share T+0 and stock option promoting in the China security market, we present a model to recognize the risk and investment opportunity according to the massive online financial textual information. Since the key word vector is in extremely high dimension space and critical in influencing the performance of our forecast models, a manifold learning method is firstly applied to reduce its dimension while keeping essential features. By utilizing financial event study, we secondly apply support vector machines to predict the news type and sentiment value. The model can achieve the intelligent and instant match between textual news and the reactions of stock market. Our results provide prompt supports for financial practitioners to make investment decisions no matter they are in long or in short positions in the market.",
  "year": 2015,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "de7c31b2d6537970d13031b9ff68ef8a",
  "timestamp": "2025-05-15T01:59:21.597830"
}