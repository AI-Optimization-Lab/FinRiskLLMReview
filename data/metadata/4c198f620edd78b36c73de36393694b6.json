{
  "id": 235,
  "title": "中国系统性金融风险的区域传染效应",
  "abstract": "识别和化解区域层面的金融风险是防范系统性金融风险的重要方面。基于网络分析方法和SIRS传染模型考察2011—2020年中国各省系统性金融风险的关联关系、相对差异和传染情况发现，各省区域系统性金融风险表现为明显的网络形态，金融风险的省份关联愈加密切。地理位置较偏远、经济发展较慢、金融监管较宽松的省份是风险溢入的集中区域，地理位置较优越、经济发展较快、金融监管较严格的省份是风险溢出的主要区域。各省在系统性金融风险传染网络中可以聚类成“净溢出”板块、“经纪人”板块、“双向溢出”板块和“净溢入”板块等，各板块在风险传染网络中发挥的作用不同。因此，各省需提前制定预案并加强定向管控和监测，采取区域差别化的风险防控措施，促进区域经济协调改革和发展，以更好地防范化解区域系统性金融风险。",
  "year": 2022,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "4c198f620edd78b36c73de36393694b6",
  "timestamp": "2025-05-14T22:27:55.671463"
}