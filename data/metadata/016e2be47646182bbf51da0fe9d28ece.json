{
  "id": 3107,
  "title": "Increased Protection Versus the Cost of Increased Protection: Victimization and the Use of Protective Measures Against Identity Theft",
  "abstract": "Most identity theft victims experience no personal monetary loss or other financial problems; rational choice theory suggests that this could lead people to not change their behavior, increasing their future risk of victimization. Consequently, the current study will investigate if and how the severity and incidence of identity theft affect individuals' protective behavior using the 2016 Identity Theft Supplement (ITS) victimization survey. It uses ordinary least squares (OLS) regression to predict the number of protective measures practiced and multinomial logistic regression to predict self-reported motivation for use of protective measures. The results indicate that victims use more protective measures than nonvictims and that victimization has a greater impact if it occurs repeatedly and/or the victims personally lost money or experienced other financial problems. However, there is evidence of a threshold effect. The multinomial results indicate victims who lost money or experienced other financial problems are more likely to say they practice protective measures because of their victimization.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "016e2be47646182bbf51da0fe9d28ece",
  "timestamp": "2025-05-15T02:22:25.194083"
}