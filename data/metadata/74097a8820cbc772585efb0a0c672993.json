{
  "id": 1917,
  "title": "A cluster-based optimization approach to support the participation of an aggregator of a larger number of prosumers in the day-ahead energy market",
  "abstract": "Optimizing the participation of a large number of prosumers in the electricity markets is a challenging problem, especially for portfolios with thousands or millions of flexible resources. To address this problem, this paper proposes a cluster-based optimization approach to support an aggregator in the definition of demand and supply bids for the day-ahead energy market. This approach consists of two steps. In the first step, the aggregated flexibility of the entire portfolio is computed by a centroid-based clustering algorithm. In the second step, the supply and demand bids are defined by an optimization model that can assume the form of a deterministic or a two-stage stochastic problem. A case study of 10,000 prosumers from the Iberian market is used to evaluate and compare the performance of the bidding optimization models with and without pre-clustering. The numerical results show that the optimized bidding strategies outperform an inflexible strategy by more than 20% of cost savings. The centroid-based clustering algorithm reduces effectively the execution times of the bidding optimization problems, without affecting the quality of the energy bids.",
  "year": 2019,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "74097a8820cbc772585efb0a0c672993",
  "timestamp": "2025-05-15T01:01:06.151654"
}