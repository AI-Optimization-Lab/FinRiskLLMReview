{
  "id": 2502,
  "title": "Credit card fraud detection using a deep learning multistage model",
  "abstract": "The banking sector is on the eve of a serious transformation and the thrust behind it is artificial intelligence (AI). Novel AI applications have been already proposed to deal with challenges in the areas of credit scoring, risk assessment, client experience and portfolio management. One of the most critical challenges in the aforementioned sector is fraud detection upon streams of transactions. Recently, deep learning models have been introduced to deal with the specific problem in terms of detecting and forecasting possible fraudulent events. The aim is to estimate the unknown distribution of normal/fraudulent transactions and then to identify deviations that may indicate a potential fraud. In this paper, we elaborate on a novel multistage deep learning model that targets to efficiently manage the incoming streams of transactions and detect the fraudulent ones. We propose the use of two autoencoders to perform feature selection and learn the latent data space representation based on a nonlinear optimization model. On the delivered significant features, we subsequently apply a deep convolutional neural network to detect frauds, thus combining two different processing blocks. The adopted combination has the goal of detecting frauds over the exposed latent data representation and not over the initial data.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8133fc77cb7da568a16f8a58c392d586",
  "timestamp": "2025-05-15T01:07:35.688130"
}