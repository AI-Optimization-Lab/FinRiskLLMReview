{
  "id": 2448,
  "title": "A classification application for using learning methods in bank costumer's portfolio churn",
  "abstract": "To ensure the sustainability of customer-company loyalty and to control the financial flow of the company, studies involving customer loss or gain are carried out. When the studies are examined, it is seen that many methods are used for this purpose. Traditional machine learning methods are widely used in loss analysis due to their ability to process large amounts of customer data. In this study, the classification of the customer group in the banking sector has been made. In the context of the banking sector, this study delved into the classification of customer groups, utilizing a dataset and various machine learning models. Since the imbalance in the data set negatively affects the success parameters, the imbalance of the data is also discussed in this study. Within the scope of the study, the results obtained from the models analyzed by applying them to the dataset were evaluated by using F1-score, precision, recall, and model accuracy comparison tools. When the results are compared, it is seen that the proposed random oversampling (ROS)-voting (random forest [RF]-gradient boosting machines [GBM]) model has a better classification and prediction success than the other applied models and an accuracy rate of 95%.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b668078028a7c7c9a7512f04097b6364",
  "timestamp": "2025-05-15T01:07:02.969527"
}