{
  "id": 929,
  "title": "Hybrid Model for Large Scale Forecasting of Power Consumption",
  "abstract": "After the electricity liberalization in Europe, the electricity market moved to a more competitive supply market with higher efficiency in power production. As a result of this competitiveness, accurate models for forecasting long-term power consumption become essential for electric utilities as they help operating and planning of the utility's facilities including Transmission and Distribution (T&D) equipments. In this paper, we develop a multi-step statistical analysis approach to interpret the correlation between power consumption of residential as well as industrial buildings and its main potential driving factors using the dataset of the Irish Commission for Energy Regulation (CER). In addition we design a hybrid model for forecasting long-term daily power consumption on the scale of portfolio of buildings using the models of conditional inference trees and linear regression. Based on an extensive evaluation study, our model outperforms two robust machine learning algorithms, namely random forests (RF) and conditional inference tree (ctree) algorithms in terms of time efficiency and prediction accuracy for individual buildings as well as for a portfolio of buildings. The proposed model reveals that dividing buildings in homogeneous groups, based on their characteristics and inhabitants demographics, can increase the prediction accuracy and improve the time efficiency.",
  "year": 2017,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b9e050d80385ddc68c609ad2947a993f",
  "timestamp": "2025-05-16T17:50:25.544272"
}