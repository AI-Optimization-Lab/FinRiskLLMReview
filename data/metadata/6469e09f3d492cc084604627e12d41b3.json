{
  "id": 172,
  "title": "USD to INR Exchange Rate Prediction: A Deep Learning Approach for Forecasting Currency Exchange Rates Using Different Techniques of LSTM",
  "abstract": "This research paper investigates the application of three different Long Short-Term Memory (LSTM) techniques, for prediction of USD to INR exchange rates. Historical exchange rate data is collected, pre-processed, and relevant features are extracted. The LSTM models, known for their ability to capture temporal dependencies, are implemented and evaluated using performance metrics such as MAE, RMSE, and R-2. The trained models are utilized to forecast the exchange rate for a few days ahead. The results showcase the predictive capabilities of the models and provide valuable insights for financial decision-making and risk management in the currency market. This study contributes to the advancement of knowledge, enhancing both understanding and forecasting accuracy in the domain of USD to INR exchange rate dynamics.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6469e09f3d492cc084604627e12d41b3",
  "timestamp": "2025-05-15T01:35:04.364565"
}