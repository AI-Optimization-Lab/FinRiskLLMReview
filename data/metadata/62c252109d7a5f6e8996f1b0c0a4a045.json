{
  "id": 2443,
  "title": "Conditional volatility targeting strategy considering jump effects: Evidence from sustainable ESG equity index",
  "abstract": "This paper considers the sustainable ESG equity index in the proposed conditional volatility targeting strategy. The research first detects jump risk using a jump test and then extends Bongaerts et al. (2020) by addressing jump risk and employing different volatility models to project volatilities under the conditional volatility targeting strategy. To capture consideration of the fact that index return dynamics, we propose an ARMA-GARCH jump model that can capture the characteristics of jump persistence, autocorrelation, and volatility clustering according to the return of the sustainable equity index. Our numerical analyses reveal that the portfolio allocation using a sustainable equity index to predict volatility, combined with a conditional volatility target strategy, can achieve higher performance. Furthermore, the proposed ARMA-GARCH jump model can enhance the performance with conditional volatility targeting strategy.",
  "year": 2024,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "62c252109d7a5f6e8996f1b0c0a4a045",
  "timestamp": "2025-05-15T01:07:02.956801"
}