{
  "id": 918,
  "title": "Improving REITs Time Series Prediction Using ML and Technical Analysis Indicators",
  "abstract": "One of the most popular ways to reduce the risk of an investment portfolio is by holding shares of Real Estate Investment Trusts (REITs), which own and manage real estate. An important aspect of this process is to be able to forecast future REITs prices, as this allows investors to achieve higher returns at lower risk. This paper examines the performance of five different machine learning algorithms in the task of REITs price forecasting: Ordinary Least Squares Linear Regression, Support Vector Regression, k-Nearest Neighbours Regression, Extreme Gradient Boosting, and Long/Short-Term Memory Neural Networks. In addition to past REITs prices, we also use Technical Analysis indicators to assist the algorithms in the task of price prediction. While such indicators are very popular in stocks forecasting, they have never been used to forecast REITs. Our experiments show that (i) all ML algorithms produce low error and standard deviation, and are able to outperform the well-known statistical benchmark of AutoRegressive Integrated Moving Average (ARIMA), and (ii) the introduction of Technical Analysis (TA) indicators into the feature set leads to an error reduction of up to 50%.",
  "year": 2023,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "2f5393a47e70c45143d10f2c31223c3c",
  "timestamp": "2025-05-15T00:49:36.347352"
}