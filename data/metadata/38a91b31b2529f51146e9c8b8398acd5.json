{
  "id": 352,
  "title": "A gradient-boosting decision-tree approach for firm failure prediction: an empirical model evaluation of Chinese listed companies",
  "abstract": "Firm failure prediction is playing an increasingly important role in financial decision making. Ensemble methods have recently shown better classification performance than a single classifier, but the tree-based ensemble method for firm failure prediction has not been fully studied and remains to be further validated. Compared with other machine learning methods, it is more easily interpreted and requires little data preprocessing. In this paper, we employ a gradient-boosting decision-tree (GBDT) method to improve firm failure prediction and explain how to better analyze the relative importance of each financial variable. Because the GBDT deliberately adds new trees in order to correct errors made in previous steps, it has the potential to improve firm failure predictive performance. The influences of different parameters on model performance are analyzed in detail. Moreover, our proposed model is compared with four other popular ensemble methods. Our experimental results show that the GBDT outperforms these other methods in accuracy, precision, F - score and area under the curve. We therefore provide a full validation of GBDT, and believe that it is useful in controlling risk in financial risk management.",
  "year": 2017,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "38a91b31b2529f51146e9c8b8398acd5",
  "timestamp": "2025-05-15T01:49:41.094275"
}