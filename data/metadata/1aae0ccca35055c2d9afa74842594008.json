{
  "id": 1382,
  "title": "E-portfolio use and its effects on exam performance - a field study",
  "abstract": "The current field study investigated the weekly use of a reflective electronic (e-)portfolio by 1469 higher education students throughout a term and its effect on exam performance. Students' use of the e-portfolio elements as well as their self-reported use of several learning strategies were documented during a 9-week period. Regression analyses showed that over and above the continuous use and the weekly time spent on the e-portfolio, the reported use of cognitive strategies was a significant predictor for exam grade. Finally, students who used the e-portfolio outperformed their peers without e-portfolio use on the final exam. We discuss results with regard to future implementation and training of the e-portfolio use.",
  "year": 2020,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1aae0ccca35055c2d9afa74842594008",
  "timestamp": "2025-05-15T00:54:56.550598"
}