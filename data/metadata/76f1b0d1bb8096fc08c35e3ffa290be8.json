{
  "id": 6146,
  "title": "Measuring the scope of inter-firm agreements in the container shipping industry: an empirical assessment",
  "abstract": "In container shipping industry inter-firm agreements are becoming progressively popular as ship-owners share their slot capacity with commercial partners in order to have fully loaded container ships and reduce financial risk. This manuscript focuses on the cooperative agreements among shipping firms, i.e., vessel sharing and slot charter agreements within consortia and strategic alliances. Through a quantitative approach based on network and OLS regression analysis, we scrutinise the propensity to cooperate, the geographic extent and 'leveraging effect' generated by this commercial practise on the container-shipping industry. Results show that carriers, usually regarded as independent, are instead fairly cooperative, especially when involved in trade lanes originating from the Far East. Finally, we show that carriers increase their commercial objectives by leveraging the operated fleet capacity. We conclude with some implications for managers and practitioners as well as a discussion on limitations and future extensions of this study.",
  "year": 2014,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "76f1b0d1bb8096fc08c35e3ffa290be8",
  "timestamp": "2025-05-15T02:55:12.937806"
}