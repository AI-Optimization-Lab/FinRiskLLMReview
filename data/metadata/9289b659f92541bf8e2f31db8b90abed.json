{
  "id": 1685,
  "title": "'Too interconnected to fail' financial network of US CDS market: Topological fragility and systemic risk",
  "abstract": "A small segment of credit default swaps (CDS) on residential mortgage backed securities (RMBS) stand implicated in the 2007 financial crisis. The dominance of a few big players in the chains of insurance and reinsurance for CDS credit risk mitigation for banks' assets has led to the idea of too interconnected to fail (TITF) resulting, as in the case of AIG, of a tax payer bailout. We provide an empirical reconstruction of the US CDS network based on the FDIC Call Reports for off balance sheet bank data for the 4th quarter in 2007 and 2008. The propagation of financial contagion in networks with dense clustering which reflects high concentration or localization of exposures between few participants will be identified as one that is TITF. Those that dominate in terms of network centrality and connectivity are called 'super-spreaders'. Management of systemic risk from bank failure in uncorrelated random networks is different to those with clustering. As systemic risk of highly connected financial firms in the CDS (or any other) financial markets is not priced into their holding of capital and collateral, we design a super-spreader tax based on eigenvector centrality of the banks which can mitigate potential socialized losses. (C) 2012 Elsevier B.V. All rights reserved.",
  "year": 2012,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "9289b659f92541bf8e2f31db8b90abed",
  "timestamp": "2025-05-15T02:06:22.446211"
}