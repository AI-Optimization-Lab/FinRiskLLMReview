{
  "id": 2045,
  "title": "Capacity planning and resource allocation in assembly systems consisting of dedicated and reconfigurable lines",
  "abstract": "Companies with diverse product portfolio often face capacity planning problems due to the diversity of the products and the fluctuation of the order stream. High volume products can be produced cost-efficiently in dedicated assembly lines, but the assembly of low-volume products in such lines involves high idle times and operation costs. Reconfigurable assembly lines offer reasonable solution for the problem; however, it is still complicated to identify the set of products which are worth to assemble in such a line instead of dedicated ones. In the paper a novel method is introduced that supports the long-term decision to relocate the assembly of a product with decreasing demand from a dedicated to a reconfigurable line, based on the calculated investment and operational costs. In order to handle the complex aspects of the planning problem a new approach is proposed that combines discrete-event simulation and machine learning techniques. The feasibility of the approach is demonstrated through the results of an industrial case study. (C) 2014 The Authors. Published by Elsevier B.V.",
  "year": 2014,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "fa7afa2152131722d8ea859a809045e6",
  "timestamp": "2025-05-15T01:02:32.796820"
}