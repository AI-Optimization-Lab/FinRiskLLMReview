{
  "id": 392,
  "title": "ElectroBlock: Reinforcement Learning and Blockchain-based Energy Trade to Optimize Tariffs",
  "abstract": "Energy prices have increased by more than 62% globally on average, while power companies are trying to provide more affordable energy with different options: fixed-rate, slab-based tariffs, and Time-of-Use pricing. This article aims to combine blockchains, smart contracts, smart grids, energy forecasting through reinforcement learning, and energy trading between closed communities, bringing consumer savings. Our proposed model, ElectroBlock, uses the first 25 days of each month's energy usage history along with seasonal and exogenous factors to forecast the final end-of-month usage. Then with the forecast we can predict which customers are the most likely to be pushed to the next energy consumption slab and be charged at a higher rate for the remaining month. This allows these customers to be buyers, and seamlessly buy energy units from users who would sell, the energy units they are predicted to leave unused by the end of the month. Moreover, trading is done with WalletCoins, at a coin per kilowatt hour, but could also be traded directly for fiat currency. Furthermore, the power company makes a profit on every trade through transaction fees. Hence there is great incentive for both customers and power companies to adopt our proposed model. We integrated Hyperledger Fabric into our ElectroBlock prototype to store all customer data and prevent tampering with WalletCoin and consumption records. Finally, we did a performance analysis, on the actual cost savings based on a real-world dataset; and a scalability test for concurrency and customer bases on our prototype.",
  "year": 2024,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "75a82c890c8162e8b7aa8826dbb8a8d3",
  "timestamp": "2025-05-15T01:31:13.215948"
}