{
  "id": 4778,
  "title": "Patient Interest in Receiving Assistance with Self-Reported Social Risks",
  "abstract": "Objectives: This study evaluated how often patients who reported social risk factors requested assistance with these risks in an integrated health system. Methods: We examined how self-reports of risk related to stated desire for help with that risk reported during social risk screenings at Kaiser Permanente Northwest (KPNW). We examined how patient characteristics were associated with desire for help with each social risk domain using logistic regression. Results: Approximately 24% (n = 7,807) of the 32,865 KPNW members aged >= 18 years who were screened between June 1, 2017, and December 31, 2019, reported at least 1 social risk. More than half of patients who reported a risk were risk/help concordant (i.e., they also wanted help with that risk). The highest concordance (81.7%) was observed among patients reporting medical financial hardship. Several demographic, health, and other factors were associated with concordance across domains. Conclusions: Patients do not request assistance for all reported social needs. Our findings could help shape future work examining patients' reasons for not accepting assistance and developing interventions to help patients with high social risk more effectively. ( J Am Board Fam Med 2021;34:914-924.)",
  "year": 2021,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "79537a17edd9d1b12fc91cb8b3730dff",
  "timestamp": "2025-05-15T02:41:00.805585"
}