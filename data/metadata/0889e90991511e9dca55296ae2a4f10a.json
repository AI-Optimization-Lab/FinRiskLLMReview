{
  "id": 1,
  "title": "Time-sequencing European options and pricing with deep learning - Analyzing based on interpretable ALE method",
  "abstract": "In this paper, we investigated the feasibility of pricing European options with time-sequencing data processing method and deep learning models, based on two European options, the ETF50 options of China and the S&P 500 options of America. Four competing models were built to verify the improvement of the 1D-CNN and LSTM models on the option pricing task. Methods like cross-validations and statistical tests were also used to make our experiments more robust. Besides, in order to increase the stability and the interpretability of our pricing models, we selected the ALE method to interpret and analyze the behavior of the deep learning models. The empirical results indicate that, in both ETF50 option and S&P500 option pricing tasks, the 1D-CNN and LSTM models had significant advantages in forecasting accuracy and robustness under moneyness, trading date or maturity dimension irrespectively. Especially for the LSTM model, which has robust performance using different kinds of cross-validation methods. With the help of ALE method, we proved that the improved performance brought by the 1D-CNN and LSTM models could be attributed to their capability of capturing time-series information and their different emphasis on input features and lags.",
  "year": 2022,
  "source": "WOS",
  "area": "derivatives_pricing",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "0889e90991511e9dca55296ae2a4f10a",
  "timestamp": "2025-05-15T01:26:26.261019"
}