{
  "id": 2185,
  "title": "A comparison of non-Gaussian VaR estimation and portfolio construction techniques",
  "abstract": "We propose a multivariate model of returns that accounts for four of the stylised facts of financial data: heavy tails, skew, volatility clustering, and asymmetric dependence with the aim of improving the accuracy of risk estimates and increasing out-of-sample utility of investors' portfolios. We accommodate volatility clustering, the generalised Pareto distribution to capture heavy tails and skew, and the skewed-t copula to provide for asymmetric dependence. The proposed approach produces more accurate VaR estimates than seven competing approaches across eight data sets encompassing five asset classes. We show that this produces portfolios with higher utility, and lower downside risk than alternative approaches including mean-variance. We confirm that investors can substantially increase utility by accounting for departures from normally.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "95104883f7ffb6fd0ac51c29569bdeb7",
  "timestamp": "2025-05-15T02:12:17.397340"
}