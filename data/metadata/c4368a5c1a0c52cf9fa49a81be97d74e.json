{
  "id": 1223,
  "title": "An algorithmic model for retail credit portfolio segmentation",
  "abstract": "Under the new Basel bank capital framework, a bank must group its retail exposures into multiple segments with homogeneous risk characteristics. The US regulatory agencies believe that a bank may use the internal models, including the loan-level risk parameter estimates such as probability of default and loss given default, to group exposures into the resultant segments with homogeneous risk attributes. In contrast to the conventional decision tree method, we propose a new algorithmic technique for retail consumer loan portfolio segmentation. This new technique identifies the optimal number of segments, sorts the individual loan exposures into the various segments, and then leads to a greater degree of risk homogeneity in comparison with the baseline equal-bin and quantile-bin schemes. Furthermore, we analyze the Monte Carlo implied asset correlation values for the retail loan segments over time to help assess the implications for bank capital measurement. Our recommended method for retail credit portfolio segmentation results in some capital relief that serves as an incentive for the bank to invest in this alternative segmentation. This positive outcome accords with the core principle of statistical conservatism that is enshrined in the Basel regulatory requirements for bank capital measurement.",
  "year": 2013,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c4368a5c1a0c52cf9fa49a81be97d74e",
  "timestamp": "2025-05-15T00:53:09.959233"
}