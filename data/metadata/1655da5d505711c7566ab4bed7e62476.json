{
  "id": 885,
  "title": "MNFS-FPM: A novel memetic neuro-fuzzy system based financial portfolio management",
  "abstract": "Portfolio management consists of deciding what assets to include in a portfolio given the investor's objectives and changing market and economic conditions. The always difficult selection process includes identifying which assets to purchase, how much, and when. This paper presents a novel Memetic Neuro-fuzzy System for Financial Portfolio Management (MNFS-FPM) which emulates the thinking process of a rational investor and generates the optimal portfolio from a collection of assets based on a chosen investment style. The system consists mainly of two modules: the Generic Self-Organizing Fuzzy Neural Network realizing Yager inference (GenSoFNN-Yager), to predict the expected return of each asset, and a memetic algorithm using simplex local searches (MA-NM/SMD) to determine the optimal investment weight allocation for all assets in the portfolio. Experimental results on Dow Jones Industrial Average (DJIA) stocks show that the proposed system yields better performance compared to that of existing financial models: statistical mean-variance analysis and Capital Asset Pricing Model (CAPM).",
  "year": 2007,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1655da5d505711c7566ab4bed7e62476",
  "timestamp": "2025-05-15T00:49:03.265527"
}