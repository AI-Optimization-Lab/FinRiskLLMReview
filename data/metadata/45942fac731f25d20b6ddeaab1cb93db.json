{
  "id": 518,
  "title": "Optimizing Resource Allocation with Intelligent Agents",
  "abstract": "Playing the stock market is one of the many frontiers of applied artificial intelligence. The problem of optimizing asset allocation within a portfolio to yield a return above the market is a hard problem. Current approaches include multi-agent systems in which the task of gathering data, predicting trend and choosing assets are divided between specialized cooperative agents that simulate the environment of an investment fund. This paper builds upon existing models to create ORACLIA (Optimizing Resource Allocation and Capital Lucrativeness with Intelligent A gents), a multi-agent system for portfolio optimization in the Brazilian Stock Market (Bovespa). A multi-agent architecture was de fined and implemented with the use of machine learning classification models to generate buy and sell signals based on the success or failure probability of a predefined strategy. The classification models are able to predict success or failure of a strategy with over 80% accuracy for certain assets. These models successfully replaces the traditional approach that uses regression to predict stock price trends. Backtesting results, conducted in a simulated environment with actual stock market data from 2015 and 2016, show ORACLIA achieves net results up to eight times higher than single asset portfolios or general benchmarks such as Ibovespa, the main index for Bovespa.",
  "year": 2017,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "45942fac731f25d20b6ddeaab1cb93db",
  "timestamp": "2025-05-15T00:44:21.042836"
}