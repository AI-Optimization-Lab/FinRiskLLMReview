{
  "id": 7658,
  "title": "Social support and depression during a global crisis",
  "abstract": "Depression rates have risen globally during the COVID-19 pandemic. While social support is a known protective factor, more research is needed to quantify the extent to which social support could reduce depression risk during a global crisis and identify which types of support are most helpful and for whom. We analysed longitudinal data from 69,066 participants in the All of Us Research Program who completed COVID-19 Participant Experience surveys between May and July 2020, including measures of perceived social support and depressive symptoms. Using mixed-effects logistic regression models, we tested associations between social support (overall and its subtypes) and elevated depressive symptoms, and assessed potential effect modifiers. Approximately 16% of participants experienced elevated depressive symptoms. Overall social support was associated with a 55% lower odds of depression. Emotional/informational support and positive social interactions showed strongest protective associations with depression, followed by tangible support. Combinations of support subtypes showed a dose-response gradient, with higher levels across all three subtypes linked to over a sixfold reduction in depression odds. Significant effect modifiers included sex, age, pre-pandemic mood disorder and pandemic-related financial stressors. Enhanced social support across multiple domains could benefit individuals with higher risks for depression, supporting a precision prevention approach.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "50a23977efa85147138f776204d5a041",
  "timestamp": "2025-05-15T03:10:33.139953"
}