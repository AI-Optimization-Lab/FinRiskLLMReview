{
  "id": 1520,
  "title": "Self-Organizing Swarm (SOSwarm) for Financial Credit-Risk Assessment",
  "abstract": "This paper applies a self-organizing Particle Swarm algorithm, SOSwarm, for the purposes of credit-risk assessment. SoSwarm can be applied for unsupervised clustering and for classification. In the algorithm, input vectors are projected into a lower dimensional map space producing a visual representation of the input data in a manner similar to a self-organizing map (SOM). However, unlike SOM, the nodes (particles) in this map react to input data during the learning process by modifying their velocities using an adaptation of the Particle Swarm Optimization velocity update step. The utility of SoSwarm is tested by applying it to two important credit-risk assessment problems drawn from the domain of finance, namely the prediction of corporate bond ratings and the prediction of corporate failure. The results obtained on the financial benchmark problems are highly-competitive against those of traditional classification methodologies. The paper makes a further contribution showing that the canonical SOM can be explored within the PSO paradigm. This highlights an important linkage between the heretofore distinct literatures of SOM and PSO.",
  "year": 2008,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "6a2d83ba77705e4ca5763184673dfae8",
  "timestamp": "2025-05-15T02:04:20.014401"
}