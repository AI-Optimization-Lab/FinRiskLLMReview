{
  "id": 1267,
  "title": "Application of SVM-KNN Using SVR as Feature Selection on Stock Analysis for Indonesia Stock Exchange",
  "abstract": "Stocks are known as high-risk and high-return investments. Forecasting stock prices movement is the challenging problem for researchers and financial analysts. Support Vector Machines (SVM) with K Nearest Neighbor (KNN) approach will be applied to forecast stock prices of a listed company in Indonesia Stock Exchange (IDX). The stock data are collected from January 2013 to December 2016. First, this paper used feature selection method to select important indicators from thirteen technical indicators using Support Vector Regression (SVR). Second, the stock data are classified using SVM to represent profit or loss and the output helps to find the best nearest neighbor from the training set. Next, stock prices are forecasted using KNN. The performance of this model is computed using Root Mean Square Error (RMSE) and relative error. In this case, the experiment result shows that three indicators selected from feature selection present good prediction capability and the accuracy for close prices prediction is 93.33 % accurately.",
  "year": 2018,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c6a716b761ae837c10f1b559d2944dbd",
  "timestamp": "2025-05-15T02:01:11.794549"
}