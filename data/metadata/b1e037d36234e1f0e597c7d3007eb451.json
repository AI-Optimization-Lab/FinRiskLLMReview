{
  "id": 929,
  "title": "基于巨额损失波动性的最优投资决策研究",
  "abstract": "近年来伴随着金融市场广度与深度的不断拓展,频发的金融风险对世界经济及金融市场造成了巨大损失(如美国次贷危机),学者和投资者越来越关注规避小概率巨额风险的最优投资决策及有潜力风险资产遴选方法的研究.文章就此开展了如下研究:首先以损失超过VaR部分的条件期望CVaR作为投资者愿意承担风险的上限,改进投资预算约束为非紧约束,提出了基于巨额损失波动性的投资组合模型.数值试验验证了模型具有良好的收敛性,即使在生成较少数量的情景下也能快速收敛;当投资者对最低期望收益率要求不高时,不必全额投入预算资金就能满足投资者对预期收益的要求;随着投资者对最低期望收益率要求的提高,更多预算资金被投入可能带来更高收益的风险资产,资金预算约束逐渐趋于紧约束;模型给出的最优投资决策在样本外各滚动窗口测试中均实现了较高收益,但发生巨额损失的波动程度却显著降低,达到了控制小概率极端风险的目的.其次,结合常规基本面分析法和聚类分析技术,提出了风险资产的遴选方法.该方法适用于跨市场跨行业不同品种间风险资产的筛选,可兼顾同一类别内资产的同质性及不同类别资产间的异质性,以此达到分散化解风险的目的.实证研究表明,该方法遴选出的\"少量\"风险资产在各项评价指标上具有明显的优势,聚类技术的引入大大降低了投资者选择资产的难度.",
  "year": 2016,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b1e037d36234e1f0e597c7d3007eb451",
  "timestamp": "2025-05-14T22:34:27.116126"
}