{
  "id": 393,
  "title": "An Efficient Botnet Detection Methodology using Hyper-parameter Optimization Trough Grid-Search Techniques",
  "abstract": "In recent years botnets have become serious threats for Internet-based services and infrastructures. Prompt detection can mitigate the impact of several attacks including Denial-of-service (DDoS), spam, phishing, identity theft, and information leaking. Actually, physical and logical appliances over networks are addressing botnet discovery. However, signature-based solutions require constant updates from repositories, which is a concerning setback given the rapid development of new threats. An alternative solution to overcome such limitations is to train Machine Learning (ML) algorithms to accurately identify malicious network flows. Although the state-of-the-art provide significant advances in botnet classification using machine and statistical learning, the algorithm selection procedure is not properly defined nor explained. In this work an algorithm portfolio is built to test performance between several supervised learning algorithms using a hyper-parameter optimization technique known as Grid Search. Experimental results prove that by tuning algorithms trained models can outperform detection accuracy in an efficient manner.",
  "year": 2019,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5e74a1239b429d72a1942b77855f8059",
  "timestamp": "2025-05-15T00:43:10.466336"
}