{
  "id": 3694,
  "title": "Does political connection distort competition and encourage corporate risk taking? International evidence",
  "abstract": "We investigate the impact of political connection on corporate risk-taking by connected firms, their industry counterparts, as well as non-rival firms from 48 countries. We find that political connection induces higher risk taking by connected firms. By contrast, we do not find evidence that political connection, with the attendant potential competitive distortions in the industry, induces higher risk taking by competitors. We focus on non-financial industries. Our results are consistent with the hypothesis that the inability to avail themselves of political rents compels the non-connected rivals to adopt more conservative strategies. However, large rival firms, generally considered to be too-important-to-fail, exhibit evidence of higher risk taking. The top size quartile industry rivals take as much risk as the politically connected firms. The higher risk exhibited by large rivals of politically connected firms suggests that our baseline regression results of lower risk-taking among rivals of politically connected firms are biased upward by firms that would be considered too-big-to-fail. This finding also suggests that the too-big-to fail phenomenon is not unique to banks. Our results are robust to the use of alternative measures of risk, to the exclusion of privatized and state-owned firms, and to controlling for the effects of financial crisis.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "db7f6a79d4a4409da56742eea81d536b",
  "timestamp": "2025-05-15T02:29:00.171993"
}