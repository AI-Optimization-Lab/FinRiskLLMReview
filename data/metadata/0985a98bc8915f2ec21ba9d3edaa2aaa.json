{
  "id": 4849,
  "title": "Stablecoins as the cornerstone in the linkage between the digital and conventional financial markets",
  "abstract": "Do stablecoins mean anything to risk management across financial markets? We answer this question by examining the interrelationships between stocks, treasuries, stablecoins, and cryptocurrencies in nonparametric quantile-causality-in-means and quantile-on-quantile regression models. Differently from previous studies of stablecoins' price volatility, we focus on stablecoins' trade volumes. The results extend the evidence on stablecoins' responses to other crypto assets, whose declining returns, through the phenomena designated by us as flight-to-cryptosafety, fuel the stablecoins' market capitalization. Issuance of new stablecoins, because of their backing by conventional safe assets, raises US Treasuries' demand. And then, decaying Treasury yields cause flight-to-safety from stocks to Treasuries. Results from the quantile-based fixed-parameter models are robust to the dynamic connectedness metric based on the time-varying parameter vector auto-regression (TVP-VAR) framework.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "0985a98bc8915f2ec21ba9d3edaa2aaa",
  "timestamp": "2025-05-15T02:41:32.801066"
}