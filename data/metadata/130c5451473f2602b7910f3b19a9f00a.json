{
  "id": 3122,
  "title": "Automated Transformation from Competency List to Tree: Way to Competency-Based Adaptive Knowledge E-Evaluation",
  "abstract": "Featured Application The proposed model for competency list transformation to competency tree can be applied in e-learning and e-evaluation systems to ensure integration between systems, using competency lists and competency trees and, at the same time, providing some additional adaptability for the existing e-learning systems. E-learning is rapidly gaining its application. While actively adapting student-oriented learning with the competency evaluation model, the standard of competency support in existing e-learning systems is not implemented and varies. This complicated integration of different e-learning systems or transfer from one system to another might be challenging if the student had his or her competency portfolio in list form, while another system supports tree-based competency portfolios. Therefore, in this paper, we propose a transformation model dedicated to converting the competency list to a competency tree. This solution incorporates text processing and analysis, competency ranking based on Bloom's taxonomy, and competency topic area clustering. The case analysis illustrates the model's capability to generate a qualitative tree from the competency list, where the average accuracy of competency assignment to appropriate parent competency is 72%, but, in some cases, it reaches just 50%.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "130c5451473f2602b7910f3b19a9f00a",
  "timestamp": "2025-05-15T01:13:45.242743"
}