{
  "id": 3139,
  "title": "Asset-liability management using GARCH (1,1)",
  "abstract": "Asset liability management is very important process in every company. More popular it is in banks and insurance companies because they take on liabilities and invest the proceeds from these liabilities in assets. Every business company seeks to get any cash inflows but of course on this way it meets laibilities. Asset liability management helps to identify companie's financial risks, to quantify financial risks and iteractions between risks and compare alternative financial solutions. Managers of financial firms more and more focus on assset liability risk. It is so not because the value of assets might fall or the value of liabilities might rise. It is because of the capital depletion. Such a process can be succeed by narrowing of the difference between assets and liabilities. Heteroskedasticity is an important concept in finance because asset returns in the capital and commodity markets often exhibit heteroskedasticity. The prices exhibit non-constant volatility, but periods of low or high volatility are generally not known in advance. But when we are able to predict a price volatility in any period then prices exhibit unconditional heteroskedasticity. Estimates of asset return volatility are used to assess the risk of many financial produsts. Accurate measures and reliable forecasts of volatility are crucial for derivative pricing techniques as well as trading and hedging strategies that arise in portfolio allocation problems. Financial return volatility data is influenced by time dependent information flows which result in pronounced temporal volatility clustering. These time series can be parameterised using Generalised Autoregressive Conditional Heteroskedastic (GARCH) models. It has been found that GARCH models can provide good in-sample parameter estimates and, when the appropriate volatility measure is used, reliable out-of-sample volatility forecasts.",
  "year": 2005,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "b13cd8cd1be1bcfaee7293f36c75c41a",
  "timestamp": "2025-05-15T02:22:56.754891"
}