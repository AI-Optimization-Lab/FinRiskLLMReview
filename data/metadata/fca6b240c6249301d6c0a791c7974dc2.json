{
  "id": 3997,
  "title": "Developing GEP tree-based, Neuro-swarm, and whale optimization models for evaluating Groundwater Seepage into Tunnels: A Case Study",
  "abstract": "Groundwater inflow is a critical subject within the domains of hydrology, hydraulic engineering, hydrogeology, rock engineering, and related disciplines. Tunnels excavated below the groundwater table, in particular, face the inherent risk of groundwater seepage during both the excavation process and subsequent operational phases. Groundwater inflows, often perceived as rare geological hazards, can induce instability in the surrounding rock formations, leading to severe consequences such as injuries, fatalities, and substantial financial expenditures. The primary objective of this research is to explore the application of machine learning techniques to identify the most accurate method of forecasting tunnel water seepage. The prediction of water loss into the tunnel during the forecasting phase employed a tree equation based on gene expression programming (GEP). These results were compared with those obtained from a hybrid model comprising particle swarm optimization (PSO) and artificial neural networks (ANN). The Whale Optimization Algorithm (WOA) was selected and developed during the optimization phase. Upon contrasting the aforementioned methods, the Whale Optimization Algorithm demonstrated superior performance, precisely forecasting the volume of water lost into the tunnel with a correlation coefficient of 0.99. This underscores the effectiveness of advanced optimization techniques in enhancing the accuracy of groundwater inflow predictions and mitigating potential risks associated with tunneling activities.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "fca6b240c6249301d6c0a791c7974dc2",
  "timestamp": "2025-05-15T02:31:58.684625"
}