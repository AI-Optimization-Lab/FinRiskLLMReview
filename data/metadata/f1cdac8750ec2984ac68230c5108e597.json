{
  "id": 2603,
  "title": "Value investing across asset classes",
  "abstract": "The objective of this study is to derive two long-only value risk premium multi-asset strategies, as well as naive investment strategies (equal weighted investment strategy and 60/40 portfolio) which are back tested out-of-sample and evaluated for the period from January 1995 to December 2015. The obtained results exhibit superior excess return for the absolute and relative value strategies compared to the naive investment strategies, and display more effective risk-reward ratios due to better distributed returns. However, the findings emphasise concurrently that the value investing strategies should be applied as a complementary portfolio instrument in the context of dynamic asset allocation due to value phase shifts to mitigate drawdown. Moreover, the overall statistical inference presents that the most influential determinants are interest rate related factors like the inflation rate and macro-economic driven variables, such as the I.S.M. Composite Index and the oil price. The multivariate regression analysis also shows a strong dependency between the value strategy returns, stocks and commodities.",
  "year": 2019,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "f1cdac8750ec2984ac68230c5108e597",
  "timestamp": "2025-05-15T01:08:41.858979"
}