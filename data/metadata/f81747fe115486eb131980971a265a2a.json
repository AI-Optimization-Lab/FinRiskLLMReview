{
  "id": 974,
  "title": "Globally Explainable AutoML Evolved Models of Corporate Credit Risk",
  "abstract": "Corporate credit ratings are one of the most relevant financial indicators in credit risk analysis. These are generated by different rating agencies which base their methodologies on the use of various financial variables of each company and the experience of their analysts; their impact on the market is of such importance that their mismanagement can trigger major financial crises such as the one that occurred in 2008. Along with this, the great importance of internal models for calculating credit risk and international regulations and agreements seek to have a level of explainability of the methods used to perform this risk management. This paper proposes the use of Automatic Machine Learning (AutoML) as a tool for the generation of a machine learning model that performs a prediction of corporate credit ratings using data from balance sheets, financial statements, and descriptive information about the company. The main contribution of this work lies in the development of the level of interpretability of each model as a second goal to be optimized with a global measure of explainability, allowing the generation of models that can better explain their results.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "f81747fe115486eb131980971a265a2a",
  "timestamp": "2025-05-15T01:57:29.823114"
}