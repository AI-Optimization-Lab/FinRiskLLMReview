{
  "id": 6414,
  "title": "Experience of a single healthcare system with screening mammography before and after COVID-19 shutdown",
  "abstract": "Purpose: To evaluate COVID-19's longitudinal impact on screening mammography volume trends.Methods: HIPAA-compliant, IRB-approved, single institution, retrospective study of screening mammogram volumes before (10/21/2016-3/16/2020) and greater than two years after (6/17/2020-11/30/2022) a statemandated COVID-19 shutdown (3/17/2020-6/16/2020) were reviewed. A segmented quasi-poisson linear regression model adjusting for seasonality and network and regional population growth compared volume trends before and after the shutdown of each variable: age, race, language, financial source, risk factor for severe COVID-19, and examination location.Results: Adjusted model demonstrated an overall increase of 65 screening mammograms per month before versus a persistent decrease of 5 mammograms per month for >2 years after the shutdown (p < 0.0001). In subgroup analysis, downward volume trends were noted in all age groups <70 years (age < 50: +9/month before vs. -7/ month after shutdown; age 50-60: +17 vs. -7; and age 60-70: +21 vs. -2; all p < 0.001), those identifying as White (+55 vs. -8, p < 0.0001) and Black (+4 vs. +1, p = 0.009), all financial sources (Medicare: +22 vs. -3, p < 0.0001; Medicaid: +5 vs. +2, p = 0.006; private insurance/self-pay: +38 vs. -4, p < 0.0001), women with at least one risk factor for severe COVID-19 (+30 vs. -48, p < 0.0001), and screening mammograms performed at a hospital-based location (+48 vs. -14, p = 0.0001).Conclusion: The screening mammogram volume trend more than two years after the COVID-19 shutdown has continued to decline for most patient populations. Findings highlight the need to identify additional areas for education and outreach.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8016428da47061149d8f27ca78e1f55a",
  "timestamp": "2025-05-15T02:58:05.573053"
}