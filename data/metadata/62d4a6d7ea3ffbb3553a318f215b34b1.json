{
  "id": 2907,
  "title": "Too much of a good thing? Alliance portfolio size and alliance expansion",
  "abstract": "Drawing from the organizational learning, transactions costs and resource based theories, we argue that the larger the Alliance Portfolio Size (APS) of the partners, the lower the likelihood that the alliance will be expanded. We also argue for an interactive effect by proposing that high levels of experience will neutralize some (but not all) of the detrimental impact of a large APS on the likelihood of alliance expansion. We deploy the case-control methodology to select a sample of 182 alliances from the biotechnology and pharmaceutical industries spanning the period 1980-2004. Results from logistic regression analyses support our predictions. (C) 2016 Elsevier Ltd. All rights reserved.",
  "year": 2017,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "62d4a6d7ea3ffbb3553a318f215b34b1",
  "timestamp": "2025-05-15T01:11:48.340348"
}