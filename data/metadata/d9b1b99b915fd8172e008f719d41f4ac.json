{
  "id": 3703,
  "title": "Solving group multi-objective optimization problems by optimizing consensus through multi-criteria ordinal classification",
  "abstract": "In this paper good consensus is associated with a high level of group satisfaction and a low level of dissatisfaction. A new method to improve consensus through a reformulation of the original group multi objective optimization problem is introduced. For each point in the feasible decision set, the level of satisfaction or dissatisfaction from each group member is determined by multi-criteria ordinal classification approaches. Intense satisfaction and dissatisfaction are both modeled. Group satisfaction (respectively, dissatisfaction) is maximized (resp. minimized), finding the best possible consensus solutions in correspondence with a current stage of closeness among group members' preferences, judgments, beliefs, and conservatism attitudes. Logic models are introduced to evaluate conditions for best consensus. Imperfect information (imprecision, uncertainty, ill-definition, arbitrariness) on the values of objective functions, required and available resources, and decision model parameters is handled by using interval numbers. Two different kinds of multi-criteria decision model are considered: i) an interval outranking approach and ii) an interval weighted-sum value function. The proposal can handle very general cases of group multi-objective optimization problems. The method is illustrated by solving a real size multi-objective project portfolio optimization problem using evolutionary computation tools. (c) 2021 Elsevier B.V. All rights reserved.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d9b1b99b915fd8172e008f719d41f4ac",
  "timestamp": "2025-05-15T01:20:03.403788"
}