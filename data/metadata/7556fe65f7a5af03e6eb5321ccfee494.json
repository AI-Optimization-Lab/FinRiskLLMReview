{
  "id": 3789,
  "title": "Estimating the cost of capital through time: An analysis of the sources of error",
  "abstract": "Practitioners needing estimates of a firm's equity cost of capital have long relied on the Capital Asset Pricing Model (CAPM). Recent evidence casts renewed doubt on the validity of the CAPM and beta. However, there is not much evidence to gauge the importance of the rejections of the CAPM in a practical decision-making context. This paper presents evidence on the sources of error in estimating required returns over time. We use a number of proxies for the true mean variance efficient portfolio, allowing that the CAPM is the wrong model. The analyst is assumed to rely on a standard market index. We find that the great majority of the error in estimating the cost of equity capital is found in the risk premium estimate, and relatively small errors are due to the risk measure, or beta. This suggests that analysts should improve estimation procedures for market risk premiums, which are commonly based on historical averages. This can be done by using regression models, such as:have appeared in the recent finance literature, or by purchasing forecasts from firms that specialize in producing them.",
  "year": 1998,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7556fe65f7a5af03e6eb5321ccfee494",
  "timestamp": "2025-05-15T01:20:36.138434"
}