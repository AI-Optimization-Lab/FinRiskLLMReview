{
  "id": 1256,
  "title": "Hubris or talent? Estimating the role of overconfidence in Chinese households' investment decisions",
  "abstract": "We document the extent to which overconfidence in one's financial literacy (FL overconfidence) plays a role in households' reported financial risk aversion and their actual investment behavior, using data from the China Household Finance Survey. We measure FL overconfidence by estimating the gap between people's self-reported financial literacy and their objectively measured financial knowledge. Our results indicate that FL overconfidence is negatively associated with self-reported financial risk aversion. Additionally, FL overconfidence is positively associated with the likelihood of having a brokerage account, holding risky financial instruments (other than just stock), and a proportion of assets allocated towards risky assets. We then use machine learning methods to predict which factors are most important in determining households' risky investment decisions. We find that overconfidence plays a significant predictive role. Our work signals that households' risky investments may be driven by biased optimism about their own financial know-how rather than their actual knowledge. We conclude that financial literacy programs should not only teach financial concepts but also make program participants aware of their own biases.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "7f83e80a980d23b5f9b9eac52774c953",
  "timestamp": "2025-05-15T02:00:30.657429"
}