{
  "id": 809,
  "title": "The EU Taxonomy and the Syndicated Loan Market",
  "abstract": "The European Union (EU) Taxonomy on Sustainable Activities is one of the most far-reaching financial market regulations to combat climate change. Using international data from the syndicated loan market, we demonstrate that firms with larger EU Taxonomy-eligible revenue shares paid lower interest rates in the years before the formal introduction of the Taxonomy. Business revenue is Taxonomy-eligible if it originates from transitional activities that substantially contribute to climate change mitigation. A one-standard-deviation increase in firm revenue from transitional activities is associated with 5 basis points (bp) lower loan spreads (5% relative to the standard deviation). Effects are more pronounced for firms in countries with greater climate risk exposure and more stringent environmental policies, and when lending institutions have green preferences. The effects of transitional revenue do not simply reflect a borrower's ESG ratings or broad exposure to climate risks and opportunities. Overall, our results indicate that financial markets already priced in some of the intended effects of the Taxonomy.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d6a7016160117b81bb2e55d48f56534f",
  "timestamp": "2025-05-15T01:42:44.497805"
}