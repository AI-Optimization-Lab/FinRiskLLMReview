{
  "id": 1412,
  "title": "Machine Learning-and Evidence Theory-Based Fraud Risk Assessment of China's Box Office",
  "abstract": "Box-office fraud in China is an increasingly highlighted problem of the movie market in recent years. It misleads consumers and investors and will inevitably hurt the developing motion picture industry and shadow movie market in China. More accurate supervision and auditing should be carried out to regulate the market. Nonfinancial measurement (NFM) is an important auditing method for assessing fraud risk and helping to detect financial fraud. Computational intelligence-based techniques and publicly available nonfinancial data could be used in NFM to prioritize exceptions and improve audit efficiency. In this paper, an NFM method is proposed for fraud risk assessment of China's box office. Movie-related data were collected from different movie websites by a web crawler. An evidence theory-based fraud risk assessment framework was established for iterative aggregation of different evidence. A machine learning method, i.e., ordered logistic regression, was used to calculate the basic probability assignment for evidence theory. The risk factor was put forward as the measurement of fraud risk in the proposed method for exception prioritization. Real case studies were carried out to validate the proposed method. The results show that the proposed method is effective in assessing the fraud risk of the box office and prioritizing exceptional box offices.",
  "year": 2018,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "9efe7fed4a9bafd3c7570c1e6ae87277",
  "timestamp": "2025-05-15T02:02:22.820040"
}