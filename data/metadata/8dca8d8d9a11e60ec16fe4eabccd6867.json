{
  "id": 3507,
  "title": "The momentum life cycle re-examined: Using incongruent value-growth to identify the momentum stage of stocks",
  "abstract": "The momentum life cycle (MLC) hypothesis aims to reconcile short-term momentum and long-term reversion observed in stock returns. While the MLC offers a valuable framework, it faces notable limitations: it fails to account for certain return patterns, and its ability to detect momentum stages may be mostly spurious. Using data from the five largest capital markets in the Eurozone from 1998 to 2014, along with cross-sectional regression and portfolio-based methodologies, this study re-examines the MLC. It introduces the incongruent value/growth (IVG) characteristic as an alternative to the commonly used trading volume to identify momentum stages within the MLC. The results show that using IVG significantly enhances the identification of early-and late-stage momentum stocks. Two key implications emerge: first, strategies that integrate momentum with IVG outperform those that combine momentum with trading volume; second, IVG helps address some of the MLC's key limitations, providing stronger empirical support for the hypothesis.",
  "year": 2025,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "8dca8d8d9a11e60ec16fe4eabccd6867",
  "timestamp": "2025-05-15T01:17:54.095098"
}