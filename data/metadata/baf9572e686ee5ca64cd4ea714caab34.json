{
  "id": 7201,
  "title": "Gold and CoVid-19: Uncovering the safe haven hypothesis with dynamic MSR modeling",
  "abstract": "During the catastrophic Covid-19 era, numerous assets experienced a decline in their original values, leaving the financial community grappling with the implications of the pandemic. A significant concern arising from this context is whether gold emerged as the ultimate safe haven during the pandemic and whether there were any shifts in investor behavior between the two waves of the pandemic. To address these concerns, we employed relevant analytical approaches, utilizing a dynamic Markov-Switching Regression (MSR) model. Our findings indicate that during both waves of Covid-19, gold exhibited characteristics of a safe haven asset against bonds, providing a hedge against economic turmoil. However, when it comes to stocks, gold's role slightly changed. It acted as a diversifier, offering a different pattern of returns compared to equities. This highlights gold's ability to adapt to evolving market characteristics.These results emphasize the importance of conducting further research on this topic to gain deeper insights into the factors influencing gold's behavior during periods of crisis. By expanding our understanding, we can refine risk management strategies and enhance portfolio performance in turbulent market conditions.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "baf9572e686ee5ca64cd4ea714caab34",
  "timestamp": "2025-05-15T03:06:01.287963"
}