{
  "id": 2733,
  "title": "Volatility transmission in the real estate spot and forward markets",
  "abstract": "How shocks in one market influence the returns and volatility of other markets has been an important question for portfolio managers. In the finance literature, many studies found evidence of volatility spillovers across international markets, as well as between spot and futures markets. Although real estate is often regarded as a good vehicle for diversification, the dynamics of its volatility transmission have been largely ignored. This paper provides the first study to examine volatility spillovers between the spot and forward (pre-sale) index returns of the Hong Kong real estate market through a bivariate GARCH model. Transaction-based indices were used so that our volatility modelling was free from any smoothing problem. Our results showed that real estate returns exhibited volatility clustering, and the volatility of the forward market was more sensitive to shocks than the spot market. Moreover, volatility was mainly transmitted from the forward market to the spot market, but not vice versa.",
  "year": 2007,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "0301a454966e283a51d5d05a3c47436e",
  "timestamp": "2025-05-15T01:09:43.407170"
}