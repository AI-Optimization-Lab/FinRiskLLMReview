{
  "id": 5039,
  "title": "Does the Relative Importance of the Push and Pull Factors of Foreign Capital Flows Vary Across Quantiles?",
  "abstract": "We empirically gauge the relative importance of the various push and pull factors for the magnitude of foreign flows to 51 emerging markets (EMs) across quantiles. We propose a quantile regression dynamic panel model with fixed effects and reveal several new findings: (a) Global risk aversion and regional contagion are generally significant across most quantiles. (b) Foreign short-term flows retreat less from EMs with stronger fundamentals during stress episodes. (c) EMs that previously experienced larger portfolio debt and bank inflows tend to suffer more during stress episodes. Hence, we provide novel evidence supporting the global financial cycle hypothesis, investor differentiation hypothesis, and the more-in-more-out hypothesis.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "19577c1355e77c7a8e764335826de7b2",
  "timestamp": "2025-05-15T02:43:40.190561"
}