{
  "id": 5939,
  "title": "A Comparison of Competing Asset Pricing Models: Empirical Evidence from Pakistan",
  "abstract": "In recent years, the rapid and significant development of emerging markets has globally led to insight from potential investors and academicians seeking to assess these markets in terms of risk inheritance. Therefore, this study aims to explore the validity and applicability of the capital asset pricing model (henceforth CAPM) and multi-factor models, namely Fama-French models, in Pakistan's stock market for the period of June 2010-June 2020. This study collects data on 173 non-financial firms listed on the Pakistan stock exchange, namely the KSE-100 index, and follows Fama-MacBeth's regression methodology for empirical estimation. The empirical findings of this study conclude that small portfolios (small-size companies) earn considerably higher returns than big portfolios (large-size companies). Ultimately, the risk associated with portfolio returns is reported to be higher for small portfolios (small-size companies) than for big portfolios (large-size companies). According to the regression output, the CAPM was found to be valid for explaining the market risk premium above the risk-free rate. Similarly, the FF three-factor model was found to be valid for explaining time-series variation in excess portfolio returns. Later, we added human capital into FF three- and five-factor models. This study found that the human capital base six-factor model outperformed the other competing asset pricing models. The findings of this study indicate that small portfolios (small-size companies) earn more returns than big portfolios (large-size companies) to reward the investor for taking extra risks. Investors may benefit by timing their investments to maximize stock returns. Company investment in human capital adds reliable information, replicates the value of the company and, in the long term, helps investors make rational decisions.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "c3433dec8fb54af7fe023b0249565877",
  "timestamp": "2025-05-15T02:53:03.097884"
}