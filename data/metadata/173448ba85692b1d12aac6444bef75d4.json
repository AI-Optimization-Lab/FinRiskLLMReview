{
  "id": 7643,
  "title": "Predictors of micro-costing components in liver transplantation",
  "abstract": "OBJECTIVES: Although liver transplantation procedures are common and highly expensive, their cost structure is still poorly understood. This study aimed to develop models of micro-costs among patients undergoing liver transplantation procedures while comparing the role of individual clinical predictors using tree regression models. METHODS: We prospectively collected micro-cost data from patients undergoing liver transplantation in a tertiary academic center. Data collection was conducted using an Intranet registry integrated into the institution's database for the storing of financial and clinical data for transplantation cases. RESULTS: A total of 278 patients were included and accounted for 300 procedures. When evaluating specific costs for the operating room, intensive care unit and ward, we found that in all of the sectors but the ward, human resources were responsible for the highest costs. High cost supplies were important drivers for the operating room, whereas drugs were among the top four drivers for all sectors. When evaluating the predictors of total cost, a MELD score greater than 30 was the most important predictor of high cost, followed by a Donor Risk Index greater than 1.8. CONCLUSION: By focusing on the highest cost drivers and predictors, hospitals can initiate programs to reduce cost while maintaining high quality care standards.",
  "year": 2017,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "173448ba85692b1d12aac6444bef75d4",
  "timestamp": "2025-05-15T03:10:33.062267"
}