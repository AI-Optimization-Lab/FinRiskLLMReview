{
  "id": 3481,
  "title": "Blockchain data with Ransomware detection based on deep feed forward Maxout network",
  "abstract": "The widespread use of the internet and technology has become more common and essential in daily life. The main risk to the network is malware, and ransomware is considered a destructive kind of malware. The ransomware resulted in massive data losses and produced huge financial losses. In order to overcome this issue, the Deep Feed Forward Maxout Network (DFFMN) is developed to detect ransomware using blockchain data in this study. To accomplish this, initially, the input data from the blockchain is given to feature extraction to extract features. Then, data normalization is performed and the extracted features are fused together using a Deep Belief Network (DBN) with Lorentzian similarity. Lastly, ransomware detection is executed by utilizing the DFFMN technique, which is created by the integration of Deep Maxout Network and Deep Feedforward Neural Network. The experimental results exemplify that the proposed DFFMN acquired accuracy value of 91.57 %, sensitivity value of 91.04 %, precision value of 89.35 %, False Negative Rate (FNR) of 0.086, False Positive Rate (FPR) of 0.090 and F-Measure of 89.44 %.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "cd71889df87728b0064278fd46c598ed",
  "timestamp": "2025-05-15T02:26:48.498919"
}