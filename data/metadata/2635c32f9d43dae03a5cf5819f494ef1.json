{
  "id": 85,
  "title": "基于最优异质收益率因子的资产定价研究",
  "abstract": "本文从经典因子模型的异质收益率出发，通过在残差空间中进行投资组合优化构造异质收益率因子来识别基准因子模型中的遗漏信息，从而对基准模型下的基于异质收益率的资产进行定价，提升基准模型的定价能力，并进一步证明了该拓展因子对异质收益率的资产定价能力。之后，本文基于A股1995年1月—2022年11月的6个因子数据集和美股1963年7月至2022年10月的4个因子数据集，在三因子、四因子、五因子模型的基础上加入异质收益率因子，并将拓展后的模型分别与原模型、均值方差有效单因子模型、主成分分析因子模型的定价效果进行对比。结果显示，在加入异质收益率因子之后，测试资产的α的绝对值均值、GRS统计量和t统计量均大幅减小，原模型的定价效果显著提升，该结果在样本内、样本外，A股、美股市场上都成立，表明了基于异质收益率因子的资产定价的稳健性和适应性。",
  "year": 2024,
  "source": "CNKI",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "2635c32f9d43dae03a5cf5819f494ef1",
  "timestamp": "2025-05-14T22:21:22.413398"
}