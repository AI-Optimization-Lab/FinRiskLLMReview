{
  "id": 4816,
  "title": "What drives herding in oil-rich, developing stock markets? Relative roles of own volatility and global factors",
  "abstract": "The main goal of this paper is to formally establish the volatility-herding link in the developing stock markets of the oil-rich GCC countries by examining how market volatility affects herd behavior after controlling for global factors. Using a regime-switching, smooth transition regression model (STR), we find significant evidence of herding in all Gulf Arab stock markets, with the market volatility being the more paramount factor governing the switches between the extreme states of non-herding and herding. The global variables comprised of the U.S. stock market performance, the price of oil and the US interest rate as well as the risk indexes including the CBOE Volatility Index (VIX) and the St. Louis Fed's Financial Stress Index (FSI) are found to be significant factors governing the transition to herding states. The findings stress the effect of contagion in financial markets, despite the restrictions established by the GCC policymakers in order to protect their markets. (C) 2014 Elsevier Inc. All rights reserved.",
  "year": 2014,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d3a7750e4c78028e48e5f53cff710e2c",
  "timestamp": "2025-05-15T02:41:32.662544"
}