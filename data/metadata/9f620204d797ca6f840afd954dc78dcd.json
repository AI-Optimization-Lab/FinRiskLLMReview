{
  "id": 304,
  "title": "中国系统性金融风险的高维时变测度与传导机制研究",
  "abstract": "本文以2000-2019年中国89家上市金融机构为样本,通过改进高维时变参数向量自回归模型(HD-TVP-VAR)实现了对高维时变复杂网络的有效测度。在此基础上,本文从复杂网络的视角对系统重要性金融机构进行了识别,并分析了系统性金融风险的内部成因及传导路径。研究发现,从整体来看,银行业和证券期货业分别呈现出\"风险吸收型\"与\"风险扩散型\"系统重要性,小机构则呈现出\"风险杠杆型\"系统重要性;流动性、杠杆率与规模是决定金融机构呈现不同类型系统重要性的影响因素,流动性高、杠杆率高、规模小的金融机构,其\"风险扩散型\"系统重要性通常更为显著;过度关联、发散的网络关联结构以及网络稳定性失衡是导致系统性金融风险及其传染的直接根源。",
  "year": 2021,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "9f620204d797ca6f840afd954dc78dcd",
  "timestamp": "2025-05-14T22:29:10.670974"
}