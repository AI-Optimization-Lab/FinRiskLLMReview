{
  "id": 6161,
  "title": "The impact of analysts' attention and research reports' attention on corporate bond credit spreads in China",
  "abstract": "As an important information intermediary and external monitor, analysts have a serious impact on investors. In order to study the impact of analysts' attention and research reports' attention on corporate bond credit spreads, this paper selects non-financial companies issuing bonds in China A-share market from 2017 to 2020 as samples, establish a panel data regression model for empirical research. The research found that both analyst attention and research report attention have a significant impact on the credit spread of corporate bonds, and the higher the analyst attention and research report attention, the smaller the corporate bond credit spread, indicating that analysts play an effective role in supervising the default risk of listed companies. The research in this article expands the research on analysts' attention and research reports' attention, and the research on the factors affecting bond credit spreads. (C) 2021 The Authors. Published by Elsevier B.V.",
  "year": 2022,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "ab8bfa53c8cd4ca4833fc00ef0b3f78d",
  "timestamp": "2025-05-15T02:55:13.002820"
}