{
  "id": 2772,
  "title": "Risk Analysis for Large Pools of Loans",
  "abstract": "Financial institutions, government-sponsored enterprises, and asset-backed security investors are often exposed to delinquency and prepayment risk from large numbers of loans. Examples include mortgages, credit cards, and auto, student, and business loans. Because of the size of the pools, the measurement of these exposures is computationally expensive. This paper develops and tests efficient numerical methods for the analysis of large pools of loans as well as asset-backed securities backed by such pools. For a broad class of statistical and machine learning models of loan-level risk in discrete time, we prove a law of large numbers and a central limit theorem for the pool-level risk. The asymptotics are then used to construct computationally efficient approximations for a large pool. The approximations aggregate the full loan-level dynamics, making it possible to take advantage of the detailed loan-level data often available in practice. We furthermore prove a convergence rate for the approximation and a uniform integrability result. The latter allows the approximation to be applied to a wide class of pool-level risk statistics. To demonstrate the effectiveness of our approach, we implement it on a data set of over 25 million mortgages. The results show the accuracy and speed of the approximation in comparison to brute-force simulation of a pool, for a variety of pools with different risk profiles.",
  "year": 2019,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "4925a5f2e0a0fbf1b9b7bd891d080551",
  "timestamp": "2025-05-15T02:19:08.379579"
}