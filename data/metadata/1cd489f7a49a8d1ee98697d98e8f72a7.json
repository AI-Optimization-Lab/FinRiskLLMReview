{
  "id": 2106,
  "title": "The promotion effect of digital finance development on residents' risk preference: evidence from China",
  "abstract": "The deep application of digital finance may change residents' risk preference, which poses new challenges for maintaining the stability of the financial system. However, the empirical evidence is still in its infancy. Taking China households as research samples, we use Oprobit and IV regression models, and the results confirm that digital finance has significantly improved residents' risk preference statistically. We explore the underlying mechanism and find that digital finance can improve risk preference by accumulating household wealth, financial literacy and social interaction. Our conclusion provides reference for preventing risk accumulation brought by fintech and maintaining financial stability in the digital era.",
  "year": 2025,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1cd489f7a49a8d1ee98697d98e8f72a7",
  "timestamp": "2025-05-15T02:10:59.109836"
}