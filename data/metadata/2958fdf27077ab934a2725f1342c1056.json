{
  "id": 2919,
  "title": "Risk spillovers from China's and the US stock markets during high-volatility periods: Evidence from East Asianstock markets",
  "abstract": "This paper studies cross-country risk spillovers through C-vine copula quantile regression. We find Both China's and the US markets can result in large risk spillovers to East Asian markets. Furthermore, their significant conditional spillovers indicate they can emit risk through an intermediary market. However, their distinctive dependency structures with East Asian markets reflect their differences in spillovers to the markets in magnitude. The risk spillovers from US are stronger than China in magnitude. Moreover, the risk spillover from China's stock market during its high-volatility period is weaker than the whole period, which is contrary to the US market. It may imply Chinese financial influences gradually increase with Chinese financial liberalization and regional integration. Our results have implications for macroprudential regulators adopt the effective supervision and regulation to deal with the cross-border risk spillovers, and for international investors in risk hedging, derivative valuation and investment.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "2958fdf27077ab934a2725f1342c1056",
  "timestamp": "2025-05-15T02:20:48.104934"
}