{
  "id": 2910,
  "title": "On binomial quantile and proportion bounds: With applications in engineering and informatics",
  "abstract": "The Binomial distribution is often used as a good approximation for many phenomena in engineering, medical, financial, and other applications involving discrete randomness. In many situations, for the purposes of risk management it may be required to estimate and/or track the probability of occurrence of a particular type of discrete event from a data sample, and then use such an estimate to predict outcomes from a larger sample. In this article, very simple but very accurate formulae are derived to support such actions. Analytic formulae are presented to tightly bound upper and lower estimates of a Binomial proportion to given confidence levels, and to tightly bound upper and lower estimates of a Binomial Quantile. Application to risk management are shown through synthetic and real-world examples, and accompanying analysis. It is argued that the formulae are simple enough to be embedded directly in machine learning and related analytics applications, and can also be manipulated algebraically to help analyze random behaviors in algorithms. The article concludes that the presented expressions are also useful to support decisions in situations in which specialist software may not be available.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "30225430e3c1aa3c64f9086ae081f15b",
  "timestamp": "2025-05-15T02:20:16.998215"
}