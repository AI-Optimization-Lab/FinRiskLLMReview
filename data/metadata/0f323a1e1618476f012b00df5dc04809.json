{
  "id": 1625,
  "title": "Do more concentrated supplier portfolios benefit firm innovation? The moderating roles of financial slack and growth opportunities",
  "abstract": "Purpose Firms are increasingly depending on supplier portfolios in the quest for firm innovation. However, whether concentrated supplier portfolios are beneficial to innovation remains highly disputed. This study aims to investigate the effect of supplier portfolio concentration on firm innovation and the contingencies that shape this effect. Design/methodology/approach The authors build on the knowledge search view to theorize a U-shaped effect of supplier portfolio concentration on firm innovation and further propose that the U-shaped effect is contingent on financial slack and growth opportunities. The authors collected panel data from 1,320 manufacturing firms in China. The negative binomial regression analyses were performed to test the hypotheses. Findings Supplier portfolio concentration has a U-shaped effect on firm innovation. This U-shaped effect is weakened and flipped by financial slack but strengthened by growth opportunities. Originality/value The findings extend current understandings of the influence of supplier portfolio on firm innovation by clarifying the U-shaped effect of supplier portfolio concentration on innovation and the circumstances under which supplier portfolio concentration is more effective for firm innovation.",
  "year": 2022,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "0f323a1e1618476f012b00df5dc04809",
  "timestamp": "2025-05-15T00:57:46.897551"
}