{
  "id": 5182,
  "title": "Herding behavior, market sentiment and volatility: Will the bubble resume?",
  "abstract": "This paper aims to investigate herding behavior and its impact on volatility under uncertainty. We apply a cross-sectional absolute deviation approach as well as Quantile Regression methods to capture the herding behavior in daily and monthly frequencies in US markets over several time-periods including the global financial crisis. In a novel attempt we modify the empirical CSAD herding modeling by introducing implied volatility as a measure of agent risk expectations. Our findings indicate that herding tends to be intense under extreme market conditions, as depicted in the upper high quantile range of the conditional distribution of returns. During crisis periods herding is observed at the beginning of the crisis and becomes insignificant towards the end. The US market herding behavior exhibits time-varying dynamic trading pattern that can be attributed e.g., to overconfidence or excessive flight to quality features, mostly observed in the aftermath of the global financial crisis. Moreover, implied volatility reveals asymmetric patterns and plays a key role in enforcing irrational behavior. (C) 2017 Published by Elsevier Inc.",
  "year": 2017,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5c9370208d5d816f8cc51aee6067f334",
  "timestamp": "2025-05-15T02:45:17.057145"
}