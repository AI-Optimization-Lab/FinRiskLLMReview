{
  "id": 903,
  "title": "基于神经网络分位数回归的多期CVaR风险测度",
  "abstract": "与VaR金融风险测度相比,CVaR具有更好的数理性质,其计算方法成为关注的焦点。相对于单期CVaR而言,多期CVaR风险测度具有较强的非线性特征,其建模过程更加复杂。在神经网络分位数回归基础上,建立了一种新的多期CVaR风险测度方法;基于似然比检验,建立了多期CVaR风险测度返回测试评价准则。将该新方法应用于沪深300指数的多期CVaR风险测度,并将其与传统的测度方法进行了对比,返回测试结果表明:第一,该新方法具有较强的稳健性,各期平均绝对误差大小基本不变,特别适合于多期CVaR风险测度;第二,基于神经网络分位数回归的多期CVaR风险测度效果优于传统测度方法,表现为似然比检验拒绝次数最少和平均绝对误差最小。",
  "year": 2017,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "a780bc968cc56d907b2fb4731a4e8195",
  "timestamp": "2025-05-14T22:34:27.074057"
}