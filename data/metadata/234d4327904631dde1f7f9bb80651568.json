{
  "id": 5922,
  "title": "Are Islamic banks really resilient to crises: new evidence from the COVID-19 pandemic",
  "abstract": "PurposeProponents of Islamic banking believe that this banking model is relatively superior in times of financial crises. This study aims to examine whether Islamic banks were more resilient to the coronavirus 2019 (COVID-19) pandemic than their conventional peers, especially in terms of two of the most important banking risks, capital and liquidity risks.Design/methodology/approachThe authors use a regression model to examine whether Islamic banks were more resilient to the recent health crisis, as compared to their conventional counterparts. The results are robust to alternative crisis time periods, the use of different model specifications and the inclusion of different control variables.FindingsUnlike during the 2007-2008 global financial crisis (GFC), Islamic banks have not performed relatively well during the more recent crisis caused by the COVID-19 pandemic. The results show that Islamic banks experienced an increase in both capital and liquidity risks. The results also indicate a decrease in bank profitability, improved solvency and asset quality and a decrease in operational risk.Originality/valueThis study contributes to the literature on banking business model and resilience to economic crises. Contrary to some expectations and to their performance during the GFC of 2007-2008, Islamic banks were found to be more vulnerable during the COVID-19 pandemic than conventional banks.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "234d4327904631dde1f7f9bb80651568",
  "timestamp": "2025-05-15T02:53:03.039515"
}