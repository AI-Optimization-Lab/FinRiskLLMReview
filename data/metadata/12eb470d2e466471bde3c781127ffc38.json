{
  "id": 5471,
  "title": "Problem Gambling in a Sample of Older Adult Casino Gamblers: Associations With Gambling Participation and Motivations",
  "abstract": "As older adults continue to make up a greater proportion of the Canadian population, it becomes more important to understand the implications that their leisure activities have for their physical and mental health. Gambling, in particular, is a form of leisure that is becoming more widely available and has important implications for the mental health and financial well-being of older adults. This study examines a large sample (2103) of casino-going Ontarian adults over the age of 55 and identifies those features of their gambling participation that are associated with problem gambling. Logistic regression analysis is used to analyze the data. Focusing on types of gambling participated in and motivations for visiting the casino, this study finds that several forms of gambling and motivations to gamble are associated with greater risk of problem gambling. It also finds that some motivations are associated with lower risk of problem gambling. The findings of this study have implications related to gambling availability within an aging population.",
  "year": 2017,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "12eb470d2e466471bde3c781127ffc38",
  "timestamp": "2025-05-15T02:48:23.576933"
}