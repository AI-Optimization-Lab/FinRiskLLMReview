{
  "id": 1158,
  "title": "Network-Based prediction of financial cross-sector risk spillover in China: A deep learning approach",
  "abstract": "There are complex risk correlations between financial sectors, and the risks generated by different financial sectors propagate, accrue, and cluster through the network of correlations, posing a threat to the entire financial system. This research constructs static and dynamic cross -sector risk spillover networks using VAR and generalized variance decomposition, and forecasts the evolution of risk spillover networks using recurrent neural network models such as RNN and LSTM. The results indicate that the risk spillover network will change rapidly in response to risk events, and that the total volatility spillover will increase during times of crisis, while banks and securities are the most important risk propagating and receiving sectors. The LSTM model can achieve more effective dynamic prediction of the multidimensional network, and the predicted network is essentially consistent with the actual network. According to the findings of the study, forecasting changes in the structure of financial sector networks may provide early warning of systemic financial risk and assist to a better understanding of the risk link between financial sectors.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "655fb901960520f6ab67e609538e62db",
  "timestamp": "2025-05-15T01:59:21.743096"
}