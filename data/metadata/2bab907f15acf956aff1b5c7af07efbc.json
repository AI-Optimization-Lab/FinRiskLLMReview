{
  "id": 4550,
  "title": "Designing reward and penalty scheme in performance-based regulation for electric distribution companies",
  "abstract": "A reward and penalty scheme (RPS) in performance-based regulation (PBR) penalises companies for providing poor reliability and rewards them for providing good reliability. In this study, an algorithm is presented to obtain the parameters of RPS for each electric company by using data envelopment analysis (DEA) and fuzzy c-means clustering (FCM). This algorithm is based on system average interruption duration index (SAIDI) and customers' value of interruptions. FCM algorithm is applied to find similar distribution companies and cluster companies into different clusters. The best performer in each cluster is utilised as a benchmark for other companies and DEA is used to set a quality target for each electric distribution company. The performance of the proposed algorithm is demonstrated in a case study to design RPS for Iranian electricity distribution companies. The results of the algorithm include DEA efficiency score, parameters of RPS and financial risk assessment.",
  "year": 2012,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "2bab907f15acf956aff1b5c7af07efbc",
  "timestamp": "2025-05-15T02:38:20.457206"
}