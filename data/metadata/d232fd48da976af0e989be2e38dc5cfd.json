{
  "id": 3292,
  "title": "MODELLING VOLATILITY OF MALAYSIAN STOCK MARKET USING GARCH MODELS",
  "abstract": "Stock market volatility was changed over time. The factor such as financial crisis can easily influence the movement of the volatility. This unpredictable change means uncertain risks and not well preferred by the most of the stock market players. It is because higher risk can lead to a higher returns or losses. For these reason, this study has modelled volatility to investigate the behavior of stock return volatility of FTSE Bursa Malaysia KLCI with regard to the global financial crisis occurred in 2008 until 2009. The sample consists of 2473 observations of daily index return of FBM KLCI from January 2002 to December 2011. In order to model volatility of Malaysian stock market, three of the family of GARCH models was used. The results of GARCH ( 1, 1), indicate the presence of volatility clustering and persistence effects on the stock market volatility. Besides, the asymmetric models which are TGARCH and EGARCH detect the presence of leverage effects in the data series. Finally, the last evaluation shows that EGARCH model has outperformed the other class of GARCH model and has the best ability in forecasting the volatility. In conclusion, the results from this study show the ability of GARCH model in modelling volatility and indicate the existence of volatility clustering, leverage effects, and fat tailed in the Malaysian stock returns data.",
  "year": 2015,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "d232fd48da976af0e989be2e38dc5cfd",
  "timestamp": "2025-05-15T02:24:39.704613"
}