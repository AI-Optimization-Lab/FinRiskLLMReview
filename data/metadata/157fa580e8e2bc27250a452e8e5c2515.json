{
  "id": 550,
  "title": "Hesitant fuzzy linguistic portfolio model with variable risk appetite and its application in the investment ratio calculation",
  "abstract": "Qualitative evaluation information is important for financial decision-making and investment when quantitative data are unavailable. Although an alternative ranking is available, specific portfolio and optimal investment ratios cannot be obtained by using the qualitative decision-making methods. To address this issue, this paper proposes a hesitant fuzzy linguistic portfolio model based on the max-score rule and the hesitant fuzzy linguistic element with variable risk appetite (HFLE-RA). The HFLE-RA is able to express qualitative evaluation information by using the hesitant fuzzy linguistic term set and describe the variable investor risk appetites by introducing the asymmetric sigmoid semantics. Thus, different investors can be distinguished by the risk appetite parameters according to the asymmetric sigmoid semantics, and the optimal investment ratios can be obtained by applying the proposed portfolio model. Moreover, the investment opportunities and efficient frontiers of the hesitant fuzzy linguistic portfolio model are investigated. Also, a value-at-risk fitting approach is introduced to calculate the risk appetite parameters. Based on these works, a qualitative investment ratio calculation process is provided in the HFLE-RA environment. Lastly, a real example of calculating the optimal investment ratios for four newly listed stocks in the Growth Enterprises Market board of the Shenzhen Stock Exchange is provided to demonstrate the proposed approaches. (C) 2019 Elsevier B.V. All rights reserved.",
  "year": 2019,
  "source": "WOS",
  "area": "financial_risk",
  "method": "deep learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "157fa580e8e2bc27250a452e8e5c2515",
  "timestamp": "2025-05-15T01:39:38.311833"
}