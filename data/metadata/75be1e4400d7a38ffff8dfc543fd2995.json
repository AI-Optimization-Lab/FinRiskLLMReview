{
  "id": 4700,
  "title": "Regression Models for Project Expenditures",
  "abstract": "This report discusses regression models to analyse planned and actual expenditure data from projects in an Australian Defence capital investment program. Variations in expenditure from that planned have the potential to create cash flow problems in Defence. Therefore, an understanding of the relationship between planned and actual expenditure will improve project planning and portfolio financial management. It is also useful to understand if families of projects behave differently to each other because differences may indicate varying management practices across project domains or differences in the nature of project families. The regression model accommodates project time and military domain effects, heteroscedasticity, repeated measures and nonlinear relations between planned and actual annual project expenditure. The nonlinear model is linearized into an additive lognormal model and fitted via a linear mixed models methodology that facilitates modelling the within project covariance structure. Generally, projects underspend against the plan early in their life and overspend in later years. For each year, there are significant differences in expenditure rates between domains, but the expenditure rate does not depend on planned expenditure. The model may be used by project and portfolio planners to test likely spending variations from plan and to then adjust expenditure plans accordingly; it, therefore, provides a tool to measure project and financial risk.",
  "year": 2018,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "75be1e4400d7a38ffff8dfc543fd2995",
  "timestamp": "2025-05-15T02:39:57.605309"
}