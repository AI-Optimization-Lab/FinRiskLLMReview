{
  "id": 4525,
  "title": "Belgium: risk adjustment and financial responsibility in a centralised system",
  "abstract": "Since 1995 Belgian sickness funds are partially financed through a risk adjustment system and are held partially financially responsible for the difference between their actual and their risk-adjusted expenditures. However, they did not get the necessary instruments for exerting a real influence on expenditures and the health insurance market has not been opened for new entrants. At the same time the sickness funds have powerful tools for risk selection, because they also dominate the market for supplementary health insurance. The present risk-adjustment system is based on the results of a regression analysis with aggregate data. The main proclaimed purpose of this system is to guarantee a fair treatment to all the sickness funds. Until now the danger of risk selection has not been taken seriously. Consumer mobility has remained rather low. However, since the degree of financial responsibility is programmed to increase in the near future, the potential profits from cream skimming will increase. (C) 2002 Elsevier Science Ireland Ltd. All rights reserved.",
  "year": 2003,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "366d3612b9bcfedd218324b5eee91cdb",
  "timestamp": "2025-05-15T02:38:20.305519"
}