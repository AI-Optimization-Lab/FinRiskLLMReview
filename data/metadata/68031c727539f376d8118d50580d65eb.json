{
  "id": 3834,
  "title": "In vitro assessment of eye irritancy using the Reconstructed Human Corneal Epithelial SkinEthicâ„¢ HCE model: Application to 435 substances from consumer products industry",
  "abstract": "The 7th amendment of the EU Cosmetics Directive led to the ban of eye irritation testing for cosmetic ingredients in animals, effective from March 11th 2009. Over the last 20 years, many efforts have been made to find reliable and relevant alternative methods. The SkinEthic (TM) HCE model was used to evaluate the in vitro eye irritancy potential of substances from a cosmetic industry portfolio. An optimized protocol based on a specific 1-h treatment and a 16-h post-treatment incubation period was first assessed on a set of 102 substances. The prediction model (PM) based on a 50% viability cut-off, allowed to draw up two classes (Irritants and Non-Irritants), with good associated sensitivity (86.2%) and specificity (83.5%). To check the robustness of the method, the evaluated set was expanded up to 435 substances. Final performances maintained a high level and were characterized by an overall accuracy value > 82% when using EU or GHS classification rules. Results showed that the SkinEthic (TM) HCE test method is a promising in vitro tool for the prediction of eye irritancy. Optimization datasets were shared with the COLIPA Eye Irritation Project Team and ECVAM experts, and reviewed as part of an ongoing progression to enter an ECVAM prospective validation study for eye irritation. (C) 2009 Elsevier Ltd. All rights reserved.",
  "year": 2010,
  "source": "WOS",
  "area": "portfolio",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "68031c727539f376d8118d50580d65eb",
  "timestamp": "2025-05-15T01:21:08.321166"
}