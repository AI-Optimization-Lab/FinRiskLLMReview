{
  "id": 6478,
  "title": "Health insurance, labor market shocks, and mental health during the first year of the COVID-19 crisis",
  "abstract": "We use the Census Household Pulse Survey (HPS) to examine employment and earnings loss, health insurance, and hardships related to physical and mental health and health care, as well as food insecurity and difficulty meeting expenses, during the first year of the COVID-19 pandemic. Pandemic job loss is strongly associated with uninsurance in the HPS. Moreover, among those who were not employed due to a pandemic economic reason such as a business closure, we find substantial regression-adjusted differences in hardship by insurance status, especially in the domains of mental health, mental health care and financial difficulties (food insufficiency and difficulty paying usual expenses). The uninsured generally, and uninsured job losers especially, were at high risk of untreated or under-treated mental health symptoms. We also find evidence among non-employed persons of substantial differences by gender and race/ethnicity in uninsurance, mental health symptoms and unmet needs for mental health care.",
  "year": 2023,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "9a760639be793978e8660d4ec1649e6f",
  "timestamp": "2025-05-15T02:58:34.139182"
}