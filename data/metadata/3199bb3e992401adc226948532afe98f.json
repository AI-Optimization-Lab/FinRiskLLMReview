{
  "id": 638,
  "title": "Automated cryptocurrency trading approach using ensemble deep reinforcement learning: Learn to understand candlesticks",
  "abstract": "Despite their high risk, cryptocurrencies have gained popularity as viable trading options. Cryptocurrencies are digital assets that experience significant fluctuations in a market operating 24 h a day. Recently, considerable attention has been paid to developing trading bots using machine-learning-based artificial intelligence. Previous studies have employed machine learning techniques to predict financial market trends or make trading decisions, primarily using numerical data extracted from candlesticks. However, these data often overlook the temporal and spatial information of candlesticks, leading to a limited understanding of their significance. In this study, we utilize multi-resolution candlestick images containing temporal and spatial information. Our rationale for using visual information from candlestick charts is to replicate the decision-making processes of human trading experts. To achieve this, we employ deep reinforcement learning algorithms to generate trading signals based on a state vector that includes embedded candlestick-chart images. The trading signal is generated using a multi-agent weighted voting ensemble approach. We test the proposed approach on two BTC/USDT datasets under both bullish and bearish market scenarios. Additionally, we use an attention-based technique to identify significant areas in the candlestick images targeted by the proposed approach. Our findings demonstrate that models using candlestick images 'as-is', outperform those using raw numeric data and other baseline models.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "3199bb3e992401adc226948532afe98f",
  "timestamp": "2025-05-15T01:53:24.866551"
}