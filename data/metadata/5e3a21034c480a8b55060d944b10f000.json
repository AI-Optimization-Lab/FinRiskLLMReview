{
  "id": 227,
  "title": "基于分位数因子VAR模型的金融机构间特质风险关联研究",
  "abstract": "文章采用最新发展的QFVAR (Quantile Factor VAR)模型,借助市场因子消除误差项中的横截面相关性,从而研究中国36家上市金融机构间的特质风险关联,并通过分位数回归估计,考察了金融机构间的均值风险传染和尾部风险传染,最后从风险溢出和风险溢入角度,探讨了金融机构特质风险的主要来源.研究发现:1)金融机构特质风险关联会随着分位数发生显著变化,相较条件均值和条件中位数,特质风险在两侧尾部存在强烈的时变关联效应.2)特质风险的均值传染主要集中在部门内,而尾部传染则表现出明显的跨部门效应,其中右尾的风险传染强度更高.3)在金融市场平稳期,证券部门具有较高的特质风险溢出水平,而在金融市场危机期,银行部门具有较高的特质风险溢出水平.文章的研究结果对监管部门防范化解金融风险具有借鉴意义,有助于其从特质冲击角度,加深对金融风险传染机制的理解.",
  "year": 2023,
  "source": "CNKI",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "5e3a21034c480a8b55060d944b10f000",
  "timestamp": "2025-05-14T22:27:55.665436"
}