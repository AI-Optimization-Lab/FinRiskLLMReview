{
  "id": 6231,
  "title": "Predictors of returns to the emergency department after head and neck surgery",
  "abstract": "BackgroundThirty-day hospital readmissions have become a measure of quality of care. Many readmissions enter through the emergency department. The purposes of this study were to determine the rate, risk factors, and costs of 30-day returns to the emergency department (30dEDRs) after head and neck surgery. MethodsAll adult patients undergoing head and neck surgery at the University of Florida from 2012 to 2014 were reviewed. Univariate and multivariate logistic regression analyses were performed to identify risk factors for 30dEDRs. ResultsWe found 1065 patients who underwent 1173 procedures. There were 88 cases (7.5%) that resulted in 30dEDRs and 55 patients (4.7%) who had 30-day unplanned readmissions (30dURs). Significant predictors of 30dEDRs included: smoking; hypothyroidism; and intensive care unit (ICU) stays. Significant predictors of readmission from an emergency department visit were Charlson Comorbidity Index (CCI) and cancer stage. Total costs of 30dEDRs and any subsequent readmissions topped $500000. ConclusionThe rate of 30dEDRs after head and neck surgery is low; however, these visits increase the hospitals' financial burden as well as patient morbidity. Predictors of 30dEDRs may be utilized to formulate preventative measures.",
  "year": 2018,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "84f6384c96e37452d4c586f4821d832c",
  "timestamp": "2025-05-15T02:56:10.890962"
}