{
  "id": 1727,
  "title": "Machine learning-based analysis of volatility quantitative investment strategies for American financial stocks",
  "abstract": "Volatility, a pivotal factor in the financial stock market, encapsulates the dynamic nature of asset prices and reflects both instability and risk. A volatility quantitative investment strategy is a methodology that utilizes information about volatility to guide investors in trading and profit -making. With the goal of enhancing the effectiveness and robustness of investment strategies, our methodology involved three prominent time series models with six machine learning models: K-nearest neighbors, AdaBoost, CatBoost, LightGBM, XGBoost, and random forest, which meticulously captured the intricate patterns within historical volatility data. These models synergistically combined to create eighteen novel fusion models to predict volatility with precision. By integrating the forecasting results with quantitative investing principles, we constructed a new strategy that achieved better returns in twelve selected American financial stocks. For investors navigating the real stock market, our findings serve as a valuable reference, potentially securing an average annualized return of approximately 5 to 10% for the American financial stocks under scrutiny in our research.",
  "year": 2024,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "38b1bc2f42460904248bae7048cbc47d",
  "timestamp": "2025-05-15T02:06:52.672016"
}