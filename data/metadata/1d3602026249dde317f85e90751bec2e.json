{
  "id": 1470,
  "title": "Can a machine learning model accurately predict patient resource utilization following lumbar spinal fusion?",
  "abstract": "BACKGROUND CONTEXT: With the increasing emphasis on value-based healthcare in Centers for Medicare and Medicaid Services reimbursement structures, bundled payment models have been adopted for many orthopedic procedures. Immense variability of patients across hospitals and providers makes these models potentially less viable in spine surgery. Machine-learning models have been shown reliable at predicting patient-specific outcomes following lumbar spine surgery and could, therefore, be applied to developing stratified bundled payment schemes. PURPOSE: (1) Can a Naive Bayes machine-learning model accurately predict inpatient payments, length of stay (LOS), and discharge disposition, following dorsal and lumbar fusion? (2) Can such a model then be used to develop a risk-stratified payment scheme? STUDY DESIGN: A Naive Bayes machine-learning model was constructed using an administrative database. PATIENT SAMPLE: Patients undergoing dorsal and lumbar fusion for nondeformity indications from 2009 through 2016 were included. Preoperative inputs included age group, gender, ethnicity, race, type of admission, All Patients Refined (APR) risk of mortality, APR severity of illness, and Clinical Classifications Software diagnosis code. OUTCOME MEASURES: Predicted resource utilization outcomes included LOS, discharge disposition, and total inpatient payments. Model validation was addressed via reliability, model output quality, and decision speed, based on application of training and validation sets. Risk-stratified payment models were developed according to APR risk of mortality and severity of illness. RESULTS: A Naive Bayes machine-learning algorithm with adaptive boosting demonstrated high reliability and area under the receiver-operating characteristics curve of 0.880, 0.941, and 0.906 for cost, LOS, and discharge disposition, respectively. Patients with increased risk of mortality or severity of illness incurred costs resulting in greater inpatient payments in a patient-specific tiered bundled payment, reflecting increased risk on institutions caring for these patients. We found that a large range in expected payments due to individuals' preoperative comorbidities indicating an individualized risk-based model is warranted. CONCLUSIONS: A Naive Bayes machine-learning model was shown to have good-to-excellent reliability and responsiveness for cost, LOS, and discharge disposition. Based on APR risk of mortality and APR severity of illness, there was a significant difference in episode costs from lowest to highest risk strata. After using normalized model error to develop a risk-adjusted proposed payment plan, it was found that institutions incur significantly more financial risk in flat bundled payment models for patients with higher rates of comorbidities. (C) 2019 Elsevier Inc. All rights reserved.",
  "year": 2020,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "1d3602026249dde317f85e90751bec2e",
  "timestamp": "2025-05-15T02:03:39.704451"
}