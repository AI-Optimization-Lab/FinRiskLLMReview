{
  "id": 4036,
  "title": "Diversification and risk-adjusted performance: A quantile regression approach",
  "abstract": "The effect of diversification on firm performance has been debated. We reexamine the effect using a sample of 44,248 observations of non-financial US firms for the 1997-2009 period employing the quantile regression approach. Our empirical results show that the effect of diversification on firm performance is not homogeneous across various quantile levels: the diversification discount (premium) shows up in firms with high (low) RoE quantiles. Further, we find that diversification affects firm risk as well. Therefore, we consider a risk-adjusted performance measure and find that both diversification discount and premium disappear, which is consistent with the risk-return trade-off principle. (C) 2012 Elsevier B.V. All rights reserved.",
  "year": 2012,
  "source": "WOS",
  "area": "financial_risk",
  "method": "machine learning",
  "keywords": [
    "machine learning",
    "supervised learning",
    "unsupervised learning",
    "reinforcement learning",
    "semi-supervised learning",
    "active learning",
    "classification",
    "regression",
    "PCA",
    "support vector machine",
    "SVM",
    "decision tree",
    "clustering",
    "principal components analysis",
    "manifold learning",
    "feature learning",
    "feature representation",
    "neural network",
    "deep learning",
    "representation learning",
    "backpropagation",
    "BP",
    "rectified linear unit",
    "ReLU",
    "sigmoid",
    "tanh",
    "hidden layer",
    "convolutional neural network",
    "CNN",
    "recurrent neural network",
    "long short-term memory",
    "LSTM",
    "sequence-to-sequence learning",
    "seq2seq",
    "encoder-decoder",
    "autoencoder",
    "denoising autoencoder",
    "deep belief network",
    "DBM",
    "restricted Boltzmann machine",
    "dropout regularization",
    "unsupervised pre-train",
    "memory network",
    "attention mechanism",
    "Large Language Model",
    "LLM",
    "In-context Learning",
    "Instruction Tuning",
    "Chain-of-Thought",
    "Few-shot Learning",
    "Zero-shot Learning",
    "Long Context Modeling",
    "Tool Manipulation",
    "Tool-augmented Model",
    "Memory Augmented Model",
    "ChatGPT",
    "GPT-4",
    "LLaMA"
  ],
  "cache_key": "671d38c808a1d502c244623f0eeafe74",
  "timestamp": "2025-05-15T02:32:27.528515"
}