Article Title,Abstract,Publication Year
E-Commerce Enterprises Financial Risk Prediction Based on FA-PSO-LSTM Neural Network Deep Learning Model,"The rapid development of Internet information technology has made e-commerce enterprises face complex and changing financial problems. Combining artificial intelligence algorithms and dynamic monitoring of financial risks has been a current research hotspot. Based on this, this paper conducts an empirical study with a sample of listed Chinese e-commerce enterprises from 2012 to 2022. Firstly, using factor analysis (FA) to obtain the common factors between the original financial and non-financial indicators has the effect of reducing the overfitting risk of the model. Secondly, the mean square error (MSE) of the output and predicted values of the Long Short-Term Memory neural network (LSTM) is used as the fitness function of the intelligent swarm optimization algorithm, and then the Particle Swarm Optimization (PSO) algorithm is used to optimize the learning rate (LR) and the number of hidden layer neurons in the Long Short-Term Memory (LSTM) neural network. Finally, a financial risk prediction model based on FA-PSO-LSTM deep learning is constructed, and multiple benchmark models are introduced for comparative analysis on each evaluation index. The study shows that for nonlinear multivariate data with complex structure, the fused deep learning model proposed in this paper achieves the lowest values in mean square error (MSE), mean absolute error (MAE), and mean absolute percentage error (MAPE). This indicates that the model has the best prediction effect, which is helpful to help managers make relevant decisions efficiently and scientifically and make the enterprise sustainable.",2023
Financial System Risk Warning Based on Deep earning,"As the global economy transitions towards a trajectory of high-quality development, the underlying risks within the financial system are becoming increasingly conspicuous. To precisely identify and effectively address these risks, this paper introduces a financial system risk warning based on a deep learning model. The objective is to notably enhance the accuracy of predicting enterprise financial risks and improve the responsiveness of the warning mechanism. In this study, we harness the strengths of Convolutional Neural Network (CNN) and Long Short-Term Memory Network (LSTM) to develop an efficient CNN-LSTM model. Through rigorous experimental validation and analysis, CNN-LSTM model exhibits outstanding performance in the task of financial risk warning. It not only enhances the precision of early warning but also significantly bolsters the stability and reliability of the warning system.",2024
Carbon trading price forecasting based on parameter optimization VMD and deep network CNN-LSTM model,"To meet carbon peak and neutrality targets, accurate carbon trading price forecasting is very important for enterprises making emission reduction decisions. By fusing convolutional neural network (CNN) and long short-term memory network (LSTM), the CNN-LSTM model is constructed. After variational mode decomposition (VMD), several intrinsic mode functions (IMFs) components are obtained and input into the CNN-LSTM model, thus constructing the combined sooty tern optimization algorithm (STOA)-VMD-CNN-LSTM forecasting model. To test this model, the carbon trading prices of the carbon emission trading markets of Hubei, Guangdong and Shenzhen were forecast. The prediction performance of the STOA-VMD-CNN-LSTM model is compared with ARIMA, BP, CNN and LSTM benchmark models and models combining different decomposition technologies. The international carbon trading price (EUR and CER) is used for prediction. Compared with other methods, the developed model makes fewer errors and achieves superior performance. Several important implications are provided for investors and risk managers involved in carbon financial products.",2024
Risk Measurement of the Financial Credit Industry Driven by Data: Based on DAE-LSTM Deep Learning Algorithm,"The risk measurement of the financial credit industry is an important research issue in the field of financial risk assessment. The design of a financial credit risk measurement algorithm can help investors avoid greater risks and obtain higher returns, so as to promote the benign development of financial credit industry. Based on the combined deep learning algorithm, this paper studies the risk measurement of financial and credit industry and proposes a fusion algorithm of deep auto-encoder (DAE) and long short-term memory (LSTM) network. The algorithm recombines the value of fixed features by using the unsupervised mechanism of DAE and extracts non-fixed features for measurement combined with the memory characteristics of LSTM network. The experimental results show that, compared with single generalized regression neural network and LSTM network, the average accuracy of DAE-LSTM algorithm is improved by about 6.49% and 3.25%, respectively, which has a better application effect in credit risk measurement.",2022
A WOA-CNN-BiLSTM-based multi-feature classification prediction model for smart grid financial markets,"Introduction: Smart grid financial market forecasting is an important topic in deep learning. The traditional LSTM network is widely used in time series forecasting because of its ability to model and forecast time series data. However, in long-term time series forecasting, the lack of historical data may lead to a decline in forecasting performance. This is a difficult problem for traditional LSTM networks to overcome.Methods: In this paper, we propose a new deep-learning model to address this problem. This WOA-CNN-BiLSTM model combines bidirectional long short-term memory network BiLSTM and convolution Advantages of Neural Network CNN. We replace the traditional LSTM network with a bidirectional long short-term memory network, BiLSTM, to exploit its ability in capturing long-term dependencies. It can capture long-term dependencies in time series and is bidirectional modelling. At the same time, we use a convolutional neural network (CNN) to extract features of time series data to better represent and capture patterns and regularity in the data. This method combining BiLSTM and CNN can learn the characteristics of time series data more comprehensively, thus improving the accuracy of prediction. Then,to further improve the performance of the CNN-BiLSTM model, we optimize the model using the whale algorithm WOA. This algorithm is a new optimization algorithm, which has good global search ability and convergence speed, and can complete the optimization of the model in a short time.Results: Optimizing the CNN-BiLSTM model through the WOA algorithm can reduce its calculation and training speed, improve the prediction accuracy of the smart grid financial market, and improve the prediction ability of the smart grid financial market. Experimental results show that our proposed CNN-BiLSTM model has better prediction accuracy than other models and can effectively deal with the problem of missing historical data in long-term sequence forecasting.Discussion: This provides necessary help for the development of smart grid financial markets and risk management services, and can promote the development and growth of the smart grid industry. Our research results are of great significance in deep learning, and provide an effective method and idea for solving the financial market forecasting problem of smart grid.",2023
Credit Risk Prediction Model for Listed Companies Based on CNN-LSTM and Attention Mechanism,"The financial market has been developing rapidly in recent years, and the issue of credit risk concerning listed companies has become increasingly prominent. Therefore, predicting the credit risk of listed companies is an urgent concern for banks, regulators and investors. The commonly used models are the Z-score, Logit (logistic regression model), the kernel-based virtual machine (KVM) and neural network models. However, the results achieved could be more satisfactory. This paper proposes a credit-risk-prediction model for listed companies based on a CNN-LSTM and an attention mechanism, Our approach is based on the benefits of the long short-term memory network (LSTM) model for long-term time-series prediction combined with a convolutional neural network (CNN) model. Furthermore, the advantages of being integrated into a CNN-LSTM model include reducing the complexity of the data, improving the calculation speed and training speed of the model and solving the possible lack of historical data in the long-term sequence prediction of the LSTM model, resulting in prediction accuracy. To reduce problems, we introduced an attention mechanism to assign weights independently and optimize the model. The results show that our model has distinct advantages compared with other CNNs, LSTMs, CNN-LSTMs and other models. The research on the credit-risk prediction of the listing formula has significant meaning.",2023
Financial Warning of Manufacturing Listed Companies Based on Text Mining,"The audit report, as disclosed in the annual reports of listed companies, represents a critical source of textual data for assessing enterprise risk and conducting financial analysis. Descriptions of key audit matters in the audit report offer detailed explanations and insights. This study aims to develop predictive models for assessing the financial distress status of Chinese manufacturing listed companies, enhancing early warning accuracy through the integration of financial indicators and textual data. Utilizing data from 2016 to 2022, which includes Z-Score, F-Score, and descriptions of key audit matters from the financial reports of manufacturing listed companies, we introduce text mining techniques such as TF-IDF, Word2Vec, Doc2Vec, and LDA to extract crucial information. Subsequently, the extracted textual features are dimensionally reduced via PCA and Truncated SVD techniques. We construct multiple deep learning models, including Multilayer Perceptron (MLP), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), and Long Short-Term Memory (LSTM), using ACC and AUC-ROC as evaluation metrics. The findings indicate that deep learning models incorporating textual data surpass those relying solely on traditional financial indicators in predicting financial distress, achieving an AUC value of 0.9028, marking an improvement of 0.0483. This study not only furnishes a new perspective on financial distress prediction research but also provides effective tools for investors and regulatory agencies to identify potential financial crises.",2024
A Financial Risk Early Warning Model for Listed New Energy Vehicle Companies Based on LSTM: Using SMOTE Oversampling and Simulated Annealing Optimization,"With the rapid development of artificial intelligence technology, the application of deep learning in financial data analysis is becoming increasingly widespread, particularly in the field of financial risk early warning. To address the limitations of traditional financial risk early warning models regarding insufficient samples and class imbalance issues, the paper proposed a financial risk early warning model based on Long Short-Term Memory networks for listed new energy vehicle companies, called SMOTE-SA-LSTM, which integrated SMOTE oversamping and simulated annealing optimization technique.In SMOTE-SA-LSTM, a comprehensive early warning system covering 45 key indicators is constructed by combining both financial and non-financial perspectives, and the sample categories of the training set are balanced by using the SMOTE oversampling technique in order to solve the imbalance of the sample categories in the training set, so as to improve the model's ability of identifying the risks of a few categories. Further, the number of hidden layer units of the LSTM model is optimized by Simulated Annealing SA (SA) to improve the prediction accuracy of the model. Experimental validation shows that the optimized SMOTE-SA-LSTM model performs better in predicting corporate financial changes, risk identification and early warning accuracy.Compared to other traditional models, the SMOTE-SA-LSTM model demonstrates significant advantages in prediction accuracy and recall rate, thereby confirming its practical application value in financial risk early warning.",2024
Composite Triple Activation Function: Enhancing CNN-BiLSTM-AM for Sustainable Financial Risk Prediction in Manufacturing,"As a key pillar of China's economy, the manufacturing industry faces sustainable financial risk management challenges as it undergoes digital and green low-carbon transformation. However, existing financial risk prediction models often suffer from limited accuracy, insufficient robustness, and a suboptimal activation function design. In this study, we investigated advanced deep learning architectures to address these limitations, and we introduced a novel composite triple activation function (CTAF) framework to enhance predictive performance and model robustness. We began by evaluating several deep learning models, such as CNNs, BiLSTM, CNN-AM, and BiLSTM-AM, demonstrating that CNN-BiLSTM-AM achieved the highest performance. On the basis of this model structure, we proposed a CTAF, a composite activation mechanism that combines two distinct functions applied to the raw input x, effectively mitigating gradient instability and enhancing nonlinear expressiveness. Through ablation experiments with different composite activation functions, we verified that the CTAF consistently outperformed alternatives. Meanwhile, the mainstream activation functions and CTAF were applied to different layers for comparison, further verifying the CTAF's advantages in various structures. The optimal configuration was achieved when tanh was used in the CNN and Dense layers and the CTAF (tanh_relu) was applied in a Lambda layer after a BiLSTM layer, resulting in the highest accuracy of 99.5%. Furthermore, paired t-tests and evaluations on cross-industry datasets confirmed the optimal model's stability and generalizability.",2025
Systemic risk prediction based on Savitzky-Golay smoothing and temporal convolutional networks,"Based on the data from January 2007 to December 2021, this paper selects 14 representatives from four levels of the extreme risk of financial institutions, the contagion effect between financial systems, volatility and instability of financial markets, liquidity, and credit risk systemic risk. By constructing a Savitzky-Golay-TCN deep convolutional neural network, the systemic risk indicators of China's financial market are predicted, and their accuracy and reliability are analyzed. The research found that: 1) Savitzky-Golay-TCN deep convolutional neural network has a strong generalization ability, and the prediction effect on all indices is stable. 2) Compared with the three control models (time-series convolutional network (TCN), convolutional neural network (CNN), and long short-term memory (LSTM)), the Savitzky-Golay-TCN deep convolutional neural network has excellent prediction accuracy, and its average prediction accuracy for all indices has increased. 3) Savitzky-Golay-TCN deep convolutional neural network can better monitor financial market changes and effectively predict systemic risk.",2023
Application of CNN-based financial risk identification and management convolutional neural networks in financial risk,"The application of intelligent financial analysis model to the research of enterprise financial risk prediction can improve the adaptability of the model, effectively capture complex patterns and adapt to large-scale data, but there are some problems such as insufficient accuracy and low recall rate. In order to improve the effect of enterprise financial risk management, this research applies convolutional neural network to enterprise financial risk management, and proposes a binary classification prediction model of financial risk dilemma based on onedimensional convolution and sparse attention mechanism. Then, combined with experimental research, this research verifies that the synergy of multiple modules enables the model proposed in this research to understand and classify the input data more comprehensively and accurately, and then achieve significant improvements in various indicators. Moreover, compared with the comparison model of a single module, it shows superior performance. After training, the accuracy of the model is 75.98 % in the training set and 82.34 % in the test set, which shows the ideal training results, and proves that the model has good generalization ability The model has the best performance in precision, recall and F1, which is due to the comprehensive use of CNN module, LSTM module, encoder module and AR module. After training, the accuracy of the model is 75.98 % in the training set and 82.34 % in the test set, which shows the ideal training results, and proves that the model has good generalization ability. The model has the best performance in precision, recall and F1, which is due to the comprehensive use of CNN module, LSTM module, encoder module and AR module. The experimental results show that the model proposed in this research can realize the accurate classification of binary classification prediction of financial risk dilemma, help enterprises to rationally allocate resources, control the government's unnecessary financial support to enterprises that are on the verge of bankruptcy and have no prospect, and prevent the loss of enterprises' assets.",2025
Research on Deep Learning-Based Financial Risk Prediction,"Financial text-based risk prediction is an important subset for financial analysis. Through automatic analysis of public financial comments, fundamentals on current financial expectations can be evaluated. A deep learning method for financial risk prediction based on sentiment classification is proposed in this paper. The proposed method consists of two steps. Firstly, the abstract of the financial message is extracted according to the seq2seq model. During the extraction process, the seq2seq model can cope with the situation of different input message lengths. After the abstraction, invalid information in the financial messages can be effectively filtered, thus accelerating the subsequent sentiment classification step. The sentiment classification step is performed through the GRU model according to the abstracted texts. The proposed method has the following advantages: (1) it can handle financial messages of different lengths; (2) it can filter out the invalid information of financial messages; (3) because the extracted abstract is more refined, it can speed up the subsequent sentiment classification step; and (4) it has better sentiment classification accuracy. The proposed method in this paper is then verified through financial message dataset from the financial social network StockTwits. By comparing the classification performances, it can be seen that compared with the classical SVM and LSTM methods, the proposed method in this paper can improve the accuracy of sentiment classification by 5.57% and 2.58%, respectively.",2021
CVaR Prediction Model of the Investment Portfolio Based on the Convolutional Neural Network Facilitates the Risk Management of the Financial Market,"In summary, firstly, a method for establishing a portfolio model is proposed based on the risk management theory of the financial market. Then, a prediction model for CVaR is established based on the convolutional neural network, and the improved particle swarm algorithm is employed to solve the model. The actual data analysis is implemented to prove the feasibility of CVaR prediction model based on deep learning and particle swarm optimization algorithm in financial market risk management. The test results show that the investment portfolio CVaR prediction model based on the convolutional neural network can obtain the optimal solution in the 18th generation at the fastest after using the improved particle swarm algorithm, which is more effective than the traditional algorithm. The CVaR prediction model of the investment portfolio based on the convolutional neural network facilitates the risk management of the financial market.",2022
Deep Learning Using Risk-Reward Function for Stock Market Prediction,"Many recent studies have attempted to apply a deep learning approach to build a model for stock market prediction. Most of these studies have concentrated on using prediction accuracy as a performance metric. Some of them have also performed trading simulations to evaluate financial performance. However, financial performance was not improved significantly because the loss function used in the training process focused primarily on prediction accuracy. In this paper, we propose a new framework to train a deep neural network for stock market prediction. A new loss function was developed by adding a risk-reward function, which is derived by the trading simulation results. A new scoring metric called Sharpe-F1 score, which is a combination of Sharpe ratio and F1 score is used for model selection. We employ the best prediction model from our previous work, which consists of Convolutional Neural Network (CNN) and Long Short-Term Memory Network (LSTM) architectures and takes event embedding vectors, historical prices and a set of technical indicators as inputs. The robustness of our framework is evaluated on two datasets by varying the key parameters used in the proposed framework. The results show that financial performance can be improved by adding a risk-reward function into the loss function used in the training process.",2018
Optimizing Financial Risk Models in Digital Transformation-Deep Learning for Enterprise Management Decision Systems,"The digital transformation of enterprises has amplified the complexity of financial risks, underscoring the significance of optimizing financial risk warning models to ensure sustainable development. This study integrates several deep learning techniques, including Back Propagation Neural Network (BPNN), Bi-Long Short-Term Memory (Bi-LSTM), and transfer learning, to enhance the risk warning system and improve the accuracy and efficiency of financial risk prediction models. The results demonstrate that the proposed algorithm surpasses the baseline models in various metrics. For instance, on the Altman's Z-Score dataset, there is an improvement of 1.4% in accuracy, a reduction of over 48.8% in FLOP, and an enhancement of 43.5% in MAPE. These outcomes underscore the significant advancements in risk identification, decision support, and proactive risk management facilitated by the proposed model. As a result, enterprises can derive benefits from more precise and reliable financial risk warning tools, and effectively address the challenges brought about by digital transformation.",2024
Gold Price Forecast based on LSTM-CNN Model,"An accurate prediction is certainly significant in financial data analysis. Investors have used a series of econometric techniques on pricing, stock selection and risk management but few of them have found great success due to the fact that most of them only are purely based on a single scheme. Recent advances in deep learning methods have also demonstrated the outstanding performance in the fields of image recognition and sentiment analysis. In this paper, we originally propose a novel gold price forecast method based on the integration of Long Short-Term Memory Neural Networks (LSTM) and Convolutional Neural Networks (CNN) with Attention Mechanism (denoted to LSTM-Attention-CNN model). Particularly, the LSTM-Attention-CNN model consists of three components: the LSTM component, Attention Mechanism and the CNN component. The LSTM component enables to harness the sequential order of daily gold price. Meanwhile, the Attention Mechanism assigns different attention weights on the new encoding method from LSTM component to enhance the extraction of the temporal and spatial features. In addition, the CNN component enables to capture the local patterns and abstract the spatial features. Extensive experiments on real dataset collected from World Gold Council show that our proposed approach outperforms other conventional financial forecast methods.",2019
"Research on Financial Risk Intelligent Monitoring and Early Warning Model Based on LSTM, Transformer, and Deep Learning","As global financial markets continue to evolve and change, financial risk monitoring and early warning have become increasingly important. However, the complexity and diversity of financial markets have led to the emergence of multidimensional and multimodal data. Traditional risk monitoring methods face difficulties in handling such diverse data and adapting to the monitoring and early warning needs of emerging risk types. To address these issues, this article proposes a financial risk intelligent monitoring and early warning model that integrates deep learning to better cope with uncertainty and risk in the financial market. Firstly, the authors introduce an LSTM model in the initial approach, trained on historical financial market data, to capture long-term dependencies and trends in the data, enabling effective monitoring of financial risk. They also optimize the model architecture to improve its performance and prediction accuracy. Secondly, the authors further introduce a transformer model with self -attention mechanism to better handle sequential data.",2024
Deep Learning-based Delinquent Taxpayer Prediction: A Scientific Administrative Approach,"This study introduces an effective method for predicting individual local tax delinquencies using prevalent machine learning and deep learning algorithms. The evaluation of credit risk holds great significance in the financial realm, impacting both companies and individuals. While credit risk prediction has been explored using statistical and machine learning techniques, their application to tax arrears prediction remains underexplored. We forecast individual local tax defaults in Republic of Korea using machine and deep learning algorithms, including convolutional neural networks (CNN), long short-term memory (LSTM), and sequence -to -sequence (seq2seq). Our model incorporates diverse credit and public information like loan history, delinquency records, credit card usage, and public taxation data, offering richer insights than prior studies. The results highlight the superior predictive accuracy of the CNN model. Anticipating local tax arrears more effectively could lead to efficient allocation of administrative resources. By leveraging advanced machine learning, this research offers a promising avenue for refining tax collection strategies and resource management.",2024
RETRACTED: Analysis and Risk Assessment of Corporate Financial Leverage Using Mobile Payment in the Era of Digital Technology in a Complex Environment (Retracted Article),"The study aims to improve the enterprise's ability to respond to financial crises and find some countermeasures to prevent potential financial risks. The enterprise financial risk is assessed, and the automatic summary function of mobile payment platforms based on long short-term memory (LSTM) is performed to extract the structured data and unstructured texts from its annual report. On this basis, the early warning system model of financial risks is implemented and its accuracy is improved. The structured data and unstructured text in the company's annual report are extracted. The enterprise financial risk early warning system model is constructed. The accuracy of the enterprise financial risk early warning system has been improved. Firstly, we use the convolutional neural network (CNN) to establish a financial risk prediction system using financial data and test various indicators of the system. Secondly, the financial annual report of the listed company is obtained from the Internet. The required financial statements are obtained in two ways. The first is to set high special treatment (ST) sample weights and delete some non-ST samples. The second is to delete punctuation marks, interjections, numbers, and so on and process the collected text data. The financial risk prediction model is established using the financial text, and the LSTM + attention mechanism is used to optimize the model. Finally, combining structured financial data and unstructured financial text to establish a forecasting model, the model uses LSTM. Combined with a single-layer neural network or CNN model, the comparison experiment is carried out in two ways. Experiments show that the CNN or LSTM attention mechanism cannot significantly improve the performance of the system only using financial data or texts. Using the financial data and financial text using the LSTM + CNN model, the F1 value reached 85.29%. Financial data and other indicators in the text have also been greatly improved, and the overall performance is the best. In summary, LSTM using financial data and financial texts combined with CNN to establish a risk prediction system can help investors and companies themselves find possible financial crises in listed companies as soon as possible and help companies deal with their financial risks in a timely manner.",2022
Exploration of Financial Market Credit Scoring and Risk Management and Prediction Using Deep Learning and Bionic Algorithm,"The purpose is to effectively manage the financial market, comprehensively assess personal credit, and reduce the risk of financial enterprises. Given the systemic risk problem caused by the lack of credit scoring in the existing financial market, a credit scoring model is put forward based on the deep learning network. The proposed model uses RNN (recurrent neural network) and BRNN (bidirectional recurrent neural network) to avoid the limitations of shallow models. Afterward, to optimize path analysis, bionic optimization algorithms are introduced, and an integrated deep learning model is proposed. Finally, a financial credit risk management system using the integrated deep learning model is proposed. The probability of default or overdue customers is predicted through verification on three real credit data sets, thus realizing the credit risk management for credit customers.",2022
RETRACTED: Design of Financial Risk Control Model Based on Deep Learning Neural Network (Retracted Article),"In recent years, with the continuous increase of financial business, the risk of business is on the rise. Among them, major risk cases are frequent, the cases are increasingly complex, and the means of committing crimes are concealed. The main research contents of this paper include the preprocessing of internal and external financial data and the structure design of recurrent NNs. Its purpose is to design a financial risk control model based on a deep learning NNs, thereby reducing financial risk. The Borderline-SMOTE algorithm is used first to preprocess the sample data, and the oversampling method is used to eliminate the imbalance of the data, and then, the long short-term memory deep NNs algorithm is introduced to process the sample data with time series characteristics. The final experiment shows that LSTM has a better accuracy, reaching 0.9715, compared with traditional methods; the sample preprocessing method and risk control model proposed in this paper have better ability to identify fraudulent customers, and the model itself has faster iteration efficiency.",2022
Corporation financial distress prediction with deep learning: analysis of public listed companies in Malaysia,"Purpose In the previous study of financial distress prediction, deep learning techniques performed better than traditional techniques over time-series data. This study investigates the performance of deep learning models: recurrent neural network, long short-term memory and gated recurrent unit for the financial distress prediction among the Malaysian public listed corporation over the time-series data. This study also compares the performance of logistic regression, support vector machine, neural network, decision tree and the deep learning models on single-year data. Design/methodology/approach The data used are the financial data of public listed companies that been classified as PN17 status (distress) and non-PN17 (not distress) in Malaysia. This study was conducted using machine learning library of Python programming language. Findings The findings indicate that all deep learning models used for this study achieved 90% accuracy and above with long short-term memory (LSTM) and gated recurrent unit (GRU) getting 93% accuracy. In addition, deep learning models consistently have good performance compared to the other models over single-year data. The results show LSTM and GRU getting 90% and recurrent neural network (RNN) 88% accuracy. The results also show that LSTM and GRU get better precision and recall compared to RNN. The findings of this study show that the deep learning approach will lead to better performance in financial distress prediction studies. To be added, time-series data should be highlighted in any financial distress prediction studies since it has a big impact on credit risk assessment. Research limitations/implications The first limitation of this study is the hyperparameter tuning only applied for deep learning models. Secondly, the time-series data are only used for deep learning models since the other models optimally fit on single-year data. Practical implications This study proposes recommendations that deep learning is a new approach that will lead to better performance in financial distress prediction studies. Besides that, time-series data should be highlighted in any financial distress prediction studies since the data have a big impact on the assessment of credit risk. Originality/value To the best of authors' knowledge, this article is the first study that uses the gated recurrent unit in financial distress prediction studies based on time-series data for Malaysian public listed companies. The findings of this study can help financial institutions/investors to find a better and accurate approach for credit risk assessment.",2021
Internet Financial Credit Risk Assessment with Sliding Window and Attention Mechanism LSTM Model,"With the accelerated pace of market-oriented reform, Internet finance has gained a broad and healthy development environment. Existing studies lack consideration of time trends in financial risk, and treating all features equally may lead to inaccurate predictions. To address the above problems, we propose an LSTM model based on sliding window and attention mechanism. The model uses sliding windows to enable the model to effectively exploit the contextual relevance of loan data. And we introduce the attention mechanism into the model, which enables the model to focus on important information. The result on the Lending Club public desensitization dataset shows that our model outperforms ARIMA, SVM, ANN, LSTM, and GRU models.",2023
A Hybrid CNN and LSTM based Model for Financial Crisis Prediction,"The detection and prediction of financial crises in listed companies are crucial for investors to mitigate potential losses. Traditional prediction methods primarily rely on financial indicators, yet they often overlook valuable insights hidden in financial text. To address this limitation, our study explores the integration of financial indicators and financial text from annual reports to enhance financial crisis prediction. We propose a two-step approach, leveraging a Convolutional Neural Network (CNN) model to extract features from financial indicators and utilizing a Long Short-Term Memory (LSTM) network with attention mechanism to capture the underlying semantics in financial text. Subsequently, we combine the extracted features from both sources for effective classification. Through extensive experiments with various models, we demonstrate the efficacy of our combined approach in achieving optimal prediction results. Our findings highlight the importance of considering financial text alongside traditional financial indicators for enhanced financial crisis detection and prediction. The proposed methodology contributes to the existing literature and offers valuable insights for investors and financial analysts seeking more accurate and comprehensive risk assessment tools.",2024
Financial Portfolio Construction for Quantitative Trading Using Deep Learning Technique,"Stock portfolio construction is a difficult task which involves the simultaneous consideration of dynamic financial data as well as investment criteria (e.g.: investors required return, risk tolerance, goals, and time frame). The objective of this research is to present a two phase deep learning module to csonstruct a financial stocks portfolio that can be used repeatedly to select the most promising stocks and adjust stocks allocations (namely quantitative trading system). A deep belief network is used to discover the complex regularities among the stocks while a long short-term memory network is used for time series financial data prediction. The proposed deep learning architecture has been tested on the american stock market and has outperformed other known machine learning techniques (support vector machine and random forests) in several prediction accuracy metrices. Furthermore, the results showed that our architecture as a portfolio construction model outperforms three benchmark models with several financial profitability and risk-adjusted metrics.",2021
Deep learning for enhanced risk management: a novel approach to analyzing financial reports,"Risk management is a critical component of today's financial environment because of the enormity and complexity of data contained in financial statements. Business situations, plans, and schedule risk assessment with the help of conventional ways which involve analytical, technical, and heuristic models are inadequate to address the complex structures of the latest data. This research brings out the Hybrid Financial Risk Predictor (HFRP) model, using the convolutional neural networks (CNN) and long-short term memory (LSTM) networks to improve financial risk prediction. A combination of quantitative and qualitative ratings derived from the analysis of financial texts results in high accuracy and stability compared with the HFRP model. Evaluating key findings, the quantity of training & testing loss decreased considerably and they have their final value as 0.0013 and 0.003, respectively. According to the hypothesis, the selected HFRP model demonstrates the values of the revenue, net income, and earnings per share (EPS), and are closely similar to the actual values. The model achieves substantial risk mitigation: credit risk lowered from 0.75 to 0.20, liquidity risk from 0.70 to 0.25, market risk from 0.65 to 0.30, while operational risk is at 0.80 to 0.35. By analyzing the results of the HFRP model, it can be stated that the proposal promotes improved financial stability and presents a reliable model for the contemporary financial markets, which in turn helps in making sound decisions and improve the assessment of risks.",2025
Semantic Analysis and Image Processing-Jointly Driven Multimodal Deep Learning Framework for Smart Warning of Enterprise Financial Risk,"Financial risk warning is a crucial technical issue for enterprises. Traditionally, it relied on modeling analysis of a single data type, which does not fully capture the diverse characteristics of financial risk activities. To address this, this paper introduces a multimodal deep learning framework driven by semantic analysis and image processing for intelligent warning of enterprise financial risks. Initially, natural language processing algorithms analyze textual data such as financial statements, news reports, and social media comments within the industry. Concurrently, two convolutional neural network models, M-CNN and M-RNN, extract features from images and chart data. These textual and visual feature representations are then fused to create a multimodal deep neural network framework. Extensive experimental evaluation and comparative analysis of the proposed framework were conducted. The results indicate that the financial risk rate of consumer fraud graph analysis varies significantly, displaying a fluctuating state with values ranging from 2.1% to 16.8%. Compared to other methods, the proposed approach demonstrates superior performance in financial risk warning tasks, with the risk rate increasing from 1.2% to 26.5% as it iterates from 1 to 6.",2024
An attention embedded DUAL-LSTM method for financial risk early warning of the three new board-listed companies,"Computer and financial fields are both involved in the interdisciplinary topic of financial risk early warning. We suggest an attention-embedded dual Long Short Term Memory (DUAL-LSTM) for the financial risk early warning to deal with the potential and constraints of rapid economic development to improve the precision of the financial risk prediction for the listed businesses on the New Third Board. First, feature fusion attentionally quantifies data characteristics, increasing the robustness and generalizability of data features. The model's predictive power is then increased by creating a dual LSTM model to meet the financial risk. The studies show that the attention-embedded dual LSTM model can achieve 96.9% of the F value scores and is superior to state-of-the-art model (SOTA) such as the Z-score model, Fisher discriminant method, logistic regression, and Back-Propagation network, achieves the advantage of time series in financial risk prediction. Additionally, for predicting financial risk, our algorithm performs flawlessly and effectively.",2023
Network-Based prediction of financial cross-sector risk spillover in China: A deep learning approach,"There are complex risk correlations between financial sectors, and the risks generated by different financial sectors propagate, accrue, and cluster through the network of correlations, posing a threat to the entire financial system. This research constructs static and dynamic cross -sector risk spillover networks using VAR and generalized variance decomposition, and forecasts the evolution of risk spillover networks using recurrent neural network models such as RNN and LSTM. The results indicate that the risk spillover network will change rapidly in response to risk events, and that the total volatility spillover will increase during times of crisis, while banks and securities are the most important risk propagating and receiving sectors. The LSTM model can achieve more effective dynamic prediction of the multidimensional network, and the predicted network is essentially consistent with the actual network. According to the findings of the study, forecasting changes in the structure of financial sector networks may provide early warning of systemic financial risk and assist to a better understanding of the risk link between financial sectors.",2024
Nonlinear Volatility Risk Prediction Algorithm of Financial Data Based on Improved Deep Learning,"With the gradual integration of global economy and finance, the financial market presents many complex financial phenomena. To increase the prediction accuracy of financial data, a new nonlinear volatility risk prediction algorithm is proposed based on the improved deep learning algorithm. First, the financial data are taken as the research object and the closing price is set as the prediction target. Then, the nonlinear volatility risk prediction model of the financial data is established through the wavelet principal component analysis noise reduction module and the long and short-term memory network (LSTM) module, and the nonlinear volatility trend is extracted from multiple financial data series to realize the nonlinear volatility risk prediction of the financial data. During the whole experiment, the time of the research method was less than 1.5 minutes. And for 1200 test samples, the average error of data risk prediction of the proposed method is 0.0217%. The average cost of the research method is 114.25 million yuan, which is significantly lower than other existing algorithms. Experimental results show that the research method can effectively predict the risk of financial data and is more suitable for the risk control early warning of Internet financial platform.",2022
Shanghai Containerised Freight Index Forecasting Based on Deep Learning Methods: Evidence from Chinese Futures Markets,"With the escalation of global trade, the Chinese commodity futures market has ascended to a pivotal role within the international shipping landscape. The Shanghai Containerized Freight Index (SCFI), a leading indicator of the shipping industry's health, is particularly sensitive to the vicissitudes of the Chinese commodity futures sector. Nevertheless, a significant research gap exists regarding the application of Chinese commodity futures prices as predictive tools for the SCFI. To address this gap, the present study employs a comprehensive dataset spanning daily observations from March 24, 2017, to May 27, 2022, encompassing a total of 29,308 data points. We have crafted an innovative deep learning model that synergistically combines Long Short- Term Memory (LSTM) and Convolutional Neural Network (CNN) architectures. The outcomes show that the CNN-LSTM model does a great job of finding the nonlinear dynamics in the SCFI dataset and accurately capturing its long-term temporal dependencies. The model can handle changes in random sample selection, data frequency, and structural shifts within the dataset. It achieved an impressive R2 of 96.6% and did better than the LSTM and CNN models that were used alone. This research underscores the predictive prowess of the Chinese futures market in influencing the Shipping Cost Index, deepening our understanding of the intricate relationship between the shipping industry and the financial sphere. Furthermore, it broadens the scope of machine learning applications in maritime transportation management, paving the way for SCFI forecasting research. The study's findings offer potent decision-support tools and risk management solutions for logistics enterprises, shipping corporations, and governmental entities.",2024
Big data-driven corporate financial forecasting and decision support: a study of CNN-LSTM machine learning models,"With the rapid advancement of information technology, particularly the widespread adoption of big data and machine learning, corporate financial management is undergoing unprecedented transformation. Traditional methods often lack accuracy, speed, and flexibility in forecasting and decision-making. This study proposes a hybrid Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) model to enhance financial data prediction and decision efficiency. Utilizing financial data from A-share listed companies in the CSMAR database (2000-2023), we analyzed 54 key financial indicators across 54,389 observations. The data underwent preprocessing and dimensionality reduction via Principal Component Analysis (PCA) to eliminate redundancy and noise. The CNN-LSTM hybrid model was then trained and tested on the refined dataset. Experimental results demonstrate the superior performance of the proposed model, achieving a Mean Squared Error (MSE) of 0.020 and an R2 score of 0.411, significantly outperforming benchmark models (ARIMA, Random Forest, XGBoost, and standalone LSTM). A practical enterprise case analysis further confirms the model's effectiveness in improving financial forecasting accuracy, optimizing decision-making, and mitigating financial risks. The findings highlight that a big data and machine learning-driven financial forecasting system can substantially enhance corporate financial management. By improving prediction reliability and operational efficiency, this approach aids businesses in achieving robust risk control and sustainable growth in uncertain market environments.",2025
Advanced Supply Chain Management Using Adaptive Serial Cascaded Autoencoder with LSTM and Multi-Layered Perceptron Framework,"Supply chain management is essential for businesses to handle uncertainties, maintain efficiency, and stay competitive. Financial risks can arise from various internal and external sources, impacting different supply chain stages. Companies that effectively manage these risks gain a deeper understanding of their procurement activities and implement strategies to mitigate financial threats. This paper explores financial risk assessment in supply chain management using advanced deep learning techniques on big data. The Adaptive Serial Cascaded Autoencoder (ASCA), combined with Long Short-Term Memory (LSTM) and Multi-Layered Perceptron (MLP), is used to evaluate financial risks. A data transformation process is used to clean and prepare financial data for analysis. Additionally, Sandpiper Galactic Swarm Optimization (SGSO) is employed to optimize the deep learning model's performance. The SGSO-ASCALSMLP-based financial risk prediction model demonstrated superior accuracy compared to traditional methods. It outperformed GRU (gated recurrent unit)-ASCALSMLP by 3.03%, MLP-ASCALSMLP by 7.22%, AE-LSTM-ASCALSMLP by 10.7%, and AE-LSTM-MLP-ASCALSMLP by 10.9% based on F1-score performance. The SGSO-ASCALSMLP model is highly efficient in predicting financial risks, outperforming conventional prediction techniques and heuristic algorithms, making it a promising approach for enhancing financial risk management in supply chain networks.",2024
A Hybrid Deep Learning Approach for Systemic Financial Risk Prediction,"Systemic financial risk prediction is a complex nonlinear problem and tied tightly to financial stability since the recent global financial crisis. In this paper, we propose the Systemic Financial Risk Indicator (SFRI) and a hybrid deep learning model based on CNN and BiGRU to predict systemic financial risk. Experiments have been carried out over Chinese economic and financial actual data, and the results demonstrate that the proposed model achieves superior performance in feature learning and outperformance with the baseline methods in both single-step and multi-step systemic financial risk prediction.",2020
Forecasting Financial Market Trends in a Complex Business Environment,"Applications for the stock market that can be relied upon to provide the information regular and professional investors need to make better-informed purchases are a boon to both. A well-thought-out sales approach may help buyers mitigate risk, zero in on the companies most likely to provide the highest returns, and increase their chances of making a purchase. Due to numerous interrelationships between various company values, executing stock market research utilizing batch processing methods provides an exceptionally tough task. Technology advancements, such as the licensing of global processes, usher in a new age for stock market forecasting. The present market climate has increased the significance of data applications. An interesting and new contribution made by this work is the proposal of a deep learning-based resilience time series model for forecasting future market values. By analyzing financial time series, this study aimed to build a sophisticated strategy for forecasting stock market prices. The use of artificial intelligence (AI) to forecast future market behavior is one of the most intriguing developments in this generation of technological breakthroughs. Particularly promising results have been found when applying deep learning techniques to the task of predicting the actions of market players. In this paper, we propose a method for forecasting the final prices of publicly traded firms like Tesla, Inc. and Apple, Inc. by merging a convolutional neural network with long short-term memory (LSTM). These two methods were both developed with the help of deep learning techniques. The time frame covered by statistics used in these projections is two years. To evaluate the performance of our deep learning models, we compared their market predictions using several different metrics, including mean squared error (MSE), root mean squared error (RMSE), normalized root mean squared error (NRMSE), and Pearson's R. When compared to the options, the CNN-LSTM deep learning algorithm did the best. When comparing convolution neural networks CNN-LSTM model to the normal LSTM and a simpler deep learning variant, the latter showed to be more effective at forecasting stock market values. This was the case when examining all three variants together.",2024
Prediction of Unbalanced Financial Risk Based on GRA-TOPSIS and SMOTE-CNN,"The financial status of an enterprise is related to its healthy and long-term development, and whether the interests of investors and bank loans can be guaranteed. To improve the prediction accuracy of corporate financial risk, this paper proposes a prediction model for corporate financial risk that integrates GRA-TOPSIS and SMOTE-CNN. First, using GRA-TOPSIS to make a comprehensive evaluation of the financial situation of listed companies. Second, the evaluation results are clustered to obtain the scientific level and interval of financial risk, which lays the foundation for the supervised learning of the convolutional neural network. Then, the SMOTE algorithm is introduced to solve the problem of data imbalance of enterprises at all levels, and the focal loss function is used instead of the cross-entropy loss function to further balance the data. Finally, the listed companies in A shares are randomly selected, and experiments were designed to verify the performance of the model built in this paper. The results show that the prediction accuracy of the financial risk prediction model based on GRA-TOPSIS and SMOTE-CNN is 98.57%, which indicates that the model is feasible and has certain reference value.",2022
Design Research on Financial Risk Control Model Based on CNN,"In the new era, with the rapid entry of a large number of financial products into the market environment, network finance has become an indispensable part of people's daily life. From the practical point of view, the network loan has the advantages of simple operation and a short audit cycle, so it has attracted the attention of the public once it is promoted. However, due to the influence of the environment and their own technology, it is easy to appear the risk of fraud during the operation. In the face of this development phenomenon, it is very important for the future development of the internet finance industry to construct a financial risk control model based on the credit evaluation of loan applicants. Based on the understanding of the risk control model in an unbalanced data environment, this paper constructs the design and implementation of the financial risk control model based on the convolutional neural network (CNN), and analyzes and discusses the final results.",2022
Option pricing under sub-mixed fractional Brownian motion based on time-varying implied volatility using intelligent algorithms,"Against the background of the current complex international geopolitical situation and more intense trade frictions, the volatility of financial assets has important research significance as a basis for risk analysis and option pricing. First, considering the characteristics of financial assets-such as long dependence-the pricing model can become complicated, making it difficult to calculate the implied volatility directly. Establishing the loss function between the trading data and modeled value, the implied volatility at different moments solved using the global optimal double annealing algorithm was found to differ from the generalized autoregressive conditional heteroskedasticity (GARCH) volatility and historical volatility. Second, the implied volatility considering people's future expectations of financial assets was predicted using the previously known implied volatility via deep learning methods. The empirical results showed that the implied volatilities predicted using the long short-term memory (LSTM) and one-dimensional convolutional neural network (1D-CNN) methods performed well for option pricing. Moreover, the fractal option-pricing models outperformed the traditional Black-Scholes (B-S) pricing model. Finally, based on the accumulated local effect (ALE) algorithm-which can quantify the impact analysis of different volatilities on pricing models-it was found that the predicted implied volatility using artificial intelligence algorithms was more relevant to the truth. A combination of traditional mathematical models and emerging intelligent algorithms are promoted in this study, providing a reference for investors and risk managers and contributing to the continued development of financial markets.",2023
Performance comparison analysis of classification methodologies for effective detection of intrusions,"Intrusion detection systems (IDS) are critical in many applications, including cloud environments. The intrusion poses a security threat and extracts privacy data and information from the cloud. Additionally, intrusions can cause damage to system hardware, resulting in significant financial losses and exposing critical IT infrastructure to risk. To overcome these issues, this study employs the performance comparison analysis for IDS, which has been performed with different models like Autoencoder Convolutional neural network (AE+CNN), Random forest K-means clustering assisted deep neural network (RF+K-means+DNN), Autoencoder K-means clustering assisted long short term memory (AE+K-means+LSTM), Alexnet+Bi-GRU, AE+Alexnet+Bi-GRU and Wild horse AlexNet assisted Bi-directional Gated Recurrent Unit (WABi-GRU) models to choose the best methodology for effective detection of intrusions. The data needed for the analysis is collected from CICIDS2018, UNSW-NB15, NSL-KDD and ToN-IoT datasets. The collected data are pre-processed using data normalization and data cleaning. Finally, the best model has been chosen for effective intrusion detection, which is used for further processes. Various performances, such as accuracy, precision, recall, and f1-score, are analyzed for various existing and proposed models. From this performance comparison of six models such as AE+CNN, RF+Kmeans+DNN, AE+K-means+LSTM, Alexnet+Bi-GRU, AE+Alexnet+Bi-GRU and WABi-GRU. WABi-GRU can attain an accuracy of 99.890 % for multi-class classification in the CICIDS 2018 dataset, 99.7 % in the NSL-KDD dataset, 99.53 % in the UNSW-NB 15 dataset and 99.988 % for the ToN-IoT dataset. In this analysis, the models containing AlexNet Bi-GRU-based models can obtain better performances than other existing models. The WABiGRU model can obtain better results than other models.",2024
RETRACTED: Identification and Early Warning of Financial Fraud Risk Based on Bidirectional Long-Short Term Memory Model (Retracted Article),"In modern market economy, corporate financial frauds emerge one after another, which have a huge impact on the stock market and triggered an unprecedented credit crisis. Therefore, it is particularly important to identify financial frauds. Improving the efficiency, accuracy, and coverage of fraud identification in financial reports through digital and intelligent means is one of the important links to improve credit risk control of securities companies and also for securities companies to accurately price related financial products of target companies. Traditional recognition methods based on artificial rules can cover relatively limited indicators; rule parameters are set randomly. Besides, it is difficult to make rules based on high-dimension indicators and to dig the hidden deep relationships between indicators. This paper summarizes the relevant indicators of financial fraud identification from the perspective of financial and nonfinancial characteristics. Then, the identification and early warning of financial fraud risk based on bidirectional long-short term memory model are proposed. This method uses the idea of ensemble learning, weights the probability of financial key indicators, and uses the optimal transfer probability to solve the financial fraud risk results. The results show that the industry-specific modeling can significantly improve the accuracy of the financial fraud identification model and it also can effectively help the government regulatory departments, investors, and audit departments to correctly identify the financial fraud of listed companies.",2022
CIFT: Connected Intelligent Fund Transaction System Based on Deep Learning,"Fund correlation analysis can guide investors' investment and wealth management, avoiding the selection of highly relevant funds in the investment process, which can make the risk sharing among funds. There is a strong dependence between the features of the fund data and a long-term dependence between the output of different time steps, which makes it difficult to obtain good performance in the fund data in the data analysis model used in the traditional intelligent investment system. This has brought difficulties to fund correlation analysis. However, some studies in recent years have shown that the LSTM (Long Short-Term Memory) model has good time series processing capability, and the Encoder-decoder model has made great progress in the application of financial time series analysis. Based on the above research, this paper constructs the DLIFT system using an Improved RNN model combined with attention mechanism.. The attention mechanism can select specific feature inputs and previous time step outputs, both of which are highly correlated with the current output, making system predictions more efficient. This paper applies this model to the historical data set containing multiple public funds, and compares it with several other intelligent investment systems. The results show that the fund intelligent investment system proposed in this paper performs best. The research in this paper is of great significance to the use of deep learning methods to solve fund correlation analysis problems, and provides new ideas for the research in the field of smart finance.",2019
Research on Financial Risk Forecast Model of Listed Companies Based on Convolutional Neural Network,"With the continuous improvement of China's market economy, many listed companies enjoy the unlimited development opportunities brought by the market economy environment but are also threatened by various potential risks. They may be labeled ST at any time due to financial risks. The label may even end up in danger of delisting. Most companies encountered serious financial crises or even bankruptcies in the later period because they did not pay enough attention to the financial problems that occurred in the early stage and did not take effective measures to deal with the crisis in a timely manner. This is extremely detrimental to the subsequent development of the company. Therefore, more and more attention has been paid to the research on the financial risk status of enterprises. Therefore, on the basis of analyzing the financial information of listed companies, this article extracts the characteristics of listed companies and images them and uses convolutional neural networks to construct a financial risk prediction model to improve the accuracy of risk prediction. Specifically, this article also compares and analyzes the financial risk prediction models of different types of listed companies, optimizes the index system, and uses the convolutional neural network method to construct a targeted financial risk prediction model with data characteristics. The actual operation data and actual risk data of the listed companies are verified, proving that it has strong adaptive ability to face different types of data, strong operability, and high prediction accuracy.",2022
Enhancing Financial Risk Prediction Using TG-LSTM Model: An Innovative Approach with Applications to Public Health Emergencies,"Amidst the backdrop of economic globalization and occasional public health crises, the comprehension and mitigation of financial risks confronting enterprises have emerged as imperative pursuits. This research paper delves into the intricate nexus between these global phenomena and the realm of financial risk management. Conventional approaches to financial risk prediction often falter in grappling with the intricacies of contemporary financial markets. To address this challenge, our study introduces a pioneering methodology termed the TG-LSTM (Time Series Ratio Analysis combined with Long Short-Term Memory) model, aimed at furnishing early financial warnings to enterprises. The TG-LSTM model harnesses the power of ratio analysis to discern representative financial data reflective of crucial facets such as debt-paying ability, operational efficiency, growth prospects, and profitability. Leveraging the TSVD (Truncated Singular Value Decomposition) technique bolsters prediction accuracy, while the XGboost feature screening method aids in curtailing data dimensionality. Our analysis integrates real-world data from the CSI 300 and SSE 50 datasets, with results showcasing the efficacy of the TG-LSTM model. With the lowest Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE) values, our model attains an impressive accuracy rate of 96.1%. This research represents a significant stride in advancing financial risk prediction, shedding light on the confluence of financial stability, global events, and innovative data analytics. It underscores the pivotal role of technology, knowledge management, and innovation in navigating the complexities of today's rapidly evolving knowledge economy and enhancing the anticipation and mitigation of financial risks in contemporary society.",2024
A New Perspective on Financial Risk Prediction in a Carbon-Neutral Environment: A Comprehensive Comparative Study Based on the SSA-LSTM Model,"Climate change is widely acknowledged as the paramount global challenge of the 21st century, bringing economic, social, and environmental impacts due to rising global temperatures, more frequent extreme weather events, and ecosystem disturbances. To combat this, many countries target net-zero carbon emissions by 2050, reshaping both the financial system and consumption patterns. This transition has sharpened the financial sector's focus on climate-related risks, making the carbon footprint, environmental benefits of investments, and sustainability of financial products critical to investors' decisions. However, conventional risk prediction methods may not fully capture these climate-associated risks in a carbon-neutral setting. Emerging from this context is the need for innovative predictive tools. Recently, Long Short-Term Memory networks (LSTM) have gained prominence for their efficacy in time-series forecasting. Singular Spectrum Analysis (SSA), effective for extracting time series patterns, combined with LSTM as SSA-LSTM, offers a potentially superior approach to financial risk prediction. Our study, focusing on a case study of the wind energy sector in China, situates itself within the growing body of research focusing on the integration of environmental sustainability and financial risk management. Leveraging the capabilities of SSA-LSTM, we aim to bridge the gap in the current literature by offering a nuanced approach to financial risk prediction in the carbon-neutral landscape. This research not only reveals the superiority of the SSA-LSTM model over traditional methods but also contributes a robust framework to the existing discourse, facilitating a more comprehensive understanding and management of financial risks in the evolving carbon-neutral global trend.",2023
A deep learning-based sentiment flow analysis model for predicting financial risk of listed companies,"With the advancement of natural language processing technology, more studies are applying deep learning models to extract features from unstructured data and predict corporate financial risk through horizontal comparisons. This paper proposes the Sentiment Flow Analysis (SFA) model designed to capture the nuanced emotional dynamics present in corporate annual reports and analyst reports from a longitudinal perspective. By leveraging advanced contextual embeddings from a Transformer architecture and employing a sophisticated recurrent neural network, the model effectively processes sequential data, allowing for a comprehensive understanding of sentiment trends over a five-year period. The effectiveness of our model was validated through experiments predicting the removal of special treatment (ST) status for 344 listed companies under special treatment in 2022 and 2023, achieving a prediction accuracy of up to 82.27%. Compared to stateof-the-art models in the same field, our model demonstrates improvements in prediction accuracy and recall, showcasing the application of Artificial Intelligence (AI) in financial risk assessment.",2025
A survey on deep learning for financial risk prediction,"The rapid development of financial technology not only provides a lot of convenience to people's production and life, but also brings a lot of risks to financial security. To prevent financial risks, a better way is to build an accurate warning model before the financial risk occurs, not to find a solution after the outbreak of the risk. In the past decade, deep learning has made amazing achievements in the fields, such as image recognition, natural language processing. Therefore, some researchers try to apply deep learning methods to financial risk prediction and most of the results are satisfactory. The main work of this paper is to review the predecessors' work of deep learning for financial risk prediction according to three prominent characteristics of financial data: heterogeneity, multi-source, and imbalance. We first briefly introduced some classical deep learning models as the model basis of financial risk prediction. Then we analyzed the reasons for these characteristics of financial data. Meanwhile, we studied the differences of commonly used deep learning models according to different data characteristics. Finally, we pointed out some open issues with research significance in this field and suggested the future implementations that might be feasible.",2021
Problems and Countermeasures of Financial Risk in Project Management Based on Convolutional Neural Network,"Under the background of market economy, engineering projects are faced with a lot of financial risks. If we cannot prevent them effectively, it will undoubtedly bring serious negative impact to the entire engineering management work. Therefore, it is particularly important to actively manage risks, identify and evaluate risks in a timely and correct manner, manage risks efficiently, and minimize risk losses. At the same time, the development of wireless communication technology has brought many new branches of engineering project management. Some problems in the process of risk management are often not handled by traditional empirical calculation or mathematical methods, so it is necessary to find an appropriate way to define and describe the nonlinear relationship between a large number of uncertain causes and risk losses. In order to match the changes in the background of the development of wireless communication technology, this paper studies the financial risk problems and countermeasures in the engineering management of convolutional neural networks. The financial risk prediction model in network engineering management is constructed, and the volume neural network algorithm referenced by it is tested. The test results are highly consistent with the expert assessment. In the research process, the combination of questionnaire survey and mathematical analysis method was adopted, the extreme value of risk factors was determined by questionnaire survey, and then the accuracy of prediction was verified by a mathematical model. After many calculations, it has been proved that the convolutional neural network simulation system based on the scientific node selection method has greatly improved the accuracy of risk assessment.",2022
A Hybrid GARCH and Deep Learning Method for Volatility Prediction,"Volatility prediction plays a vital role in financial data. The time series movements of stock prices are commonly characterized as highly nonlinear and volatile. This study is aimed at enhancing the accuracy of return volatility forecasts for stock prices by investigating the prediction of their price volatility through the integration of diverse models. Thus, the study integrated four powerful methods: seasonal autoregressive (AR) integrated moving average (MA), generalized AR conditional heteroskedasticity (ARCH) family models, convolutional neural network (CNN), and bidirectional long short-term memory (LSTM) network. The hybrid model was developed using the residuals generated by the seasonal AR integrated MA model as input for the generalized ARCH model. Following this, the estimated volatility obtained was utilized as an input feature for both the hybrid CNNs and bidirectional LSTM models. The model's forecasting performance was assessed using key evaluation metrics, including mean absolute error (MAE) and root mean squared error (RMSE). Compared to other hybrid models, our new proposed hybrid model demonstrates an average reduction in MAE and RMSE of 60.35% and 60.61%, respectively. The experimental results show that the model proposed in this study has good performance and accuracy in predicting the volatility of stock prices. These findings offer valuable insights for financial data analysis and risk management strategies.",2024
China futures market and world container shipping economy: An exploratory analysis based on deep learning,"As globalization increases, the volatility of China's financial market is gradually affecting world trade and economic development. However, few studies have quantified the impact of China's commodity futures market on the global container shipping market outlook. Therefore, this study collects 45,966 points of daily data from January 4, 2016, to January 1, 2023, and mines the price prediction function of Chinese commodity futures market indicators on the Shanghai Container Freight Index (SCFI). Specifically, a deep learning integrated model is constructed by combining a convolutional neural network (CNN), a bi-directional long and short-term memory network (BILSTM), and an attentional mechanism (AM). The results show that the CNN-BILSTM-AM model can accurately identify nonlinear features in SCFI data using Chinese commodity futures market indicators. In addition, the model effectively captures the long-term dependence of SCFI changes with Chinese commodity futures. Finally, this study concludes that the integrated model outperforms the single CNN, LSTM, and BILSTM machine learning models and the combined CNN-LSTM and CNN-BILSTM models (R2= 94.8 %). We also observe that when using Shapley's additive interpretation (SHAP) framework to predict SCFI, Power Coal Futures (ZCF) and CSI 300 Index Futures (IFI) significantly influence the CNN-BILSTM-AM model. In summary, this study enriches the understanding of the interaction between the Chinese commodity futures market and the global container shipping industry. This study also highlights the price mining potential of Chinese futures market indicators in forecasting world shipping economic indices, thus opening new paths in the field of forecasting and management of world shipping economic indicators. The results provide a powerful decisional support and risk management tool for financial institutions, shipping companies, individual investors, and government policymakers.",2025
DeepONet-Inspired Architecture for Efficient Financial Time Series Prediction,"Financial time series prediction is a fundamental problem in investment and risk management. Deep learning models, such as multilayer perceptrons, Convolutional Neural Networks (CNNs), and Long Short-Term Memory (LSTM), have been widely used in modeling time series data by incorporating historical information. Among them, LSTM has shown excellent performance in capturing long-term temporal dependencies in time-series data, owing to its enhanced internal memory mechanism. In spite of the success of these models, it is observed that in the presence of sharp changing points, these models fail to perform. To address this problem, we propose, in this article, an innovative financial time series prediction method inspired by the Deep Operator Network (DeepONet) architecture, which uses a combination of transformer architecture and a one-dimensional CNN network for processing feature-based information, followed by an LSTM based network for processing temporal information. It is therefore named the CNN-LSTM-Transformer (CLT) model. It not only incorporates external information to identify latent patterns within the financial data but also excels in capturing their temporal dynamics. The CLT model adapts to evolving market conditions by leveraging diverse deep-learning techniques. This dynamic adaptation of the CLT model plays a pivotal role in navigating abrupt changes in the financial markets. Furthermore, the CLT model improves the long-term prediction accuracy and stability compared with state-of-the-art existing deep learning models and also mitigates adverse effects of market volatility. The experimental results show the feasibility and superiority of the proposed CLT model in terms of prediction accuracy and robustness as compared to existing prediction models. Moreover, we posit that the innovation encapsulated in the proposed DeepONet-inspired CLT model also holds promise for applications beyond the confines of finance, such as remote sensing, data mining, natural language processing, and so on.",2024
RETRACTED: Credit Risk Evaluation in Enterprise Financial Management by Using Convolutional Neural Network under the Construction of Smart City (Retracted Article),"Smart cities are the forward goals of future cities, and the development of small- and medium-sized enterprises (SMEs) plays a key role in it. To solve the financing difficulties of SMEs, it is necessary to scientifically, objectively, and accurately assess the credit risk of SMEs. Based on the current research and analysis of scholars in related fields, taking corporate financial data as the object, the SMEs' credit risk is assessed through an adaptive and self-learning convolutional neural network (CNN) method. The GoogleNet method is further improved to reconstruct the credit risk evaluation model of SMEs. Finally, the influence of the convolution kernel depth on the accuracy is discussed through the optimization of the structure and the selection of the initial value of the learning rate. The results are verified by using the data in the 2016-2021 SME sector in Shanghai and Shenzhen in the wind database. It can be found that when the learning rate is finally set to 0.4 and the convolution kernel depth is set to 8 and 32 in turn, the evaluation accuracy of the test dataset is the highest, with a total accuracy of 96.8%. Therefore, it is believed that the newly constructed model has higher accuracy and more practical value than the other three typical risk assessment models.",2022
Deep learning-based financial risk early warning model for listed companies: A multi-dimensional analysis approach,"This study proposes a novel deep learning-based approach for financial risk early warning in listed companies through a hierarchical attention network that integrates multi-dimensional data sources. Traditional financial risk prediction models often struggle with complex non-linear relationships and fail to effectively combine diverse information types. We develop a comprehensive framework that simultaneously processes financial statements, market trading data, and textual information through specialized neural network components. The model employs a two-level attention mechanism that dynamically weights both individual features and information sources, enabling interpretable risk assessment. Using data from 2,876 Chinese A-share listed companies from 2015 to 2024, our empirical analysis demonstrates that the proposed model achieves superior predictive performance (AUC-ROC: 0.873) compared to traditional statistical approaches (0.742-0.768) and conventional machine learning methods (0.812-0.845). The model provides early warning signals approximately 4.2 months before actual distress events, significantly outperforming benchmark models (2.3-3.7 months). Notably, the model maintains robust performance during market stress periods (accuracy: 0.798) compared to traditional models (accuracy: 0.678). The attention mechanism reveals that the relative importance of different risk indicators varies systematically with market conditions, with financial ratios dominating during stable periods (weight: 0.435) and market signals becoming more crucial during crises (weight: 0.412). These findings contribute to both the theoretical understanding of financial risk dynamics and practical risk management applications, while demonstrating the effectiveness of interpretable deep learning approaches in financial analysis.",2025
Analysis of early warning of corporate financial risk via deep learning artificial neural network,"To forecast the financial crisis of manufacturing corporations more accurately, a risk warning model of corporate finance is constructed based on back propagation (BP) neural network to forecast the financial crisis. Firstly, based on the principle of index selection, the forecast indexes are selected and the index system of financial risk early warning is constructed. Then the index system is optimized by factor analysis. Finally, the BP neural network algorithm model is adopted to forecast the financial crisis of 200 manufacturing corporations in 2018 and 2019, and the forecasting results are compared with the traditional method. The results show that the prediction accuracy of the enterprise financial risk early warning model based on the BP neural network for 2018 is above 85%, and the prediction accuracy for 2019 is above 95%, or even 100%. Through comparison with other traditional methods, the prediction accuracy of the BP neural network in 2018 (above 88%) is higher than that of other algorithms (below 87%). In 2019, the prediction accuracy of BP neural network (above 90%) is higher than other algorithms (less than 88%). The accuracy of the proposed financial risk warning model is 95%, and the accuracy is at least 2% higher than traditional method, which prove that the risk early warning model constructed in this study can accurately forecast the financial crisis of the corporation. This study is of important reference value for the establishment of efficient financial crisis forecasting model under deep learning.",2021
Forecasting Detrended Volatility Risk and Financial Price Series Using LSTM Neural Networks and XGBoost Regressor,"It is common practice to employ returns, price differences or log returns for financial risk estimation and time series forecasting. In De Prado's 2018 book, it was argued that by using returns we lose memory of time series. In order to verify this statement, we examined the differences between fractional differencing and logarithmic transformations and their impact on data memory. We employed LSTM (long short-term memory) recurrent neural networks and an XGBoost regressor on the data using those transformations. We forecasted risk (volatility) and price value and compared the results of all models using original, unmodified prices. From the results, models showed that, on average, a logarithmic transformation achieved better volatility predictions in terms of mean squared error and accuracy. Logarithmic transformation was the most promising transformation in terms of profitability. Our results were controversial to Marco Lopez de Prado's suggestion, as we managed to achieve the most accurate volatility predictions in terms of mean squared error and accuracy using logarithmic transformation instead of fractional differencing. This transformation was also most promising in terms of profitability.",2022
Data-driven Risk Assessment for Peer-to-Peer Network Lending Agencies,"With the rapid development of Peer-to-Peer(P2P) network lending in the financial field, more data of lending agencies have appeared. P2P agencies also have problems such as absconded with ill-gotten gains and out of business. Therefore, it is necessary to assess their risks based on P2P company data. This paper proposes a framework of Data-driven Risk Assessment for P2P(DRAP2P) network lending agencies based on unstructured natural language data. First, use the natural language processing technology, such as word segmentation, keyword, LDA topic model, word2vec and doc2vec, to process and extract features of company profile which reflect its business status. Then, seven machine learning classifiers and three deep learning models are used for analysis. Since keywords show good performance in machine learning models, we improve Convolutional Neural Network(CNN) with keywords and propose two CNN+Keyword models, namely CNN+Keyword(static+BP) and CNN+Keyword (Expand word embedding). Experiments have shown that CNN+Keyword(static+BP) can achieve the best performance. Finally, we use the method of meta-learning to integrate CNN+Keyword(static+BP) and logistic regression classifier to further strengthen the performance.",2018
Deep Learning for Intelligent Assessment of Financial Investment Risk Prediction,"Financial investment promotes the market's fast economic growth and gradually becomes a new trend of social development in the contemporary era. From the national level, financial risk investment activities directly affect the development process of the information technology industry and social and economic benefits. The management of financial risk investment has received more attention, and the types and difficulties of risks are also gradually increasing. Financial regulatory agencies urgently need to establish a sensitive and scientific economic hazard early alarm system. The perfect earlier alarm system stands based on in-depth scientific theoretical research, so studying financial security evaluation and systemic economic earlier alarm systems is of great practical significance. Taking the systemic financial risk as the research object, this paper analyzes the mechanism of financial systemic risk. After that, deep learning technology in financial investment has been used for the first time to reconstruct the index system of financial security evaluation and early warning. The application of deep learning technology in the early warning of systemic financial risks is realized, which provides a reliable basis for the regulatory authorities to build a financial risk early warning system and makes empirical research.",2022
Application of Deep Learning in Stock Market Valuation Index Forecasting,"Deep learning is the core technology of artificial intelligence, which has higher accuracy than traditional algorithms. The characteristics of high-risk and high-yield in stock market make investors hope to make predictions on it through scientific methods, so as to reduce investment risks. Long short-term memory (LSTM) model in deep learning can effectively describe the long memory of data and is suitable for predicting financial time series. Therefore, this paper uses LSTM model in deep learning to learn and forecast the stock market valuation indicator, price-earnings ratio (P/E ratio). Then the prediction bias is measured by forecast trend accuracy (FTA), average forecast deviation rate (AFDR), and root mean square error (RMSE). Empirical results show that LSTM model has a good predictive effect on P/E ratio sequence, indicating that there is practical research value for applying deep learning network algorithm to the field of stock market forecasting. At the same time, this paper also provides a reference for stock market investors.",2019
Predicting Financial Risk Associated to Bitcoin Investment by Deep Learning,"The financial risk of investing in Bitcoin is increasing, and everyone participating in the transaction is aware of it. The rise and fall of bitcoin's value is difficult to predict, and the system is fraught with uncertainty. As a result, this study proposed to use the Deep learning technique for predicting fi-nancial risk associated with bitcoin investment, that is linked to its weighted price on the bitcoin market's volatility. The dataset used included Bitcoin historical data, which was acquired at one-minute intervals from selected exchanges of January 2012 through December 2020. The deep learning lin-ear-SVM-based technique was used to obtain an advantage in handling the high-dimensional challenges related with bitcoin-based transaction transac-tions large data volume. Four variables (High, Low, Close, and Volume (BTC).) are conceptualized to predict weighted price, in order to indicate if there is a propensity of financial risk over the effect of their interaction. The results of the experimental investigation show that the financial risk associated with bitcoin investing is accurately predicted. This has helped to discover engagements and disengagements with doubts linked with bitcoin investment transactions, resulting in increased confidence and trust in the system as well as the elimination of financial risk. Our model had a significantly greater prediction accuracy, demonstrating the utility of deep learning systems in detecting financial problems related to digital currency.",2022
Forecasting the Risk Factor of Frontier Markets: A Novel Stacking Ensemble of Neural Network Approach,"Forecasting the risk factor of the financial frontier markets has always been a very challenging task. Unlike an emerging market, a frontier market has a missing parameter named volatility, which indicates the market's risk and as a result of the absence of this missing parameter and the lack of proper prediction, it has almost become difficult for direct customers to invest money in frontier markets. However, the noises, seasonality, random spikes and trends of the time-series datasets make it even more complicated to predict stock prices with high accuracy. In this work, we have developed a novel stacking ensemble of the neural network model that performs best on multiple data patterns. We have compared our model's performance with the performance results obtained by using some traditional machine learning ensemble models such as Random Forest, AdaBoost, Gradient Boosting Machine and Stacking Ensemble, along with some traditional deep learning models such as Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM) and Bidirectional Long Short-Term (BiLSTM). We have calculated the missing parameter named volatility using stock price (Close price) for 20 different companies of the frontier market and then made predictions using the aforementioned machine learning ensemble models, deep learning models and our proposed stacking ensemble of the neural network model. The statistical evaluation metrics RMSE and MAE have been used to evaluate the performance of the models. It has been found that our proposed stacking ensemble neural network model outperforms all other traditional machine learning and deep learning models which have been used for comparison in this paper. The lowest RMSE and MAE values we have received using our proposed model are 0.3626 and 0.3682 percent, respectively, and the highest RMSE and MAE values are 2.5696 and 2.444 percent, respectively. The traditional ensemble learning models give the highest RMSE and MAE error rate of 20.4852 and 20.4260 percent, while the deep learning models give 15.2332 and 15.1668 percent, respectively, which clearly states that our proposed model provides a very low error value compared with the traditional models.",2022
The commodity risk premium and neural networks,"The paper uses linear and nonlinear predictive models to study the linkage between a set of 128 macroeconomic and financial predictors and the risk premium of commodity futures contracts. The linear models use shrinkage methods based on either naive averaging or principal components. The nonlinear models use feedforward deep neural networks (DNN) either as stand-alone or in conjunction with a long short-term memory network (LSTM). Out of the four specifications considered, the LSTM-DNN architecture best captures the risk premium, which underscores the need to estimate models that are both nonlinear and recurrent. The superior performance of the LSTM-DNN portfolio persists after accounting for transaction costs or illiquidity and is unrelated to previously-documented commodity risk factors.",2023
Energy Investment Risk Assessment for Nations Via Seq2seq Model,"China's Belt & Road Initiative has been proposed for several years, which has stimulated the economic and financial development of the countries alongside the Belt & Road. For a world's leading energy consuming country, China tries to secure the energy supply from the resource-rich countries via oversea energy investment. In this paper, we propose a sequence to sequence (seq2seq) model to evaluate the energy investment risk of 50 countries alongside the Belt & Road Initiative. Specifically, we first build an indicator system mainly containing six factors. Then we adopt Bi-long-short term memory (Bi-LSTM) as encoder to process the historical statistics. Afterward, we use self-attention mechanism to assign the weights on the six factors of the indicator system. Finally we use a hierarchical convolution neural network decoder to generate the assessment results. Our findings indicate that resource potential and Chinese factor are the most important indicators. And through our thorough investigation, we find that Russia, Kazakhstan, Pakistan, United Arab Emirates, Saudi Arabia, Malaysia and Indonesia are the most recommended target countries for China's oversea energy investment.",2021
Novel volatility forecasting using deep learning-Long Short Term Memory Recurrent Neural Networks,"The volatility is related to financial risk and its prediction accuracy is very important in portfolio optimisation. A large body of literature to-date suggests Support Vector Machines (SVM) as the best of regression algorithms for financial data regression. Recent work however found that new deep learning-Long Short Term Memory Recurrent Neural Networks (LSTM RNNs) outperformed SVM for classification problems. In the present paper we conduct a new unbiased evaluation of these two modelling techniques for regression problems, and we also compare them with a popular regression model - Generalized Autoregressive Conditional Heteroskedasticity (GARCH) model for financial volatility or risk forecasting. Our experiments using financial data show that the LSTM RNNs performed as good as v-SVR for large interval volatility forecasting and both performed much better than GARCH model for two financial indices (S&P 500 and AAPL). The LSTM RNNS deep learning method can learn from big raw data and can be run with many hidden layers and neurons under GPU to achieve a good prediction for long sequence data compared to the support vector regression. The deep learning technique - LSTM RNNs with big data can be used to improve the volatility prediction instead of v-SVR when the v-SVR does not predict well for some financial stocks of a portfolio. This will help investors to win the competition to maximize their profit. (C) 2019 Elsevier Ltd. All rights reserved.",2019
Cryptocurrency Price Analysis With Artificial Intelligence,"Cryptocurrency is playing an increasingly important role in reshaping the financial system due to its growing popular appeal and mechant acceptance. While many people are making investments in Cryptocurrency, the dynamical features, uncertainty, the predictability of Cryptocurrency are still mostly unknown, which dramatically risk the investments. It is a matter to try to understand the factors that infiuence the value formation. In this study, we use advanced artificial intelligence frameworks of fully connected Artificial Neural Network (ANN) and Long Short-Term Memory (LSTM) Recurrent Neural Network to analyse the price dynamics of Bitcoin, Etherum, and Ripple. We find that ANN tends to rely more on long-term history while LSTM tends to rely more on short-term dynamics, which indicate the efficiency of LSTM to utilise useful information hidden in historical memory is stronger than ANN. However, given enough historical information ANN can achieve a similar accuracy, compared with LSTM. This study provides a unique demonstration that Cryptocurrency market price is predictable. However, the explanation of the predictability could vary depending on the nature of the involved machine-learning model.",2019
A method for managing scientific research project resource conflicts and predicting risks using BP neural networks,"This study begins by considering the resource-sharing characteristics of scientific research projects to address the issues of resource misalignment and conflict in scientific research project management. It comprehensively evaluates the tangible and intangible resources required during project execution and establishes a resource conflict risk index system. Subsequently, a resource conflict risk management model for scientific research projects is developed using Back Propagation (BP) neural networks. This model incorporates the Dropout regularization technique to enhance the generalization capacity of the BP neural network. Leveraging the BP neural network's non-linear fitting capabilities, it captures the intricate relationship between project resource demand and supply. Additionally, the model employs self-learning to continuously adapt to new scenarios based on historical data, enabling more precise resource conflict risk assessments. Finally, the model's performance is analyzed. The results reveal that risks in scientific research project management primarily fall into six categories: material, equipment, personnel, financial, time, and organizational factors. This study's model algorithm exhibits the highest accuracy in predicting time-related risks, achieving 97.21%, surpassing convolutional neural network algorithms. Furthermore, the Root Mean Squared Error of the model algorithm remains stable at approximately 0.03, regardless of the number of hidden layer neurons, demonstrating excellent fitting capabilities. The developed BP neural network risk prediction framework in this study, while not directly influencing resource utilization efficiency or mitigating resource conflicts, aims to offer robust data support for research project managers when making decisions on resource allocation. The framework provides valuable insights through sensitivity analysis of organizational risks and other factors, with their relative importance reaching up to 20%. Further research should focus on defining specific strategies for various risk factors to effectively enhance resource utilization efficiency and manage resource conflicts.",2024
Energy Financial Risk Management in China Using Complex Network Analysis,"Effective energy financial risk management is crucial to ensure that China's economic system can remain stable. This article utilizes the quantile vector autoregressive spillover index model, complex networks, and deep learning methods to simultaneously assess both the internal and external energy financial market risks in China. Spillover effects under different market conditions are also examined. The research findings indicate that: (1) Under extreme market conditions, static total spillover values between internal and external markets exceed 70%, while under normal market conditions, they are only around 53% and 13%, respectively; (2) Crude oil and fuel oil as well as energy and stocks are important nodes in both internal and external markets; and (3) The attention-convolutional neural network-long short-term memory model outperforms the second-best performing model, and achieves an improvement of 12.9% and 21.4% in terms of mean absolute error and root mean square error, respectively; inclusion of early warning indicators leads to further improvements of 19.8% and 31.9%, respectively.",2023
Risk model of financial supply chain of Internet of Things enterprises: A research based on convolutional neural network,"The emergence of the financial supply chain provides assistance for small, medium and micro enterprises in the supply chain through a secured credit model based on real trade. Moreover, in the multi-level structure of the financial supply chain of the Internet of Things enterprise, there are information barriers and information islands. Besides, data is often not transmitted smoothly, and the intermediate offline process is complicated. What is worse, the efficiency is low, and the verification cost is high. Therefore, based on supply chain finance, an evolutionary risk model is constructed in this paper. Firstly, the income matrix of the regulatory risk model is established, and the convolutional neural network used will pool the training data to the maximum and set the local corresponding normalization layer. With the help of the evolutionary risk theory, the dynamic equation of the financial supply chain is obtained, forming the dynamic path and abnormal model of strategy selection. Then, a compact pattern tree is added to the knowledge granularity method to mine data anomalies. Finally, an experimental platform is built to verify the effectiveness of the method proposed in this paper, and experiments are performed on the accuracy of model evolution conditions, abnormal data identification, and abnormal numerical examples. The experimental results prove that the algorithm in this paper is consistent with the set parameters, and the effect is significantly higher than other comparison methods. The experimental mining time and the comparison method are shortened by 6 similar to 13S. The research results obtained from this paper solve the problem that the decision-making of supply chain finance and the supervision and review of supply chain enterprise are complex, which improves the characteristics identification of supply chain platform, and provides reference suggestions for financial institutions and supply chain platforms.",2022
Research on internet financial risk control based on deep learning algorithm,"With the rapid development of Internet technology, Internet finance has entered thousands of households, bringing a lot of convenience to people's lives. As a financial model based on Internet technology, compared with traditional bank loans, online loans have lower operating costs and faster returns, so they are developing rapidly. Providing users with better and faster services while standardizing operations has always been the development goal of various Internet finance companies. At present, many domestic Internet financial enterprises are facing many problems such as difficulty in risk control. Therefore, this paper makes full use of deep learning algorithms to build an Internet financial risk control system. After in-depth analysis and research on the deep learning algorithm, the Internet financial risk control system is divided into several modules. The project mainly includes model management module, user behavior analysis module, alarm management module, monitoring module, product management module, etc., and then by analyzing the test results of each test scenario, it is concluded that the performance test of the system design meets the actual needs of users, and simulates the test. It is carried out in accordance with the constraints and regulations of the test plan, and the performance test meets the standard. The system not only ensures the safety of the company's funds, but also helps the company to form a smooth and effective financial risk control process. This paper designs a class of effective management systems by applying deep learning algorithms to the field of Internet financial risk control.",2023
Operational Risk Prevention and Control Monitoring of Smart Financial System Based on Deep Learning,"With the development of intelligent financial level, intelligent financial system has been gradually applied to most enterprises. Once there is operational risk in the financial system, it will seriously affect the security and reliability of enterprise finance. Therefore, once the operational risk of the smart finance system is prevented and controlled, it is very necessary. In order to ensure the accuracy and effectiveness of risk prevention and control monitoring of smart financial systems during operation, a deep learning-based operational risk prevention and control monitoring method for smart financial systems is designed. First, establish the corresponding relationship between the roles and operations of the smart financial system, establish an operational risk prevention and control model based on deep learning, design a risk assessment structure tree, and complete operational risk quantification. In order to verify the effectiveness of the design method, a performance comparison experiment was designed. The experimental results show that the accuracy of the test samples finally reached 74.6%, of which 21 risk samples were correctly monitored and prevented, indicating that the designed deep learning-based smart financial system operates Risk prevention and monitoring methods have certain effectiveness.",2023
Risk Analysis of Textile Industry Foreign Investment Based on Deep Learning,"With the decline of China's economic growth rate and the uproar of antiglobalization, the textile industry, one of the business cards of China's globalization, is facing a huge impact. When the economic model is undergoing transformation, it is more important to prevent enterprises from falling into financial distress. So, the financial risk early warning is one of the important means to prevent enterprises from falling into financial distress. Aiming at the risk analysis of the textile industry's foreign investment, this paper proposes an analysis method based on deep learning. This method combines residual network (ResNet) and long short-term memory (LSTM) risk prediction model. This method first establishes a risk indicator system for the textile industry and then uses ResNet to complete deep feature extraction, which are further used for LSTM training and testing. The performance of the proposed method is tested based on part of the measured data, and the results show the effectiveness of the proposed method.",2022
CLAM: A Synergistic Deep Learning Model for Multi-Step Stock Trend Forecasting,"This paper introduces CLAM, a hybrid deep learning framework that integrates CNNs, LSTMs, and Attention Mechanism (AM) for straightforward multi-step stock trend forecasting. By leveraging CNNs for spatial feature extraction, LSTMs for capturing temporal dependencies, and AM for dynamically focusing on relevant data, CLAM significantly outperforms traditional models in predictive accuracy. Evaluated on diverse stock datasets from different industries, CLAM demonstrates an average reduction of over 80% in MAE and RMSE compared to standalone CNN, LSTM, and fused CNN-LSTM. The model's ability to capture both short-term and long-term trends is particularly advantageous for real-time financial trading, resulting in 75% trend prediction accuracy, with most cases witnessing consecutive accurate forecasts of flash crashes or uptrends, which aids in strategic investment decisions and risk management. Code and data are available at: https://anonymous.4open.science/r/CNN-LSTM-AM-AB13/src/CLAM.ipynb.",2025
Forecasting the elasticity of variance with LSTM recurrent neural networks,"Volatility forecasting is an important tool because it can be used in many different applications across the industry including risk management, derivatives trading and optimal portfolio selection. On the other hand, machine learning tends to be more accurate in making predictions when large volumes of data are involved in the system which the financial services industry tends to encounter. In this paper, we show that a fractional stochastic generalization of the elasticity of variance can contain latent features of the market elasticity of variance by using an artificial recurrent neural network architecture called LSTM (Long Short-Term Memory) to forecast the elasticity of variance. It is shown that the forecast only with the elasticity of variance data has no statistically significant difference from forward filling, but information on the Hurst exponent can improve the power of forecasting the elasticity of variance.",2023
A Denoising Autoencoder Approach for Credit Risk Analysis,"Credit risk evaluation is a key consideration in financial activities. Financial institutions such as banks rely on credit risk analysis for determining the potential risk involved in financial activities and then decide the degree of involvement in such activities as well as the appropriate interest rate and the amount of capital that should be reserved. The recent development of machine learning has provided powerful tools for computer-aided credit risk analysis, and neural networks are one of the most promising approaches. However, conventional artificial neural networks involve multiple layers of neurons which then become a universal function that can approximate any function. Therefore, it will learn from not only the information in the training data set but also from the noise in it. It is critical to remove the noise in order to improve the accuracy and efficiency of such algorithms. In this paper, a denoising autoencoder approach is proposed for the training process for neural networks. The denoising-autoencoder-based neural network model is then applied to credit risk analysis, and the performance is evaluated.",2018
Stock Market Index Prediction Using CEEMDAN-LSTM-BPNN-Decomposition Ensemble Model,"This study investigates the forecasting of the Deutscher Aktienindex (DAX) market index by addressing the nonlinear and nonstationary nature of financial time series data using the CEEMDAN decomposition method. The CEEMDAN technique is used to decompose the time series into intrinsic mode functions (IMFs) and residuals, which are classified into low-frequency (LF), medium-frequency (MF), and high-frequency (HF) components. Long short-term memory (LSTM) networks are applied to the MF and HF components, while the backpropagation neural network (BPNN) is utilized for the LF components, resulting in a robust hybrid model termed CEEMDAN-LSTM-BPNN. To evaluate the performance of the proposed model, we compare it against several benchmark models, including ARIMA, RNN, LSTM, GRU, BIGRU, BILSTM, BPNN, CEEMDAN-LSTM, CEEMDAN-GRU, CEEMDAN-BPNN, and CEEMDAN-GRU-BPNN, across different training-testing splits (70% training/30% testing, 80% training/20% testing, and 90% training/10% testing). The model's predictive accuracy is measured using six metrics: root mean squared error (RMSE), mean absolute error (MAE), mean absolute percentage error (MAPE), symmetric mean absolute percentage error (SMAPE), root mean squared logarithmic error (RMSLE), and R-squared. To further assess model performance, we conduct the Diebold-Mariano (DM) test to compare forecast accuracy between the proposed and benchmark models and the model confidence set (MCS) test to evaluate the statistical significance of the improvement. The results demonstrate that the CEEMDAN-LSTM-BPNN model significantly outperforms other methods in terms of accuracy, with the DM and MCS tests confirming the superiority of the proposed model across multiple evaluation metrics. The findings highlight the importance of combining advanced decomposition methods and deep learning models for financial forecasting. This research contributes to the development of more accurate forecasting techniques, offering valuable implications for financial decision-making and risk management.",2025
DLIFT: A deep-learning-based intelligent fund transaction system for financial Internet of Things,"Analyzing the correlation between two funds can help investors control investment risks and optimize investment portfolios, which has a strong guiding significance for fund investment in reality. Constructing an intelligent investment system with fund correlation analysis capabilities can help investors automatically make profits from financial markets. In previous research, many researchers have built intelligent investment systems using Bayesian networks, support vector machines (SVM), and LSTM models. However, the strong historical dependence between fund data and the high-dimensional and high-noise characteristics of fund data prevent traditional methods from obtaining excellent performance in fund analysis. This paper designs a deep learning-based fund intelligent trading system-DLIFT which has functions such as investment push, income prediction, and risk control. The systems data analysis module is implemented using the Improved RNN model. This model employed encoder-decoder architecture. The encoder is responsible for analyzing the fund's feature, and the decoder is responsible for analyzing the dependency relationship between the historical correlation and the current correlation. LSTM and an attention mechanism are simultaneously applied to the encoder and decoder, which enabled the discovery of the implicit dependence of time series data. This article places the designed system on a historical dataset containing multiple public funds for verification. In specific experiments, the experimental results of the comparative experiments show the superiority of our model. At the same time, the results of the ablation experiment results show that LSTM and attention mechanism play critical role in the proposed system.",2021
Forecasting the Volatility of CSI 300 Index with a Hybrid Model of LSTM and Multiple GARCH Models,"Volatility is a key indicator of market risk in financial markets. This paper proposes a novel hybrid model that combines Long Short-Term Memory (LSTM) with multiple generalized autoregressive conditional heteroskedasticity (GARCH) models to predict stock price volatility. The GARCH models serve as feature extractors, while the LSTM model utilizes these features to forecast next-day volatility. To better capture the leverage effect, the model integrates one symmetric and three asymmetric GARCH models (GEJT-LSTM-1), yielding the best forecast accuracy under a fixed-parameter approach. The proposed hybrid model significantly outperforms existing approaches by leveraging deep learning with multiple asymmetric GARCH models, demonstrating superior predictive performance. Furthermore, the methodology provides a flexible framework that can be extended to other fields, contributing to advancements in volatility forecasting techniques.",2024
The GSO-Deep Learning-based Financial Risk Management System for Rural Economic Development Organization,"Financial risk management has always been a key concern for major enterprises. At the same time, with the continuous attention to impoverished rural areas worldwide, financial risk management tools have become an important component of rural economic development organizations to avoid financial risks. With the rapid development of artificial intelligence technologies such as neural networks and deep learning, and due to their strong learning ability, high adaptability, and good portability, some financial risk management tools are gradually adopting technologies such as neural networks and machine learning. However, existing financial risk management tools based on neural networks are mostly developed for large enterprises such as banks or power grid companies, and cannot guarantee their full applicability to rural economic development organizations. Therefore, this study focuses on the financial risk management system used for rural economic development organizations. In order to improve the accuracy of deep learning algorithms in predicting financial risks, this paper designs an improved Glowworm Swarm Optimization (IGSO) algorithm to optimize Deep Neural Networks (DNN). Finally, the effectiveness of the financial risk management tool based on IGSO-DNN proposed in this article was fully validated using data from 45 rural economic development organizations as a test set.",2023
"Research on the multifractal volatility of Chinese banks based on the synthetic minority oversampling technique, edited nearest neighbors and long short-term memory","This paper uses five-minute high-frequency trading data for the Shanghai Stock Exchange Banks Index (ticker: SH.000134) from 2014 to 2023 as a research sample, and it employs a method based on multifractal characteristics to classify the financial market risk states of listed banks. A long short-term memory (LSTM) neural network is improved by combining it with the SMOTEENN method (itself a combination of the synthetic minority oversampling technique and edited nearest neighbors), and the SMOTEENN-LSTM model is then used to predict these risk states. The results show that the financial market for China's banking industry exhibits obvious multifractal behavior, and that we can accurately determine the normal state of the market and the states that need attention based on multifractal volatility parameters. The SMOTEENN-LSTM model greatly improves the prediction accuracy of the unmodified LSTM model, and it also significantly outperforms two traditional machine learning models - support vector machines and backpropagation neural networks - with its accuracy reaching 89.27% (as measured by the area under the receiver operating characteristic curve). Fivefold cross-validation shows that, compared with the support vector machine and backpropagation neural network models, the SMOTEENN-LSTM model has superior stability in accuracy indicators such as the area under the receiver operating characteristic curve and the geometric mean, indicating its strong robustness and reliability. This proves it can effectively deal with the problems encountered by traditional models when processing imbalanced data sets. This paper can provide effective tools for financial regulators and financial institutions to better monitor and manage the risks of banking markets and promote their healthy development.",2024
Enhancing Performance of Credit Card Model by Utilizing LSTM Networks and XGBoost Algorithms,"This research paper presents novel approaches for detecting credit card risk through the utilization of Long Short-Term Memory (LSTM) networks and XGBoost algorithms. Facing the challenge of securing credit card transactions, this study explores the potential of LSTM networks for their ability to understand sequential dependencies in transaction data. This research sheds light on which model is more effective in addressing the challenges posed by imbalanced datasets in credit risk assessment. The methodology utilized for imbalanced datasets includes the use of the Synthetic Minority Oversampling Technique (SMOTE) to address any imbalance in class distribution. This paper conducts an extensive literature review, comparing various machine learning methods, and proposes an innovative framework that compares LSTM with XGBoost to improve fraud detection accuracy. LSTM, a recurrent neural network renowned for its ability to capture temporal dependencies within sequences of transactions, is compared with XGBoost, a formidable ensemble learning algorithm that enhances feature-based classification. By meticulously carrying out preprocessing tasks, constructing competent training models, and implementing ensemble techniques, our proposed framework demonstrates unwavering performance in accurately identifying fraudulent transactions. The comparison of LSTM and XGBoost shows that LSTM is more effective for our imbalanced dataset. Compared with XGBOOST's 97% accuracy, LSTM's accuracy is 99%. The final result emphasizes how crucial it is to select the optimal algorithm based on particular criteria within financial concerns, which will ultimately result in more reliable and knowledgeable credit score decisions.",2025
Optimized backpropagation neural network for risk prediction in corporate financial management,"Corporate financial management is responsible for constructing, optimizing, and modifying finance-related structures for an unremitting function. The finance optimization model incorporates risk prediction and fund balancing for distinguishable corporate operations. This risk prediction is handled using sophisticated computing models with artificial intelligence and machine learning for self-training and external learning. Therefore, this article introduces a Backpropagation-aided Neural Network for designing an Optimal Risk Prediction (ORP-BNN) to pre-validate existing and new financial imbalances. The risk prediction model is designed to cope with corporate standards and minimum riskless financial management. This is designed as a linear snowfall model wherein the BNN decides the significance between fund allocation and restraining. The snowfall model significantly relies on allocation or restraining, which is achieved by assigning significant weights depending on the previous financial decision outcome. The weight factor is determined using gradient loss functions associated with the computing model. The training process is pursued using different structural modifications used for successful financial management in the past. In particular, the risk thwarted financial planning using a snowfall-like computing model, and its data inputs are used for training optimization. Therefore, the proposed model's successful risk mitigation stands high under prompt decisions.",2023
Intelligent credit scoring using deep learning methods,"Credit scoring is one the most important parts of credit risk management in reducing the risk of client defaults and bankruptcies. Deep learning has received much attention in recent years, but it has not been implemented so intensively in credit scoring compared to other financial domains. In this article, stacked unidirectional and bidirectional LSTM (long short-term memory) networks as a complex area of deep learning are applied in solving credit scoring problems for the first time. The proposed robust model exploits the full potential of the three-layer stacked LSTM and BDLSTM (bidirectional LSTM) architecture with the treatment and modeling of public datasets in a novel way since credit scoring is not a time sequence problem. Attributes of each loan instance were transformed into a sequence of the matrix with a fixed sliding window approach with a one-time step. Our proposed models outperform existing and much more complex deep learning solutions thus we succeeded in preserving simplicity. In this article, measures of different types are employed to carry out consistent conclusions. The results by applying three hidden layers on the German Credit dataset showed an accuracy of 87.19%, for Kaggle dataset accuracy reached 93.69%, and for Microcredit dataset accuracy of 97.80%.",2023
Explainable deep learning model for predicting money laundering transactions,"Money laundering has been a global issue for decades. The ever-changing technology landscape, digital channels, and regulations make it increasingly difficult. Financial institutions use rule-based systems to detect suspicious money laundering transactions. However, it suffers from large false positives (FPs) that lead to operational efforts or misses on true positives (TPs) that increase the compliance risk. This paper presents a study of convolutional neural network (CNN) to predict money laundering and employs SHapley Additive exPlanations (SHAP) explainable artificial intelligence (AI) method to explain the CNN predictions. The results highlight the role of CNN in detecting suspicious transactions with high accuracy and SHAP's role in bringing out the rationale of deep learning predictions.",2024
Gold price prediction by a CNN-Bi-LSTM model along with automatic parameter tuning,"Banking and stock markets consider gold to be an important component of their economic and financial status. There are various factors that influence the gold price trend and its fluctuations. Accurate and reliable prediction of the gold price is an essential part of financial and portfolio management. Moreover, it could provide insights about potential buy and sell points in order to prevent financial damages and reduce the risk of investment. In this paper, different architectures of deep neural network (DNN) have been proposed based on long short-term memory (LSTM) and convolutional-based neural networks (CNN) as a hybrid model, along with automatic parameter tuning to increase the accuracy, coefficient of determination, of the forecasting results. An illustrative dataset from the closing gold prices for 44 years, from 1978 to 2021, is provided to demonstrate the effectiveness and feasibility of this method. The grid search technique finds the optimal set of DNNs' parameters. Furthermore, to assess the efficiency of DNN models, three statistical indices of RMSE, RMAE, and coefficient of determination (R2), were calculated for the test set. Results indicate that the proposed hybrid model (CNN-Bi-LSTM) outperforms other models in total bias, capturing extreme values and obtaining promising results. In this model, CNN is used to extract features of input dataset. Furthermore, Bi-LSTM uses CNN's outputs to predict the daily closing gold price.",2024
A novel company financial risk warning method based on BP neural network,"This paper focuses on the problem of company financial risk warning, which is of great importance in modern company management. As BP neural network is a powerful tool to make state forecasting in complex system, in this paper, we propose a new company financial risk warning approach based on BP neural network. After demonstrating the main characterics of BP neural network, the proposed algorithm is given. The main innovations of this paper lie in two aspects. For the first aspect, we propose a hybrid model to make financial risk warning which combines BP neural network and particle swarm optimization together. For the second aspect, we select eighteen indicators from the five types of financial indicators to construct neurons of the BP neural network. Experiments demonstrate that the proposed approach can effectively company financial risk, and the financial risk estimated of our algorithm is very close to the experts' evaluation",2014
Study on early warning of E-commerce enterprise financial risk based on deep learning algorithm,"With the development trend of economic progress, the capital business of e-commerce enterprises has become complicated. The financial risk of listed companies is a problem that needs to be paid attention to. The financial risk of e-commerce companies is a complex and gradual process, and its unique reasons may be many. E-commerce companies are facing financial risks or difficulties, and bankruptcy and liquidation are also increasing. Financial risk has seriously affected e-commerce companies and society. As a result, the early warning methods of financial risks have been constantly improved. With the arrival of the new economic era in the era of knowledge economy, the early warning of financial risks in e-commerce companies has become a hot issue in the financial management of e-commerce companies. Based on the deep learning algorithm, this paper studies from the perspective of establishing the financial early warning model based on deep learning and constructing the financial risk early warning mechanism of e-commerce companies, and analyzes and forecasts the financial risks of listed companies. Through the construction of financial security early warning system, crisis signals can be diagnosed as soon as possible, and crisis signals can be prevented and solved timely and effectively.",2022
APPLICATION OF BP NEURAL NETWORK MODEL IN SUPPLY CHAIN FINANCIAL RISK CONTROL,". The diversification of the market development model has rapidly promoted financial innovation, and the improvement of the supply chain has also given rise to the supply chain financial form. However, the risk problem also arises. In order to effectively control supply chain financial risk and improve the ability of supply chain enterprises to resist financial crises, the application of the BP neural network model in supply chain financial risk control is studied. The BP neural network model is designed to categorize the dynamic risk types of supply chain finance according to the dynamic development characteristics of supply chain finance in the past, with the corresponding weight distribution allocated to each category. The BP neural network model is employed to extract the financial risk characteristics of the supply chain, and a dynamic measurement of supply chain finance is conducted based on the risk characteristics. This paper constructs a supply chain financial risk management model based on the BP neural network model and controls the supply chain financial risk. The experimental results demonstrate that after employing various control methods, the risk exhibits a declining trend, effectively mitigating the financial risk of the supply chain with high efficacy.",2024
Forecasting peer-to-peer platform default rate with LSTM neural network,"Peer-to-peer (P2P) online lending as an innovative financial derivative has emerged around the world, which is different from a bank loan in several aspects, such as borrower qualification and source of funding. These differences potentially increase the risk of P2P loans. Therefore, it is critical to develop suitable methods for the default rate prediction of P2P platform. This paper adopts a new approach, named long short-term memory network (LSTM), to study the default rate of monthly fresh loans in US P2P lending platform Lending Club from 2008 to 2015. Our experimental results suggest that, compared with some traditional models like ARIMA, SVM and ANN, the LSTM network has the highest accuracy of default rate prediction. Besides, the performance of the proposed LSTM is robust in diverse time-series cross-validation modes and time periods. Further results demonstrate that it is the unique ability of extracting time-series information makes the LSTM outperform traditional approaches.",2020
The Risk Analysis of Digital Inclusive Financial Platform Using Deep Learning Approach,"This paper intends to investigate the risk management of inclusive digital financial platforms. First, it explains the idea of smart cities, their function, and inclusive financial risk control technologies based on big data. The varieties of digital inclusive financial platforms and their risk profiles are next examined. The Back Propagation (BP) neural network is used to build a BP-KMV model based on the KMV model. Finally, utilizing M Company as a case study, this paper uses the BP-KMV model to examine the credit risk and risk management of unlisted enterprises on the digital inclusive financial platform. The results show that of the four unlisted companies, L Company has the greatest default rate (7.35%), while J Company has the lowest default rate (4.82%). The highest research and development (R&D) spending rate is 14.1% for J company, while the highest patent ownership rate is 43.09% for L company. The data demonstrates a negative correlation between the percentage of R&D expenditures and the default rate of unlisted enterprises. In other words, a larger default risk is associated with lower R&D expense rates. Additionally, there is a correlation between patent ownership and default rates that is positive, suggesting that higher patent ownership rates are linked to higher default rates. Additionally, the risk management technologies of M business can complement one another. The theoretical research of comprehensive digital inclusive finance risk control can be enriched by the risk analysis of digital inclusive financial platforms utilizing the BP-KMV model in the context of smart cities.",2024
Threshold-based portfolio: the role of the threshold and its applications,"This paper aims at developing a new method by which to build a data-driven portfolio featuring a target risk-return. We first present a comparative study of recurrent neural network models (RNNs), including a simple RNN, long short-term memory (LSTM), and gated recurrent unit. The models are applied to the investment universe consisted of 10 stocks in theS&P500 The experimental results show that the LSTM-based prediction model outperforms the others in terms of hit ratio of 1-month-ahead forecasts. We then build predictive threshold-based portfolios (TBPs) that are subsets of the universe satisfying given threshold criteria for the LSTM-based return forecasts. The TBPs are rebalanced monthly to restore equal weight to the constituents of the TBPs. We find that the risk and return profile of the realized TBP represents a monotonically increasing frontier on the risk-return plane, where the equally weighted universe portfolio plays a role in the lower bound of TBPs. This shows the availability of TBPs in targeting specific risk-return levels, and the EWP of an universe plays a role in the reference portfolio of the TBPs. In the process, thresholds play dominant roles in characterizing risk, return, and the prediction accuracy of the TBPs. The TBP is more data-driven in designing portfolio return and risk than existing ones, in the sense that it requires no prior knowledge of finance such as financial assumptions, financial mathematics, or expert insights. For practical uses, we present a multiperiod TBP management method and also discuss the application of TBP to mean-variance portfolios to reduce estimation risk.",2020
Return Rate Prediction in Blockchain Financial Products Using Deep Learning,"Recently, bitcoin-based blockchain technologies have received significant interest among investors. They have concentrated on the prediction of return and risk rates of the financial product. So, an automated tool to predict the return rate of bitcoin is needed for financial products. The recently designed machine learning and deep learning models pave the way for the return rate prediction process. In this aspect, this study develops an intelligent return rate predictive approach using deep learning for blockchain financial products (RRP-DLBFP). The proposed RRP-DLBFP technique involves designing a long short-term memory (LSTM) model for the predictive analysis of return rate. In addition, Adam optimizer is applied to optimally adjust the LSTM model's hyperparameters, consequently increasing the predictive performance. The learning rate of the LSTM model is adjusted using the oppositional glowworm swarm optimization (OGSO) algorithm. The design of the OGSO algorithm to optimize the LSTM hyperparameters for bitcoin return rate prediction shows the novelty of the work. To ensure the supreme performance of the RRP-DLBFP technique, the Ethereum (ETH) return rate is chosen as the target, and the simulation results are investigated in different measures. The simulation outcomes highlighted the supremacy of the RRP-DLBFP technique over the current state of art techniques in terms of diverse evaluation parameters. For the MSE, the proposed RRP-DLBFP has 0.0435 and 0.0655 compared to an average of 0.6139 and 0.723 for compared methods in training and testing, respectively.",2021
Intelligent Financial Risk Warning for Enterprises Through Knowledge Graph-Based Deep Learning,"The financial risk warning methods for enterprises have always been a practical concern. In digital society, the computational intelligence has brought more spirit to this demand. This paper first introduces the current situation of the development of Knowledge graph technology, describes the deep learning fusion method based on Knowledge graph, and expresses the feasibility of this study. Then, according to the requirements of Knowledge graph, it completes the method fusion of core data training and extraction, and completes the adaptive deep learning design for the Beautiful SCOP database, and establishes a STDE-FG financial risk early warning model. Through empirical analysis, the shortcomings of this model were identified, and a comparison of optimized and optimized results was completed. Two aspects of phenomenon can be found from experimental results. For one thing, the accuracy of the unoptimized STDE-FG early warning model has been improved by 37.5-55.3% compared to traditional prediction models, but the prediction value during legal person changes has a greater error than traditional prediction values. For another, the optimized STDE-FG early warning model has also improved its accuracy in predicting new investments and equity changes, with improvements of 17-32% and 16-28%, respectively, with significant changes. This model will have a positive impact on improving enterprise risk management capabilities and reducing financial risk costs.",2024
Intelligent Feature Selection with Deep Learning Based Financial Risk Assessment Model,"Due to global financial crisis, risk management has received significant attention to avoid loss and maximize profit in any business. Since the financial crisis prediction (FCP) process is mainly based on data driven decision making and intelligent models, artificial intelligence (AI) and machine learning (ML) models are widely utilized. This article introduces an intelligent feature selection with deep learning based financial risk assessment model (IFSDL-FRA). The proposed IFSDL-FRA technique aims to determine the financial crisis of a company or enterprise. In addition, the IFSDL-FRA technique involves the design of new water strider optimization algorithm based feature selection (WSOA-FS) manner to an optimum selection of feature subsets. Moreover, Deep Random Vector Functional Link network (DRVFLN) classification technique was applied to properly allot the class labels to the financial data. Furthermore, improved fruit fly optimization algorithm (IFFOA) based hyperparameter tuning process is carried out to optimally tune the hyperparameters of the DRVFLN model. For enhancing the better performance of the IFSDL-FRA technique, an extensive set of simulations are implemented on benchmark financial datasets and the obtained state of art approaches.",2022
A novel approach to flood risk zonation: integrating deep learning models with APG in the Aji Chay catchment,"Each year, floods, as one of the natural calamities, lead to significant destruction in various regions globally. Consequently, precise flood prediction becomes crucial in mitigating human and financial losses and effectively managing water resources. To achieve this, Convolutional Neural Network and Long Short-Term Memory (LSTM) models were utilized in this study to map flood hazards in the Aji Chay watershed. Flood data points were collected from the study area and subsequently divided into two groups using the Absence Point Generation technique. The first group, comprising 70% of the data, served as the training dataset for model construction, while the remaining 30% formed the testing dataset for validation. Seven key factors influencing floods, namely, precipitation, land use, Normalized Difference Vegetation Index, drainage density, flow direction, topographic wetness index, and terrain ruggedness index, were identified through Leave-One-Feature-Out approach and employed in the modeling process. The LSTM model with a Kolmogorov-Smirnov (KS) statistic value of 88.14 was chosen as the best model based on the KS plot. The results revealed that approximately 37% of the study area fell into high and very high flood risk classes. These research findings can be valuable in the effective management of flood-prone areas and the reduction of flood damages.",2024
Can deep learning predict risky retail investors? A case study in financial risk behavior forecasting,"The paper examines the potential of deep learning to support decisions in financial risk management. We develop a deep learning model for predicting whether individual spread traders secure profits from future trades. This task embodies typical modeling challenges faced in risk and behavior forecasting. Conventional machine learning requires data that is representative of the feature-target relationship and relies on the often costly development, maintenance, and revision of handcrafted features. Consequently, modeling highly variable, heterogeneous patterns such as trader behavior is challenging. Deep learning promises a remedy. Learning hierarchical distributed representations of the data in an automatic manner (e.g. risk taking behavior), it uncovers generative features that determine the target (e.g., trader's profitability), avoids manual feature engineering, and is more robust toward change (e.g. dynamic market conditions). The results of employing a deep network for operational risk forecasting confirm the feature learning capability of deep learning, provide guidance on designing a suitable network architecture and demonstrate the superiority of deep learning over machine learning and rule-based benchmarks. (C) 2019 Elsevier B.V. All rights reserved.",2020
Analyzing the Internet financial market risk management using data mining and deep learning methods,"Purpose To identify and analyze the occurrence of Internet financial market risk, data mining technology is combined with deep learning to process and analyze. The market risk management of the Internet is to improve the management level of Internet financial risk, improve the policy of Internet financial supervision and promote the healthy development of Internet finance. Design/methodology/approach In this exploration, data mining technology is combined with deep learning to mine the Internet financial data, warn the potential risks in the market and provide targeted risk management measures. Therefore, in this article, to improve the application ability of data mining in dealing with Internet financial risk management, the radial basis function (RBF) neural network algorithm optimized by ant colony optimization (ACO) is proposed. Findings The results show that the actual error of the ACO optimized RBF neural network is 0.249, which is 0.149 different from the target error, indicating that the optimized algorithm can make the calculation results more accurate. The fitting results of the RBF neural network and ACO optimized RBF neural network for nonlinear function are compared. Compared with the performance of other algorithms, the error of ACO optimized RBF neural network is 0.249, the running time is 2.212 s, and the number of iterations is 36, which is far less than the actual results of the other two algorithms. Originality/value The optimized algorithm has a better spatial mapping and generalization ability and can get higher accuracy in short-term training. Therefore, the ACO optimized RBF neural network algorithm designed in this exploration has a high accuracy for the prediction of Internet financial market risk.",2022
Forecasting the high-frequency volatility based on the LSTM-HIT model,"Volatility forecasting from high-frequency data plays a crucial role in many financial fields, such as risk management, option pricing, and portfolio management. Many existing statistical models could better describe and forecast the characteristics of volatility, whereas they do not simultaneously account for the long-term memory of volatility, the nonlinear characteristics of high-frequency data, and technical index information during the modeling phase. The purpose of this paper is to use the prediction advantage of deep learning long short-term memory (LSTM) model to predict the volatility fusing three classes of information, that is, high frequency realized volatility (H), technical indicators (I), and the parameters of generalized autoregression conditional heteroskedasticity(GARCH), heterogeneous autoregressive (HAR), and c, resulting in a novel LSTM-HIT model to forecast realized volatility. We employ the extreme value theory (EVT) of a semiparametric method to estimate the quantile of standardized return and construct the LSTM-HIT-EVT model to forecast the value at risk (VaR). Empirical results show that the LSTM-HIT model provides the most accurate volatility forecast among the various considered models and that the LSTM-HIT-EVT model yields forecasts more accurate than other VaR models.",2024
Symmetry-Aware Credit Risk Modeling: A Deep Learning Framework Exploiting Financial Data Balance and Invariance,"With the proliferation of mobile devices and payment systems in modern financial services, there is an increasing need to process and analyze continuous streams of transaction data for credit risk assessment. Leveraging the inherent symmetries in financial markets and data structures, this paper introduces DeepCreditRisk, a symmetry-aware deep learning framework that addresses key challenges while maintaining critical invariance properties in financial data representation. The framework incorporates three main components: an adaptive temporal fusion mechanism, a heterogeneous graph neural network, and an attention-based interpretable output layer. The temporal fusion mechanism effectively models both short-term fluctuations and long-term trends in financial time series, while the heterogeneous graph neural network captures intricate relationships within the financial ecosystem. The framework maintains important symmetrical properties in both temporal and structural representations, ensuring balanced feature learning and invariant risk assessment. The attention-based output layer preserves representation symmetry while enhancing model interpretability. Extensive experiments on a large-scale credit risk dataset demonstrate DeepCreditRisk's superior performance, achieving a 7.2% improvement in the Area Under the Receiver Operating Characteristic Curve (AUC-ROC) and an 18.6% improvement in the Kolmogorov-Smirnov (KS) statistic over state-of-the-art baseline models. The framework maintains high predictive power across various time horizons and provides interpretable insights into feature importance. DeepCreditRisk represents a significant advancement in applying deep learning to credit risk assessment, offering financial institutions a more accurate, robust, and transparent approach for evaluating creditworthiness and managing risk.",2025
Boosting Financial Market Prediction Accuracy With Deep Learning and Big Data: Introducing the CCL Model,"The accuracy of financial market trend prediction directly impacts investors' decisions and financial institutions' risk management, making it a focal point of research in the financial domain. While traditional statistical methods lay the foundation for market forecasting, they still face limitations in handling complex, nonlinear, and non-stationary financial time series data with accuracy and adaptability. Time series analysis plays a pivotal role in financial market prediction, revealing historical patterns and future trends within the data. Addressing the limitations of existing methods, this study proposes a deep learning-based CEEMDAN-CNN-LSTM model. Leveraging the CEEMDAN decomposition method to capture the multi-frequency components of time series, CNN extracts spatial features, and LSTM learns temporal dependencies. Experimental results demonstrate that the performance of the CEEMDAN-CNN-LSTM model surpasses traditional models on standardized evaluation metrics such as RMSE, MAE, and MAPE across four major financial datasets.",2024
Listed Company Financial Risk Prediction Based on BP Neural Work,"This paper discusses correlative relation between company's financial risk and data mining and studies currently financial crisis warning optimization method of listed company. It analyzes and demonstrates neural network input dimension optimization of rough intension simplification, network weights, and threshold value of genetic algorithm optimization. In addition, it empirically analyzes the optimized model and traditional BP neural network model. Then, the genetic algorithm is used as preset device of neural network model which optimizes the initial value and threshold value at input terminal, to shorten the training time and to improve network predictive efficiency. Empirical research shows that financial risk predictive accuracy of optimized model is higher than traditional predictive accuracy and efficiency of BP neural network model.",2015
A Big Data Mining Approach of PSO-Based BP Neural Network for Financial Risk Management With IoT,"In recent years, the technology about IoT (Internet of Things) has been applied into finance domain, and the generated data, such as the real-time data of chattel mortgage supervision with GPS, sensors, network cameras, mobile devices, etc., has been used to improve the capability of financial credit risk management of bank loans. Financial credit risk is by far one of the most significant risks that commercial banks have to face, however, when confronting to the massively growing financial data from multiple sources including Internet, mobile networks or IoT, traditional statistical models and neural network models might not operate fairly or accurately enough for credit risk assessment with those diverse data. Hence, there is a practical need to establish more powerful risk prediction models with artificial intelligence based on big data analytics to predict default behaviors with better accuracy and capacity. In this article, a big data mining approach of Particle Swarm Optimization (PSO) based Backpropagation (BP) neural network is proposed for financial risk management in commercial banks with IoT deployment, which constructs a nonlinear parallel optimization model with Apache Spark and Hadoop HDFS techniques on the dataset of on-balance sheet item and off-balance sheet item. The experiment results indicate that this parallel risk management model has fast convergence rate and powerful predictive capacity, and performs efficiently in screening default behaviors. In the meanwhile, the distributed implementation on big data clusters largely reduces the processing time of model training and testing.",2019
Innovative Mechanism of Rural Finance: Risk Assessment Methods and Impact Factors of Agricultural Loans Based on Personal Emotion and Artificial Intelligence,"Agricultural finance is in an embarrassing position in the current financial environment, especially during the process of COVID-19. Based on a small-scale peasant economy, it can no longer meet the rapidly rising demand of farmers for agricultural finance. Moreover, there has been a serious disconnection between the financial system of secondary and tertiary industries, and the quality of development needs to be improved urgently. The agricultural loan risk assessment has always been the main problem that we pay great attention to in the innovation of agricultural finance. Agricultural loans are an indispensable element in supporting agricultural development and promoting rural revitalization strategy. However, financial institutions have certain credit risks in reviewing and issuing agricultural loans. This article studies the speech emotion recognition of farmers in loan review to assess loan risk. As for emotional confusion caused by speech segmentation, a special method of data connection between Convolutional Neural Networks (CNNs) and Bidirectional Long Short-Term Memory (Bi-LSTM) Networks is designed, and a variable-length speech emotion recognition model including CNN and Bi-LSTM is designed. Experimental results show that the proposed algorithm can effectively improve the risk assessment of farmers in loan review.",2022
Hybrid ML models for volatility prediction in financial risk management,"Predicting volatility in financial markets is an important task with practical uses in decision- making, regulation, and academic research. This study focuses on forecasting realized volatility in stock indices using advanced machine learning techniques. We examine three key indices: the Shanghai Stock Exchange Composite (SSE), Infosys (INFY), and the National Stock Exchange Index (NIFTY). To achieve this, we propose a hybrid model that combines optimized Variational Mode Decomposition (VMD) with deep learning methods like Artificial Neural Networks (ANN), Long Short-Term Memory (LSTM), and Gated Recurrent Units (GRU). Using data from 2015 to 2022, we analyse how well these models predict volatility. Our findings reveal distinct patterns: the SSE shows high unpredictability, INFY is prone to extreme positive volatility, and NIFTY is relatively moderate. Among the models tested, the Q-VMD-ANN-LSTM-GRU hybrid model consistently performs best, providing highly accurate predictions for all three indices. This model has practical benefits for financial institutions. It improves risk management, supports investment decisions, and provides real-time insights for traders and risk managers. Additionally, it can enhance stress testing and inspire innovative trading strategies. Overall, our study highlights the potential of advanced machine learning, especially hybrid models, to address financial market complexities and improve risk management practices.",2025
Deep Reinforcement Learning based Multi-Objective Systems for Financial Trading,"Because of the risky nature of stock market, most people do not feel a secure option to invest their money in financial trading. Focusing on this basic concern of investors much research efforts are devoted to develop automated trading systems that make intelligent decisions according to the market situation and help investor to make profit beside risk. In contrast, in this paper we proposed multi-objective systems based on deep reinforcement learning for stock trading. Target of the multi-objective systems is to get maximum profit by adjusting risk. We design the whole structure of systems consisting two deep neural networks first is LSTM autoencoder for robust feature extraction and second deep reinforcement learning with LSTM recurrent neural network for decision making in order to achieve the investor's goal. We conduct an experiment on real historic data for verification of the systems and compare them with conventional trading systems.",2020
Deep Residual Convolutional Long Short-term Memory Network for Option Price Prediction Problem,"In the realm of financial markets, the precise prediction of option prices remains a cornerstone for effective portfolio management, risk mitigation, and ensuring overall market equilibrium. Traditional models, notably the Black-Scholes, often encounter challenges in comprehensively integrating the multifaceted interplay of contemporary market variables. Addressing this lacuna, this study elucidates the capabilities of a novel Deep Residual Convolution Long Short -term Memory (DR-CLSTM) network, meticulously designed to amalgamate the superior feature extraction prowess of Convolutional Neural Networks (CNNs) with the unparalleled temporal sequence discernment of Long Short-term Memory (LSTM) networks, further augmented by deep residual connections. Rigorous evaluations conducted on an expansive dataset, representative of diverse market conditions, showcased the DR-CLSTM's consistent supremacy in prediction accuracy and computational efficacy over both its traditional and deep learning contemporaries. Crucially, the integration of residual pathways accelerated training convergence rates and provided a formidable defense against the often detrimental vanishing gradient phenomenon. Consequently, this research positions the DR-CLSTM network as a pioneering and formidable contender in the arena of option price forecasting, offering substantive implications for quantitative finance scholars and practitioners alike, and hinting at its potential versatility for broader financial instrument applications and varied market scenarios.",2023
Financial Derivative Price Forecasting and Trading for Multiple Time Horizons with Deep Long Short-Term Memory Networks,"Price forecasting and trading in the international crude oil market are important issues for investors in energy finance. In this study, we propose an alternative forecasting approach for financial derivative price multiple days ahead and simulated trading based on long short-term memory (LSTM). This study aims to evaluate for different multiple days ahead forecasting and trading by deep LSTM-based model using technical analytic features, which have nonlinear behaviors. The effectiveness of LSTM networks trained by backpropagation through time for test objective prediction is explored. Moreover, instead of using only one crude oil market's spot price data as a data source, we build up a crude oil database with the two most important crude oil markets. The results indicate that the proposed approach outperforms others in terms of accuracy, return, and risk aspect. The forecasting and holding (for trade) time horizons are 1-3 days ahead, respectively. For all three multiple days ahead forecasting and trading, the average test accuracy (judged by root mean square error) of two crude oil markets for four datasets of deep LSTM-based model yields best results among all methods. This study also developed trading strategies, and the proposed LSTM-based method also outperforms other benchmark methods on both return and return-risk ratio (judged by Sharpe ratio). The experimental results indicate that the proposed method can help traders make profits in the financial derivative market and is more effective than the state-of-the-art methods in actual trading.",2022
Analysis of Regional Financial Risk in Guangdong Province Based on the DCN Deep Learning Model,"In the free flow of financial factors oriented to capital, returns will be accompanied by the concentration and diffusion of financial resources to form regional financial spatial differences, which is an objective phenomenon of regional financial practice. Localized regional financial risks may appear in the process of regional financial practice in each region. To address the abovementioned problems, we propose a model for regional financial risk analysis based on the DCN deep learning model. The main contents are as follows: elaborating the financial risk transmission mechanism involving intra- and interregional financial risks, sorting out the relationship between sectors as clues; the designing process of regional financial risk index as well as the measurement method, and the regional financial risk index for typical regions is measured and found to be at peak in 2017 with a risk index of 0.58; and the construction of an early warning model based on the value of the regional financial risk index and the expansion of the RNN network applied to the construction of the regional financial risk early warning system. Based on the construction of the RNN network application risk early warning system, the three types of risks, payment risk, loan loss risk, and market risk with the percentages of 49.62%, 26.82%, and 23.56%, respectively, are derived, and the focus is on their supervision and management in the follow-up work.",2022
Comparative analysis of deep learning algorithms for predicting construction project delays in Saudi Arabia,"Construction projects in Saudi Arabia often encounter delays, which present significant challenges to project managers and result in financial losses and stakeholder dissatisfaction. Effectively managing these delays is essential for maintaining project timelines and optimizing resource use. This study explores the hypothesis that advanced deep learning algorithms can significantly improve the prediction and management of construction project delays in Saudi Arabia. The research focuses on three algorithms: Generative Adversarial Networks (GAN), Long Short-Term Memory (LSTM), and Multilayer Perceptron (MLP), evaluating their effectiveness across datasets with varying class imbalances. A structured methodology was employed to assess the algorithms based on key performance metrics, including accuracy, precision, sensitivity, specificity, and misclassification errors. GAN, LSTM, and MLP were trained and tested using real-world construction project data, incorporating tools such as k-fold cross-validation for validation. The GAN model achieved the highest accuracy at 91 %, with a misclassification error of 9 %, outperforming both LSTM (accuracy: 88 %, error: 12 %) and MLP (accuracy: 83 %, error: 17 %). GAN also demonstrated superior precision (90 %) and sensitivity (87 %), making it the most reliable algorithm for delay risk assessment. While LSTM was effective, it had slightly lower precision (88 %) but exhibited strong generalization to unseen data. MLP showed the weakest performance, with higher misclassification rates and lower robustness. These findings suggest that deep learning models, particularly GAN, can significantly improve decision-making and delay mitigation in construction projects.",2025
Research on Operational Risk Monitoring Method of Intelligent Financial System Based on Deep Learning and Improved RPA,"The accuracy of traditional financial system operational risk monitoring is low. Therefore, this paper proposes a method of intelligent financial system operational risk monitoring based on deep learning and improved RPA. Set the financial monitoring index and obtain the warning threshold parameters; Using deep neural network method to mine key risk indicators and obtain reconstruction coefficients of data mining errors of financial system; By improving the RPA method to calculate the fit degree of financial risk, it matches the internal business process of the enterprise; The operational risk monitoring algorithm of financial system is designed to realize the operational risk monitoring of financial system. The experimental results show that the risk monitoring accuracy of the design method is 80.3%, and the overall test threshold of the model is 0.5 after the introduction of non-financial indicators, which shows that it can be applied in practice.",2023
"Stock index prediction and uncertainty analysis using multi-scale nonlinear ensemble paradigm of optimal feature extraction, two-stage deep learning and Gaussian process regression","Reliable prediction of stock indexes can be highly valuable for financial decision-making and risk management. The stock market is a highly complicated nonlinear system which makes it difficult to present accurate predictors. In this paper, an innovative multi-scale nonlinear ensemble paradigm is proposed for stock index prediction and uncertainty analysis, which consists of an optimal feature extraction including variational mode decomposition and auto-encoder, a two-stage deep learning based on recurrent neural network and long short-term memory, and Gaussian process regression. The optimal feature extraction is proposed to extract the optimal features of stock index fluctuations and eliminate the disturbance of illusive components. The two-stage deep learning is developed to conduct the prediction of each feature sub-signal and implement its nonlinear integration. The Gaussian process regression is utilized to construct the interval prediction of the original stock signal and analyze the uncertainties of stock market. The validity of the developed model is verified by the data from S&P 500, Dow Jones index and NASDAQ. After a series of comparisons, the mean absolute percentage errors of the proposed model in S&P 500, Dow Jones index and NASDAQ are 0.55%, 0.65% and 1.11%, respectively. These results fully verify the effectiveness of proposed model. (C) 2021 Elsevier B.V. All rights reserved.",2021
Simulation of network traffic risk of enterprise cloud financial system by using deep learning,"Traditional network traffic analysis methods fall short in addressing the requirements of complex network environments. Therefore, the introduction of advanced technologies, such as deep learning, is necessary to enhance the accuracy and efficiency of network traffic analysis. This paper designs a risk analysis method of enterprise cloud financial system network traffic based on deep learning to improve the level and effect of network security assurance. A deep learning based traffic analysis framework has been constructed, which includes several main steps such as data preprocessing, feature extraction, model training, and result evaluation. The test results on the experimental data set show that this method can identify network attacks and abnormal traffic more quickly and accurately than the traditional network traffic analysis methods, and has better practicability and application prospects.",2023
Skew Index: a machine learning forecasting approach,"The Skew Index originated in response to the Black Monday Crisis in 1987 to provide investors and regulators with a tool to gauge turbulence in the financial markets. Understanding and forecasting the Skew Index is crucial for anticipating market downturns and managing financial risk. This paper presented key descriptive statistics of the Skew Index, a topic not extensively covered in existing literature. Furthermore, we utilized a range of Deep Learning models-Dense, LSTM, GRU, CNN, and Hybrid-CNN-in both stand-alone configurations and with external variables to forecast the Index with daily data from April 1, 1997, to November 30, 2023. LASSO regression analysis was applied to select the most predictive exogenous variables for the index forecast. Our findings indicated that the Dense model provided an effective forecast for stand-alone models, while the CNN-LSTM model offered a superior forecast compared to other deep learning models when external variables were included. This research is novel in its application of neural network architectures to forecast the daily levels of the Skew Index, contributing to the field by providing a robust framework for financial market risk assessment and forecasting.",2025
Improving Deep Learning for Forecasting Accuracy in Financial Data,"Financial forecasting is based on the use of past and present financial information to make the best prediction of the future financial situation, to avoid high-risk situations, and to increase benefits. Such forecasts are of interest to anyone who wants to know the state of possible finances in the future, including investors and decision-makers. However, the complex nature of financial data makes it difficult to get accurate forecasts. Artificial intelligence, which has been shown to be suitable for analyzing very complex problems, can be applied to financial forecasting. Financial data is both nonlinear and nonstationary, with broadband frequency features. In other words, there is a large range of fluctuation, meaning that predictions made only using long short-term memory (LSTM) are not enough to ensure accuracy. This study uses an LSTM model for analysis of financial data, followed by a comparison of the analytical results with the actual data to see which has a larger root-mean-square-error (RMSE). The proposed method combines deep learning with empirical mode decomposition (EMD) to understand and predict financial trends from financial data. The financial data for this study are from the Taiwan corporate social responsibility (CSR) index. First, the EMD method is used to transform the CSR index data into a limited number of intrinsic mode functions (IMF). The bandwidth of these IMFs becomes narrower, with regular cyclic, periodic, or seasonal components in the time domain. In other words, the range of fluctuation is small. LSTM is a good way to forecast cyclic or seasonal data. The forecast result is obtained by adding all the IMFs together. It has been verified in past studies that only the LSTM and LSTM combined with the EMD can be used. The analytical results show that smaller RMSEs can be obtained using the LSTM combined with EMD compared to real data.",2020
PERFORMANCE OF DEEP LEARNING IN PREDICTION OF STOCK MARKET VOLATILITY,"Volatility forecasting is an important issue for investment analysis and risk management in finance. Based on the Long Short Term Memory (LSTM) deep learning algorithm, we propose an accurate algorithm for forecasting stock market index and its volatility. The proposed algorithm is tested on the data from 5 stock market indices including S&P500, NASDAQ, German DAX, Korean KOSPI200 and Mexico IPC over a 7-yearperiod from 2010 to 2016. The highest prediction performance is observed with hybrid momentum, the difference between the price and the moving average of the past prices, for the predictions of both market index and volatility. Unlike stock index, the prediction accuracy for the volatility does not show dependency on other financial variables such as open, low, high prices, volume, etc. except the volatility itself.",2019
Robust portfolio management: A novel multi-task learning model fusing predicted returns and residual data under the framework of Mean-VaR,"We investigate how to build a robust portfolio by introducing a novel multi-task learning model that fuses predicted returns and residual data to assess the portfolio risk under the decision-making framework of Mean-VaR. A common way to build a portfolio is to predict the return of assets and then allocate weights according to the predicted return and corresponding risk. However, predicting asset returns accurately in financial markets remains a challenge. To improve prediction accuracy and, more importantly, effectively reduce risk in the portfolio, we adopt the multi-task learning anomaly detection (MTLAD). In this model, predicting asset returns using deep learning model (long short-term memory, LSTM) is the main task, and anomaly detection is the auxiliary task. We then combine the predicted returns and residual data to evaluate the risk measure when allocating the asset weights. Furthermore, we perform an extensive numerical investigation based on data in the Chinese financial market. Results obtained show that our robust portfolio management approach has great potential compared with multiple benchmarks.",2024
Integrating Deep Learning and Reinforcement Learning for Enhanced Financial Risk Forecasting in Supply Chain Management,"In today's dynamic business landscape, the integration of supply chain management and financial risk forecasting is imperative for sustained success. This research paper introduces a groundbreaking approach that seamlessly merges deep autoencoder (DAE) models with reinforcement learning (RL) techniques to enhance financial risk forecasting within the realm of supply chain management. The primary objective of this research is to optimize financial decision-making processes by extracting key feature representations from financial data and leveraging RL for decision optimization. To achieve this, the paper presents the PSO-SDAE model, a novel and sophisticated approach to financial risk forecasting. By incorporating advanced noise reduction features and optimization algorithms, the PSO-SDAE model significantly enhances the accuracy and reliability of financial risk predictions. Notably, the PSO-SDAE model goes beyond traditional forecasting methods by addressing the need for real-time decision-making in the rapidly evolving landscape of financial risk management. This is achieved through the utilization of a distributed RL algorithm, which expedites the processing of supply chain data while maintaining both efficiency and accuracy. The results of our study showcase the exceptional precision of the PSO-SDAE model in predicting financial risks, underscoring its efficacy for proactive risk management within supply chain operations. Moreover, the augmented processing speed of the model enables real-time analysis and decision-making - a critical capability in today's fast-paced business environment.",2024
EEG-Based Emotion Classification in Financial Trading Using Deep Learning: Effects of Risk Control Measures,"Day traders in the financial markets are under constant pressure to make rapid decisions and limit capital losses in response to fluctuating market prices. As such, their emotional state can greatly influence their decision-making, leading to suboptimal outcomes in volatile market conditions. Despite the use of risk control measures such as stop loss and limit orders, it is unclear if these strategies have a substantial impact on the emotional state of traders. In this paper, we aim to determine if the use of limit orders and stop loss has a significant impact on the emotional state of traders compared to when these risk control measures are not applied. The paper provides a technical framework for valence-arousal classification in financial trading using EEG data and deep learning algorithms. We conducted two experiments: the first experiment employed predetermined stop loss and limit orders to lock in profit and risk objectives, while the second experiment did not employ limit orders or stop losses. We also proposed a novel hybrid neural architecture that integrates a Conditional Random Field with a CNN-BiLSTM model and employs Bayesian Optimization to systematically determine the optimal hyperparameters. The best model in the framework obtained classification accuracies of 85.65% and 85.05% in the two experiments, outperforming previous studies. Results indicate that the emotions associated with Low Valence and High Arousal, such as fear and worry, were more prevalent in the second experiment. The emotions associated with High Valence and High Arousal, such as hope, were more prevalent in the first experiment employing limit orders and stop loss. In contrast, High Valence and Low Arousal (calmness) emotions were most prominent in the control group which did not engage in trading activities. Our results demonstrate the efficacy of our proposed framework for emotion classification in financial trading and aid in the risk-related decision-making abilities of day traders. Further, we present the limitations of the current work and directions for future research.",2023
On the Use of a Sequential Deep Learning Scheme for Financial Fraud Detection,"Forecasting fraud detection has never been more essential for the finance industry than today. The detection of fraud has been a major concern for the banking industry due to the high impact on banks' revenues and reputation. Fraud can be related with an augmented financial risk, which is often underestimated until it is too late. Recently, deep learning models have been introduced to detect and forecast possible fraud transactions with increased efficiency compared to the conventional machine learning methods and statistics. Such methods gain significant popularity due to their ability to estimate the unknown distribution of the collected data, thus, increasing their capability of detecting more complex fraud events. In this paper, we introduce a novel multistage deep learning model that combines a feature selection process upon an Autoencoder model and a deep convolutional neural network to detect frauds. To manage highly unbalanced datasets, we rely on the Synthetic Minority Over-sampling Technique (SMOTE) to oversample our dataset and adjust the class distribution delivering an efficient classification approach. We describe the problem under consideration and our contribution that provides a solution for it. An extensive set of experimental scenarios are adopted to reveal the performance of the proposed scheme exposing the relevant numerical results. A comparative assessment is used for proving the superiority of our model compared with a Support Vector Machine (SVM) scheme, a classical CNN model and the results of two researches that use the same dataset.",2021
RETRACTED: Financial risk assessment to improve the accuracy of financial prediction in the internet financial industry using data analytics models (Retracted Article),"A sound credit assessment mechanism has been explored for many years and is the key to internet finance development, and scholars divide credit assessment mechanisms into linear assessment and nonlinear assessment. The purpose is to explore the role of two important data analytics models including machine learning and deep learning in internet credit risk assessment and improve the accuracy of financial prediction. First, the problems in the current internet financial risk assessment are understood, and data of MSE (Micro small Enterprises) are chosen for analysis. Then, a feature extraction method based on machine learning is proposed to solve data redundancy and interference in enterprise credit risk assessment. Finally, to solve the data imbalance problem in the credit risk assessment system, a credit risk assessment system based on the deep learning DL algorithm is introduced, and the proposed credit risk assessment system is verified through a fusion algorithm in different models with specific enterprise data. The results show that the credit risk assessment model based on the machine learning algorithm optimizes the standard algorithm through the global optimal solution. The credit risk assessment model based on deep learning can effectively solve imbalanced data. The algorithm generalization is improved through layer-by-layer learning. Comparison analysis shows that the accuracy of the proposed fusion algorithm is 25% higher than that of the latest CNN (Convolutional Neural Network) algorithm. The results can provide a new research idea for the assessment of internet financial risk, which has important reference value for preventing financial systemic risk.",2022
RETRACTED: Risk Prediction and Response Strategies in Corporate Financial Management Based on Optimized BP Neural Network (Retracted Article),"This paper mainly analyzes the theories related to the financial risk of the company and combines the principles of principal component analysis, particle swarm optimization algorithm, and artificial neural network to derive the financial risk index system of the company. To improve the accuracy of financial risk prediction, principal component analysis and particle swarm algorithm are applied to optimize the BP neural network model, the input data of the prediction model is improved, and the optimal initial weights and thresholds are given to the BP neural network by using particle swarm algorithm search, whereby the financial risk prediction model of particle swarm optimization BP neural network is constructed. The empirical results show that the model constructed by BP neural network not only has a high accuracy rate for static financial risk evaluation but also has a better prediction effect. After training and testing, the BP neural network-based enterprise financial risk evaluation model can accurately determine the existing financial situation of enterprise financial management and has a good prediction effect. Our research method is a fusion of the processing of the two methods, which belongs to the first integration of results.",2021
Design and Implementation of China Financial Risk Monitoring and Early Warning System Based on Deep Learning,"Affected by the COVID-19 epidemic, financial regulators urgently need to establish a sensitive and scientific financial risk pre-alarm system that is suitable for the economic environment under the COVID-19 epidemic. The perfect pre-alarm system is based on in-depth scientific theoretical research, so it is of great practical significance to study the financial security assessment and systemic financial risk pre-alarm. The accumulation of massive data puts forward higher requirements for the effective organization and management of financial information. How to quickly extract effective information and analyze and predict it effectively on the basis of data has become an important issue in academic and industrial research. Exploring the nature of financial markets, analyzing and mastering the potential development rules between data not only provide effective technical support for financial management and investment business, but also play a pivotal role in promoting the steady growth of financial markets. This article proposes a financial risk pre-alarm model based on deep learning (DL). This model can detect the financial risk behaviors brought by a few people, and provides a new theory and method for the financial risk management (FRM) system. This algorithm solves the difficulties that traditional models are difficult to deal with highly nonlinear models and lack of adaptive ability.",2023
A comparative study of hybrid and individual models for predicting the Moroccan MASI index: Integrating machine learning and deep learning approaches,"Forecasting financial market fluctuations is inherently challenging due to its complexity, volatility, and non-linear behavior. This research investigates the predictive accuracy of novel machine learning (ML) approaches for forecasting stock prices. Our approach combines individual ML and deep learning (DL) techniques to predict the daily price of the Moroccan all-share index (MASI). This study introduces novel hybrid models, specifically SVR-XGBoost, MLP-XGBoost, and LSTM-XGBoost. Daily closing price data for the MASI index and sector indices, from 2013 to 2023, is collected. The dataset is used to train and optimize Support Vector Regression (SVR), XGBoost, Multilayer Perceptron (MLP), and Long Short-Term Memory (LSTM) models using the Grid search (GS) algorithm. The performance of these individual models is compared with the hybrid model using standard metrics such as mean absolute error (MAE), mean square error (MSE), mean absolute percentage error (MAPE), and root mean square error (RMSE). In addition, backtesting and bootstrapping interval from the Skforecast library are used. The results demonstrate that the hybrid model achieves the highest accuracy. Moreover, this research holds significant value for investors, financial analysts, and policymakers by refining investment strategies and improving risk management practices.",2025
A Deep Network-Based Trade and Trend Analysis System to Observe Entry and Exit Points in the Forex Market,"In the Forex market, trend trading, where trend traders identify trends and attempt to capture gains through the analysis of an asset's momentum in a particular direction, is a great way to profit from market movement. When the price of currency is moving in one either of the direction such as; up or down, it is known as trends. This trend analysis helps traders and investors find low risk entry points or exit points until the trend reverses. In this paper, empirical trade and trend analysis results are suggested by two-phase experimentations. First, considering the blended learning paradigm and wide use of deep-learning methodologies, the variants of long-short-term-memory (LSTM) networks such as Vanilla-LSTM, Stacked-LSTM, Bidirectional-LSTM, CNN-LSTM, and Conv-LSTM are used to build effective investing trading systems for both short-term and long-term timeframes. Then, a deep network-based system used to obtain the trends (up trends and down trends) of the predicted closing price of the currency pairs is proposed based on the best fit predictive networks measured using a few performance measures and Friedman's non-parametric tests. The observed trends are compared and validated with a few readily available technical indicators such as average directional index (ADX), rate of change (ROC), momentum, commodity channel index (CCI), and moving average convergence divergence (MACD). The predictive ability of the proposed strategy for trend analysis can be summarized as follows: (a) with respect to the previous day for short-term predictions, AUD:INR achieves 99.7265% and GBP:INR achieves 99.6582% for long-term predictions; (b) considering the trend analysis strategy with respect to the determinant day, AUD:INR achieves 98.2906% for short-term predictive days and USD:INR achieves an accuracy of trend forecasting with 96.0342%. The significant outcome of this article is the proposed trend forecasting methodology. An attempt has been made to provide an environment to understand the average, maximum, and minimum unit up and/or downs observed during trend forecasting. In turn, this deep learning-based strategy will help investors and traders to comprehend the entry and exit points of this financial market.",2022
Quantifying Uncertainty of Portfolios using Bayesian Neural Networks,"Quantifying the uncertainty of a financial portfolio is important for investors and regulatory agencies. Reporting such uncertainty accurately is challenging due to time-dependent market dynamics, non-linearities in the return and risk properties of a portfolio, and due to the unobserved nature of the market risk. We propose Bayesian Neural Network (BNN) models, namely Recurrent Neural Network (RNN) and Long Short Term Memory (LSTM) models, to estimate the time-varying return distribution of an asset portfolio. The proposed models estimate the density of returns and incorporate parameter uncertainty through Bayesian inference. The uncertainty and any financial risk metric of interest can directly be obtained from the estimated density. Furthermore, through the BNN input-output design, proposed BNNs incorporate potential non-linear effects of each asset in the portfolio on the obtained density estimates. The proposed method is applicable to assess the uncertainty of any portfolio where the portfolio weight optimization is separated from risk assessment. We analyze the risk of a daily, equally weighted portfolio of 29 ETFs and a risk-free asset for a long time span with differing market environments between 09/06/2005 and 10/09/2020. We study the effects of different inference methods on the obtained results. The proposed models improve portfolio risk estimates compared to the benchmark. The performances of the proposed models depend on BNN design and the inference method. RNN models lead to relatively more stable results compared to LSTMs. Furthermore, the results of models with a relatively higher number of parameters depend heavily on the estimation method.",2024
A Multimodal Deep Neural Network-based Financial Fraud Detection Model Via Collaborative Awareness of Semantic Analysis and Behavioral Modeling,"The monitoring and early warning of financial risks have become a crucial link in maintaining market stability and safeguarding the rights and interests of investors. Traditional financial risk monitoring methods often rely on a single data source or analysis model, making it challenging to comprehensively and accurately capture risk signals. Therefore, this paper proposes a novel financial risk monitoring model based on multimodal neural networks, which innovatively integrates multiple data sources, such as vision, language and audio, and utilizes their inherent correlations to enhance the accuracy of risk identification. First, by employing the Bidirectional Long Short-Term Memory Network (BiLSTM) structure and incorporating the self-attention mechanism, the semantic information of financial texts is deeply analyzed through the calculation of dynamic weight coefficients. Additionally, Option-based Hierarchical Reinforcement Learning (OHRL) is utilized to accurately model the behavior of market participants, capturing nuanced changes in their decision-making process. By integrating these two types of information, a comprehensive BiLSTM-OHRL model is formulated to evaluate the risk status of financial markets in a more comprehensive and accurate manner. The results demonstrate that the model performs impressively in financial risk monitoring, accurately capturing the emotional and behavioral characteristics of market participants, thereby enhancing the comprehensiveness and predictive capability of the monitoring model. It provides robust technical support for the stable operation of the financial market.",2025
GARCH-Informed Neural Networks for Volatility Prediction in Financial Markets,"Volatility, which indicates the dispersion of returns, is a crucial measure of risk and is hence used extensively for pricing and discriminating between different financial investments. As a result, accurate volatility prediction receives extensive attention. The Generalized Autoregressive Conditional Heteroscedasticity (GARCH) model and its succeeding variants are well established models for stock volatility forecasting. More recently, deep learning models have gained popularity in volatility prediction as they demonstrated promising accuracy in certain time series prediction tasks. Inspired by Physics-Informed Neural Networks (PINN), we constructed a new, hybrid Deep Learning model that combines the strengths of GARCH with the flexibility of a Long Short-Term Memory (LSTM) Deep Neural Network (DNN), thus capturing and forecasting market volatility more accurately than either class of models are capable of on their own. We refer to this novel model as a GARCH-Informed Neural Network (GINN). When compared to other time series models, GINN showed superior out-of-sample prediction performance in terms of the Coefficient of Determination (R-2), Mean Squared Error (MSE), and Mean Absolute Error (MAE).",2024
A novel deep learning framework: Prediction and analysis of financial time series using CEEMD and LSTM,"Deep learning is well-known for extracting high-level abstract features from a large amount of raw data without relying on prior knowledge, which is potentially attractive in forecasting financial time series. Long short-term memory (LSTM) networks are deemed as state-of-the-art techniques in sequence learning, which are less commonly applied to financial time series predictions, yet inherently suitable for this domain. We propose a novel methodology of deep learning prediction, and based on this, construct a deep learning hybrid prediction model for stock markets-CEEMD-PCA-LSTM. In this model, complementary ensemble empirical mode decomposition (CEEMD), as a sequence smoothing and decomposition module, can decompose the fluctuations or trends of different scales of time series step by step, generating a series of intrinsic mode functions (IMFs) with different characteristic scales. Then, with retaining the most of information on raw data, PCA reduces dimension of the decomposed IMFs component, eliminating the redundant information and improving prediction response speed. After that, high-level abstract features are separately fed into LSTM networks to predict closing price of the next trading day for each component. Finally, synthesizing the predicted values of individual components is utilized to obtain a final predicted value. The empirical results of six representative stock indices from three types of markets indicate that our proposed model outperforms benchmark models in terms of predictive accuracy, i.e., lower test error and higher directional symmetry. Leveraging key research findings, we perform trading simulations to validate that the proposed model outperforms benchmark models in both absolute profitability performance and risk-adjusted profitability performance. Furthermore, model robustness test unveils the more stable robustness compared to benchmark models. (C) 2020 Elsevier Ltd. All rights reserved.",2020
Construction of Mobile Internet Financial Risk Cautioning Framework Based on BP Neural Network,"With the emergence of the 21st-century global economy, the international financial system faces economic risks. A competitive cautioning model for financial management is required to mitigate risks and losses in the financial sector. The financial losses of the banking industry have been categorized and analyzed using the Internet of Things (IoT) and big data technologies to minimize the economic risk of commercial banks in mobile internet finance (MIF). This article proposes a new financial risk cautioning framework (FRCF) based on the IoT, big data, and back propagation-neural network (BP-NN) to ensure steady growth of MIF in the long term. In this article, a big data technology-based approach for data recognition and mining has been suggested. A BP-NN-based method for risk identification and assessment in MIF is also presented. The BP-NN technique calculates each neural network (NN) layer's node count, transfer functions, learning rate, and other characteristics. The proposed FRCF has been developed through the proper construction, analysis, and testing of many information samples. A conceptual understanding of the use of IoT, big data, and artificial intelligence (AI) technologies through NN models in the financial industry has been described in the article. The proposed FRCF can predict the MIF risks associated with the MIF lending infrastructure with a 98.2% accuracy.",2022
A Deep Learning-based Cryptocurrency Price Prediction Scheme for Financial Institutions,"A cryptocurrency is a network-based digital exchange medium, where the records are secured using strong cryptographic algorithms such as Secure Hash Algorithm 2 (SHA-2) and Message Digest 5 (MD5). It uses blockchain technology to make the transactions secure, transparent, traceable, and immutable. Due to these properties, the cryptocurrencies have gained popularity in almost all the sectors especially in financial sectors. Though, cryptocurrencies are getting recognition form the approval bodies, but still, the uncertainty and dynamism in their prices risk the investments substantially. Cryptocurrency price prediction has become a trending research topic globally. Many machine learning and deep learning algorithms such as Gated Recurrent Unit (GRU), Neural Networks (NN), and Long short-term memory (LSTM) have been used by the researchers to predict and analyze the factors affecting the cryptocurrency prices. In this paper, a LSTM and GRU-based hybrid cryptocurrency prediction scheme is proposed, which focuses on only two cryptocurrencies, namely Litecoin and Monero. The results depict that the proposed scheme accurately predicts the prices with high accuracy, revealing that the scheme can be applicable in various cryptocurrencies price predictions.",2020
Improved AHP Model and Neural Network for Consumer Finance Credit Risk Assessment,"With the rapid expansion of the consumer financial market, the credit risk problem in borrowing has become increasingly prominent. Based on the analytic hierarchy process (AHP) and the long short-term memory (LSTM) model, this paper evaluates individual credit risk through the improved AHP and the optimized LSTM model. Firstly, the characteristic information is extracted, and the financial credit risk assessment index system structure is established. The data are input into the AHP-LSTM neural network, and the index data are fused with the AHP so as to obtain the risk level and serve as the expected output of the LSTM neural network. The results of the prewarning model after training can be used for financial credit risk assessment and prewarning. Based on LendingClub and PPDAI data sets, the experiment uses the AHP-LSTM model to classify and predict and compares it with other classification methods. Experimental results show that the performance of this method is superior to other comparison methods in both data sets, especially in the case of unbalanced data sets.",2022
A Suspicious Financial Transaction Detection Model Using Autoencoder and Risk-Based Approach,"This study focuses on the detection of suspicious transactions characterized by the opaque and complex electronic channels that have emerged with the advancement of electronic financial technology. A model that can immediately reflect trends in various types of fund and transaction flows, and autonomously learn complex transaction types, is proposed. As a key outcome, an internal control model for detecting suspicious transactions based on the risk-based approach is constructed by utilizing autoencoder to enhance anti-money laundering (AML) operations, and this method surpasses traditional AML methods. Additionally, the proposed model facilitates the extraction of candidate factors for suspicious transactions and updates warning models in AML monitoring systems, thereby allowing for the analysis of alert cases. As a result, AML operations based on the proposed model are quantitatively and qualitatively superior to those based on the traditional approaches, resulting in swift processing by avoiding exhaustive examinations of suspicious transaction types. This research provides information that can improve the AML operation systems used within the financial sector by evaluating the risk of suspicious transactions and reflecting various elements of funds and transactions.",2024
A Deep Learning Model for ERP Enterprise Financial Management System,"With the advent of the information age, the need for information technology construction is beginning to be realized when working in corporate financial management. The application of ERP systems to financial management has become a major trend in the development of modern society. This can help companies collect financial information in real time and analyze and process the obtained information. This paper first gives the significance and models of the ERP financial management system. Then, a financial risk prediction model based on a deep learning model is designed. The method proposes an improved temporal convolutional network-long and short-term memory network (TCN_LSTM) structure and introduces an optimization algorithm to optimize the parameters of the deep learning model. Finally, several benchmark models and evaluation methods are used for comparative study. The experimental results show that the deep learning risk prediction model has significant superiority in prediction accuracy and stability. The proposed model can help enterprises organize their limited resources, realize the scientific allocation of enterprise resources, and create more benefits for enterprises.",2022
Intelligent BiLSTM-Attention-IBPNN Method for Anomaly Detection in Financial Auditing,"Anomaly detection is a fundamental requirement in financial auditing, its detecting results can be used to correct the defects and predict risks for audited enterprise. However, with the auditing data becoming very huge, the anomaly detection error probabilities and material misstatement risk will be significantly increased. In this case, it is essential to develop an intelligent anomaly detection technology to address above problems. For these reasons, this paper develops a new intelligent anomaly detection method that combines the advantages of bidirectional long-short term memory (BiLSTM), improved backpropagation neural network (IBPNN) and an attention mechanism, also it possesses the strong abilities of nonlinear predicting, long time series feature extracting and important information attention. Furthermore, we present a correlation analysis algorithm to process the various types of huge financial auditing data, which can effectively remove the irrelevant information and discover the correlation relationships in financial auditing data before the BiLSTM-Attention-IBPNN method runs on it. The experimental results proved that our proposed method has better performances and evaluation results in anomaly detection compared with the state-of-the-art methods, also significantly improves the anomaly detection quality and efficiency for financial auditing.",2024
Research on Default Prediction for Credit Card Users Based on XGBoost-LSTM Model,"The credit card business has become an indispensable financial service for commercial banks. With the development of credit card business, commercial banks have achieved outstanding results in maintaining existing customers, tapping potential customers, and market share. During credit card operations, massive amounts of data in multiple dimensions-including basic customer information; billing, installment, and repayment information; transaction flows; and overdue records-are generated. Compared with preloan and postloan links, user default prediction of the on-loan link has a huge scale of data, which makes it difficult to identify signs of risk. With the recent growing maturity and practicality of technologies such as big data analysis and artificial intelligence, it has become possible to further mine and analyze massive amounts of transaction data. This study mined and analyzed the transaction flow data that best reflected customer behavior. XGBoost, which is widely used in financial classification models, and Long-Short Term Memory (LSTM), which is widely used in time-series information, were selected for comparative research.The accuracy of the XGBoost model depends on the degree of expertise in feature extraction, while the LSTM algorithm can achieve higher accuracy without feature extraction. The resulting XGBoost-LSTM model showed good classification performance in default prediction. The results of this study can provide a reference for the application of deep learning algorithms in the field of finance.",2021
A novel deep learning approach to enhance creditworthiness evaluation and ethical lending practices in the economy,"Evaluating a borrower's creditworthiness and enabling ethical lending practices are two of the most essential functions of credit scoring, making it an integral part of the economy. Credit risk management is an essential aspect of the financial industry, with the primary goal of minimising potential losses caused by customers failing to meet their credit responsibilities, such as fails to pay and bankruptcies. This risk is inherent in lending activities, where lenders extend credit to individuals or businesses. The traditional credit scoring approaches, which rely on statistical and machine learning techniques to analyse complex data and non-linear correlations in credit data has to be improved. Because the current financial sector lacks credit scoring, a deep learning network-based credit ranking model is presented in this research. This paper applies the complicated field of deep learning known as the stacked unidirectional and bidirectional long short-term memory model in the network to resolve credit scoring issues. Since scoring is not a time sequence issue, the suggested model uses the three-layer stacked LSTM and bidirectional LSTM architecture by modelling public datasets in a new way. Our suggested models beat state-of-the-art, considerably more difficult deep learning methods, proving that we could keep complexity to a minimum. The research findings indicate that the model demonstrates high levels of accuracy across various datasets. The model obtains an accuracy of 99.5% on the Australian dataset, 99.4% on the German dataset (categorical), 99.7% on the German dataset (numerical), 99.2% on the Japanese dataset, and 99.8% on the Taiwanese dataset. These results highlight the robustness and effectiveness of the model in accurately predicting outcomes for different geographical regions.",2025
Multivariate LSTM for Stock Market Volatility Prediction,"Volatility is a measure of fluctuation in financial asset returns, practical measurement of risk, and a key variable for calculating options prices. Accurate prediction of volatility is crucial to maintaining profitable investments and trading strategies. Statistical models such as GARCH are used today to predict volatility and time series, though new methods are actively being researched to improve the prediction accuracy to cope with the rapidly increasing trading volumes and stock market influencing factors. The aim of this paper is to investigate a new method to improve market volatility forecasting accuracy by innovatively introducing a new setup of the Recurrent Neural Network (RNN) algorithm. In particular, the proposed model is a stacked Long Short-Term Memory (LSTM) with multivariate input composed of multiple asset daily prices of different lag time-steps. The proposed model is used to predict volatility under different market conditions and is compared to the predictions obtained with GARCH as well as to the actual volatility of the same forecasting period. The results show that the prediction of the future realized volatility using a single feature LSTM has comparable accuracy to GARCH. They also indicate that a stacked LSTM can significantly improve the volatility prediction accuracy when configured with multivariate input of more than one asset and a lagging period of more than a day. A stacked multivariate LSTM setup enables the prediction model to capture complex patterns in the time series data of assets prices and provides a superior alternative to statistical models in volatility modelling and prediction. The proposed multivariate LSTM architecture clearly shows faster and more accurate modelling of daily volatility and therefore can be used for intra-day modelling specifically for high frequency trading environments.",2022
"Forecasting COVID-19 Pandemic Using Prophet, ARIMA, and Hybrid Stacked LSTM-GRU Models in India","Due to the proliferation of COVID-19, the world is in a terrible condition and human life is at risk. The SARS-CoV-2 virus had a significant impact on public health, social issues, and financial issues. Thousands of individuals are infected on a regular basis in India, which is one of the populations most seriously impacted by the pandemic. Despite modern medical and technical technology, predicting the spread of the virus has been extremely difficult. Predictive models have been used by health systems such as hospitals, to get insight into the influence of COVID-19 on outbreaks and possible resources, by minimizing the dangers of transmission. As a result, the main focus of this research is on building a COVID-19 predictive analytic technique. In the Indian dataset, Prophet, ARIMA, and stacked LSTM-GRU models were employed to forecast the number of confirmed and active cases. State-of-the-art models such as the recurrent neural network (RNN), gated recurrent unit (GRU), long short-term memory (LSTM), linear regression, polynomial regression, autoregressive integrated moving average (ARIMA), and Prophet were used to compare the outcomes of the prediction. After predictive research, the stacked LSTM-GRU model forecast was found to be more consistent than existing models, with better prediction results. Although the stacked model necessitates a large dataset for training, it aids in creating a higher level of abstraction in the final results and the maximization of the model's memory size. The GRU, on the other hand, assists in vanishing gradient resolution. The study findings reveal that the proposed stacked LSTM and GRU model outperforms all other models in terms of R square and RMSE and that the coupled stacked LSTM and GRU model outperforms all other models in terms of R square and RMSE. This forecasting aids in determining the future transmission paths of the virus.",2022
Intelligent Asset Allocation using Predictions of Deep Frequency Decomposition,"The boom of financial technology and artificial intelligence (AI) has influenced financial industry. Application of AI-based techniques especially deep neural networks in the stock market has drawn particular attention in recent years. Moreover, applying modern technology in finance has created new fields such as computational finance and intelligent asset management. Following this revolution, the present research aims to shed light on deep learning models in stocks analysis and apply theses analyses in portfolio management. To this end, we introduced a novel hybrid deep learning model for stock prediction and incorporated these predictions as investors' views in Black-Litterman asset allocation model. The finding indicates that the Black-Litterman portfolio based on the predictions of the hybrid CEEMD-CNN-LSTM model constructed portfolios with high return, low extreme allocation, and low risk. Furthermore, the Black-Litterman portfolios based on the introduced prediction model outperformed the mean-variance portfolio, equal-weighted portfolio, and the Black-Litterman portfolios based on the predictions of CNN-LSTM and LSTM. This remarkable performance could be attributed to each constituting model used in the hybrid model and portfolio formation strategy.",2021
Investment factor timing: Harvesting the low-risk anomaly using artificial neural networks,"We perform investment factor timing based on risk forecasts exploiting the low-risk anomaly. Among various risk measures, we find downside deviation most suited for this task. We apply Long Short Term Memory Artificial Neural Networks (LSTM ANNs) to model the relationship between macro-economic as well as financial market data and the downside deviation of factors. The LSTM ANNs allow for complex, non-linear long-term dependencies. We use LSTM-based forecasts to select high-and low-risk factors in setting up an investment strategy. The strategy succeeds in differentiating positive from negative yielding factor investments, and an accordingly constructed investment strategy outperforms every factor individually as well as LASSO and Multilayer Perceptron neural network benchmark models.",2022
A maintenance hemodialysis mortality prediction model based on anomaly detection using longitudinal hemodialysis data,"Background: Most end-stage renal disease patients rely on hemodialysis (HD) to maintain their life, and they face a serious financial burden and high risk of mortality. Due to the current situation of the health care system in China, a large number of patients on HD are lost to follow-up, making the identification of patients with high mortality risks an intractable problem. Objective: This paper aims to propose a maintenance HD mortality prediction approach using longitudinal HD data under the situation of data imbalance caused by follow-up losses. Methods: A long short-term memory autoencoder (LSTM AE) based model is proposed to capture the physical condition changes of HD patients and distinguish between surviving and nonsurviving patients. The approach adopts anomaly detection theory, using only the surviving samples in the model training and identifying dead samples based on autoencoder reconstruction errors. The data are from a Chinese hospital electronic health record system between July 30, 2007, and August 25, 2016, and 36/72/108 continuous HD sessions were used to predict mortality within prediction windows of 90/180/365 days. Furthermore, the model performance is compared to that of logistic regression, support vector machine, random forest, LSTM classifier, isolation forest, and stacked autoencoder models. Results: Data for 1200 patients (survival: 1055, death: 145) were used to predict mortality during the next 90 days using 36 continuous HD sessions. The area under the PR curve for the LSTM AE was 0.57, the Recallmacro was 0.86, and the F1-scoremacro was 0.87, outperforming the other models. Upon varying the observation window or prediction window length, LSTM AE continued to outperform the other models. According to the variable importance analysis, the dialysis session length was the feature that contributed the most to the prediction model. Conclusions: The proposed approach was able to detect patients on maintenance HD with high mortality risk from an imbalanced dataset using anomaly detection theory and leveraging longitudinal HD data.",2021
Predicting the Direction of US Stock Prices Using Effective Transfer Entropy and Machine Learning Techniques,"This study aims to predict the direction of US stock prices by integrating time-varying effective transfer entropy (ETE) and various machine learning algorithms. At first, we explore that the ETE based on 3 and 6 months moving windows can be regarded as the market explanatory variable by analyzing the association between the financial crises and Granger-causal relationships among the stocks. Then, we discover that the prediction performance on the stock price direction can be improved when the ETE driven variable is integrated as a new feature in the logistic regression, multilayer perceptron, random forest, XGBoost, and long short-term memory network. Meanwhile, we suggest utilizing the adjusted accuracy derived from the risk-adjusted return in finance as a prediction performance measure. Lastly, we confirm that the multilayer perceptron and long short-term memory network are more suitable for stock price prediction. This study is the first attempt to predict the stock price direction using ETE, which can be conveniently applied to the practical field.",2020
Design of an IoT-based Flood Early Detection System using Machine Learning,"Floods are a complex phenomenon that is difficult to predict because of their non-linear and dynamic nature. Gauging stations that transmit measured data to the server are often placed in very harsh and far environments that make the risk of missing data so high. The purpose of this study is to develop a real-time reliable flood monitoring and detection system using deep learning. This paper proposed an Internet of Things (IoT) approach for utilizing LoRaWAN as a reliable, low power, wide area communication technology by considering the effect of radius and transmission rate on packet loss. Besides, we evaluate an artificial neural network (ANN), Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU) neural network models for flood forecasting. The data from 2013 to 2019 were collected from four gauging stations at Brandywine-Christina watershed, Pennsylvania. Our results show that the deep learning models are more accurate than the physical and statistical models. These results can help to provide and implement flood detection systems that would be able to predict floods at rescue time and reduce financial, human, and infrastructural damage.",2021
RETRACTED: Construction and Simulation of the Enterprise Financial Risk Diagnosis Model by Using Dropout and BN to Improve LSTM (Retracted Article),"In view of the financial risks faced by listed enterprises, how to accurately predict the risks is an important work. However, the traditional LSTM financial diagnosis model has the disadvantage of low accuracy; the specific reason is that the LSTM model has the problems of overfitting and gradient disappearance in risk diagnosis. Therefore, Dropout is adopted to solve the overfitting problem in the process of premodel prediction, and the BN algorithm is used to solve the gradient disappearance problem in the process of iteration. In order to verify the feasibility of above improvements, the financial data of China's A-share listed enterprises from 2017 to 2020 are taken as samples to analyze the financial data of listed enterprises through single-step dimension and multistep dimension. The experimental results show that under the analysis of two dimensions, the financial prediction accuracy of the improved LSTM for T-2 similar to T-3 years can reach 83.96% and 91.19%, respectively, which indicates that through the above improvements, the model can be improved and has certain reference value.",2022
Financial portfolio optimization with online deep reinforcement learning and restricted stacked autoencoder-DeepBreath,"The process of continuously reallocating funds into financial assets, aiming to increase the expected return of investment and minimizing the risk, is known as portfolio management. In this paper, a portfolio management framework is developed based on a deep reinforcement learning framework called DeepBreath. The DeepBreath methodology combines a restricted stacked autoencoder and a convolutional neural network (CNN) into an integrated framework. The restricted stacked autoencoder is employed in order to conduct dimensionality reduction and features selection, thus ensuring that only the most informative abstract features are retained. The CNN is used to learn and enforce the investment policy which consists of reallocating the various assets in order to increase the expected return on investment. The framework consists of both offline and online learning strategies: the former is required to train the CNN while the latter handles concept drifts i.e. a change in the data distribution resulting from unforeseen circumstances. These are based on passive concept drift detection and online stochastic batching. Settlement risk may occur as a result of a delay in between the acquisition of an asset and its payment failing to deliver the terms of a contract. In order to tackle this challenging issue, a blockchain is employed. Finally, the performance of the DeepBreath framework is tested with four test sets over three distinct investment periods. The results show that the return of investment achieved by our approach outperforms current expert investment strategies while minimizing the market risk. Crown Copyright (C) 2020 Published by Elsevier Ltd.",2020
UNLOCKING THE POWER OF VOICE FOR FINANCIAL RISK PREDICTION: A THEORY-DRIVEN DEEP LEARNING DESIGN APPROACH,"Unstructured multimedia data (text and audio) provides unprecedented opportunities to derive actionable decision-making in the financial industry, in areas such as portfolio and risk management. However, due to formidable methodological challenges, the promise of business value from unstructured multimedia data has not materialized. In this study, we use a design science approach to develop DeepVoice, a novel nonverbal predictive analysis system for financial risk prediction, in the setting of quarterly earnings conference calls. DeepVoice forecasts financial risk by leveraging not only what managers say (verbal linguistic cues) but also how managers say it (vocal cues) during the earnings conference calls. The design of DeepVoice addresses several challenges associated with the analysis of nonverbal communication. We also propose a two-stage deep learning model to effectively integrate managers' sequential vocal and verbal cues. Using a unique dataset of 6,047 earnings call samples (audio recordings and textual transcripts) of S&P 500 firms across four years, we show that DeepVoice yields remarkably lower risk forecast errors than that achieved by previous efforts. The improvement can also translate into nontrivial economic gains in options trading. The theoretical and practical implications of analyzing vocal cues are discussed.",2023
Research on Financial Risk Crisis Prediction of Listed Companies Based on IWOA-BP Neural Network,"To avoid the risk brought by the financial crisis, the Improved Whale Optimization Algorithm-Back Propagation neural network (IWOA-BP) financial crisis early warning model is proposed. This paper selects the data from financial statements of some of the listed Chinese manufacturing companies from 2015-2019 as the research sample. First, the financial data of enterprises are screened by principal component analysis, and the early warning model is constructed from the financial and nonfinancial factors of six indicators: solvency, operating capacity, profitability, development capacity, cash flow and risk level factors. Second, the Whale Optimization Algorithm is optimized by the chaos strategy, as well as by the dynamic weight and sine cosine algorithm. Finally, the improved Whale Algorithm is optimized for BP neural network parameters. In the simulation experiments, the performance of the improved whale optimization algorithm is substantially improved. In addition, in the empirical analysis, compared to the prediction model with other algorithms, the prediction model of this paper has better results in terms of prediction accuracy.",2022
A Financial Risk Early Warning of Listed Companies Based on PCA and BP Neural Network,"Financial risk, as one of the most influential and destructive risks in business, will make enterprises unable to escape the fate of bankruptcy if not warned and prevented in time. In the paper, we conducted research on the financial risk early warning of listed companies. A total of 250 companies were randomly selected from the Chinese A-share market from 2019 to 2021. By building the 26 financial indicators of listed companies and constructing the PCA-BP neural network, we compared the financial risk early warning effects among PCA-BPNN, SVM, and Logistic. It is found that the financial data processed by PCA can better adapt to the financial risk early warning model. The PCA-BPNN model improved the prediction accuracy of the financial risk early warning, which has strong generalization ability for the prediction of financial risk. Research findings have certain reference significance for precise judgment on the financial risk of companies.",2022
A novel prediction model based on long short-term memory optimised by dynamic evolutionary glowworm swarm optimisation for money laundering risk,"The accurate prediction of money laundering risk is conducive to the risk prevention, and its task implies the characteristics of time series. Long short-term memory (LSTM) is widely developed in time series problems, but its parameters need to be optimised for delivering good predictive capacity. In this work, a novel bio-inspired algorithm, named dynamic evolutionary glowworm swarm optimisation (DEGSO), is designed. DEGSO employs adaptive step-size strategy, dynamic evolutionary mechanism, and directional mutation mechanism for improving the search performance. The money laundering risk is identified via a combination of DEGSO and LSTM (DEGSO-LSTM). DEGSO is wielded to optimise the main parameters of LSTM. Numerical results on four test functions indicate that DEGSO delivers better performance. Performance test results demonstrate that DEGSO-LSTM performs better than other state-of-the-art approaches. DEGSO-LSTM also attains satisfactory results in money laundering risk prediction, and its potential as a solution to financial fraud risk prediction.",2022
FactorVQVAE: Discrete latent factor model via Vector Quantized Variational Autoencoder,"This study introduces FactorVQVAE, the first integration of the Vector Quantized Variational Autoencoder (VQVAE) into factor modeling, providing a novel framework for predicting cross-sectional stock returns and constructing systematic investment portfolios. The model employs a two-stage architecture to improve the extraction and utilization of latent financial factors. In the first stage, an encoder-decoder-quantizer compresses high-dimensional input data into discrete latent factors through vector quantization, addressing posterior collapse and ensuring distinct representations. In the second stage, an autoregressive Transformer captures sequential dependencies among these latent factors, enabling precise return predictions. Empirical results in the CSI300 and S&P500 markets demonstrate FactorVQVAE's superior performance. The model achieves the best Rank IC and Rank ICIR scores, surpassing the state-of-the-art latent factor models in varying market conditions. In portfolio evaluations, FactorVQVAE consistently excels in both Top-k Drop-n and Long-Short strategies, translating predictive accuracy into robust investment performance. In particular, it delivers the highest risk-adjusted returns, highlighting its ability to balance returns and risks effectively. These findings position FactorVQVAE as a significant advancement in integrating modern deep learning methodologies with financial factor modeling. Its adaptability, robustness, and exceptional performance in portfolio investment establish it as a promising tool for systematic investing and financial analytics.",2025
A Fast-Warning Method of Financial Risk Behavior Based on BP Neural Network,"With the speedy development of economy, there are many issues in business enterprise finance, and organization finance is going through large risks. With more and more complicated market environment, the uncertainty danger of business enterprise operation intensifies, and economic crises happen frequently. The monetary disaster of a company regularly shows that there can also be a complete crisis. Once the organization is deeply in economic crisis, it can also now not be capable to make certain the ordinary capital chain of the enterprise, and in serious cases, it may also have an effect on the sustainable operation of the agency or even make the employer bankrupt and liquidate. Therefore, we have to set up a best financial catastrophe early warning model to prevent and control the occurrence of economic disaster risk. BP neural network can, quite in shape nonlinear feature relationship, have true gaining knowledge of adaptability, excessive parallel computing and statistics processing ability. In view of the actual state of affairs of commercial enterprise, business enterprise and economic risk, the BP neural community algorithm is used to predict agency financial risk and a hazard prediction model in particular primarily based on BP neural community is established. The simulation consequences exhibit that the accuracy and correctness of economic hazard conduct early warning primarily based on BP neural network are 91.51% and 95.28%, respectively. It is proved that the fast-warning approach of economic threat that is conducted primarily based on BP neural network has excessively taken a look at the accuracy and robust cognizance ability.",2024
An Efficient Risk Data Learning with LSTM RNN,"The use of big risk data for risk management has evolved into a concern within financial services industry in recent years. Whether the quality of big risk data can be relied upon is to be ascertained till 2019. To facilitate the measurement and prediction of data quality, we propose an efficient approach to slide a piece of data from the big risk data and a model to train divergent Long Short-Term Memory (LSTM) Recurrent Neural Networks (RNNs) with various algorithms. The network is evaluated by the improvement in network run time, prediction accuracy and relevant error. This enables financial institutions to identify potential data risks instantly for earlier mitigation soon.",2019
BP artificial neural network modeling of early-warning on financial derivatives' risk,"This paper addresses the development of an early-warning model for the risk of financial derivatives' (FD). The risks of derivatives are so complicated and the speed of spread is so rapid, that understanding the exact risk of FD by disclosure is needed. An early-warming model for derivatives is designed. After being trained and learning 342 times, the results indicate that early-warning of the risk of derivatives based on back propagation artificial neural network (BP-ANN) can be achieved.",2006
The Evaluation Study of Supply Chain Financial Risk Based on the BP Neural Network,"In recent years, the supply chain financial has become the focus of attention of the many financial institutions, because the supply chain financing model is to make full use of the supply chain and the characteristics of small and medium-sized enterprise designed. It is not only the effective way of small and medium-sized enterprises in China to solve the difficulty of financing, but also is an effective way of the Commercial Banks expand financial services [1]. This paper firstly constructed the financial credit risk evaluation index system of small and medium-sized enterprise based on supply chain, through the BP neural network model analyze credit risk of small and medium-sized enterprise, then predicted their financing credit level, to provide the basis for Commercial Banks for credit.",2013
A financial risk identification model based on artificial intelligence,"Financial management issues affect companies, and there have been many articles describing examples of companies that have suffered due to the lack of effective and efficient financial management. Studies on financial risk detection is important for companies to detect possible risks as soon as possible and find out corresponding measures, which is also of great significance for capital market and economic development. This study proposes a financial risk warning model based on the Convolutional Neural Network (CNN), which is a classical artificial intelligent model. We first conduct a Principal Component Analysis method to realize the financial data pre-processing to tackle the data noise issue. Then a lightweight CNN network is constructed to detect the hidden financial risks of companies. Finally, the proposed model outperforms other machine learning models according to experiment results.",2024
Research on Decision-Making of Complex Venture Capital Based on Financial Big Data Platform,"The prediction of stock premium has always been a hot issue. By predicting stock premiums to provide a way for companies to respond to financial risk investments, companies can avoid investment failures. In this paper, under the financial big data platform, bootstrap resampling technology and long short-term memory (LSTM) are used to predict the value of the stock premium within 20 months. First, using the theme crawler, jsoup page parsing, Solr search, and Hadoop architecture to build a platform for financial big data. Secondly, based on the block bootstrap resampling technology, the existing data information is expanded to make full use of the existing data information. Then, based on the LSTM network, the stock premium in 20 months is predicted and compared with the values predicted by support vector machine regression (SVR), and the SSE and R-square average indicators are calculated, respectively. The calculation results show that the SSE value of LSTM is lower than SVR, and the R-square value of LSTM is higher than SVR, which means that the effect of LSTM prediction is better than SVR. Finally, based on the forecast results and evaluation indicators of the stock premium, we provide countermeasures for the company's financial risk investment.",2018
Systemic Financial Risk Forecasting with Decomposition-Clustering-Ensemble Learning Approach: Evidence from China,"Establishing a scientifically effective systemic financial risk early warning model is of great significance for prudently mitigating systemic financial risks and enhancing the efficiency of financial supervision. Based on the measurement of systemic financial risk and the network sentiment index of 47 financial institutions, this study adopted the decomposition-reconstruction-integration approach, utilizing techniques such as extreme-point symmetric empirical mode decomposition (ESMD), empirical mode decomposition (EMD), variational mode decomposition (VMD), hierarchical clustering, fast independent component analysis (FastICA), attention mechanism, bidirectional long short-term memory neural network (BiLSTM), support vector regression (SVR), and their combination, to construct a systemic financial risk prediction model. The empirical results demonstrate that decomposing and reconstructing relevant indicators before predicting systemic financial risks can enhance prediction accuracy. Among the proposed models, the ESMD-HFastICA-BiLSTM-Attention model exhibits superior performance in systemic financial risk early warning.",2024
Unidirectional and bidirectional LSTM models for edge weight predictions in dynamic cross-market equity networks,"Predicting financial networks has important implications in finance. However, less research attention has been given in this direction. This study aims to predict cross market linkage strengths in financial networks using dynamic edge weight prediction. The study builds edge weight prediction models using deep learning based unidirectional and bidirectional long short-term memory (LSTM and BiLSTM) approaches. The models are built on temporally variant equity cross market networks in Asia. A rolling window approach is used to generate temporally synchronous observations of edge weight structures and subsequent networks. The models are trained with a series of historical network structure information. Tuning of hyperparameters was performed to obtain the optimized models. The models were validated using nested cross validation methods. The applicability of the optimized models was assessed for different scenarios, and promising results were found for edge weight pre-dictions on both unfiltered and filtered structures. The study also shows that the predictive performance of the BiLSTM model is the same across correlated (positively weighted) and anti-correlated (negatively weighted) edges. However, for LSTM the same does not hold true. The results also demonstrate that the proposed models predict edge weights better during normal conditions than in the crisis period. The proposed models are benchmarked against ARIMA and RNN. To our knowledge, this is the first attempt to build network prediction models for cross market equity networks. The findings can have key implications such as managing international portfolio diversifications and controlling systemic risk transmissions.",2022
Research on Financial Risk Evaluation of Railway Logistics Based on BP Neural Network Model,"This paper analyzes the risk factors of developing logistics finance business in railway enterprises, identifies the risks from two aspects of external risk and internal risk, and constructs the evaluation index system of railway logistics financial risk. Based on the analysis of BP neural network structure, the training and testing of the sampling samples are carried out by using the neural network, and the risk grade of each influencing factor is obtained, which provides a basis for judging the risk prevention and control of railway logistics finance.",2018
Risk Analysis of the Chinese Financial Market with the Application of a Novel Hybrid Volatility Prediction Model,"This paper endeavors to enhance the prediction of volatility in financial markets by developing a novel hybrid model that integrates generalized autoregressive conditional heteroskedasticity (GARCH) models and long short-term memory (LSTM) neural networks. Using high-frequency data, we first estimate realized volatility as a robust measure of volatility. We then feed the outputs of multiple GARCH models into an LSTM network, creating a hybrid model that leverages the strengths of both approaches. The predicted volatility from the hybrid model is used to generate trading strategy signals, which are subsequently used to build an investment strategy. Empirical analysis using the China Securities Index 300 (CSI300) dataset demonstrates that the hybrid model significantly improves value-at-risk (VaR) prediction performance compared to traditional GARCH models. This study's findings have broad implications for risk management in financial markets, suggesting that hybrid models incorporating mathematical models and economic mechanisms can enhance derivative pricing, portfolio risk management, hedging transactions, and systemic risk early-warning systems.",2023
Improved Recurrent Neural Networks (RNN) based Intelligent Fund Transaction Model,"Fund correlation analysis can guide investors' investment and wealth management, avoiding the selection of highly relevant funds in the investment process, which can make the risk sharing among funds. There is a strong dependence between the features of the fund data and a long-term dependence between the output of different time steps, which makes it difficult to obtain good performance in the fund data in the data analysis model used in the traditional intelligent investment system. This has brought difficulties to fund correlation analysis. In order to solve the above problems, this paper uses an encoder-decoder model combined with the attention mechanism-Improved RNN model. The Encoder-decoder model has made great strides in the application of financial time series analysis. And the attention mechanism can select specific feature inputs and previous time step outputs, both of which are highly correlated with the current output, making system predictions more efficient. This paper applies this model to the historical data set containing multiple public funds. The results show that the fund intelligent investment system proposed in this paper performs hest.",2019
Rural micro-credit model design and credit risk assessment via improved LSTM algorithm,"Rural microcredit plays an important role in promoting rural economic development and increasing farmers' income. However, traditional credit risk assessment models may have insufficient adaptability in rural areas. This study is based on the improved Long Short Term Memory (LSTM) algorithm using self organizing method, aiming to design an optimized evaluation model for rural microcredit risk. The improved LSTM algorithm can better capture the long-term dependence between the borrower's historical behavior and risk factors with its advantages in sequential data modeling. The experimental results show that the rural microcredit risk assessment model based on the self organizing LSTM algorithm has higher accuracy and stability compared to traditional models, and can effectively control credit default risk, providing more comprehensive risk management support for financial institutions. In addition, the model also has real-time monitoring and warning functions, which helps financial institutions adjust their decisions in a timely manner and reduce credit losses. The practical application of this study is expected to promote the stable development of rural economy and the advancement of financial technology. However, future work needs to further validate the practical application effectiveness and interpretability of the model, taking into account the special circumstances of different rural areas, in order to achieve sustainable application of the model in the rural microcredit market.",2023
Predicting bankruptcy of firms using earnings call data and transfer learning,"Business collapse is a common event in economies, small and big alike. A firm's health is crucial to its stakeholders like creditors, investors, partners, etc. and prediction of the upcoming financial crisis is significantly important to devise appropriate strategies to avoid business collapses. Bankruptcy prediction has been regarded as a critical topic in the world of accounting and finance. Methodologies and strategies have been investigated in the research domain for predicting company bankruptcy more promptly and accurately. Conventionally, predicting the financial risk and bankruptcy has been solely achieved using the historic financial data. CEOs also communicate verbally via press releases and voice characteristics, such as emotion and tone may reflect a company's success, according to anecdotal evidence. Companies' publicly available earning calls data is one of the main sources of information to understand how businesses are doing and what are expectations for the next quarters. An earnings call is a conference call between the management of a company and the media. During the call, management offers an overview of recent performance and provides a guide for the next quarter's expectations. The earning calls summary provided by the management can extract CEO's emotions using sentiment analysis. This article investigates the prediction of firms' health in terms of bankruptcy and non-bankruptcy based on emotions extracted from earning calls and proposes a deep learning model in this regard. Features extracted from long short-term memory (LSTM) network are used to train machine learning models. Results show that the models provide results with a high score of 0.93, each for accuracy and F1 when trained on LSTM extracted feature from synthetic minority oversampling technique (SMOTE) balanced data. LSTM features provide better performance than traditional bag of words and TF-IDF features.",2023
Deep LSTM and LSTM-Attention Q-learning based reinforcement learning in oil and gas sector prediction,"Accurate prediction of stock market trends and movements holds great significance in the financial industry as it enables investors, traders, and decision-makers to make informed choices and optimize their investment strategies. In the context of the oil and gas sector, where stock prices are influenced by complex market dynamics and various external factors, reliable predictions are essential for effective decision-making and risk management. This study proposes Deep Long Short-Term Memory Q-Learning (DLQL) and Deep Long Short-Term Memory Attention Q-Learning (DLAQL) models and state-of-the-art Long Short-Term Memory (LSTM) for predicting stock prices in the oil and gas sector. The study utilizes historical stock price data of Cenovus Energy Inc. (CVE), MPLX LP (MPLX), Cheniere Energy Inc. (LNG), and Suncor Energy Inc. (SU) to create and validate these models. The research employs the Markov Decision Process (MDP) framework, a widely-used reinforcement learning technique, to train the deep LSTM Q-Learning and deep LSTM Attention Q-Learning models. This framework allows the models to learn optimal policies based on historical data, enabling them to make accurate predictions and adapt to changing market conditions. The findings of this study reveal that the proposed DLQL and DLAQL perform excellently well in terms of prediction accuracy in the oil and gas sector. The inclusion of attention mechanisms in the DLAQL model further enhances its performance by allowing it to focus on important features and capture relevant information. The results of this research underscore the potential of deep LSTM QLearning and deep LSTM Attention Q-Learning models in stock market prediction within the oil and gas sector. The application of these models can lead to improved decision-making, enhanced risk management, and increased profitability for market participants. Further exploration and refinement of these models, along with the incorporation of additional variables and market indicators, can contribute to the development of more sophisticated prediction models in the future. Overall, this study contributes to the advancement of stock market prediction techniques, specifically in the oil and gas sector, by introducing and evaluating the efficacy of deep LSTM Q-Learning and deep LSTM Attention Q-Learning models. The findings highlight the importance of accurate stock market predictions and demonstrate the potential benefits of leveraging these models within the MDP framework to support decision-making and risk management in the dynamic and competitive oil and gas industry.",2024
A multi-factor two-stage deep integration model for stock price prediction based on intelligent optimization and feature clustering,"Stock market fluctuations have a great impact on various economic and financial activities worldwide. Accurate prediction of stock prices plays a decisive role in constructing the investment decision or risk hedging. However, accurate prediction of the stock price is a thorny task, because stock price fluctuations are non-linear and chaotic. In order to promote the accuracy of stock price prediction, a multi-factor two-stage deep learning integrated prediction system based on intelligent optimization and feature clustering is proposed to predict stock price in this paper. Firstly, a multi-factor analysis is carried out to select a variety of factors that have an impact on the stock price, and adopt the extreme gradient boosting (XGBoost) algorithm to eliminate factors with low correlation. The second step is to apply the idea of classification prediction to cluster the filtered feature set. Further, multiple parameters of long short-term memory (LSTM) are optimized by genetic algorithm (GA), and multiple GA-LSTM models are obtained by training each clustering result. Finally, the results of each class predicted by the GA-LSTM model are nonlinearly integrated to acquire the final prediction model, which is applied to the prediction of the test set. The experimental results indicate that the performance of the proposed model outperforms other baseline models in China's two stock markets and the New York stock exchange. At the same time, these results fully prove that the prediction model proposed by us possesses more reliable and better predictive ability.",2023
Novel forecasting of white maize futures volatility: a hybrid GARCH-based bi-directional LSTM model,"Price volatility in grain markets, especially for maize, has substantial socio-economic impacts, particularly in low-income regions where food security remains a critical concern. Accurate forecasting of grain price volatility is therefore crucial in safeguarding the financial interests of commodity traders, as well as shielding consumers from detrimental effects of inflationary food prices. This study proposes a hybrid Bi-directional Long Short-Term Memory (BLSTM) model, integrated with generalised autoregressive conditional heteroscedasticity (GARCH)-type methods, to forecast white maize futures volatility in South Africa. By comparing the forecasting accuracy of the hybrid BLSTM model against several benchmarks, including standard LSTM and BLSTM models, our results demonstrate notable improvements in prediction accuracy, as shown through heteroscedasticity-adjusted performance metrics. The key contribution of this research is its enhancement of volatility forecasting by combining advanced machine learning with traditional econometric approaches, bridging a gap in predictive accuracy for commodity price dynamics. Additionally, this study supports the United Nations Sustainable Development Goals (SDGs), particularly Zero Hunger and Responsible Consumption and Production, by improving food price stability and risk management in agriculture. This approach exemplifies the evolving role of data science in financial analysis, offering market participants an effective tool to manage price risk and improve food security.Impact StatementThis study introduces a novel hybrid forecasting model that integrates GARCH-type econometric techniques with Bi-directional Long Short-Term Memory (BLSTM) neural networks to predict the realised volatility of white maize futures. As white maize is a staple food, accurate volatility forecasting directly contributes to improved food security and price stability. The model significantly outperforms traditional approaches and standard deep learning models across multiple forecast horizons, offering a powerful risk management tool for farmers, traders, and policymakers. By enhancing the accuracy of agricultural price forecasts, this research supports the United Nations Sustainable Development Goals (SDGs), particularly Zero Hunger (SDG 2) and Responsible Consumption and Production (SDG 12), while also demonstrating the value of advanced data science methods in addressing real-world socio-economic challenges.",2025
RETRACTED: Application of artificial intelligence technology in financial data inspection and manufacturing bond default prediction in small and medium-sized enterprises (SMEs),"This work aims to solve the problem that the traditional deep learning model has low prediction accuracy and is not suitable for enterprise default risk prediction. Firstly, it expounds the definition and influencing factors of corporate bond default, including macroeconomic factors, industry factors, policy factors, and financial factors. Secondly, the fault prediction model for manufacturing corporate bonds is realized based on Convolutional Neural Network. Finally, 20 manufacturing enterprises in the current financial market are selected. By establishing the evaluation index system and designing simulation experiments, their financial data is tested and analyzed to verify the model's effectiveness. The experimental results reveal that the main differences between the experimental group (defaulting company) and the control group (non-defaulting company) lie in the internal financial indicators and the self-characteristics of the company. The overall capital flow rate of the defaulting company is lower than that of the non- defaulting company, and the average total operating interest rate and return on net assets are 15.16% and 11.6%, respectively, lower than 26.3% and 18.9% in the control group. Additionally, the prediction accuracy of the Convolutional Neural Network model for defaulting companies is 80%; the average prediction error is 1.87, which is 65.4% lower than that of Random Forest model. To sum up, the Convolutional Neural Network model shows better performance in corporate default prediction. This work effectively reduces the default risk of China's bond enterprises and provides important technical support to ensure the healthy development of the bond market.",2022
The model and application of the financial risk evaluation in power enterprises based on improved BP neural network algorithm,"At present, the traditional or commonly used methods to measure the financial risk in power enterprises is limited and inadequate. To evaluate the financial risk of the power enterprises scientifically and accurately, this paper proposes the improved BP neural network model which imports the adjustable activation function and the Levenberg-Marquardt optimization algorithm for the financial risk evaluation. The improved model not only can simulate the expert in evaluating the financial risk and avoiding the subjective mistakes in the evaluation process, but also enhance the learning accuracy and the algorithm convergence speed greatly. The financial risk evaluation of 12 power enterprises in National Power Company shows that the improved model is stable and reliable, and this method to forecast the financial risk of the power enterprises is feasible.",2007
Forecasting realized volatility through financial turbulence and neural networks,"This paper introduces and examines a novel realized volatility forecasting model that makes use of Long Short-Term Memory (LSTM) neural networks and the risk metric financial turbulence (FT). The proposed model is compared to five alternative models, of which two incorporate LSTM neural networks and the remaining three include GARCH(1,1), EGARCH(1,1), and HAR models. The results of this paper demonstrate that the proposed model yields statistically significantly more accurate and robust forecasts than all other studied models when applied to stocks with middle-to-high volatility. Yet, considering low-volatility stocks, it can only be confidently affirmed that the proposed model yields statistically significantly more robust forecasts relative to all other models considered.",2023
Enhancing stock market predictions via hybrid external trend and internal components analysis and long short term memory model,"When it comes to financial decision-making, stock market predictability is extremely important since it offers valuable information that may guide investment strategies, risk management, and portfolio allocation overall. Traditional methods often fail to accurately predict stock prices due to their complexity and inability to handle non-linear and non-stationary patterns in market data. To address these issues, this study introduces an innovative model that combines the External Trend and Internal Components Analysis decomposition method (ETICA) with the Long Short-Term Memory (LSTM) model, aiming to enhance stock market predictions for S&P 500, NASDAQ, Dow Jones, SSE and SZSE indices. Through rigorous testing across various training data proportions and epoch settings, our findings reveal that the proposed hybrid model outperforms the single LSTM model, delivering significantly lower Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) values. This enhanced precision reduces prediction errors, underscoring the model's robustness and reliability. The superior performance of the ETICA-LSTM model highlights its potential as a powerful financial forecasting tool, promising to transform investment strategies, optimize risk management, and enhance portfolio performance.",2024
Deep Learning in Finance: A Survey of Applications and Techniques,"Machine learning (ML) has transformed the financial industry by enabling advanced applications such as credit scoring, fraud detection, and market forecasting. At the core of this transformation is deep learning (DL), a subset of ML that is robust in processing and analyzing complex and large datasets. This paper provides a comprehensive overview of key deep learning models, including Convolutional Neural Networks (CNNs), Long Short-Term Memory networks (LSTMs), Deep Belief Networks (DBNs), Transformers, Generative Adversarial Networks (GANs), and Deep Reinforcement Learning (Deep RL). Beyond summarizing their mathematical foundations and learning processes, this study offers new insights into how these models are applied in real-world financial contexts, highlighting their specific advantages and limitations in tasks such as algorithmic trading, risk management, and portfolio optimization. It also examines recent advances and emerging trends in the financial industry alongside critical challenges such as data quality, model interpretability, and computational complexity. These insights can guide future research directions toward developing more efficient, robust, and explainable financial models that address the evolving needs of the financial sector.",2024
The model and application of the financial risk forecast in electric power enterprises based on improved BP neural network algorithm,"For the particularity of electric power enterprises themselves, the commonly methods used to forecast their financial risk is limited and inadequate. To forecast the financial risk of the power enterprises scientifically and accurately, this paper proposes the improved BP neural network imports the adjustable activation function and Levenberg-Marquardt optimization algorithm. The improved model not only simulate the expert in forecasting the financial risk and avoiding the subjective mistakes in the evaluation process, but also enhance the learning accuracy and the algorithm convergence speed greatly. The financial risk forecast of 12 power enterprises in National Power Company shows that the improved model is stable and reliable, and this method to forecast the financial risk of the power enterprises is feasible.",2007
"Sustainability, Accuracy, Fairness, and Explainability (SAFE) Machine Learning in Quantitative Trading","The paper investigates the application of advanced machine learning (ML) methodologies, with a particular emphasis on state-of-the-art deep learning models, to predict financial market dynamics and maximize profitability through algorithmic trading strategies. The study compares the predictive capabilities and behavioral characteristics of traditional machine learning approaches, such as logistic regression and support vector machines, with those of highly sophisticated deep learning architectures, including Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM) networks, and Gated Recurrent Units (GRUs). The findings underscore the fundamental distinctions between these methodologies, with deeply trained models exhibiting markedly different predictive behaviors and performance, particularly in capturing complex temporal patterns within financial data. A cornerstone of the paper is the introduction and rigorous analysis of a framework to evaluate models, by means of the SAFE framework (Sustainability, Accuracy, Fairness, and Explainability). The framework is designed to address the opacity of black-box ML models by systematically evaluating their behavior across a set of critical dimensions. It also demonstrates how models' predictive outputs align with the observed data, thereby reinforcing their reliability and robustness. The paper leverages historical stock price data from International Business Machines Corporation (IBM). The dataset is partitioned into a training phase during which the models are calibrated, and a validation phase, used to evaluate the predictive performance of the generated trading signals. The study addresses two primary machine learning tasks: regression and classification. Classical models are utilized for classification tasks, with their outputs directly interpreted as trading signals, while advanced deep learning models are employed for regression, with predictions of future stock prices further processed into actionable trading strategies. To evaluate the effectiveness of each strategy, rigorous backtesting is conducted, incorporating visual representations such as equity curves to assess profitability and key risk metrics like maximum drawdown for risk management. Supplementary performance indicators, including hit rates and the incidence of false positions, are analyzed alongside the equity curves to provide a holistic assessment of each model's performance. This comprehensive evaluation not only highlights the superiority of cutting-edge deep learning models in predicting financial market trends but also demonstrates the pivotal role of the SAFE framework in ensuring that machine learning models remain trustworthy, interpretable, and aligned with ethical considerations.",2025
Forecasting cryptocurrency prices using Recurrent Neural Network and Long Short-term Memory,"The rapid development of cryptocurrencies over the past decade is one of the most controversial and ambiguous innovations in the modern global economy. Numerous and unpredictable fluctuations in cryptocurrencies rates, as well as the lack of intelligent and proper management of transactions of this type of currency in most developing countries and users of this type of currency, has led to increased risk and distrust of these roses in investors. Capitalists and investors prefer to invest in programs which have the least risk, the most profit and the least time to achieve the main profit. Therefore, the issue of developing appropriate methods and models for predicting the price of cryptographic products is essential both for the scientific community and for financial analysts, investors and traders. In this research, a new deep learning model is used to predict the price of cryptocurrencies. The proposed model uses a Recurrent Neural Networks (RNN) algorithm based on Long Short-Term Memory (LSTM) method to predict the price. In the presented results of the simulation of the proposed method, factors such as the Root Mean Square Error (RMSE), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), R-Squared (R2) were compared with other similar methods. Finally, the superiority of the proposed method over other methods was proven.",2022
Systemic Risk Document Classification on Indonesian News Articles using Deep Learning and Active Learning,"Indonesian online news articles are growing fastly in this decade. One of the information is about economic news, including the information on financial systemic risk. In order to get information on financial systemic risk in real time, the task on systemic risk document classification should be done automatically. Here, we employ deep learning and active learning to classify systemic risk document automatically. We use 15 classes of financial systemic risk, such as defined before by Bank of Indonesia. The task is a multi-label classification, where a text document may contain more than 1 information of systemic risk. For the deep learning strategy, we've conducted several experiments of CNN, Bi-LSTM and Bi-GRU. We've also compared it with two steps of classification. In the experimental result, using 1752 documents as the training data and 228 documents as the testing data, the highest F1 score was achieved by using Bi-LSTM topology with one classification step and large common corpus as the resource for the word embedding. The highest F1 score was 45.37% for 15 classes with probability threshold defined as 0.15. In the two steps of classification, the first classification for 2 classes (contain risk information or not), the accuracy was 82.46%. To handle the limited data, we've conducted active learning to select the next candidate to be labeled as training data. In the experiment, for 420 new data with each iteration of 20 new data, the results showed that using active learning couldn't improve the performance.",2019
USD to INR Exchange Rate Prediction: A Deep Learning Approach for Forecasting Currency Exchange Rates Using Different Techniques of LSTM,"This research paper investigates the application of three different Long Short-Term Memory (LSTM) techniques, for prediction of USD to INR exchange rates. Historical exchange rate data is collected, pre-processed, and relevant features are extracted. The LSTM models, known for their ability to capture temporal dependencies, are implemented and evaluated using performance metrics such as MAE, RMSE, and R-2. The trained models are utilized to forecast the exchange rate for a few days ahead. The results showcase the predictive capabilities of the models and provide valuable insights for financial decision-making and risk management in the currency market. This study contributes to the advancement of knowledge, enhancing both understanding and forecasting accuracy in the domain of USD to INR exchange rate dynamics.",2024
Volatility forecasting with Hybrid-long short-term memory models: Evidence from the COVID-19 period,"Volatility forecasting, a central issue in financial risk modelling and management, has attracted increasing attention after several major financial market crises. In this article, we draw upon the literature on volatility forecasting and hybrid models to construct the Hybrid-long short-term memory (LSTM) models to forecast the intraday realized volatility in three major US stock indexes. We construct the hybrid models by combining one or multiple traditional time series models with the LSTM model, and incorporating either the estimated parameters, or the predicted volatility, or both from the statistical models as additional input values into the LSTM model. We perform the out-of-sample test of our Hybrid-LSTM models in volatility forecasting during the coronavirus disease 2019 (COVID-19) period. Empirical results show that the Hybrid-LSTM models can still significantly improve the volatility forecasting performance of the LSTM model during the COVID-19 period. By analysing how the construction methods may influence the forecasting performance of the Hybrid-LSTM models, we provide some suggestions on their design. Finally, we identify the optimal Hybrid-LSTM model for each stock index and compare its performance with the LSTM model on each day during our sample period. We find that the Hybrid-LSTM models' great capability of capturing market dynamics explains their good performance in forecasting.",2024
Population based Optimized and Condensed Fuzzy Deep Belief Network for Credit Card Fraudulent Detection,"In this information era, with the advancement in technology, there is a high risk due to financial fraud which is a continually increasing menace during online transactions. Credit card fraudulent identification is a toughest challenge because of two important issues, as the profile of the credit card user's behavior changes constantly and credit card datasets are skewed. The factors which greatly affects the credit card fraudulent transaction detection are primarily based on data sampling models, features involved in feature selection and detection approaches implied. To overwhelm these issues, instead of using certainty theory, this paper encapsulates with three different empowered models are deployed for intellectual way of fraudulent transaction detection. In this work uncertainty theory of intuitionistic fuzzy theorem to determine the significant features which will influence the detection process effectively. Maximized relevancy among dependent and independent features of credit card dataset are determined using grade of membership and non-membership information of each features. The intuitionistic fuzzy mutual information with the knowledge of entropy it selects the features with highest information score as significant feature subset. This proposed model devised Fuzzy Deep Belief Network enriched with Sea Turtle Foraging for credit card fraudulent detection (EFDBN-STFA). The fuzzy deep belief network greatly handles the complex pattern of credit card transactions with its deep knowledge and stacked restricted Boltzmann machine the pattern of dataset is analyzed. The weights assigned to the hidden nodes are fine-tuned by the sea turtle foraging using its fitness measure and thus it improves the detection accuracy of the FDBN. Simulation results proved the efficacy of EFDBN-STFA on two different credit card datasets with its gained ability of handling hesitation factor and optimization using metaheuristic approach, it achieves higher detection rate with reduced false alarms compared to other existing detection models.",2020
"Long-term financial predictions based on Feynman-Dirac path integrals, deep Bayesian networks and temporal generative adversarial networks","This paper presents a new deep learning framework, QuantumPath, for long-term stock price prediction, which is of great significance in portfolio management and risk mitigation, especially when the market becomes volatile due to unpredictable circumstances such as a pandemic. Our approach is based on stochastic equations, the Feynman-Dirac path integral, deep Bayesian networks, and temporal generative adversarial neural networks (t-GAN). The expected financial trajectory is evaluated with a Feynman-Dirac path integral. The latter involves summing all possible financial trajectories that could have been taken by the financial instrument. These trajectories are generated with a t-GAN. A probability is attributed to each point of each path. The probability is a function of the Lagrangian, which is derived from a stochastic equation describing the temporal evolution of the stock. The drift and the volatility at each point, which are required in order to evaluate the Lagrangian, are predicted with a deep Bayesian neural network. Given that the evolution of a stock's price is isomorphic to a time series, our temporal GAN consists of long short-term memory (LSTM) neural networks, which introduce a memory mechanism, and temporal convolutional neural networks (TCN), which ensure causality. Stock prices are predicted over periods of twenty and thirty days for nine stocks, eight of which are included in the S&P 500 index. Our experimental results clearly demonstrate the efficiency of our approach.",2022
Earthquake vulnerability assessment for the Indian subcontinent using the Long Short-Term Memory model (LSTM),"Earthquakes are one of the most destructive and unpredictable natural hazards with a long-term physical, psychological, and economic impact to the society. In the past century, more than 1100 destructive earthquakes occurred, and caused around 1.5 million deaths worldwide. Some recent studies have suggested that a future earthquake in the Himalayan region of magnitude range MW 7.5-8 can cause more than 0.2 million human lives and around 150 billion dollar financial loss. Deep learning methods in recent studies proved very useful in natural hazards forecasting and prediction modelling. Long Short-Term Memory (LSTM) model has been particularly popular in several natural hazard forecasting. In this research, for the first time, LSTM model is implemented with suitable Geospatial Information Systems (GIS) techniques to assess the earthquake vulnerability for whole of India. In India, most of the seismic vulnerability assessment available are at city level or state level using traditional techniques. Several factors such as land use, geology, geomorphology, fault distribution, transportation facility, population density were all used to develop the social, structural, and geotechnical vulnerability maps. The results show that the areas around Delhi, NE region of India, major parts of Gujrat, West Bengal plain exhibit high to very-high seismic vulnerability. This model achieved an accuracy of 87.8%, sensitivity (90%) and specificity (84.9%). The present analysis can be helpful towards prioritization of regions which are in higher need of risk reduction interventions. Also, based on this vulnerability index map, the risk metrics can be attenuated.",2021
Early Warning of Systemic Financial Risk of Local Government Implicit Debt Based on BP Neural Network Model,"In recent years, local governments have boosted their local economies by raising large amounts of debt. Even though the state further strictly controls local government debt, the hidden debt formed by the local government borrowing in disguised form can infect systemic financial risks, creating an urgent need to carry out risk warning based on local government hidden debt. The paper uses the macro indicators of local government implicit debt risk at the prefecture-level city level, and introduces the micro indicators of PPP projects, financing platform bank debt, and urban investment debt to establish a BP neural network model. We not only study the contagion effect of local government hidden debt on systemic financial risks, but also predict the systemic financial risks in 2019 and construct an early warning risk system based on the prefecture-level city data from 2015 to 2018. In addition, the early warning effect of local government implicit debt on systemic financial risk under different stress scenarios is investigated. The study found that the implicit debt risk of local governments, the scale of financing platform bank debt, the scale of PPP, and the scale of urban investment bonds have a significant impact on systemic financial risks. The neural network model constructed by introducing these four variables at the same time can better predict the level of systemic financial risk. The model can also accurately predict the changes in systemic financial risks under the stress test of the increase in hidden debt of different local governments, and has a good early warning effect.",2022
Readmission prediction using deep learning on electronic health records,"Unscheduled 30-day readmissions are a hallmark of Congestive Heart Failure (CHF) patients that pose significant health risks and escalate care cost. In order to reduce readmissions and curb the cost of care, it is important to initiate targeted intervention programs for patients at risk of readmission. This requires identifying high-risk patients at the time of discharge from hospital. Here, using real data from over 7500 CHF patients hospitalized between 2012 and 2016 in Sweden, we built and tested a deep learning framework to predict 30-day unscheduled readmission. We present a cost-sensitive formulation of Long Short-Term Memory (LSTM) neural network using expert features and contextual embedding of clinical concepts. This study targets key elements of an Electronic Health Record (EHR) driven prediction model in a single framework: using both expert and machine derived features, incorporating sequential patterns and addressing the class imbalance problem. We evaluate the contribution of each element towards prediction performance (ROC-AUC, Fl-measure) and costsavings. We show that the model with all key elements achieves higher discrimination ability (AUC: 0.77; Fl: 0.51; Cost: 22% of maximum possible savings) outperforming the reduced models in at least two evaluation metrics. Additionally, we present a simple financial analysis to estimate annual savings if targeted interventions are offered to high risk patients.",2019
Forecasting stock volatility and value-at-risk based on temporal convolutional networks,"In recent years, deep learning has attracted increasing popularity in modern financial fields. The volatility of financial asset returns as well as the Value-at-Risk (VaR) play a significant role in many applications such as risk management, investment portfolios and etc. Thus, it is extremely essential to accurately estimate volatility and VaR. Temporal convolutional networks (TCNs), a relatively new deep learning architecture for solving sequential modeling tasks, have demonstrated convincingly good performance in many applications. In this paper, we utilize TCNs to forecast stock volatility and VaR. To the best of our knowledge, this is the first attempt to address this task with TCNs. In the experiments conducted with both synthetic data and some real stock data, TCNs are compared with other twelve popular models which include nine conventional approaches (i.e., three GARCH-type models with each being considered three tail distributions) and three deep learning methods (i.e., LSTM, LSTM with attention mechanism and GRU). The Friedman test followed by the Nemenyi post-hoc test is also employed to analyze whether TCNs perform significantly better than the other methods across the real stock datasets. As for volatility modeling, experimental results show that TCNs outperforms all the other methods in terms of RMSE (root mean squared error) and MAE (mean absolute error). In the meantime, TCNs behave best in calculating VaR when evaluating their performance with several metrics. More importantly, the superiority of TCNs over GARCH-type methods are statistically significant. As a result, TCNs can be regarded as an important technique to forecast return volatility and the associated VaR.",2022
"A Comprehensive Analysis of Hypertension Disease Risk-Factors, Diagnostics, and Detections Using Deep Learning-Based Approaches","High blood pressure, often known as hypertension, is a common and possibly fatal disorder that affects a large section of the world's population. For complications to be avoided and the risk of cardiovascular diseases to be decreased, early detection and control of hypertension are essential. By examining numerous physiological and clinical data, deep learning models have shown the potential in assisting in the identification of hypertension. The aim of the paper is to explore the application of deep learning-based approaches to building an automated system for hypertension detection. A diverse dataset comprising blood pressure measurements, demographic information, medical history, and lifestyle factors is utilized. Different deep learning models, including Gated Recurrent Unit, Embedded GRU, Bidirectional GRU, Long Short-Term Memory, and their different versions are employed to build predictive models for hypertension detection along with stroke and heart-disease prediction. Pre-processing is done on the applied dataset, which has many different features for predicting hypertension, dealing with missing values, normalizing features, and dealing with class imbalance. Techniques for feature selection are used to determine which variables are most useful for predicting hypertension. The outcomes show that hypertension can be accurately detected using models that have been implemented. The best performance is shown by bidirectional GRU, which detects hypertension with an accuracy of 99.68% and an F1-score, precision, and recall of 0.99. While Embedded GRU produced the greatest results, such as 98.10% to predict heart disease, Bidirectional LSTM also yields the finest outcomes for stroke prediction with an accuracy of 98.85%. The used models perform better than conventional diagnostic methods and display encouraging outcomes. By integrating these models into healthcare systems, it may be likely to classify people at high risk for developing hypertension early and to support prompt therapies, which will improve patient outcomes and lower the financial burden on the healthcare system.",2024
Risk prediction in financial management of listed companies based on optimized BP neural network under digital economy,"In the era of Internet plus, the world economy is becoming more and more globalized and informationalized. China's enterprises are facing unprecedented opportunities for their operation and development. However, it is also facing the financial uncertainties brought about by the fluctuations of the general economic environment, and the company is facing increasing financial risks. The reason why most enterprises encounter a serious financial crisis or even close down in the later stage is that they do not pay full attention to the initial financial problems and do not take effective measures to deal with the crisis in time. Financial risk warning has become an important part of modern enterprise financial management. This paper mainly puts forward the optimized BP neural system as the financial early warning model and ensures its high prediction accuracy. In the research, the operation principle and related reasoning process of the model are described, its shortcomings are analyzed, and solutions are put forward. Through the financial risk analysis of listed companies from 2017 to 2020, we find that the correct rate of the prediction results of the financial distress of normal companies in the selected companies based on the optimized BPNN has reached more than 80%, which proves the effectiveness of the optimized BPNN.",2023
DGIC: A Distributed Graph Inference Computing Framework Suitable For Encoder-Decoder GNN,"*A graph is a structure that can express the relationship between objects. The emergence of GNN enables deep learning to be applied in the field of graphs. However, most GNNs are trained offline and cannot be directly used in real-time monitoring scenarios such as financial risk control. In addition, due to the large scale of graph data, a single machine often cannot meet actual needs, and there are bottlenecks such as throughput performance. Therefore, we propose a distributed graph inference computing framework, which can be applied to Encoder-Decoder GNN models. We complete the adaptation of the model by disassembling the graph data and using the extension storage and dynamic invocation mechanism to solve the model invocation problem. For inference performance, we implement dynamic graph construction through incremental composition and decouple the inference process to apply to different scenarios, so that GNNs conforming to the Encoder-Decoder style can be applied to the framework. A large number of experiments show that this method has good timeliness while improving the throughput upper limit, and can maintain the model effect of multi-tasking.",2022
Efficient multimodal learning for corporate credit risk prediction with an extended deep belief network,"Precise corporate credit risk (CCR) prediction empowers investors, banks and other financial institutions to build risk prevention and crisis evasion mechanisms. Currently, CCR prediction gradually trends towards integrating multi-source data for more accurate prediction, but the effective fusion of these data is still insufficient. For this purpose, this paper presents a novel method titled the multimodal extended deep belief network (MEDBN) for CCR prediction. First, a multimodal dataset comprising numerical, categorical, and textual data is constructed based on two public corporate credit rating datasets, with textual data sourced from 10-K/Q filings. Each modality is processed using specialized preprocessing techniques. Then, to effectively extract features from each modality while addressing the challenges of multimodal fusion and joint representation learning, the DBN is extended by incorporating advanced deep learning techniques, including residual networks (ResNet), embedding layers, and bidirectional encoders (BERT). Finally, MEDBN undergoes two-stage training consisting of unsupervised pretraining followed by supervised fine-tuning, enabling sufficient learning of joint representations to enhance model performance. Extensive experimental results indicate that MEDBN consistently outperforms benchmark models across most key metrics, with particularly notable robustness on smaller datasets. These findings imply that MEDBN can effectively fuse and utilize multimodal data to achieve more reliable predictions. Additionally, this study demonstrates how the textual content influences performance, providing interpretable insights to support the decision-making process.",2025
The Data Analysis of Enterprise Operational Risk Prediction Under Machine Learning: Innovations and Improvements in Corporate Law Risk Management Strategies,"In the digital age, the financial sector faces increasingly severe risk management challenges. Traditional methods often rely on historical data and statistical models, which struggle to cope with the high volatility of the market. These methods exhibit poor adaptability in rapidly changing financial markets and often fail to meet demands in terms of accuracy and reliability. To address these issues, this study proposes a law risk prediction model based on deep learning-the WBIF model. This model integrates Bidirectional Long Short-Term Memory (BiLSTM) and Fully Convolutional Networks (FCN) and employs the Whale Optimization Algorithm (WOA) for parameter optimization. Experimental results show that compared to traditional models, the WBIF model reduces the Mean Absolute Error (MAE) by 51.73% on the UCI machine learning library dataset and improves accuracy by 12% on the Kaggle credit card fraud detection dataset.",2024
Fourier transform based LSTM stock prediction model under oil shocks,"This paper analyses the impact of various oil shocks on the stock volatility prediction by using a Fourier transform-based Long Short-Term Memory (LSTM) model. Oil shocks are decomposed into five components following individual oil price change indicators. By employing a daily dataset involving S&P 500 stock index and WTI oil futures contract, our results show that different oil shocks exert varied impacts on the dynamics of stock price volatility by using gradient descent. Having exploited the role of oil shocks, we further find that the Fourier transform-based LSTM technique improves forecasting accuracy of the stock volatility dynamics from both statistical and economic perspectives. Additional analyses reassure the robustness of our findings. Clear comprehension of the future stock market dynamics possesses important implications for sensible financial risk management.",2022
RLSTM: A New Framework of Stock Prediction by Using Random Noise for Overfitting Prevention,"An accurate prediction of stock market index is important for investors to reduce financial risk. Although quite a number of deep learning methods have been developed for the stock prediction, some fundamental problems, such as weak generalization ability and overfitting in training, need to be solved. In this paper, a new deep learning model named Random Long Short-Term Memory (RLSTM) is proposed to get a better predicting result. RLSTM includes prediction module, prevention module, and three full connection layers. Input of the prediction module is a stock or an index which needs to be predicted. That of the prevention module is a random number series. With the index of Shanghai Securities Composite Index (SSEC) and Standard & Poor's 500 (S&P500), simulations show that the proposed RLSTM can mitigate the overfitting and outperform others in accuracy of prediction.",2021
Fluctuations and Forecasting of Carbon Price Based on A Hybrid Ensemble Learning GARCH-LSTM-Based Approach: A Case of Five Carbon Trading Markets in China,"Carbon trading risk management and policy making require accurate forecasting of carbon trading prices. Based on the sample of China's carbon emission trading pilot market, this paper firstly uses the Augmented Dickey-Fuller test and Autoregressive conditional heteroscedasticity model to test the stationarity and autocorrelation of carbon trading price returns, uses the Generalized Autoregressive Conditional Heteroscedasticity family model to analyze the persistence, risk and asymmetry of carbon trading price return fluctuations, and then proposes a hybrid prediction model neural network (generalized autoregressive conditional heteroscedasticity-long short-term memory network) due to the shortcomings of GARCH models in carbon price fluctuation analysis and prediction. The model is used to predict the carbon trading price. The results show that the carbon trading pilots have different degrees of volatility aggregation characteristics and the volatility persistence is long, among which only the Shanghai and Beijing carbon trading markets have risk premiums. The other pilot returns have no correlation with risks, and the fluctuations of carbon trading prices and returns are asymmetrical. The prediction results of different models show that the root mean square error (RMSE) of Hubei, Shenzhen and Shanghai carbon trading pilots based on the GARCH-LSTM model is significantly lower than that of the single GARCH model, and the RMSE values are reduced by 0.0006, 0.2993 and 0.0151, respectively. The RMSE in the three pilot markets improved by 0.0007, 0.3011 and 0.0157, respectively, compared to the standalone LSTM model. At the same time, compared with the single model, the GARCH-LSTM model significantly increased the R<^>2 value in Hubei (0.2000), Shenzhen (0.7607), Shanghai (0.0542) and Beijing (0.0595). Therefore, compared with other models, the GARCH-LSTM model can significantly improve the prediction accuracy of carbon price and provide a new idea for scientifically predicting the fluctuation of financial time series such as carbon price.",2024
Deep Learning to Improve the Sustainability of Agricultural Crops Affected by Phytosanitary Events: A Financial-Risk Approach,"Given the challenges in reducing greenhouse gases (GHG), one of the sectors that have attracted the most attention in the Sustainable Development Agenda 2030 (SDA-2030) is the agricultural sector. In this context, one of the crops that has had the most remarkable development worldwide has been oil-palm cultivation, thanks to its high productive potential and being one of the most efficient sources of palmitic acid production. However, despite the significant presence of oil palm in the food sector, oil-palm crops have not been exempt from criticism, as its cultivation has developed mainly in areas of ecological conservation around the world. This criticism has been extended to other crops in the context of the Sustainable Development Goals (SDG) due to insecticides and fertilisers required to treat phytosanitary events in the field. To reduce this problem, researchers have used unmanned aerial vehicles (UAVs) to capture multi-spectral aerial images (MAIs) to assess fields' plant vigour and detect phytosanitary events early using vegetation indices (VIs). However, detecting phytosanitary events in the early stages still suggests a technological challenge. Thus, to improve the environmental and financial sustainability of oil-palm crops, this paper proposes a hybrid deep-learning model (stacked-convolutional) for risk characterisation derived from a phytosanitary event, as suggested by lethal wilt (LW). For this purpose, the proposed model integrates a Lagrangian dispersion model of the backward-Gaussian-puff-tracking type into its convolutional structure, which allows describing the evolution of LW in the field for stages before a temporal reference scenario. The results show that the proposed model allowed the characterisation of the risk derived from a phytosanitary event, (PE) such as lethal wilt (LW), in the field, promoting improvement in agricultural environmental and financial sustainability activities through the integration of financial-risk concepts. This improved risk management will lead to lower projected losses due to a natural reduction in insecticides and fertilisers, allowing a balance between development and sustainability for this type of crop from the RSPO standards.",2022
A Distributed Approach of Big Data Mining for Financial Fraud Detection in a Supply Chain,"Supply Chain Finance (SCF) is important for improving the effectiveness of supply chain capital operations and reducing the overall management cost of a supply chain. In recent years, with the deep integration of supply chain and Internet, Big Data, Artificial Intelligence, Internet of Things, Blockchain, etc., the efficiency of supply chain financial services can be greatly promoted through building more customized risk pricing models and conducting more rigorous investment decision-making processes. However, with the rapid development of new technologies, the SCF data has been massively increased and new financial fraud behaviors or patterns are becoming more covertly scattered among normal ones. The lack of enough capability to handle the big data volumes and mitigate the financial frauds may lead to huge losses in supply chains. In this article, a distributed approach of big data mining is proposed for financial fraud detection in a supply chain, which implements the distributed deep learning model of Convolutional Neural Network (CNN) on big data infrastructure of Apache Spark and Hadoop to speed up the processing of the large dataset in parallel and reduce the processing time significantly. By training and testing on the continually updated SCF dataset, the approach can intelligently and automatically classify the massive data samples and discover the fraudulent financing behaviors, so as to enhance the financial fraud detection with high precision and recall rates, and reduce the losses of frauds in a supply chain.",2020
Volatility Spillovers and Contagion During Major Crises: An Early Warning Approach Based on a Deep Learning Model,"This paper contributes to the ongoing debate on the nature and characteristics of the volatility transmission channels of major crash events in international stock markets between 03 July 1997 and 09 March 2021. Using dynamic conditional correlations (DCC) for conditional correlations and volatility clustering, GARCH-BEKK for the direction of transmission of disturbances, and the Diebold-Yilmaz spillover index for the level of volatility contagion, the paper finds that the climbs in external shock transmissions have long-lasting impacts in domestic markets due to the contagion effect during crisis periods. The findings also reveal that the heavier magnitude of financial stress is transmitted between Asian countries via the Hong Kong stock market. Additionally, the degree of volatility spillovers between advanced and emerging equity markets is smaller compared to the pure spillovers between advanced markets or emerging markets, offering a window of opportunity for international market participants in terms of portfolio diversification and risk management applications. Furthermore, the study introduces a novel early warning system created by integrating DCC correlations with a state-of-the-art deep learning model to predict the global financial crisis and COVID-19 crisis. The experimental analysis of long short-term memory network finds evidence of contagion risk by verifying bursts in volatility spillovers and generating signals with high accuracy before the 12-month crisis period. This provides supplementary information that contributes to the decision-making process of practitioners, as well as offering indicative evidence that facilitates the assessment of market vulnerability for policymakers.",2024
Volatility forecasting using deep recurrent neural networks as GARCH models,"Estimating and predicting volatility in time series is of great importance in different areas where it is required to quantify risk based on variability and uncertainty. This work proposes a new methodology to predict Time Series volatility by combining Generalized AutoRegressive Conditional Heteroscedasticity (GARCH) methods with Deep Neural Networks. Additionally, the proposal incorporates a mechanism to determine the optimal size of the sliding window used to estimate volatility. In this work, the recurrent neural networks Gated Recurrent Units, Long/Short-Term Memory (LSTM), and Bidirectional Long/Short-Term Memory (BiLSTM) are evaluated with the methods of the family Garch (fGARCH). We conducted Monte Carlo simulation studies with heteroscedastic time series to validate our proposed methodology. Moreover, we have applied the proposed method to real financial data from the stock market, such as the Selective Stock Price Index Chile index, Standard & Poor's 500 Index (S &P500), and the prices of the Stock Exchange from Australia (ASX200). The proposed methodology performs well in predicting the stock options returns volatility one week ahead.",2023
"Exploring the Relationship and Predictive Accuracy for the Tadawul All Share Index, Oil Prices, and Bitcoin Using Copulas and Machine Learning","Financial markets are increasingly interlinked. Therefore, this study explores the complex relationships between the Tadawul All Share Index (TASI), West Texas Intermediate (WTI) crude oil prices, and Bitcoin (BTC) returns, which are pivotal to informed investment and risk-management decisions. Using copula-based models, this study identified Student's t copula as the most appropriate one for encapsulating the dependencies between TASI and BTC and between TASI and WTI prices, highlighting significant tail dependencies. For the BTC-WTI relationship, the Frank copula was found to have the best fit, indicating nonlinear correlation without tail dependence. The predictive power of the identified copulas were compared to that of Long Short-Term Memory (LSTM) networks. The LSTM models demonstrated markedly lower Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and Mean Absolute Scaled Error (MASE) across all assets, indicating higher predictive accuracy. The empirical findings of this research provide valuable insights for financial market participants and contribute to the literature on asset relationship modeling. By revealing the most effective copulas for different asset pairs and establishing the robust forecasting capabilities of LSTM networks, this paper sets the stage for future investigations of the predictive modeling of financial time-series data. The study highlights the potential of integrating machine-learning techniques with traditional econometric models to improve investment strategies and risk-management practices.",2024
Singular Spectrum Analysis based Long Short-Term Memory for Predicting Bitcoin Price,"Bitcoin, a leading cryptocurrency in the financial market, is full of non-linearity, non-stationarity and high volatility. To make risk management strategies, emphasis on cryptocurrency price predicting is truly needy. However, studies about cryptocurrency prediction are lacking. In this paper, a novel hybrid model combining long short-term memory (LSTM), a state-of-the-art sequence learning method, with singular spectrum analysis (SSA) was proposed to predict Bitcoin price. SSA was employed to decompose the original time series into independent signals in term of trend, market fluctuation and noise. A smoothed series with valid information was reconstructed with reduction of noise. By introducing the smoothed series sequence into LSTM, prediction value is obtained. Empirical analysis shows that the proposed hybrid SSA-LSTM model outperforms baseline single LSTM model, according to root mean square error (RMSE), mean absolute error (MAE) and mean absolute percentage error (MAPE). The result suggests that the proposed hybrid model has satisfactory ability to grasp pattern of Bitcoin price series since SSA can extract valid information from the original series and avoid overfitting.",2019
Intelligent Financial Forecasting with Granger Causality and Correlation Analysis Using Bayesian Optimization and Long Short-Term Memory,"Financial forecasting plays a critical role in decision-making across various economic sectors, aiming to predict market dynamics and economic indicators through the analysis of historical data. This study addresses the challenges posed by traditional forecasting methods, which often struggle to capture the complexities of financial data, leading to suboptimal predictions. To overcome these limitations, this research proposes a hybrid forecasting model that integrates Bayesian optimization with Long Short-Term Memory (LSTM) networks. The primary objective is to enhance the accuracy of market trend and asset price predictions while improving the robustness of forecasts for economic indicators, which are essential for strategic positioning, risk management, and policy formulation. The methodology involves leveraging the strengths of both Bayesian optimization and LSTM networks, allowing for more effective pattern recognition and forecasting in volatile market conditions. Key contributions of this work include the development of a novel hybrid framework that demonstrates superior performance with significantly reduced forecasting errors compared to traditional methods. Experimental results highlight the model's potential to support informed decision-making amidst market uncertainty, ultimately contributing to improved market efficiency and stability.",2024
Text Mining of the Securities and Exchange Commission Financial Filings of Publicly Traded Construction Firms Using Deep Learning to Identify and Assess Risk,"Risk factor identification is a critical topic in the construction industry. It is vital for the various construction firms and industry stakeholders to understand the different types of risks that affect their businesses and financial bottom lines. This research created a systematic methodology implementing a new set of text mining methods to identify and classify risk types affecting the publicly traded construction companies, by leveraging their 10-K reports filed with the Securities and Exchange Commission (SEC). A structured procedure was developed to apply advancements from text mining and natural language processing (NLP) to extract information from textual disclosures. A state-of-the-art deep learning algorithm named FastText was implemented to identify risk patterns and classify the text into appropriate risk types. Key findings showed that operational and financial risks associated with doing business most commonly are disclosed in the risk disclosures filed by the publicly traded construction firms. A steady monotonic increase was found in the average number of total risk disclosures from 2006 to 2018. Over the same period, growth occurred in the proportion of technology risks, reputation/intangible assets risks, financial markets risk, and third-party risks. The primary contributions of this research are (1) the development of a new methodology which serves as a risk thermometer for identification and quantification of risk at an individual company level, subindustry level, and the overall industry level; and (2) minimization of any existing information asymmetry in risk studies by utilization of a source of data that previously has not been used by construction researchers. It is anticipated that the developed methodology and its results can be used by (1) publicly traded construction companies to understand risks affecting themselves and their peers; and (2) surety bond companies and insurance providers to supplement their risk pricing models; and (3) equity investors and capital financial institutions to make more-informed risk-based decisions for their investments in the construction business. (C) 2020 American Society of Civil Engineers.",2020
Deep Learning for Financial Time Series Forecast Fusion and Optimal Portfolio Rebalancing,"Portfolio selection is complicated by the difficulty of forecasting financial time series and the sensitivity of portfolio optimisers to forecasting errors. To address these issues, a portfolio management model is proposed that makes use of Deep Learning Models for weekly financial time series forecasting of returns. Our model uses a late fusion of an ensemble of forecast models and modifies the standard mean-variance optimiser to account for transaction costs, making it suitable for multi-period trading. Our empirical results show that our portfolio management tool outperforms the equally-weighted portfolio benchmark and the buy-and-hold strategy, using both Long Short-Term Memory and Gated Recurrent Unit forecasts. Although the portfolios are profitable, they are also sub-optimal in terms of their risk to reward ratio. Therefore, greater forecasting accuracy is necessary to construct truly optimal portfolios.",2021
Accurate and efficient stock market index prediction: an integrated approach based on VMD-SNNs,"The stock market index typically mirrors the financial market's performance. Hence, accurate prediction of stock market index trends is essential for investors aiming to mitigate financial risk and enhance future investment returns. Traditional statistical approaches often struggle with the non-linear nature of stock market index data, leading to potential inaccuracies in long-term predictions. To address this issue, we introduce the TCN-LSTM-SNN (TLSNN) model, a hybrid framework that integrates Long Short-Term Memory (LSTM) and Temporal Convolutional Network (TCN) for robust feature extraction, within a highly efficient Spiking Neural Network (SNN) architecture. Additionally, we employ the Subtraction-Average-Based Optimizer (SABO) to refine the Variational Mode Decomposition (VMD) technique, thereby separating the periodic and trend components of stock indices, reducing noise interference, and establishing a decomposition ensemble framework to bolster the model's resilience. The experimental results show that the VMD-TLSNN hybrid model suggested in this study surpasses other individual benchmark models and their hybrid models in prediction accuracy. Additionally, it demonstrates notably lower energy consumption compared to other hybrid models.",2025
A Kepler Optimization Algorithm-Based Convolutional Neural Network Model for Risk Management of Internet Enterprises,"Internet enterprises, as the representative enterprises of technology-based enterprises, contribute more and more to the growth of the world economy. To ensure the sustainable development of enterprises, it is necessary to predict the risks in the operation of Internet enterprises. An accurate risk prediction model can not only safeguard the interests of enterprises but also provide certain references for investors. Therefore, this study designed a Convolutional Neural Network (CNN) model based on the Kepler optimization algorithm (KOA) for risk prediction of Internet enterprises, aiming to maximize the accuracy of the prediction model, and to help Internet enterprises carry out risk management. Firstly, we select the indicators related to the financial risk of Internet enterprises, and predict the risk based on the traditional statistical analysis of Logistic regression model. On this basis, KOA was improved based on evolutionary strategies and fish foraging strategies, and the improved algorithm was applied to optimize CNN. Based on improved KOA and CNN algorithms, an IKOA-CNN risk prediction model is proposed. Finally, by comparing traditional statistical analysis-based models and other learning-based models, the results show that the IKOA-CNN algorithm proposed in this study has the highest prediction accuracy.",2024
A Kepler Optimization Algorithm-Based Convolutional Neural Network Model for Risk Management of Internet Enterprises,"Internet enterprises, as the representative enterprises of technology-based enterprises, contribute more and more to the growth of the world economy. To ensure the sustainable development of enterprises, it is necessary to predict the risks in the operation of Internet enterprises. An accurate risk prediction model can not only safeguard the interests of enterprises but also provide certain references for investors. Therefore, this study designed a Convolutional Neural Network (CNN) model based on the Kepler optimization algorithm (KOA) for risk prediction of Internet enterprises, aiming to maximize the accuracy of the prediction model, and to help Internet enterprises carry out risk management. Firstly, we select the indicators related to the financial risk of Internet enterprises, and predict the risk based on the traditional statistical analysis of Logistic regression model. On this basis, KOA was improved based on evolutionary strategies and fish foraging strategies, and the improved algorithm was applied to optimize CNN. Based on improved KOA and CNN algorithms, an IKOA-CNN risk prediction model is proposed. Finally, by comparing traditional statistical analysis-based models and other learning-based models, the results show that the IKOA-CNN algorithm proposed in this study has the highest prediction accuracy.",2024
Identifying Fintech risk through machine learning: analyzing the Q&A text of an online loan investment platform,"Financial risks associated with Fintech have been increasing with its significant growth in recent years. Aiming at addressing the problem of identifying risks in online lending investment under a financial technology platform, we develop a Q&A text risk recognition model based on attention mechanism and Bi-directional Long Short-Term Memory. First, the Q&A pairing on the text data set is carried out, and the matching data set is selected for the next analysis. Secondly, the online loan investment platform is assessed by the named entity recognition of the question text. Finally, the risk level of the corresponding investment platform is evaluated based on the answer text. The experimental results show that the proposed model has achieved improved precision, recall, F1-score, and accuracy compared with other models. Our proposed model can be applied to identify the risks from the text posted on online loan investment platforms and can be used to guide investors' investment and improve the management of financial technology platforms.",2024
Network Traffic Prediction Model Based on Convolutional Neural Networks-Long Short-Term Memory and iTransformer,"Accurately predicting network traffic is crucial for dynamically deploying computing resources in network data centers and reducing carbon emissions. In this paper, a hybrid prediction model Convolutional Neural Networks-Long Short-Term and iTransformer (CNN-LSTM-iTransformer) based on CNN-LSTM and iTransformer is proposed. CNN-LSTM is used to capture local features and long-term dependencies, while iTransformer is employed for feature relevance learning and prediction. In addition, the Huber Loss function is used to further improve the model prediction accuracy. In the experiment, the dataset was provided by Ant Financial Group, and the experimental results show that CNN-LSTM-iTransformer significantly reduces MAE to 0.112, MSE to 0.0212, MAPE to 0.123, and RWMAPE which represents prediction risk to 0.122, so the hybrid model CNN-LSTM-iTransformer achieves not only a higher prediction accuracy but also a lower prediction risk.",2025
Forecasting Crude Oil Risk Using a Multivariate Multiscale Convolutional Neural Network Model,"In light of the increasing level of correlation and dependence between the crude oil markets and the external influencing factors in the related financial markets, we propose a new multivariate empirical decomposition convolutional neural network model to incorporate the external influence of financial markets such as stock market and exchange market in a multiscale setting into the modeling of crude oil market risk movement. We propose a multivariate empirical model decomposition to analyze the finer details of interdependence among risk movement of different markets across different time horizons or scales. We also introduce the convolutional neural network to construct a new nonlinear ensemble algorithm to reduce the estimation bias and improve the forecasting accuracy. We used the major crude oil price data, stock market index, and the euro/United States dollar exchange rate data to evaluate the performance of the multivariate empirical model decomposition convolutional neural network model. The combination of both the multivariate empirical model decomposition and the convolutional neural network model in this paper has produced the risk forecasts with significantly improved risk forecasting accuracy.",2022
Applying Machine Learning to Healthcare Operations Management: CNN-Based Model for Malaria Diagnosis,"The purpose of this study is to explore how machine learning technologies can improve healthcare operations management. A machine learning-based model to solve a specific medical problem is developed to achieve this research purpose. Specifically, this study presents an AI solution for malaria infection diagnosis by applying the CNN (convolutional neural network) algorithm. Based on malaria microscopy image data from the NIH National Library of Medicine, a total of 24,958 images were used for deep learning training, and 2600 images were selected for final testing of the proposed diagnostic architecture. The empirical results indicate that the CNN diagnostic model correctly classified most malaria-infected and non-infected cases with minimal misclassification, with performance metrics of precision (0.97), recall (0.99), and f1-score (0.98) for uninfected cells, and precision (0.99), recall (0.97), and f1-score (0.98) for parasite cells. The CNN diagnostic solution rapidly processed a large number of cases with a high reliable accuracy of 97.81%. The performance of this CNN model was further validated through the k-fold cross-validation test. These results suggest the advantage of machine learning-based diagnostic methods over conventional manual diagnostic methods in improving healthcare operational capabilities in terms of diagnostic quality, processing costs, lead time, and productivity. In addition, a machine learning diagnosis system is more likely to enhance the financial profitability of healthcare operations by reducing the risk of unnecessary medical disputes related to diagnostic errors. As an extension for future research, propositions with a research framework are presented to examine the impacts of machine learning on healthcare operations management for safety and quality of life in global communities.",2023
Advanced financial market forecasting: integrating Monte Carlo simulations with ensemble Machine Learning models,"This paper presents a novel integration of Machine Learning (ML) models with Monte Carlo simulations to enhance financial forecasting and risk assessments in dynamic market environments. Traditional financial forecasting methods, which primarily rely on linear statistical and econometric models, face limitations in addressing the complexities of modern financial datasets. To overcome these challenges, we explore the evolution of financial forecasting, transitioning from time-series analyses to sophisticated ML techniques such as Random Forest, Support Vector Machines, and Long Short-Term Memory (LSTM) networks. Our methodology combines an ensemble of these ML models, each providing unique insights into market dynamics, with the probabilistic scenario analysis of Monte Carlo simulations. This integration aims to improve the predictive accuracy and risk evaluation in financial markets. We apply this integrated approach to a quantitative analysis of the SPY Exchange-Traded Fund (ETF) and selected major stocks , focusing on various risk-reward ratios including Sharpe, Sortino, and Treynor. The results demonstrate the potential of our approach in providing a comprehensive view of risks and rewards, highlighting the advantages of combining traditional risk assessment methods with advanced predictive models. This research contributes to the field of applied mathematical finance by o ff ering a more nuanced, adaptive tool for financial market analyses and decision-making.",2024
Attention is all you need: An interpretable transformer-based asset allocation approach,"Deep learning technology is rapidly adopted in financial market settings. Using a large data set from the Chinese stock market, we propose a return-risk trade-off strategy via a new transformer model. The empirical findings show that these updates, such as the self-attention mechanism in technology, can improve the use of time-series information related to returns and volatility, increase predictability, and capture more economic gains than other nonlinear models, such as LSTM. Our model employs Shapley additive explanations (SHAP) to measure the economic feature importance and tabulates the different important features in the prediction process. Finally, we document several economic explanations for the TF model. This paper sheds light on the burgeoning field on asset allocation in the age of big data.",2023
Effect of public sentiment on stock market movement prediction during the COVID-19 outbreak,"Forecasting the stock market is one of the most difficult undertakings in the financial industry due to its complex, volatile, noisy, and nonparametric character. However, as computer science advances, an intelligent model can help investors and analysts minimize investment risk. Public opinion on social media and other online portals is an important factor in stock market predictions. The COVID-19 pandemic stimulates online activities since individuals are compelled to remain at home, bringing about a massive quantity of public opinion and emotion. This research focuses on stock market movement prediction with public sentiments using the long short-term memory network (LSTM) during the COVID-19 flare-up. Here, seven different sentiment analysis tools, VADER, logistic regression, Loughran-McDonald, Henry, TextBlob, Linear SVC, and Stanford, are used for sentiment analysis on web scraped data from four online sources: stock-related articles headlines, tweets, financial news from Economic Times and Facebook comments. Predictions are made utilizing both feeling scores and authentic stock information for every one of the 28 opinion measures processed. An accuracy of 98.11% is achieved by using linear SVC to calculate sentiment ratings from Facebook comments. Thereafter, the four estimated sentiment scores from each of the seven instruments are integrated with stock data in a step-by-step fashion to determine the overall influence on the stock market. When all four sentiment scores are paired with stock data, the forecast accuracy for five out of seven tools is at its most noteworthy, with linear SVC computed scores assisting stock data to arrive at its most elevated accuracy of 98.32%.",2022
A Study of Malware Datasets and Techniques to Detect the Malware using Deep Learning Approach,"Cyber analytics play a vital role in solving the various domain problems in our day-to-day life. In this, Malware and web based attacks are most common types. Business organizations have their own apps to run their business. Malware captures the business information and corrupt the system. Malwares are developed based on financial gain. Security issues are now a big challenge with the ever increasing risk of malware attacks. Recently researchers are highly motivated to detect the malwares in the cyber field. Similarly some international highly trained programmer's community are also interested to detect the malwares for profit yielding purpose. The proposed study is based on the different malware datasets, deep learning techniques and its applications involved in malware analysis. The study infers the comprehensive comparison between different neural networks using Deep learning algorithm such as CNN, LSTM, RNN, GRU, GAN, Transfer learning, etc for Static malware analysis with different datasets.",2020
Research on the Construction of Financial Supervision Information System Based on Machine Learning,"In order to fully implement systematic, continuous and effective supervision of financial institutions and promote the safe, steady, and efficient operation of China's financial system, this research needs to develop a fully intelligent financial supervision information system, so as to take measures to effectively prevent and resolve financial risks. In this paper, based on ML (machine learning), an LSTM (long short-term memory) model with good comprehensive performance is built. This model is different from the existing scorecard model which relies on statistical learning. It not only further reduces the dependence on financial experts, but also has the ability of rapid iteration. The post-loan risk early warning model based on RF (random forest) algorithm is designed. The model parameters are optimized, which makes the risk early warning model have higher accuracy. The results show that when the data amount is 10,000 to 50,000, the accuracy of the model is relatively high when it is input into the model. When the amount of data is low, the overall throughput of the model is still very high. It shows that the pre-warning model of post-lending risk constructed in this paper has a strong risk prediction ability.",2022
Dynamic sparse portfolio rebalancing model: A perspective of investors' behavior-related decisions,"By using the elaboration likelihood model (ELM) and prospect theory (PT) to model investors' behavior-related decisions in portfolio optimization, we propose a novel dynamic behavior-based sparse portfolio selection model (BPSM) operating over multiple periods. With the BPSM model, we complement recent research that involves only investors' sentiments by also considering market sentiments to model investors' portfolio rebalancing behavior. Market sentiments are obtained by analyzing the online information through deep learning text analysis algorithms based on the Bi-directional Long Short-Term Memory (Bi-LSTM) model. The stochastic neural networks-based algorithm is designed to solve the BPSM. We demonstrate the effectiveness of the BPSM model on the Shanghai 50 and Hushen 300 data sets. The frame of experiments includes a dynamic portfolio rebalancing model, in which both the investors' sentiments and the market sentiments are modeled to analyze investors' dynamic portfolio rebalancing behavior. The experiment results show that, first, by updating the expected return rate of each period according to investors' sentiments and market sentiments, in all cases, the BPSM model achieves a higher investment return per unit risk (Rpr) than the conventional Mean-variance (MV) model to minimize investment risk. Second, compared with the two baseline models that include only investors' sentiments, the BPSM realizes a portfolio policy that improves investment return per unit risk (Rpr) in 70% of situations. These results reveal that incorporating investors' behavior-related signals into the portfolio selection model is beneficial to investors' investment results, which offers implications for financial stakeholders.",2022
Automatic phishing website detection and prevention model using transformer deep belief network,"In the digitally connected world cybersecurity is paramount, phishing where attackers pose as trusted entities to steal sensitive data, looms large. The proliferation of phishing attacks on the internet poses a substantial threat to individuals and organizations, compromising sensitive information and causing financial and reputational damage. This study's goal is to establish an automated system for the early detection and prevention of phishing websites, thereby enhancing online security and protecting users from cyber threats. This research initially employs One Hot Encoding (OHE) mechanism-based pre-processing mechanism that converts every URL string into a numerical vector with a particular dimension. This study utilizes two feature selection techniques which are transfer learning-based feature extraction using DarkNet19 and Variational Autoencoder (VAE) to select the value of the most important feature. The robust security mechanisms are presented to prevent phishing attacks and safeguard personal information on websites. List-based deep learning-based systems to prevent and detect phishing URLs more efficiently. The study proposes a transformer-based Deep Belief Network (TB-DBN), a veritable pre-trained deep transformer network model for phishing behaviour detection. A cross-validation technique with grid search hyper-parameter tuning based on the Intelligence Binary Bat Algorithm (IBBA) was designed using the proposed hybrid model. Predictions were made to classify the phishing URLs using a probabilistic estimation guided boosting classifier model and evaluate their performance in terms of accuracy, precision, recall, specificity, and F1- score. The risk level associated with the URL will be assessed based on various factors, such as the source's reputation, content analysis results, and behavioural anomalies. The computational complexity of DL model training is influenced by various factors, such as the model's complexity, the training data's size, and the optimization algorithm exploited, for training. The outcome demonstrates that tweaking variables increases the effectiveness of Python-based deep learning systems. The findings of the proposed method excel, achieving an accuracy of 99.4 %, precision of 99.2 %, recall of 99.3 %, and an F1-score of 99.2 %. This innovative automatic phishing website detection and prevention model, based on a Transformerbased Deep Belief Network, offers advanced accuracy and adaptability, strengthening cybersecurity measures to safeguard sensitive user information and mitigate the substantial threat of phishing attacks in the digitally connected world.",2024
Nickel Price Forecast Based on the LSTM Neural Network Optimized by the Improved PSO Algorithm,"Nickel is a vital strategic metal resource with commodity and financial attributes simultaneously, whose price fluctuation will affect the decision-making of stakeholders. Therefore, an effective trend forecast of nickel price is of great reference for the risk management of the nickel market's participants; yet, traditional forecast methods are defective in prediction accuracy and applicability. Therefore, a prediction model of nickel metal price is proposed based on improved particle swarm optimization algorithm (PSO) combined with long-short-term memory (LSTM) neural networks, for higher reliability. This article introduces a nonlinear decreasing assignment method and sine function to improve the inertia weight and learning factor of PSO, respectively, and then uses the improved PSO algorithm to optimize the parameters of LSTM. Nickel metal's closing prices in London Metal Exchange are sampled for empirical analysis, and the improved PSO-LSTM model is compared with the conventional LSTM and the integrated moving average autoregressive model (ARIMA). The results show that compared with the standard PSO, the improved PSO has a faster convergence rate and can improve the prediction accuracy of the LSTM model effectively. In addition, compared with the conventional LSTM model and the integrated moving average autoregressive (ARIMA) model, the prediction error of the LSTM model optimized by the improved PSO is reduced by 9% and 13%, respectively, which has high reliability and can provide valuable guidance for relevant managers.",2019
Financial risk tolerance profiling from text,"Traditionally, individual financial risk tolerance information is gathered via questionnaires or similar structured psychometric tools. Our abundant digital footprint, as an unstructured alternative, is less investigated. Leveraging such information can potentially support largescale and cost-efficient financial services. Therefore, I explore the possibility of building a computational model that distills risk tolerance information from user texts in this study, and discuss the design principles discovered from empirical results and their implications. Specifically, a new quaternary classification task is defined for text mining-based risk profiling. Experiments show that pre-trained large language models set a baseline micro-F1 of circa 0.34. Using a convolutional neural network (CNN), the reported system achieves a micro-F1 of circa 0.51, which significantly outperforms the baselines, and is a circa 4% further improvement over the standard CNN configurations (micro-F1 of circa 0.47). Textual feature richness and supervised learning are found to be the key contributors to model performances, while other machine learning strategies suggested by previous research (data augmentation and multitasking) are less effective. The findings confirm user texts to be a useful risk profiling resource and provide several insights on this task.",2024
DMDP2: A Dynamic Multi-source Based Default Probability Prediction Framework,"In this paper, we propose a dynamic forecasting framework, named DMDP2 (Dynamic Multi-source based Default Probability Prediction), to predict the default probability of a company. The default probability is a very important factor to assess the credit risk of listed companies on a stock market. Aiming at aiding financial institutions in decision making, our DMDP2 framework not only analyses financial data to well capture the historical performance of a company, but also utilizes Long Short-Term Memory model (LSTM) to dynamically incorporate daily news from social media to take the perceptions of market participants and public opinions into consideration. The study of this paper makes two key contributions. First, we make use of unstructured news crawled from social media to alleviate the impact of financial fraud issue made on default probability prediction. Second, we propose a neural network method to integrate both structured financial factors and unstructured social media data with appropriate time alignment for default probability prediction. Extensive experimental results demonstrate the effectiveness of DMDP2 in predicting default probability for the listed companies in mainland China, compared with various baselines.",2018
Application of deep learning model under improved emd in railway transportation investment benefits and national economic attribute analysis,"The railway transportation industry is one of the essential factors to promote economic development, so research is made on improving the investment benefit of construction planning of the railway transportation industry, and on this basis, the national emergency attribute is analyzed. A prediction model of railway transportation investment benefits and national economic attributes based on EEMD-LSTM (ensemble empirical mode decomposition-long-short-term memory) model is proposed. The EEMD algorithm is used to decompose the daily investment price of the railway transportation industry to obtain the IMF (intrinsic mode function) with different cycle characteristics. The daily investment price, IMF component, and residual series of the railway transportation industry are taken as input data. The input data are transmitted through the LSTM model to predict the investment price of the next day. The results show that the EEMD-LSTM model can retain the advantages of EEMD and LSTM and meet the accurate prediction of financial data. The model has good performance for the fitting of actual data and forecast data, and the model has the highest prediction accuracy of 0.2964%. In conclusion, the model proposed is a useful model for predicting financial time series. The exploration can provide an absolute theoretical basis for the formulation and planning of investment risk coping strategies of the railway transportation industry and provide particular theoretical support for the national economic attribute and positioning of the railway transportation industry.",2021
Forecasting volatility of crude oil futures using a GARCH-RNN hybrid approach,"Volatility is an important element for various financial instruments owing to its ability to measure the risk and reward value of a given financial asset. Owing to its importance, forecasting volatility has become a critical task in financial forecasting. In this paper, we propose a suite of hybrid models for forecasting volatility of crude oil under different forecasting horizons. Specifically, we combine the parameters of generalized autoregressive conditional heteroscedasticity (GARCH) and Glosten-Jagannathan-Runkle (GJR)-GARCH with long short-term memory (LSTM) to create three new forecasting models named GARCH-LSTM, GJR-LSTM, and GARCH-GJRGARCH LSTM in order to forecast crude oil volatility of West Texas Intermediate on different forecasting horizons and compare their performance with the classical volatility forecasting models. Specifically, we compare the performances against existing methodologies of forecasting volatility such as GARCH and found that the proposed hybrid models improve upon the forecasting accuracy of Crude Oil: West Texas Intermediate under various forecasting horizons and perform better than GARCH and GJR-GARCH, with GG-LSTM performing the best of the three proposed models at 7-, 14-, and 21-day-ahead forecasts in terms of heteroscedasticity-adjusted mean square error and heteroscedasticity-adjusted mean absolute error, with significance testing conducted through the model confidence set showing that GG-LSTM is a strong contender for forecasting crude oil volatility under different forecasting regimes and rolling-window schemes. The contribution of the paper is that it enhances the forecasting ability of crude oil futures volatility, which is essential for trading, hedging, and purposes of arbitrage, and that the proposed model dwells upon existing literature and enhances the forecasting accuracy of crude oil volatility by fusing a neural network model with multiple econometric models.",2021
Enhancing credit risk prediction with hybrid deep learning and sand cat swarm feature selection,"Credit risk prediction method acts as a vital financial tool for measuring the default probability of credit applicants. For financial institutions, proper credit risk management becomes mandatory to avoid significant losses incurred by borrowers' default. Thus, statistics are an increasingly vital technique that can analyse and measure credit risk. Generally, manual auditing and statistical methods measure credit risk. Current developments in financial artificial intelligence (AI) evolved from machine learning (ML)-driven credit risk methods that obtained great interest from academia and industry. The most significant step in the process of developing a credit risk assessment method is feature selection, which chooses a subset of appropriate features for enhancing the performance of an ML technique. With this motivation, this study concentrates on the design of sand cat swarm optimization-based feature selection with hybrid deep learning (SCSOFS-HDL) model for credit risk assessment. The presented SCSOFS-HDL technique presents a new SCSOFS technique for the optimal selection of feature subsets from the credit risk data. In addition, the deep LSTM Supervised Autoencoder Neural Network (DLSTM-SANN) model is presented for classification purposes. To enhance the performance of the DLSTM-SANN technique, the political optimizer (PO) methodology is utilized for the hyperparameter tuning process. The experimental validation of the SCSOFS-HDL technique is tested on credit risk datasets and the results highlighted the better performance of the SCSOFS-HDL algorithm with maximum accuracy of 96.49% and 96.12% on German Credit and Australian Credit datasets, respectively.",2024
Enhancing Credit Risk Decision-Making in Supply Chain Finance With Interpretable Machine Learning Model,"The increasing complexity of supply chain finance poses significant challenges to effective credit risk assessment. Traditional black-box models often fail to provide insights into the factors driving credit risk, which is essential for stakeholders when making informed decisions. By conducting analysis of interpretable machine learning models, the study evaluated their performance in assessing credit risks. Specifically, we applied Extreme Gradient Boosting (XGBoost), Random Forest (RF), Least Squares Support Vector Machine (LSSVM) and Convolutional Neural Network (CNN) models for risk assessment. Our methodology included an ablation experiment along with utilizing Shapley Additive Explanation (SHAP) to elucidate the contribution and significance of specific risk factors. The results indicated that the asset-liability ratio, cash ratio, and quick ratio notably influence credit risk. This study clarified the applicability and limitations of various models, highlighting the superior performance and interpretability of XGBoost through the SHAP algorithm. Ultimately, the insights from this study provided valuable guidance for companies and financial institutions, fostering more sustainable allocation of financial resources.",2025
Forecasting volatility spillovers across Chinese financial industries: an out-of-sample framework using a novel matrix autoregressive model,"Effective control of current and future financial volatility spillovers is crucial for risk management. Earlier studies indicate the presence of financial volatility spillovers; however, little is known about how to predict their dynamic evolution. This article proposes an out-of-sample forecasting framework based on the novel matrix autoregressive (MAR) model, which fully exploits the predictive information contained in the matrix structure of financial volatility spillovers. Specifically, we estimate cross-industry volatility spillover matrices of Chinese financial institutions by the Elastic Net vector autoregression network approach. We then apply the MAR model to forecast cross-industry volatility spillovers, and further evaluate its predictive ability versus different benchmark models. We find that cross-industry volatility spillovers increase rapidly in response to risk events during the entire period. The banking, insurance, and real estate industries are net volatility receivers, while the securities and diversified financial industries act as net transmitters. Moreover, it is demonstrated that the MAR model outperforms long short-term memory (LSTM) network model, vector autoregressive (VAR) model, and the VAR models with various predictors. The results are robust to a series of tests. Forecasting changes in cross-industry volatility spillovers can provide early warnings for financial regulation and investment decision.",2025
Multi-Transformer: A New Neural Network-Based Architecture for Forecasting S&P Volatility,"Events such as the Financial Crisis of 2007-2008 or the COVID-19 pandemic caused significant losses to banks and insurance entities. They also demonstrated the importance of using accurate equity risk models and having a risk management function able to implement effective hedging strategies. Stock volatility forecasts play a key role in the estimation of equity risk and, thus, in the management actions carried out by financial institutions. Therefore, this paper has the aim of proposing more accurate stock volatility models based on novel machine and deep learning techniques. This paper introduces a neural network-based architecture, called Multi-Transformer. Multi-Transformer is a variant of Transformer models, which have already been successfully applied in the field of natural language processing. Indeed, this paper also adapts traditional Transformer layers in order to be used in volatility forecasting models. The empirical results obtained in this paper suggest that the hybrid models based on Multi-Transformer and Transformer layers are more accurate and, hence, they lead to more appropriate risk measures than other autoregressive algorithms or hybrid models based on feed forward layers or long short term memory cells.",2021
Deep Reinforcement Learning Agent for S&P 500 Stock Selection,"This study investigated the performance of a trading agent based on a convolutional neural network model in portfolio management. The results showed that with real-world data the agent could produce relevant trading results, while the agent's behavior corresponded to that of a high-risk taker. The data used were wide in comparison with earlier reported research and was based on the full set of the S&P 500 stock data for twenty-one years supplemented with selected financial ratios. The results presented are new in terms of the size of the data set used and with regards to the model used. The results provide direction and offer insight into how deep learning methods may be used in constructing automatic trading systems.",2020
Explainable Multistage Ensemble 1D Convolutional Neural Network for Trust Worthy Credit Decision,"Banking is a dynamic industry that places significant importance on risk management, requiring accurate and interpretable AI models to make transparent lending decisions. This study introduces a groundbreaking approach that combines a multistage ensemble technique with a 1D convolutional neural network (CNN) architecture. The algorithm not only delivers superior classification performance but also offers interpretable explanations for its decisions. The algorithm is designed with multiple strategic steps to enhance model performance without sacrificing explainability. Thorough experiments were conducted using datasets from private banks and non-banking financial companies (NBFCs) in India to evaluate the algorithm's performance. It was compared against various state-of-the-art models, demonstrating remarkable precision, recall, F1 score, and accuracy values of 0.994, 0.992, 0.993, and 0.991, respectively. This outperformed competing models like homogeneous deep ensembles, 1D CNN, and Artificial Neural Networks (ANN). Furthermore, individual borrower dataset evaluations confirmed the proposed algorithm's consistency and efficiency, achieving precision, recall, F1 score, and accuracy values of 0.960, 0.961, 0.952, and 0.964, respectively. The research emphasizes the effectiveness of the explanatory integration decision process, wherein the Explainable Multistage Ensemble 1D CNN not only provides enhanced credit risk prediction but also facilitates transparent and interpretable lending decisions. The algorithm's ability to offer understandable explanations empowers financial institutions to make well-informed lending decisions, reduce credit risk, and foster a more stable and inclusive financial ecosystem.",2024
Explainable Multistage Ensemble 1D Convolutional Neural Network for Trust Worthy Credit Decision,"Banking is a dynamic industry that places significant importance on risk management, requiring accurate and interpretable AI models to make transparent lending decisions. This study introduces a groundbreaking approach that combines a multistage ensemble technique with a 1D convolutional neural network (CNN) architecture. The algorithm not only delivers superior classification performance but also offers interpretable explanations for its decisions. The algorithm is designed with multiple strategic steps to enhance model performance without sacrificing explainability. Thorough experiments were conducted using datasets from private banks and non-banking financial companies ( NBFCs) in India to evaluate the algorithm's performance. It was compared against various state-of-the-art models, demonstrating remarkable precision, recall, F1 score, and accuracy values of 0.994, 0.992, 0.993, and 0.991, respectively. This outperformed competing models like homogeneous deep ensembles, 1D CNN, and Artificial Neural Networks (ANN). Furthermore, individual borrower dataset evaluations confirmed the proposed algorithm's consistency and efficiency, achieving precision, recall, F1 score, and accuracy values of 0.960, 0.961, 0.952, and 0.964, respectively. The research emphasizes the effectiveness of the explanatory integration decision process, wherein the Explainable Multistage Ensemble 1D CNN not only provides enhanced credit risk prediction but also facilitates transparent and interpretable lending decisions. The algorithm's ability to offer understandable explanations empowers financial institutions to make well-informed lending decisions, reduce credit risk, and foster a more stable and inclusive financial ecosystem.",2024
Deep learning with long short-term memory networks for financial market predictions,"Long short-term memory (LSTM) networks are a state-of-the-art technique for sequence learning. They are less commonly applied to financial time series predictions, yet inherently suitable for this domain. We deploy LSTM networks for predicting out-of-sample directional movements for the constituent stocks of the S&P 500 from 1992 until 2015. With daily returns of 0.46 percent and a Sharpe ratio of 5.8 prior to transaction costs, we find LSTM networks to outperform memory-free classification methods, i.e., a random forest (RAF), a deep neural net (DNN), and a logistic regression classifier (LOG). The outperformance relative to the general market is very clear from 1992 to 2009, but as of 2010, excess returns seem to have been arbitraged away with LSTM profitability fluctuating around zero after transaction costs. We further unveil sources of profitability, thereby shedding light into the black box of artificial neural networks. Specifically, we find one common pattern among the stocks selected for trading - they exhibit high volatility and a short-term reversal return profile. Leveraging these findings, we are able to formalize a rules-based short-term reversal strategy that yields 0.23 percent prior to transaction costs. Further regression analysis unveils low exposure of the LSTM returns to common sources of systematic risk also compared to the three benchmark models. (C) 2017 Elsevier B.V. All rights reserved.",2018
RETRACTED: Green Financial Health Risk Early Monitoring of Commercial Banks Based on Neural Network Model in a Small Sample Environment (Retracted Article),"Financial innovations emerge in an endless stream, and it is difficult for the regulatory measures and efforts of banks in various countries and the credit risk management level of commercial banks themselves to adapt to the increasingly complex risk environment faced by banks. In the process of building GFR (green financial risk) mixed governance model, the division of powers and responsibilities of governance subjects should be effectively defined. Therefore, it is very necessary to comprehensively and systematically study and grasp the characteristics, performance, and causes of commercial banks' GFR and build an early-warning model of commercial banks' GFR to comprehensively monitor the risks of banks, so as to reduce risks and avoid crises. Therefore, this paper uses the forward three-layer BPNN (BP neural network) technology to establish a real-time warning model of commercial banks' GFR. IL (input layer) to HL (hidden layer) adopts Sigmoid function, while HL to OL (output layer) function adopts linear function Purelin function. The results show that the test result of this method is greatly improved compared with the traditional method, and the correct rate is increased from 81.27% to 94.38%. It shows that the model in this paper has achieved a good warning effect of GFR for commercial banks.",2022
Integrating Macroeconomic and Technical Indicators into Forecasting the Stock Market: A Data-Driven Approach,"Forecasting stock markets is challenging due to the influence of various internal and external factors compounded by the effects of globalization. This study introduces a data-driven approach to forecast S&P 500 returns by incorporating macroeconomic indicators including gold and oil prices, the volatility index, economic policy uncertainty, the financial stress index, geopolitical risk, and shadow short rate, with ten technical indicators. We propose three hybrid deep learning models that sequentially combine convolutional and recurrent neural networks for improved feature extraction and predictive accuracy. These models include the deep belief network with gated recurrent units, the LeNet architecture with gated recurrent units, and the LeNet architecture combined with highway networks. The results demonstrate that the proposed hybrid models achieve higher forecasting accuracy than the single deep learning models. This outcome is attributed to the complementary strengths of convolutional networks in feature extraction and recurrent networks in pattern recognition. Additionally, an analysis using the Shapley method identifies the volatility index, financial stress index, and economic policy uncertainty as the most significant predictors, underscoring the effectiveness of our data-driven approach. These findings highlight the substantial impact of contemporary uncertainty factors on stock markets, emphasizing their importance in studies analyzing market behaviour.",2025
Performance Evaluation of Hybrid Machine Learning Algorithms for Online Lending Credit Risk Prediction,"Peer-to-Peer systems are still in the early stages of development when it comes to the processing of credit and the appraisal of the risk associated with it. In this study, we used a hybrid convolutional neural network with logistic regression, a gradient-boosting decision tree, and a k-nearest neighbor to predict the credit risk in a P2P lending club. The lending clubs publicly available P2P loan data was used to train the model. In order to address the issue of data imbalance within the dataset, specifically between the non-defaulter and defaulter classes, the synthetic minority oversampling technique sampling approach is utilized. We developed the architecture of our hybrid model by removing the fully connected layer with the soft-max, which is the final layer of the fully connected CNN model and replaced by LR, GBDT, and k-NN algorithms. The experimental results show that the hybrid CNN-kNN model outperforms the CNN-GBDT and CNN-LR models based on the performance metrics accuracy, recall, F1-score, and area under the curve for both all input and important features. This shows that hybrid machine learning models effectively identify and categorize credit risk in peer-to-peer lending clubs, hence assisting in financial loss prevention.",2024
LSTM-GARCH Hybrid Model for the Prediction of Volatility in Cryptocurrency Portfolios,"In the present work, the volatility of the leading cryptocurrencies is predicted through generalised autoregressive conditional heteroskedasticity (GARCH) models, multilayer perceptron (MLP), long short-term memory (LSTM), and hybrid models of the type LSTM and GARCH, where parameters of the GARCH family are included as features of LSTM models. The study period covered the scenario of the World Health Organization pandemic declaration around March 2020 at hourly frequency. We have found that the different variants of deep neural network models outperform those of the GARCH family in the sense of the hetorerocedastic error, and absolute and squared error (HSE). Under the sharpe ratio, the volatility forecasting of a uniform portfolio at long horizons systematically outperforms the stablecoin Tether, which is considered here as the risk-free asset. Also, including transaction volume helps reduce the value at risk or loss probability for the uniform portfolio. Moreover, in a minimum variance portfolio, it is observed that before the pandemic declaration, a large proportion of the capital was allocated to bitcoin (BTC). In contrast, after March 2020, the portfolio is more diversified with short positions for BTC. Moreover, the MLP models give the best predictive results, although not statistically different in accuracy compared to the LSTM and LSTM-GARCH versions under the Diebold-Mariano test. In sum, MLP models outperform most stylised financial models and are less computationally expensive than more complex neural networks. Therefore, simple learning models are suggested in highly non-linear time series volatility forecasts as it is the cryptocurrency market.",2024
Assessment of financial risk pre-alarm mechanism based on financial ecosystem using BPNN and genetic algorithm,"Enhancing the financial ecosystem encourages financial reform, stability, and the achievement of all-encompassing and sustainable development. Financial risk assessment is essential, because it affects not only a company's development but also the general economic progress of society. The backpropagation neural network (BPNN) was used in this study to create a proactive financial risk pre-alarm system by recognizing the critical role that risk assessment plays in promoting financial reform, stability, and sustainable development within the financial ecosystem. In this paper, we utilized the capabilities of the backpropagation neural network (BPNN) as a way of creating a proactive financial risk pre-alarm system by realizing the crucial significance of risk assessment in supporting financial reform, stability, and sustainable development within the financial ecosystem. First, data on assessing financial risk is collected, including earnings reports, economic indicators, political developments that have an impact on the economy, and some previous financial data. After the data have been acquired, it is preprocessed by being cleaned, having extra attributes removed, missing values removed, and normalized. An initial set of random parameters is used to create a BPNN architecture, which is then trained using a fraction of the collected data. Next, a genetic algorithm is employed to optimize the parameters of BPNN, including learning rate, neuronal count, hidden layer count, etc. The remaining data from the collection is then used to test the optimized BPNN, and its performance is assessed. The result of the developed model is carefully assessed and compared with other methodologies and with previously published works, showing that this method's accuracy is unquestionably superior to that of the other financial risk analysis algorithms. The mistake is reduced by 45.69%, and our model's accuracy is 97.94%, which is 21.32% greater than the accuracy of the comparison algorithm.",2023
Research on early warning of agricultural credit and guarantee risk based on deep learning,"Under the impact of agricultural industry differentiation, traditional financial risk model cannot forewarn the guarantee risk of agricultural credit with effectively. This paper proposes an early warning algorithm of agricultural credit and guarantee risk that can effectively overcome the interference of external factors. Using deep learning network, the risk algorithm of agricultural credit and guarantee was built and it could change the deep belief network into supervised learning. To train for an optimal model, two new hidden layers are added to extract image feature vectors, as well as a Softmax classifier. The model is trained and evaluated by the usage of the risk data set of L province from 2017 to 2019, reinforcing the pre-training network and data to deal with the issue of overfitting in training. The results show that the accuracy of the model reaches 92.56%, when the training sample proportion is 90%, with all the 13 factors in the test set taken as input. It shows that the training of the model worked well and that it can effectively predict the risk of agricultural credit and guarantee.",2022
On Forecasting Realized Volatility for Bitcoin Based on Deep Learning PSO-GRU Model,"As the trendsetter of the digital currency market, Bitcoin fluctuates dramatically in a short period of time and has received increasing attention from investors. However, its high volatility has brought great uncertainty to the financial market. In this paper, we focus on forecasting the realized volatility of Bitcoin by using an optimized deep learning model. Firstly, we construct a more comprehensive system of factor indicators and employ different methods for feature selection, and find that the Random Forest-based feature selection fits better on the deep learning model. Then, we use the particle swarm optimization (PSO) algorithm to optimize the parameters of gated recurrent unit (GRU) model to improve the prediction accuracy, and the results show that the prediction accuracy of PSO-GRU model is 10.47%, 15.28%, 21.73%, 34.79% better than the GRU model, long-short term memory model, machine learning models and the generalized autoregressive conditional heteroscedasticity model on the mean absolute error, respectively. Finally, we establish an early risk warning scheme for Bitcoin volatility and a butterfly option arbitrage strategy, that provide investors with a reference for reasonable arrangement of trading strategies.",2024
Systemic risk measurement: A Quantile Long Short-Term Memory network approach,"In finance, systemic risk is the risk that the crisis of an institution could trigger instability or bring down an entire system or market. The Delta Conditional Value-at-Risk is a market-based measure proposed by the recent literature to quantify the systematicity of some financial institutions. Several methods have been proposed to estimate this measure, and the choice of the best method is still an open question. The bivariate constant conditional correlation GARCH model represents one of the most preferred approaches since it allows the computation of the Delta Conditional Value-at-Risk in a closed form. Nevertheless, it requires strong distributional assumptions that are often considered unrealistic. We develop a Quantile Long Short-Term Memory network approach that allows the estimation of the Delta Conditional Value-at-Risk of several financial institutions simultaneously. The model consists of a multi -output neural network able to provide, at the same time, the log-return quantiles of different institutions useful to measure the systemic risk. Furthermore, the proposed model does not need any particular assumption, and it is specifically designed to avoid quantile crossing issues affecting the traditional quantile regression-based approach. Numerical experiments on data of some global systemically important banks reported in the Financial Stability Board validated our approach. We obtain Delta Conditional Value-at-Risk estimates that accurately capture market dynamics and produce a ranking of systemic banks that meets the desired properties of stability and persistence.",2024
A Novel Anti-Risk Method for Portfolio Trading Using Deep Reinforcement Learning,"In the past decade, the application of deep reinforcement learning (DRL) in portfolio management has attracted extensive attention. However, most classical RL algorithms do not consider the exogenous and noise of financial time series data, which may lead to treacherous trading decisions. To address this issue, we propose a novel anti-risk portfolio trading method based on deep reinforcement learning (DRL). It consists of a stacked sparse denoising autoencoder (SSDAE) network and an actor-critic based reinforcement learning (RL) agent. SSDAE will carry out off-line training first, while the decoder will used for on-line feature extraction in each state. The SSDAE network is used for the noise resistance training of financial data. The actor-critic algorithm we use is advantage actor-critic (A2C) and consists of two networks: the actor network learns and implements an investment policy, which is then evaluated by the critic network to determine the best action plan by continuously redistributing various portfolio assets, taking Sharp ratio as the optimization function. Through extensive experiments, the results show that our proposed method is effective and superior to the Dow Jones Industrial Average index (DJIA), several variants of our proposed method, and a state-of-the-art (SOTA) method.",2022
Dynamic portfolio rebalancing through reinforcement learning,"Portfolio managements in financial markets involve risk management strategies and opportunistic responses to individual trading behaviours. Optimal portfolios constructed aim to have a minimal risk with highest accompanying investment returns, regardless of market conditions. This paper focuses on providing an alternative view in maximising portfolio returns using Reinforcement Learning (RL) by considering dynamic risks appropriate to market conditions through dynamic portfolio rebalancing. The proposed algorithm is able to improve portfolio management by introducing the dynamic rebalancing of portfolios with vigorous risk through an RL agent. This is done while accounting for market conditions, asset diversifications, risk and returns in the global financial market. Studies have been performed in this paper to explore four types of methods with variations in fully portfolio rebalancing and gradual portfolio rebalancing, which combine with and without the use of the Long Short-Term Memory (LSTM) model to predict stock prices for adjusting the technical indicator centring. Performances of the four methods have been evaluated and compared using three constructed financial portfolios, including one portfolio with global market index assets with different risk levels, and two portfolios with uncorrelated stock assets from different sectors and risk levels. Observed from the experiment results, the proposed RL agent for gradual portfolio rebalancing with the LSTM model on price prediction outperforms the other three methods, as well as returns of individual assets in these three portfolios. The improvements of the returns using the RL agent for gradual rebalancing with prediction model are achieved at about 27.9-93.4% over those of the full rebalancing without prediction model. It has demonstrated the ability to dynamically adjust portfolio compositions according to the market trends, risks and returns of the global indices and stock assets.",2022
Credit Risk Classification Using Discriminative Restricted Boltzmann Machines,"Credit risk analysis plays an important role in the financial market. In this paper, discriminative restricted Boltzmann machine (RBM) is used in credit risk classification. RBM is a generative model associated with an undirected graph, which can capture complicated features from observed data, and after introducing discriminative component into RBM, it can be used to train a non-linear classifier. The method is tested in a real-world credit risk prediction task, and the empirical results demonstrate the advantage of the method over other competing ones.",2014
Large-scale End-of-Life Prediction of Hard Disks in Distributed Datacenters,"On a daily basis, data centers process huge volumes of data backed by the proliferation of inexpensive hard disks. Data stored in these disks serve a range of critical functional needs from financial, and healthcare to aerospace. As such, premature disk failure and consequent loss of data can be catastrophic. To mitigate the risk of failures, cloud storage providers perform condition-based monitoring and replace hard disks before they fail. By estimating the remaining useful life of hard disk drives, one can predict the time-to-failure of a particular device and replace it at the right time, ensuring maximum utilization whilst reducing operational costs. In this work, large-scale predictive analyses are performed using severely skewed health statistics data by incorporating customized feature engineering and a suite of sequence learners. Past work suggests using LSTMs as an excellent approach to predicting remaining useful life. To this end, we present an encoder-decoder LSTM model where the context gained from understanding health statistics sequences aid in predicting an output sequence of the number of days remaining before a disk potentially fails. The models developed in this work are trained and tested across an exhaustive set of all of the 10 years of S.M.A.R.T. health data in circulation from Backblaze and on a wide variety of disk instances. It closes the knowledge gap on what full-scale training achieves on thousands of devices and advances the state-of-the-art by providing tangible metrics for evaluation and generalization for practitioners looking to extend their workflow to all years of health data in circulation across disk manufacturers. The encoder-decoder LSTM posted an RMSE of 0.83 during training and 0.86 during testing over the exhaustive 10-year data while being able to generalize competitively over other drives from the Seagate family.",2023
Forecasting commodity prices: empirical evidence using deep learning tools,"Since the last two decades, financial markets have exhibited several transformations owing to recurring crises episodes that has led to the development of alternative assets. Particularly, the commodity market has attracted attention from investors and hedgers. However, the operational research stream has also developed substantially based on the growth of the artificial intelligence field, which includes machine learning and deep learning. The choice of algorithms in both machine learning and deep learning is case-sensitive. Hence, AI practitioners should first attempt solutions related to machine learning algorithms, and if such solutions are unsatisfactory, they must apply deep learning algorithms. Using this perspective, this study aims to investigate the potential of various deep learning basic algorithms for forecasting selected commodity prices. Formally, we use the Bloomberg Commodity Index (noted by the Global Aggregate Index) and its five component indices: Bloomberg Agriculture Subindex, Bloomberg Precious Metals Subindex, Bloomberg Livestock Subindex, Bloomberg Industrial Metals Subindex, and Bloomberg Energy Subindex. Based on daily data from January 2002 (the beginning wave of commodity markets' financialization) to December 2020, results show the effectiveness of the Long Short-Term Memory method as a forecasting tool and the superiority of the Bloomberg Livestock Subindex and Bloomberg Industrial Metals Subindex for assessing other commodities' indices. These findings is important in term for investors in term of risk management as well as policymakers in adjusting public policy, especially during Russian-Ukrainian war.",2024
Enhancing Credit Risk Assessment Through Transformer-Based Machine Learning Models,"This study evaluates the effectiveness of transformer-based deep learning models in improving credit risk assessment for predicting default probabilities among credit card customers. By employing the CNN-SFTransformer and GRU-Transformer models, this research aims to enhance predictive accuracy and robustness compared to traditional machine learning methods. The models were trained and tested on diverse datasets from Taiwan, Germany, and Australia, representing various credit risk scenarios. The experimental setup included rigorous hyperparameter tuning and utilized key evaluation metrics such as ROC AUC, KS statistic, and G-(mu) over tilde to assess model performance comprehensively. The CNN-SFTransformer model demonstrated superior performance, consistently surpassing baseline models like LSTM, Support Vector Machines (SVM), and Random Forest across all datasets. This performance indicates its enhanced capability in differentiating between defaulters and non-defaulters. The GRU-Transformer model also showed promising results, further validating the effectiveness of transformer architectures in this domain. Statistical significance of the results was confirmed through the McNemar test, ensuring the robustness and reliability of the proposed models. This research introduces a novel approach to credit risk management by providing scalable and adaptable models that improve the precision of default predictions, thereby aiding financial institutions in making more informed lending decisions with greater confidence.",2025
A novel strongly-typed Genetic Programming algorithm for combining sentiment and technical analysis for algorithmic trading,"The use of algorithms in finance and trading has become an increasingly thriving research area, with researchers creating automated and pre programmed trading instructions utilising indicators from technical and sentiment analysis. The indicators of the two analyses have been used mostly individually, despite evidence that their combination can be profitable and financially advantageous. In this paper, we examine the advantages of combining indicators from both technical and sentiment analysis through a novel genetic programming algorithm, named STGP-SATA. Our algorithm introduces technical and sentiment analysis types, through a strongly-typed architecture, whereby the associated tree contains one branch with only technical indicators and another branch with only sentiment analysis indicators. This approach allows for better exploration and exploitation of the search space of the indicators. To evaluate the performance of STGP-SATA we compare it with three other GP variants on three financial metrics, namely Sharpe ratio, rate of return and risk. We furthermore compare STGP-SATA against two financial and four algorithmic benchmarks, namely, multilayer perceptron, support vector machine, extreme gradient boosting, and long short term memory network. Our study shows that the combination of technical and sentiment analysis indicators through STGP-SATA improves the financial performance of the trading strategies and statistically and significantly outperforms the other benchmarks across the three financial metrics.",2025
Internet Financial Risk Monitoring and Evaluation Based on GABP Algorithm,"Due to the generality and particularity of Internet financial risks, it is imperative for the institutions involved to establish a sound risk prevention, control, monitoring, and management system and timely identify and alert potential risks. Firstly, the importance of Internet financial risk monitoring and evaluation is expounded. Secondly, the basic principles of backpropagation (BP) neural network, genetic algorithm (GA), and GABP algorithms are discussed. Thirdly, the weight and threshold of the BP algorithm are optimized by using the GA, and the GABP model is established. The financial risks are monitored and evaluated by the Internet financial system as the research object. Finally, GABP is further optimized by the simulated annealing (SA) algorithm. The results show that, compared with the calculation results of the BP model, the GABP algorithm can reduce the number of BP training, has high prediction accuracy, and realizes the complementary advantages of GA and BP neural network. The GABP network optimized by simulated annealing method has better global convergence, higher learning efficiency, and prediction accuracy than the traditional BP and GABP neural network, achieves better prediction effect, effectively solves the problem that the enterprise financial risk cannot be quantitatively evaluated, more accurately assesses the size of Internet financial risk, and has certain popularization value in the application of Internet financial risk prediction.",2022
A Hybrid Methodology Using Machine Learning Techniques and Feature Engineering Applied to Time Series for Medium- and Long-Term Energy Market Price Forecasting,"In the electricity market, the issue of contract negotiation prices between generators/traders and buyers is of particular relevance, as an accurate contract modeling leads to increased financial returns and business sustainability for the various participating agents, encouraging investments in specialized sectors for price forecasting and risk analysis. This paper presents a methodology applied in experiments on energy forward curve scenarios using a set of techniques, including Long Short-Term Memory (LSTM), Extreme Gradient Boosting (XGBoost), Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors (SARIMAX), and Feature Engineering to generate a 10-year projection of the Conventional Long-Term Price. The model validation proved to be effective, with errors of only 4.5% by Root Mean Square Error (RMSE) and slightly less than 2% by Mean Absolute Error (MAE), for a time series spanning from 7 January 2012 to 31 August 2024, in the Brazilian energy market.",2025
LSTM based Algorithmic Trading model for Bitcoin,"Cryptocurrencies have emerged as an alternative financial asset in the last decade, with their market growing exponentially in recent years. The price of cryptocurrencies is highly volatile and is prone to rapid swings within short periods of time. This behaviour makes them a high-risk and high-return financial asset. The efficacy of neural networks in forecasting the high frequency financial time series has become widely accepted in the research community. This work explored the use of Long Short Term Memory (LSTM), a neural network based non-linear sequence model, to propose a novel algorithmic trading strategy for cryptocurrencies. The proposed novel high frequency algorithmic trading strategy built over an LSTM based short-term price forecasting is used for Bitcoin and Ethereum. This simple, yet effective trading algorithm uses the network's price forecasts to make buy and short selling decisions for cryptocurrency based on certain set criteria. The proposed trading strategy gives positive returns when backtested on Bitcoin hourly prices taken from yahoo! finance. We also verified the effectiveness of the trading strategy for Ethereum, the second largest cryptocurrency, based on the positive backtesting returns. As an extension to the study, the proposed strategy is applied on an even higher frequency (minute by minute) Bitcoin price data, and the strategy gives positive backtesting returns in this extended study. We also provide fuzzy intervals for the algorithmic return of our strategy and compare those with corresponding intervals on a simple buy and hold strategy.",2022
A Multi-Objective Deep Reinforcement Learning Approach for Stock Index Futures's Intraday Trading,"Modern artificial intelligence has been widely discussed to practice in automated financial asserts trading. Automated intraday trading means that the agent can react to the market conditions automatically, while simultaneously make the right decisions. Besides, the profits will be made within a day considering transaction cost charged by the brokerage company. In this paper, we introduce a multi-objective deep reinforcement learning approach for intraday financial signal representation and trading. We design the deep neural networks to automatically discover the dynamic market features, then a reinforcement learning method implemented by a special kind of recurrent neural network (LSTM) is applied to make continuous trading decisions. In terms of balancing the profit and risk, we implement a multi-objective structure which includes two objectives with different weights. We conduct experiments on stock index futures data, and our analysis and experiments not only offer insights into financial market features mining, but also provide a straightforward and reliable method to make profits, which sheds light on its wide application on automated financial trading.",2017
Automatic Generation of Critical Audit Matters (CAMs) Using LSTM-MacBert-Based Dual-Stream Transfer Learning,"The disclosure of critical audit matters (CAMs) plays an important part in audit report reform and financial risk warnings. Current CAMs include matters that need to be focused on from the audit after a comprehensive evaluation of the internal control and other enterprise information, combined with the experience of the project manager, which is closely related to subjective factors, such as auditor professionalism and independence. An increase in subjective judgment becomes a breeding ground for audit failure. First, since long short-term memory (LSTM) is often used to process temporal data, MacBERT is often used as a text encoding, so LSTM is used to encode financial information to overcome the influence of subjective factors, and MacBert is used to encode nonfinancial information. The two modes are then separately encoded to form a dual-stream structure that simulates the process of auditors reviewing documents. Second, a transformer is used to perform multimodal interactions on the dual-stream encoding results to simulate the process of auditors integrating important information. Finally, the multimodal interaction results are fed into the fully connected layers and the SoftMax function to achieve cross-modal fusion, which simulates the process of auditors obtaining CAMs. Simulating single-modal coding, multimodal interaction, and cross-modal fusion helps to realize the automatic generation of CAMs. This ensemble model is called the CAMs automatic generation model and is based on LSTM-MacBert dual-stream transfer learning. The experimental results show that the features of financial statements and public disclosure text extracted by the model can effectively screen CAMs and realize the automatic generation of high-level CAMs.",2024
Portfolio formation with preselection using deep learning from long-term financial data,"Portfolio theory is an important foundation for portfolio management which is a well-studied subject yet not fully conquered territory. This paper proposes a mixed method consisting of long short-term memory networks and mean-variance model for optimal portfolio formation in conjunction with the asset preselection, in which long-term dependences of financial time-series data can be captured. The experiment uses a large volume of sample data from the UK Stock Exchange 100 Index between March 1994 and March 2019. In the first stage, long short-term memory networks are used to forecast the return of assets and select assets with higher potential returns. After comparing the outcomes of the long short-term memory networks against support vector machine, random forest, deep neural networks, and autoregressive integrated moving average model, we discover that long short-term memory networks are appropriate for financial time-series forecasting, to beat the other benchmark models by a very clear margin. In the second stage, based on selected assets with higher returns, the mean-variance model is applied for portfolio optimisation. The validation of this methodology is carried out by comparing the proposed model with the other five baseline strategies, to which the proposed model clearly outperforms others in terms of the cumulative return per year, Sharpe ratio per triennium as well as average return to the risk per month of each triennium. i.e. potential returns and risks. (C) 2019 Elsevier Ltd. All rights reserved.",2020
Dynamic monitoring of financial security risks: A novel China financial risk index and an early warning system,"From the perspective of financial risk-a more macro level, this letter selected three levels of indicators which reflect emerging risks, synthesized seven dimensional indices, and developed a China financial risk index using two different methods, identifying the risk regime by Markov switching model. The convolution for neural network-long short-term memory model was used to construct an early warning system for financial risks. The model was optimized using regime-based prediction. The empirical results show that the composite dynamic monitoring system and the early warning system have good effects.",2024
Improved Financial Predicting Method Based on Time Series Long Short-Term Memory Algorithm,"With developments in global economic integration and the increase in future economic uncertainty, it is imperative to have the ability to predict future capital in relation to financial capital inflow and outflow predictions to ensure capital optimization is within a controllable range within the current macroeconomic environment and situation. This paper proposes an automated capital prediction strategy for the capital supply chain using time series analysis artificial intelligence methods. Firstly, to analyze the fluctuation and tail risk of the financial characteristics, the paper explores the financial characteristics for measuring the dynamic VaR from the perspectives of volatility, tail, and peak with the Bayesian peaks over threshold (POT) model. Following this, in order to make the modeling more refined, the forecast targets are split before modeling with seasonal Autoregressive Integrated Moving Average (ARIMA) models and Prophet models. Finally, the time series modeling of the wavelet Long Short-Term Memory (LSTM) model is carried out using a two-part analysis method to determine the linear separated wavelet and non-linear embedded wavelet parts to predict strong volatility in financial capital. Taking the user capital flow of the Yu'e Bao platform, the results prove the feasibility and prediction accuracy of the innovative model proposed.",2024
Analysis and prediction of unplanned intensive care unit readmission using recurrent neural networks with long shortterm memory,"Background Unplanned readmission of a hospitalized patient is an indicator of patients' exposure to risk and an avoidable waste of medical resources. In addition to hospital readmission, intensive care unit (ICU) readmission brings further financial risk, along with morbidity and mortality risks. Identification of high-risk patients who are likely to be readmitted can provide significant benefits for both patients and medical providers. The emergence of machine learning solutions to detect hidden patterns in complex, multi-dimensional datasets provides unparalleled opportunities for developing an efficient discharge decision-making support system for physicians and ICU specialists. Methods and findings We used supervised machine learning approaches for ICU readmission prediction. We used machine learning methods on comprehensive, longitudinal clinical data from the MIMIC-III to predict the ICU readmission of patients within 30 days of their discharge. We incorporate multiple types of features including chart events, demographic, and ICD-9 embeddings. We have utilized recent machine learning techniques such as Recurrent Neural Networks (RNN) with Long Short-Term Memory (LSTM), by this we have been able to incorporate the multivariate features of EHRs and capture sudden fluctuations in chart event features (e.g. glucose and heart rate). We show that our LSTM-based solution can better capture high volatility and unstable status in ICU patients, an important factor in ICU readmission. Our machine learning models identify ICU readmissions at a higher sensitivity rate of 0.742 (95% CI, 0.718-0.766) and an improved Area Under the Curve of 0.791 (95% CI, 0.782-0.800) compared with traditional methods. We perform in-depth deep learning performance analysis, as well as the analysis of each feature contribution to the predictive model. Conclusion Our manuscript highlights the ability of machine learning models to improve our ICU decision-making accuracy and is a real-world example of precision medicine in hospitals. These data-driven solutions hold the potential for substantial clinical impact by augmenting clinical decision-making for physicians and ICU specialists. We anticipate that machine learning models will improve patient counseling, hospital administration, allocation of healthcare resources and ultimately individualized clinical care.",2019
Two-stage stock portfolio optimization based on AI-powered price prediction and mean-CVaR models,"With the advancement of prediction methods in the field of artificial intelligence, accurate price predictions can effectively support financial portfolio selection. This paper proposes an intelligent stock portfolio selection method based on a prediction neural network, incorporating signal processing and hyperparameter optimization techniques. The method is divided into two key stages: stock price prediction and portfolio selection. In the first stage, we apply Savitzky-Golay filtering to denoise price data and reveal its patterns, and optimize the hyperparameters of the long short-term memory network using the sparrow search algorithm to achieve high-precision stock price predictions. In the second stage, we use the mean-Conditional Value-at-Risk (meanCVaR) model to select the optimal stock allocation, considering factors such as potential returns, prediction accuracy, and growth rate. Numerical comparisons based on multiple public financial datasets demonstrate that the proposed two-stage method significantly outperforms seven benchmark methods. Specifically, on the Shanghai and Shenzhen 300 (CSI 300) Index dataset, the proposed method achieves a determination coefficient of 0.9980 and an accuracy rate of 97.05%. Additionally, its cumulative returns reach 9.38%, 8.63%, and 7.54% at different confidence levels.",2024
A hybrid optimized deep learning model via the Golden Jackal Optimizer for accurate stock price forecasting,"Stock markets have historically been the reference point of the worldwide financial environment throughout the years. Investing in the stock market carries risk; however, it can offer significant short- or long-term returns for the investor. Forecasting stock prices has been a vital topic among professionals and researchers; however, it has always been a difficult task. Machine learning and metaheuristic algorithms over the last years have shown remarkable performance in a variety of sectors, encompassing the financial sector. In this work, we propose an optimized hybrid deep learning model via the Golden Jackal Optimizer (GJO) algorithm for the task of precise stock price prediction. We select the twenty highest stocks in terms of market capitalization from the S&P 500 index as our benchmark dataset. We compare the proposed model with eighteen different neural network models, as well as the PSO-GRU | LSTM and GA-GRU | LSTM models, which refer to optimized deep learning models using the Particle Swarm Optimization (PSO) algorithm and Genetic Algorithms (GA), respectively. The experiments are evaluated based on RMSE, MAE, and MAPE criteria. The results demonstrate that metaheuristicoptimized models outperform standard approaches, with the proposed GJO-GRU | LSTM model enhancing forecasting quality.",2025
Self-Attention Recurrent Conditional Generative Adversarial Networks for Corporate Credit Rating Prediction,"Financial risk management has always been a critical issue; banks, debt issuers, and government officials all need credit ratings in order to make intelligent financial decisions. Most of the existing studies on corporate credit rating prediction utilize financial statement features as their input data. Credit rating is closely related to credit risk. However, very few studies consider credit risk elements, such as credit systematic risk / beta and Credit Default Swap (CDS) spread data in credit rating prediction. Furthermore, the application of generative adversarial learning for corporate credit rating prediction was rarely investigated. In this work, a novel generative adversarial network (GAN), Self-Attention Recurrent Conditional GAN (SAR-CGAN) for corporate credit rating prediction is proposed. The proposed model takes advantage of Conditional GAN and Recurrent GAN to improve prediction performance. The financial statement features and corporates' CDS spread-related features: credit systematic risk / beta and quarter mean of CDS spread are used as input features. The proposed model adopts long short-term memory networks (LSTM) based on self-attention to process historical data and generate corporate credit rating. We improve the recurrent-based GAN model by modifying the network structure, in which the self-multi-head attention layer is added to capture the weighted importance of the time series data. Moreover, a data sampling strategy is designed to alleviate the overfitting issue and enhance the effectiveness of the proposed GAN model. The experimental results indicate that the proposed model performs better than other state-of-art models on the applied datasets.",2023
Portfolio Transformer for Attention-Based Asset Allocation,"Traditional approaches to financial asset allocation start with returns forecasting followed by an optimization stage that decides the optimal asset weights. Any errors made during the forecasting step reduce the accuracy of the asset weightings, and hence the profitability of the overall portfolio. The Portfolio Transformer (PT) network, introduced here, circumvents the need to predict asset returns and instead directly optimizes the Sharpe ratio, a risk-adjusted performance metric widely used in practice. The PT is a novel end-to-end portfolio optimization framework, inspired by the numerous successes of attention mechanisms in natural language processing. With its full encoder-decoder architecture, specialized time encoding layers, and gating components, the PT has a high capacity to learn long-term dependencies among portfolio assets and hence can adapt more quickly to changing market conditions such as the COVID-19 pandemic. To demonstrate its robustness, the PT is compared against other algorithms, including the current LSTM-based state of the art, on three different datasets, with results showing that it offers the best risk-adjusted performance.",2023
Low correlation portfolio formation with preselection using rich relational data,"The integration of return prediction and portfolio optimization has been widely proven effective. Traditional portfolio optimization approaches, however, rely solely on financial time series data, neglecting the inherent correlations among assets. This study introduces a novel low-correlation portfolio construction methodology utilizing rich relational data integrated via meta-paths. The proposed framework enhances return prediction while minimizing portfolio risk. In the first stage, Long Short-Term Memory (LSTM) networks are implemented to capture sequential patterns in the data. A Graph Neural Network (GNN) with a dual attention mechanism is employed in our framework. This network structure effectively summarizes information from relevant assets while selectively updating features. In the second stage, we develop an asset correlation scoring metric derived from the comprehensive relational data. Based on the predicted returns and correlation scores, we introduce two portfolio construction strategies: (1) a low-correlation strategy and (2) a hybrid strategy with high returns and low correlation. We use sample data from the S&P 500 Index between January 2017 and December 2021 to justify our proposed method. Results demonstrate that incorporating rich relational data significantly improves prediction accuracy. Under Markowitz's framework, the correlation of high-quality assets is negatively related to their optimal weights. The correlation scoring metric is demonstrated to facilitate portfolio optimization. Assets exhibiting low correlations contribute to portfolio variance reduction and enhanced risk-adjusted performance. Our Prediction-based Low Correlation Portfolio (P-LCP) enhances returns at lower levels of risk. The Prediction-based Hybrid Portfolio (P-HP) demonstrates exceptional performance in terms of cumulative returns and Sharpe ratios. This work implements a data-driven portfolio construction method that utilizes historical and relational data, highlighting the effectiveness of combining predictive theory with low-correlation portfolio strategies.",2025
Volatility index prediction based on a hybrid deep learning system with multi-objective optimization and mode decomposition,"Advances in volatility index prediction based on computational intelligence have brought wide-ranging benefits to financial risk management. However, current studies in the field remain limited and need further improve-ment due to these research gaps: (1) ignoring the important role of probabilistic prediction in characterizing uncertainty risks; (2) relying on single-objective optimization algorithm to optimize prediction model, thereby ignoring the advantages of multi-objective optimization; (3) emphasizing nonlinear modeling, not considering both nonlinear and linear modeling simultaneously. Aiming to address these gaps, a novel multi-objective hybrid deep learning system, composed of a modified multi-objective optimizer, a clockwork recurrent neural network, and an improved mode decomposition method, is newly proposed to perform deterministic and probabilistic volatility index prediction. Concretely, the volatility index is decomposed into some modes using an advanced data decomposition method; further, the clockwork recurrent neural network is considered a prediction engine to model these modes, which has an excellent ability to model the long-term dependency for linear and nonlinear time series depending on its mechanism of temporal granularity, as compared to traditional recurrent neural networks; finally, the prediction results can be obtained by integrating the predictions from these modes, using the mode weights calculated by an improved multi-objective optimizer with the objectives of prediction accuracy and stability. To validate the performance of the proposed hybrid deep learning system, case studies and cor-responding sensitivity and convergence analyses are carried out. From the perspective of the indicator mean absolute percentage error, the maximum improvements of our proposed system reach 67.50%, 75.82%, and 75.42% in Case I, Case II, and Case III, respectively, thus indicating its superiority and practical feasibility.",2023
Classification algorithms based on neural network and its application in the credit market,"The different types of classification algorithms for credit scoring systems are used to evaluate credit risk Neural Network-based systems that allow the system, through an analysis of historical data to determine the relationship between account characteristics and the probability of default.The backpropagation algorithm - the multilayer feedforward network structure is described based on data with nine financial ratios from 81 firms listed in china, A simulation on network is made. Neural Network model for classification algorithms are established. By varying Network Parameters we demonstrate that LevenbergMarque training error is smallest among 4 learning algorithms and its performance is better. Increasing the number of hidden layer can result in minor improvement.",2007
Android-IoT Malware Classification and Detection Approach Using Deep URL Features Analysis,"Currently, malware attacks pose a high risk to compromise the security of Android-IoT apps. These threats have the potential to steal critical information, causing economic, social, and financial harm. Because of their constant availability on the network, Android apps are easily attacked by URL-based traffic. In this paper, an Android malware classification and detection approach using deep and broad URL feature mining is proposed. This study entails the development of a novel traffic data preprocessing and transformation method that can detect malicious apps using network traffic analysis. The encrypted URL-based traffic is mined to decrypt the transmitted data. To extract the sequenced features, the N-gram analysis method is used, and afterward, the singular value decomposition (SVD) method is utilized to reduce the features while preserving the actual semantics. The latent features are extracted using the latent semantic analysis tool. Finally, CNN-LSTM, a multi-view deep learning approach, is designed for effective malware classification and detection.",2023
The implementation of leisure tourism enterprise management system based on deep learning,"The foremost part of the leisure tourism enterprise management system is evaluated and studied to explore the financial risk of leisure tourism enterprise and find the loopholes in enterprise risk management. First, the current financial risk management of tourism enterprises is evaluated, using the solvency of corporate finance, capital structure, operating efficiency, and profitability as indexes. Then, the backpropagation neural network (BPNN) model is constructed through the neural network in deep learning. Consequently, the BPNN algorithm model is used to identify and address risks and analyze the financial risks in the risk management system of leisure tourism enterprises. The results show that the shareholders' equity ratio has a great influence on the financial security of tourism enterprises; most of the tourism enterprises have a good financial situation, and most of them do not have large financial risk, and most of them can counter the debt risk properly. Thus, the BPNN model can effectively improve the efficiency and quality of the risk management system in traditional tourism enterprises. The results can help tourism enterprises utilize the enterprise management system better.",2021
ANN and SSO Algorithms for a Newly Developed Flexible Grid Trading Model,"In the modern era, the trading methods and strategies used in the financial market have gradually changed from traditional on-site trading to electronic remote trading, and even online automatic trading performed by pre-programmed computer programs. This is due to the conduct of trading automatically and self-adjustment in financial markets becoming a competitive development trend in the entire financial market, with the continuous development of network and computer computing technology. Quantitative trading aims to automatically form a fixed and quantifiable operational logic from people's investment decisions and apply it to the financial market, which has attracted the attention of the financial market. The development of self-adjustment programming algorithms for automatically trading in financial markets has transformed to being a top priority for academic research and financial practice. Thus, a new flexible grid trading model incorporating the Simplified Swarm Optimization (SSO) algorithm for optimizing parameters for various market situations as input values and the Fully Connected Neural Network (FNN) and Long Short-Term Memory (LSTM) model for training a quantitative trading model for automatically calculating and adjusting the optimal trading parameters for trading after inputting the existing market situation are developed and studied in this work. The proposed model provides a self-adjust model to reduce investors' effort in the trading market, obtains outperformed Return of Investment (ROI) and model robustness, and can properly control the balance between risk and return.",2022
Predicting movie box-office revenues using deep neural networks,"In the film industry, the ability to predict a movie's box-office revenues before its theatrical release can decrease its financial risk. However, accurate predictions are not easily obtained. The complex relationship between movie-related data and movie box-office revenues, plus the increasing volume of data in online movie databases, pose challenges for their effective analysis. In this paper, a multimodal deep neural network, incorporating input about movie poster features learned in a data-driven fashion, is proposed for movie box-office revenues prediction. A convolutional neural network (CNN) is built to extract features from movie posters. By pre-training the CNN, features that are relevant to movie box-office revenues can be learned. To evaluate the performance of the proposed multimodal deep neural network, comparative studies with other prediction techniques were carried out on an Internet Movie Database dataset, and visualization of movie poster features was also performed. Experimental results demonstrate the superiority of the proposed multimodal deep neural network for movie box-office revenues prediction.",2019
Development of a Deep Learning Algorithm for Automatic Diagnosis of Diabetic Retinopathy,"This paper mainly focuses on the deep learning application in classifying the stage of diabetic retinopathy and detecting the laterality of the eye using funduscopic images. Diabetic retinopathy is a chronic, progressive, sight-threatening disease of the retinal blood vessels. Ophthalmologists diagnose diabetic retinopathy through early funduscopic screening. Normally, there is a time delay in reporting and intervention, apart from the financial cost and risk of blindness associated with it. Using a convolutional neural network based approach for automatic diagnosis of diabetic retinopathy, we trained the prediction network on the publicly available Kaggle dataset. Approximately 35,000 images were used to train the network which observed a sensitivity of 80.28% and a specificity of 92.29% on the validation dataset of similar to 53,000 images. Using 8,810 images, the network was trained for detecting the laterality of the eye and observed an accuracy of 93.28% on the validation set of 8,816 images.",2017
Convolutional Neural Network for Software Vulnerability Detection,"Exploitable vulnerabilities in software are one of the root causes of cybercrime, leading to financial losses, reputational damage, and wider security breaches for both enterprise and consumers. Furthermore, checking for vulnerabilities in software is no longer a human-scale problem due to code volume and complexity. To help address this problem, our work presents a deep learning model able to identify risk signals in Java source code and output a classification for a program as either vulnerable or safe. Sequences of raw Java opcodes are used to train a convolutional neural network that automatically encapsulates discriminative characteristics of a program that are then used for the prediction. Compared to traditional machine learning methods, this approach requires no prior knowledge of the software vulnerability domain, nor any hand-crafted input features. When evaluated on the publicly available benchmark dataset Juliet Test Suite containing 38520 vulnerable and 38806 safe programs, our method achieves an F1 score of 0.92.",2022
An Improved Deep-Learning-Based Financial Market Forecasting Model in the Digital Economy,"The high-complexity, high-reward, and high-risk characteristics of financial markets make them an important and interesting study area. Elliott's wave theory describes the changing models of financial markets categorically in terms of wave models and is an advanced feature representation of financial time series. Meanwhile, deep learning is a breakthrough technique for nonlinear intelligent models, which aims to discover advanced feature representations of data and thus obtain the intrinsic laws underlying the data. This study proposes an innovative combination of these two concepts to create a deep learning + Elliott wave principle (DL-EWP) model. This model achieves the prediction of future market movements by extracting and classifying Elliott wave models from financial time series. The model's effectiveness is empirically validated by running it on financial data from three major markets and comparing the results with those of the SAE, MLP, BP network, PCA-BP, and SVD-BP models. Interestingly, the DL-EWP model based on deep confidence networks outperforms other models in terms of stability, convergence speed, and accuracy and has a higher forecasting performance. Thus, the DL-EWP model can improve the accuracy of financial forecasting models that incorporate Elliott's wave theory.",2023
"Crude oil price shocks, volatility spillovers, and global systemic financial risk transmission mechanisms: Evidence from the stock and foreign exchange markets","Crude oil, as one of the most important international bulk commodities, has both financial and geopolitical attributes. As such, its price fluctuations are bound to have profound impacts on the international financial markets. We decomposed crude oil price shocks into supply, demand and risk shocks using a structural vector autoregressive (SVAR) model. We then established a network of volatility spillovers and selected four typical time periods to examine the spillover effects between the three price shocks, the global stock market, and the foreign exchange market. Based on this data, we constructed the DCC-GARCH and asymmetric BEKK-GARCH models to study the dy-namic interconnections between markets, risk spillover effects, and cross-impact relationships. Finally, we established an early warning model for the risk of oil price fluctuations using the machine learning method of the long short-term memory (LSTM).Based on the empirical research, this paper draws the following conclusions: (a) the risk spillovers of crude oil price shocks exhibit typical time-variant characteristics in different periods, with demand shocks having the strongest spillover effects, while the effects of supply shocks are the weakest; (b) in the vast majority of cases, crude oil-importing countries are the recipients of these risks; and (c) due to the close linkage between global stock markets and foreign exchange markets, the possibility of oil price shocks exacer-bating the spread of global systemic financial risks is greatly enhanced. The findings provide policymakers and investors with a reference for the regulation of market operations, as well as risk prevention and avoidance.",2023
Which uncertainty measure better predicts gold prices? New evidence from a CNN-LSTM approach,"Quantifying the influence of uncertainty on gold prices is significant for improving related financial decision making. This study proposes a novel CNN-LSTM neural network that can extract potential features from sample data to effectively predict gold prices. Specifically, we demonstrate various uncertainty measures containing market volatility information, such as the economic policy uncertainty index (EPU), epidemic stock market volatility index (IDEMV), and volatility index (VIX), which can contribute to the prediction of gold prices rather than relying solely on the history of tickers, which is conventionally used for prediction. In addition, the proposed model is evaluated against SVR and two different LSTM models. The empirical findings reveal that incorporating additional features, such as uncertainty measures, contributes to improving the predictive accuracy of the model. The CNN-LSTM model, with the inclusion of EPU, IDEMV, and both, achieves a high prediction accuracy. Additionally, the overall prediction accuracy of the CNN-LSTM model outperforms the other proposed methods. The findings provide profound insight into portfolio diversification and risk management practices for governments and businesses.",2025
Artificial intelligence-driven financial innovation: A robo-advisor system for robust returns across diversified markets,"With the advancement in artificial intelligence, robo-advisor systems have emerged as powerful tools for formulating financial product trading strategies and assisting investors in making rational investment decisions. Consequently, to reduce risk and provide investors greater returns in volatile markets, improving the performance of these systems has become a key research focus. This paper proposes an enhanced roboadvisor system that employs deep mathematical feature engineering to embed a hybrid mechanism for robust feature extraction. The system implements a novel integrated algorithm, where technical indicators are first decomposed using variational mode decomposition technology, followed by feature extraction through a deep convolutional neural network with an attention mechanism. The high-level features are then fed into a bidirectional gated recurrent unit network to predict returns on short-term time-scale financial products. The experimental results indicate that the proposed robo-advisor system achieves robust, remarkable return performance on several types of assets under different market conditions, and provides decision support for investors in managing asset risks and seeking cross-market investment opportunities.",2025
Research on corporate financial performance prediction based on self-organizing and convolutional neural networks,"Economic risks faced by manufacturing enterprises are gradually increasing and risk reduction whilst maintaining high financial performance has become key to their survival and development of enterprises. Enterprise performance affects not only enterprise development but also does the interests of investors and creditors. Therefore, a well-performing model for financial performance prediction is particularly important. In this paper, we combine unsupervised and supervised learning, fusing self-organizing mapping neural networks and convolutional neural networks, and apply deep learning to financial analysis to construct a new financial performance prediction model, called SNN-CNN. This paper uses crawler technology to obtain financial data of listed manufacturing enterprises and classifies their financial performance into five levels. It finds that enterprises with high financial performance tend to have balanced financial indicators, strong corporate vitality and stable development of various capabilities, while enterprises with low financial performance have poor repayment and profitability, significant risks in corporate operation and limited growth and development. Compared with traditional risk prediction models, the SOM-CNN model has a higher accuracy rate, up to 95.69%.",2022
GALSTM-FDP: A Time-Series Modeling Approach Using Hybrid GA and LSTM for Financial Distress Prediction,"Despite the obvious benefits and growing popularity of Machine Learning (ML) technology, there are still concerns regarding its ability to provide Financial Distress Prediction (FDP). An accurate FDP model is required to avoid financial risk at the lowest possible cost. However, in the Internet era, financial data are exploding, and they are being coupled with other kinds of risk data, making an FDP model challenging to operate. As a result, researchers presented several novel FDP models based on ML and Deep Learning. Time series data is are important to reflect the multi-source and heterogeneous aspects of financial data. This paper gives insight into building a time-series model and forecasting distress far in advance of its occurrence. To build an efficient FDP model, we provide a hybrid model (GALSTM-FDP) that incorporates LSTM and GA. Unlike other previous studies, which established models that predicted distress probability only within one year, our approach predicts distress two years ahead. This research integrates GA with LSTM to find the optimum hyperparameter configuration for LSTM. Using GA, we focus on optimizing architectural aspects for modeling the optimal network based on prediction accuracy. The results showed that our algorithm outperforms other state-of-the-art methods in terms of predictive accuracy.",2023
Research on credit risk of listed companies: a hybrid model based on TCN and DilateFormer,"The ability to assess and manage corporate credit risk enables financial institutions and investors to mitigate risk, enhance the precision of their decision-making, and adapt their strategies in a prompt and effective manner. The growing quantity of data and the increasing complexity of indicators have rendered traditional machine learning methods ineffective in enhancing the accuracy of credit risk assessment. Consequently, academics have begun to explore the potential of models based on deep learning. In this paper, we apply the concept of combining Transformer and CNN to the financial field, building on the traditional CNN-Transformer model's capacity to effectively process local features, perform parallel processing, and handle long-distance dependencies. To enhance the model's ability to capture financial data over extended periods and address the challenge of high-dimensional financial data, we propose a novel hybrid model, TCN-DilateFormer. This integration improves the accuracy of corporate credit risk assessment. The empirical study demonstrates that the model exhibits superior prediction accuracy compared to traditional machine learning assessment models, thereby offering a novel and efficacious tool for corporate credit risk assessment.",2025
The Global Organizational Behavior Analysis for Financial Risk Management Utilizing Artificial Intelligence,"Enterprise financial risks are analyzed utilizing the theory of organizational behavior, and a financial risk management system is constructed to improve the design and algorithm of the enterprise risk management system. Based on the CCER (China Center for Economic Research) database, the early warning model for enterprise financial risk management containing five indices is proposed for enterprises. Through logistic regression analysis, the design principle of the financial risk management system based on AI (artificial intelligence) technology is explained. The proposed system innovatively introduces the AI-integrated learning method, optimizes objective function through XGBoost (extreme gradient boosting) algorithm, and trains the model through BP (backpropagation) NN (neural network). Finally, following comparative analysis, the effectiveness of the proposed method is verified.",2022
Forecasting the volatility of stock price index: A hybrid model integrating LSTM with multiple GARCH-type models,"Volatility plays crucial roles in financial markets, such as in derivative pricing, portfolio risk management, and hedging strategies. Therefore, accurate prediction of volatility is critical. We propose a new hybrid long short-term memory (LSTM) model to forecast stock price volatility that combines the LSTM model with various generalized autoregressive conditional heteroscedasticity (GARCH)-type models. We use KOSPI 200 index data to discover proposed hybrid models that combine an LSTM with one to three GARCH-type models. In addition, we compare their performance with existing methodologies by analyzing single models, such as the GARCH, exponential GARCH, exponentially weighted moving average, a deep feedforward neural network (DFN), and the LSTM, as well as the hybrid DFN models combining a DFN with one GARCH-type model. Their performance is compared with that of the proposed hybrid LSTM models. We discover that GEW-LSTM, a proposed hybrid model combining the LSTM model with three GARCH-type models, has the lowest prediction errors in terms of mean absolute error (MAE), mean squared error (MSE), heteroscedasticity adjusted MAE (HMAE), and heteroscedasticity adjusted MSE (HMSE). The MAE of GEW-ISTM is 0.0107, which is 37.2% less than that of the E-DFN (0.017), the model combining EGARCH and DFN and the best model among those existing. In addition, the GEW-LSTM has 57.3%, 24.7%, and 48% smaller MSE, HMAE, and HMSE, respectively. The first contribution of this study is its hybrid LSTM model that combines excellent sequential pattern learning with improved prediction performance In stock market volatility. Second, our proposed model markedly enhances prediction performance of the existing literature by combining a neural network model with multiple econometric models rather than only a single econometric model. Finally, the proposed methodology can be extended to various fields as an integrated model combining time-series and neural network models as well as forecasting stock market volatility. (C) 2018 Elsevier Ltd. All rights reserved.",2018
Research of BP-SOM evaluation model and its application,"Various neural network models have proven useful in evaluation or prediction. Neural classification ability is just beginning to be deployed in financial application. And it is very important to study credit evaluation model when create a credit risk prediction system. This paper analyses the disadvantage of traditional model based on statistical analysis, and proposed a hybrid system to combine the backpropagation (BP) learning with Kohonen's Self-Organizing Map (SOM) Neural Network, for the application of credit risk evaluation. BP Neural Network has been successfully used in several domains of artificial intelligence. In order to enhance its generalization performance, we connected the SOM method to deal with overfitting problem of BP. After discussing the structure and arithmetic of the model, we train the model with financial ratios for a credit risk early warning experiment The preliminary experimental results demonstrate that the BP-SOM model outperforms some traditional ones in rates of prediction precision and efficiency, and improves generalization performance.",2008
An adaptive local linear optimized radial basis functional neural network model for financial time series prediction,"For financial time series, the generation of error bars on the point of prediction is important in order to estimate the corresponding risk. In recent years, optimization techniques-driven artificial intelligence has been used to make time series approaches more systematic and improve forecasting performance. This paper presents a local linear radial basis functional neural network (LLRBFNN) model for classifying finance data from Yahoo Inc. The LLRBFNN model is learned by using the hybrid technique of backpropagation and recursive least square algorithm. The LLRBFNN model uses a local linear model in between the hidden layer and the output layer in contrast to the weights connected from hidden layer to output layer in typical neural network models. The obtained prediction result is compared with multilayer perceptron and radial basis functional neural network with the parameters being trained by gradient descent learning method. The proposed technique provides a lower mean squared error and thus can be considered as superior to other models. The technique is also tested on linear data, i.e., diabetic data, to confirm the validity of the result obtained from the experiment.",2017
Telecom Churn Prediction Using CNN with Variational Autoencoder,"Customer churn is a major problem across traditional and new age companies like telecom, digital services providers, online marketplace, payment banking and social media companies. Customer churn means customer is moving out from the company, hence impacting the top line of financial sheets. This is particularly more relevant for companies having subscription-based plans. Telecom industry which has sizable customer base and cut-throat competition is at higher risk of impact due to churn. With the customer database size running into petabyte and terabytes, it is a tedious and time-taking task to accurately predict customer churn based on some random logic. While machine learning appears to be an easier alternative, often such database contains large number of string attributes that are tough to use in machine learning algorithms. Various traditional machine learning and data mining techniques have been applied for handling such big data. All such techniques have leveraged different techniques for data engineering. In this study, we have demonstrated how a new and powerful technique convolutional neural network with variational autoencoder can help predict churn with higher accuracy. CNN automatically has the ability of good feature selection and representation of input data, and this study has come with a new aspect, i.e. integrating all string attributes in dataset (ISAD) for using all existing string variable of database helping in enhancing model performance. Experiment is done on three telecom companies Cell2Cell, Telco and Orange datasets of size 51,048, 7048 and 3333, respectively. Model outperformed on all three datasets and achieved a good accuracy level. ISAD model helped to enhance the performance by giving more feature option for predicting the customer behaviour correctly.",2022
"A Comparative Analysis on Probability of Volatility Clusters on Cryptocurrencies, and FOREX Currencies","In recent years, the attention of investors, practitioners and academics has grown in cryptocurrency. Initially, the cryptocurrency was designed as a viable digital currency implementation, and subsequently, numerous derivatives were produced in a range of sectors, including nonmonetary activities, financial transactions, and even capital management. The high volatility of exchange rates is one of the main features of cryptocurrencies. The article presents an interesting way to estimate the probability of cryptocurrency volatility clusters. In this regard, the paper explores exponential hybrid methodologies GARCH (or EGARCH) and through its portrayal as a financial asset, ANN models will provide analytical insight into bitcoin. Meanwhile, more scalable modelling is needed to fit financial variable characteristics such as ANN models because of the dynamic, nonlinear association structure between financial variables. For financial forecasting, BP is contained in the most popular methods of neural network training. The backpropagation method is employed to train the two models to determine which one performs the best in terms of predicting. This architecture consists of one hidden layer and one input layer with N neurons. Recent theoretical work on crypto-asset return behavior and risk management is supported by this research. In comparison with other traditional asset classes, these results give appropriate data on the behavior, allowing them to adopt the suitable investment decision. The study conclusions are based on a comparison between the dynamic features of cryptocurrencies and FOREX Currency's traditional mass financial asset. Thus, the result illustrates how well the probability clusters show the impact on cryptocurrency and currencies. This research covers the sample period between August 2017 and August 2020, as cryptocurrency became popular around that period. The following methodology was implemented and simulated using Eviews and SPSS software. The performance evaluation of the cryptocurrencies is compared with FOREX currencies for better comparative study respectively.",2021
Deep Robust Reinforcement Learning for Practical Algorithmic Trading,"In algorithmic trading, feature extraction and trading strategy design are two prominent challenges to acquire long-term profits. However, the previously proposed methods rely heavily on domain knowledge to extract handcrafted features and lack an effective way to dynamically adjust the trading strategy. With the recent breakthroughs of deep reinforcement learning (DRL), sequential real-world problems can be modeled and solved with a more human-like approach. In this paper, we propose a novel trading agent, based on deep reinforcement learning, to autonomously make trading decisions and gain profits in the dynamic financial markets. We extend the value-based deep Q-network (DQN) and the asynchronous advantage actor-critic (A3C) for better adapting to the trading market. Specifically, in order to automatically extract robust market representations and resolve the financial time series dependence, we utilize the stacked denoising autoencoders (SDAEs) and the long short-term memory (LSTM) as parts of the function approximator, respectively. Furthermore, we design several elaborate mechanisms to make the trading agent more practical to the real trading environment, such as position-controlled action and n-step reward. The experimental results show that our trading agent outperforms the baselines and achieves stable risk-adjusted returns in both the stock and the futures markets.",2019
Multi-Step Multidimensional Statistical Arbitrage Prediction Using PSO Deep-ConvLSTM: An Enhanced Approach for Forecasting Price Spreads,"Due to its effectiveness as a risk-hedging trading strategy in financial markets, futures arbitrage is highly sought after by investors in turbulent market conditions. The essence of futures arbitrage lies in formulating strategies based on predictions of future futures price differentials. However, contemporary research predominantly focuses on projections of single indicators for the subsequent temporal juncture, and devising efficacious arbitrage strategies often necessitates the examination of multiple indicators across timeframes. To tackle the aforementioned challenge, our methodology leverages a PSO Deep-ConvLSTM network, which, through particle swarm optimization (PSO), refines hyperparameters, including layer architectures and learning rates, culminating in superior predictive performance. By analyzing temporal-spatial data within financial markets through ConvLSTM, the model captures intricate market patterns, performing better in forecasting than traditional models. Multistep forward simulation experiments and extensive ablation studies using future data from the Shanghai Futures Exchange in China validate the effectiveness of the integrated model. Compared with the gate recurrent unit (GRU), long short-term memory (LSTM), Transformer, and FEDformer, this model exhibits an average reduction of 39.8% in root mean squared error (RMSE), 42.5% in mean absolute error (MAE), 45.6% in mean absolute percentage error (MAPE), and an average increase of 1.96% in coefficient of determination (R2) values.",2024
Investor sentiment-aware prediction model for P2P lending indicators based on LSTM,"In recent years, online lending has created many risks while providing lending convenience to Chinese individuals and small and medium-sized enterprises. The timely assessment and prediction of the status of industry indicators is an important prerequisite for effectively preventing the spread of risks in China's new financial formats. The role of investor sentiment should not be underestimated. We first use the BERT model to divide investor sentiment in the review information of China's online lending third-party information website into three categories and analyze the relationship between investor sentiment and quantitative indicators of online lending product transactions. The results show that the percentage of positive comments has a positive relationship to the borrowing interest rate of P2P platforms that investors are willing to participate in for bidding projects. The percentage of negative comments has an inverse relationship to the borrowing period. Second, after introducing investor sentiment into the long short-term memory (LSTM) model, the average RMSE of the three forecast periods for borrowing interest rates is 0.373, and that of the borrowing period is 0.262, which are better than the values of other control models. Corresponding suggestions for the risk prevention of China's new financial formats are made.",2022
Predicting At-Risk Students Using Clickstream Data in the Virtual Learning Environment,"In higher education, predicting the academic performance of students is associated with formulating optimal educational policies that vehemently impact economic and financial development. In online educational platforms, the captured clickstream information of students can be exploited in ascertaining their performance. In the current study, the time-series sequential classification problem of students' performance prediction is explored by deploying a deep long short-term memory (LSTM) model using the freely accessible Open University Learning Analytics dataset. In the pass/fail classification job, the deployed LSTM model outperformed the state-of-the-art approaches with 93.46% precision and 75.79% recall. Encouragingly, our model superseded the baseline logistic regression and artificial neural networks by 18.48% and 12.31%, respectively, with 95.23% learning accuracy. We demonstrated that the clickstream data generated due to the students' interaction with the online learning platforms can be evaluated at a week-wise granularity to improve the early prediction of at-risk students. Interestingly, our model can predict pass/fail class with around 90% accuracy within the first 10 weeks of student interaction in a virtual learning environment (VLE). A contribution of our research is an informed approach to advanced higher education decision-making towards sustainable education. It is a bold effort for student-centric policies, promoting the trust and the loyalty of students in courses and programs.",2019
"Discovery and Prediction of Stock Index Pattern via Three-Stage Architecture of TICC, TPA-LSTM and Multivariate LSTM-FCNs","In this study, we attempt to discover and predict stock index patterns through analysis of multivariate time series. Our motivation is based on the notion that financial planning guided by pattern discovery and prediction of stock index prices maybe more realistic and effective than traditional approaches, such as Autoregressive Integrated Moving Average (ARIMA) model. A three-stage architecture constructed by combining Toeplitz Inverse Covariance-Based Clustering (TICC), Temporal Pattern Attention and Long- Short-Term Memory (TPA-LSTM) and Multivariate LSTM-FCNs (MLSTM-FCN and MALSTM-FCN) is applied for pattern discovery and prediction of stock index. In the first stage, we use TICC to discover repeated patterns of stock index. Then, in the second stage, TPA-LSTM that considers weak periodic patterns and long short-term information is used to predict multivariate stock indices. Finally, in the third stage, MALSTM-FCN is applied to predict stock index price pattern. The Hangseng Stock Index and eleven industrial sub-indices are used in the experiment. Empirical results show that the three-stage architecture achieves satisfactory and better performance than traditional methods, such as Naive Bayes Classifier (NB), Support Vector Machine Classifier (SVM), Random Forest (RF), etc. Moreover, we construct equal proportion portfolios based on the bullish trading rules to further analyze the feasibility of the proposed three-stage architecture. Seven comprehensive stock indices are used in the experiment. Empirical results show that the portfolio based on the proposed three-stage architecture presents better performance than the market-based portfolio. These findings may provide new direction for the portfolio construction and risk aversion.",2020
Deep learning-based NT-proBNP prediction from the ECG for risk assessment in the community,"Objectives: The biomarker N-terminal pro B-type natriuretic peptide (NT-proBNP) has predictive value for identifying individuals at risk for cardiovascular disease (CVD). However, it is not widely used for screening in the general population, potentially due to financial and operational reasons. This study aims to develop a deep-learning model as an efficient means to reliably identify individuals at risk for CVD by predicting serum levels of NT-proBNP from the ECG.Methods: A deep convolutional neural network was developed using the population-based cohort study Hamburg City Health Study (HCHS, n=8,253, 50.9 % women). External validation was performed in two independent population-based cohorts (SHIP-START, n=3,002, 52.1 % women, and SHIP-TREND, n=3,819, 51.2 % women). Assessment of model performance was conducted using Pearson correlation (R) and area under the receiver operating characteristics curve (AUROC).Results: NT-proBNP was predictable from the ECG (R, 0.566 [HCHS], 0.642 [SHIP-START-0], 0.655 [SHIP-TREND-0]). Across cohorts, predicted NT-proBNP (pNT-proBNP) showed good discriminatory ability for prevalent and incident heart failure (HF) (baseline: AUROC 0.795 [HCHS], 0.816 [SHIP-START-0], 0.783 [SHIP-TREND-0]; first follow-up: 0.669 [SHIP-START-1, 5 years], 0.689 [SHIP-TREND-1, 7.3 years]), comparable to the discriminatory value of measured NT-proBNP. pNT-proBNP also demonstrated comparable results for other incident CVD, including atrial fibrillation, stroke, myocardial infarction, and cardiovascular death.Conclusions: Deep learning ECG algorithms can predict NT-proBNP concentrations with high diagnostic and predictive value for HF and other major CVD and may be used in the community to identify individuals at risk. Long-standing experience with NT-proBNP can increase acceptance of such deep learning models in clinical practice.",2024
SELF-ATTENTIVE SENTIMENTAL SENTENCE EMBEDDING FOR SENTIMENT ANALYSIS,"We propose the use of a word-level sentiment bidirectional LSTM in tandem with the self-attention mechanism for sentence-level sentiment prediction. In addition to the proposed model, we also present a finance report dataset for sentence-level financial risk detection. Experiments conducted on the proposed dataset together with two public review datasets attest the effectiveness of our model for sentence sentiment prediction.",2020
Management Analysis Method of Multivariate Time Series Anomaly Detection in Financial Risk Assessment,"The significance of financial risk lies in its impact on economic stability and individual/institutional financial security. Effective risk management is crucial for market confidence and crisis prevention. Current methods for multivariate time series anomaly detection have limitations in adaptability and generalization. To address this, we propose an innovative approach integrating contrastive learning and Generative Adversarial Networks (GANs). We use geometric distribution masking for data augmentation to enhance dataset diversity. Within the GAN framework, we train a Transformer -based autoencoder to capture normal point distributions. We include contrastive loss in the discriminator to ensure robust generalization. Rigorous experiments on four real -world datasets show that our method effectively mitigates overfitting and outperforms state-of-the-art approaches. This enhances anomaly identification in risk management, paving the way for deep learning in finance, and offering insights for future research and practical use.",2024
A monetary policy prediction model based on deep learning,"Applying neural network and error t-value test, this study trains and analyzes 28 interest rate changes of China's macro-monetary policy and the mutual influences between reserve adjustments and financial markets for 51 times from 2000 to 2018 according to the data correlation between financial market and monetary policy. Through the principal component analysis, the bilateral financial risk system and data set are established, and the data set pre-process and dimensionality reduction are carried out to extract the most informative features. Six training cases are designed with processed features, and then the cases are input to each neural network model for combined prediction. Firstly, based on backpropagation neural network (BP), the forecasting model of monetary policy is established. Then, considering the importance characteristics of financial index data, expert weights based on BP, are introduced to propose weights backpropagation (WBP) model. On the basis of the timing characteristics of financial market, the WBP model is improved and the timing weights backpropagation (TWBP) model is proposed. Experiments show that different training cases bring out various effects. The accuracy rate of interest rate and reserve change value is lower than the original value after training. The mutation after data processing affects the learning of neural network. At the same time, the WBP and TWBP models improve according to the importance and timing characteristics of financial indicators have less errors in results, and the TWBP model has higher accuracy. When the number of hidden layers is 3, good results can be obtained, but in manifold training of the timing cycle, the efficiency of that is not as good as the WBP model.",2020
Deep Learning-Based Attention Mechanism Algorithm for Blockchain Credit Default Prediction,"With the rise of internet finance and the increasing demand for personal credit risk management, accurate credit default prediction has become essential for financial institutions. Traditional models face limitations in handling complex and largescale data, especially in the blockchain domain, which has emerged as a crucial technology for securing and processing financial transactions. This paper aims to improve the accuracy and generalization of blockchain-based credit default prediction models by optimizing deep learning algorithms with the Special Forces Algorithm (SFA) and attention mechanism (AM) networks. The study introduces a hybrid approach combining SFA with AM to optimize hyperparameters of the credit default prediction model. The model preprocesses blockchain credit data, extracts critical features such as user and loan information, and applies the SFA-AM algorithm to improve classification accuracy. Comparative analysis is conducted using other machine learning algorithms like XGBoost, LightGBM, and LSTM. Results: The SFA-AM model outperforms traditional models in key metrics, achieving higher precision (0.8289), recall (0.8075), F1 score (0.8180), and AUC value (0.9407). The model demonstrated better performance in identifying both default and non-default cases compared to other algorithms, with significant improvements in reducing misclassifications. The proposed SFA-AM model significantly enhances blockchain credit default prediction accuracy and generalization. While effective, the study acknowledges limitations in dataset diversity and model interpretability, suggesting future research could expand on these areas for more robust applications across different financial sectors.",2025
Users Sentiment Analysis Using Artificial Intelligence-Based FinTech Data Fusion in Financial Organizations,"Innovative applications surprised the research communities in the 21st by presenting in diverse domains. Financial technology (FinTech) is an example of these innovative applications. Financial technology applications have renovated traditional banking systems into improved smart business models. Financial technology applications enable the customers with minimum risk or other possible attacks and can make transactions through credit cards and mobile applications from anywhere and anytime. However still the customer doesn't fully trusted and preferred the uncertain behavior about FinTech-driven applications. To precisely solve this uncertain behavior of customer sentiments, this paper identifies and encourage them towards the use of FinTech-assisted applications. This paper proposed a pipelined model to evaluate user sentiments for their uncertain behaviors towards these FinTech-assisted applications. The proposed model consists of a convolutional neural network (CNN) and support vector machine (SVM), where the CNN is used for classifying the sentiments of different behaviors while SVM is used for statistical information to measure to what extent the users reflect negative behavior. The simulation results are based on the sentiments of users against the OVO application and Mint application on Google Play Store. An overall accuracy rate of 91.7% is recorded for the OVO application. This high accuracy rate reflects the satisfaction of the users with the OVO application and Mint application. Furthermore, this automatic analysis of negative reviews can be used as evidence for future contributions in the revised versions of these applications to secure a safer and more competitive position in the market.",2024
High return and low risk: Shaping composite financial investment decision in the new energy stock market,"As an emerging market, the new energy stock market is characterized by high volatility and instability, and investors seeking to make investment decisions face significant challenges. To enable investors to diversify risk and obtain more consistent high returns, we have built a composite financial investment decision system that combines portfolio selection, trend forecasting, and quantitative trading. The system takes a sequential, rolling Sharpe ratio calculation and dynamically selects portfolios to reduce risk from market changes and achieve optimal portfolio diversification. Then, the variational mode decomposition (VMD)-bidirectional gated recurrent unit (BiGRU) model is introduced to predict the trend of the portfolio and quantify the trades of the portfolios. Experimental results show that the system can obtain an average annual return of up to 758,508 CNY with a principal capital of 30,000 CNY. Compared with observing the investment ratio of the portfolio statically, selecting the portfolio by calculating the Sharpe ratio continuously and rolling can improve the portfolio return and diversify the risk. In terms of trend forecasting, VMD-BiGRU is shown to greatly improve forecasting performance compared to single gated recurrent unit (GRU) or long short-term memory (LSTM) models. Compared with human-driven trading, quantitative trading has been shown to have the advantage of short holding times, low risk, and high returns by capturing trading opportunities promptly based on the results obtained from predictive models.",2023
Hierarchical Gated Recurrent Unit with Semantic Attention for Event Prediction,"Event prediction plays an important role in financial risk assessment and disaster warning, which can help government decision-making and economic investment. Previous works are mainly based on time series for event prediction such as statistical language model and recurrent neural network, while ignoring the impact of prior knowledge on event prediction. This makes the direction of event prediction often biased or wrong. In this paper, we propose a hierarchical event prediction model based on time series and prior knowledge. To ensure the accuracy of the event prediction, the model obtains the time-based event information and prior knowledge of events by Gated Recurrent Unit and Associated Link Network respectively. The semantic selective attention mechanism is used to fuse the time-based event information and prior knowledge, and finally generate predicted events. Experimental results on Chinese News datasets demonstrate that our model significantly outperforms the state-of-the-art methods, and increases the accuracy by 2.8%.",2020
Credit default swap prediction based on generative adversarial networks,"Purpose Financial price forecast issues are always a concern of investors. However, the financial applications based on machine learning methods mainly focus on stock market predictions. Few studies have explored credit risk predictions. Understanding credit risk trends can help investors avoid market risks. The purpose of this study is to investigate the prediction model that can effectively predict credit default swaps (CDS). Design/methodology/approach A novel generative adversarial network (GAN) for CDS prediction is proposed. The authors take three features into account that are highly relevant to the future trends of CDS: historical CDS price, news and financial leverage. The main goal of this model is to improve the existing GAN-based regression model by adding finance and news feature extraction approaches. The proposed model adopts an attentional long short-term memory network and convolution network to process historical CDS data and news information, respectively. In addition to enhancing the effectiveness of the GAN model, the authors also design a data sampling strategy to alleviate the overfitting issue. Findings The authors conduct an experiment with a real dataset and evaluate the performance of the proposed model. The components and selected features of the model are evaluated for their ability to improve the prediction performance. The experimental results show that the proposed model performs better than other machine learning algorithms and traditional regression GAN. Originality/value There are very few studies on prediction models for CDS. With the proposed novel approach, the authors can improve the performance of CDS predictions. The proposed work can thereby increase the commercial value of CDS predictions to support trading decisions.",2022
A Novel Linear-Model-Based Methodology for Predicting the Directional Movement of the Euro-Dollar Exchange Rate,"Predicting the price and trends of financial instruments is a major challenge in the financial industry, impacting investment decision-making efficiency for various stakeholders. Although numerous and effective artificial intelligence techniques have been applied to time series analysis, the prediction of exchange rate movements in the Forex market still necessitates parsimonious, interpretable, and accurate solutions. This paper presents a novel methodology for predicting the short-term directional movement of the euro-dollar exchange rate using market data, specifically by measuring price action. The proposed methodology prioritizes using market inflection points and the multidimensional nature of the differences between uptrends and downtrends to construct a linear discriminant function (LDA). The core of our methodology is our novel Linear Classifier Configurator (LCC) which includes stages for data preparation, feature selection, and detection of underlying structures. We validate the results and interpretations using the statistical power of parametric tests. The experiments use market data of the euro-dollar exchange rate in 15-minute and 1-week time frames. Additionally, we incorporate a collection of intraday winning trades provided by an algorithmic trading model applied between January 1999 and April 2023. The proposed LCC methodology achieves an out-of-sample classification accuracy of 98.77%, outperforming other methodologies based on sophisticated approaches such as Long Short-Term Memory (LSTM), Deep reinforcement learning (DRL), Wavelet analysis (WA), Sentiment analysis of textual content, Support Vector Machines (SVM), and Genetic Algorithms (GA). Furthermore, our methodology improves financial performance and reduces risk exposure in trading strategies, as well as it is useful in selecting variables and transferable to other financial assets.",2023
Prediction of the Stock Market From Linguistic Phrases: A Deep Neural Network Approach,"Automation of financial data collection, generation, accumulation, and interpretation for decision making may reduce volatility in the stock market and increase liquidity occasionally. Thus, future markets' prediction factoring in the sentiment of investors and algorithmic traders is an exciting area for research with deep learning techniques emerging to understand the market and its future direction. The paper develops two FINBERT deep neural network models pre-trained on the financial phrase dataset, the first one to extract sentiment from the NSE market news. The second model is adopted to predict the stock market movement of NSE with the above sentiment, historical stock prices, return on investment, and risk as predictors. The accuracy is compared with RNN and LSTM and baseline machine learning classifiers like naive bayes and support vector machine (SVM). The accuracy of the FINBERT model is found to out-perform the deep learning algorithms and above baseline machine learning classifiers thus justifying the importance of the FINBERT model in stock market prediction.",2023
Stock Market Forecasting Using Deep Learning and Technical Analysis: A Systematic Review,"Stock market forecasting is one of the biggest challenges in the financial market since its time series has a complex, noisy, chaotic, dynamic, volatile, and non-parametric nature. However, due to computing development, an intelligent model can help investors and professional analysts reduce the risk of their investments. As Deep Learning models have been extensively studied in recent years, several studies have explored these techniques to predict stock prices using historical data and technical indicators. However, as the objective is to generate forecasts for the financial market, it is essential to validate the model through profitability metrics and model performance. Therefore, this systematic review focuses on Deep Learning models implemented for stock market forecasting using technical analysis. Discussions were made based on four main points of view: predictor techniques, trading strategies, profitability metrics, and risk management. This study showed that the LSTM technique is widely applied in this scenario (73.5%). This work significant contribution is to highlight some limitations found in the literature, such as only 35.3% of the studies analysed profitability, and only two articles implemented risk management. Therefore, despite the widely explored theme, there are still interesting open areas for research and development.",2020
A Deep Learning approach for Diagnosis of Mild Cognitive Impairment Based on MRI Images,"Mild cognitive impairment (MCI) is an intermediary stage condition between healthy people and Alzheimer's disease (AD) patients and other dementias. AD is a progressive and irreversible neurodegenerative disorder, which is a significant threat to people, age 65 and older. Although MCI does not always lead to AD, an early diagnosis at the stage of MCI can be very helpful in identifying people who are at risk of AD. Moreover, the early diagnosis of MCI can lead to more effective treatment, or at least, significantly delay the disease's progress, and can lead to social and financial benefits. Magnetic resonance imaging (MRI), which has become a significant tool for the diagnosis of MCI and AD, can provide neuropsychological data for analyzing the variance in brain structure and function. MCI is divided into early and late MCI (EMCI and LMCI) and sadly, there is no clear differentiation between the brain structure of healthy people and MCI patients, especially in the EMCI stage. This paper aims to use a deep learning approach, which is one of the most powerful branches of machine learning, to discriminate between healthy people and the two types of MCI groups based on MRI results. The convolutional neural network (CNN) with an efficient architecture was used to extract high-quality features from MRIs to classify people into healthy, EMCI, or LMCI groups. The MRIs of 600 individuals used in this study included 200 control normal (CN) people, 200 EMCI patients, and 200 LMCI patients. This study randomly selected 70 percent of the data to train our model and 30 percent for the test set. The results showed the best overall classification between CN and LMCI groups in the sagittal view with an accuracy of 94.54 percent. In addition, 93.96 percent and 93.00 percent accuracy were reached for the pairs of EMCI/LMCI and CN/EMCI, respectively.",2019
Improving Financial Forecasting Accuracy Through Swarm Optimization-Enhanced Deep Learning Models,"Financial forecasting is a crucial factor for decision-making in numerous fields, it demands very accurate predictive models. Traditional methods, like Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Gradient Boosting Machines (GBM), display suitable performance however have proven not totally efficient in complex high-dimensional financial data. This paper introduces a new approach combining swarm-based algorithms and deep learning architectures to improve predicative accuracy in financial forecasting. The proposed method relies on elite data preprocessing algorithms to optimize the learning process and prevent overfitting. By experimenting with large variety of dataset, the optimized model was able to achieve accuracy of 98% out running traditional models such as CNN (80%), RNN (83%), and GBM (95.6%). Furthermore, the model performed a good precision-recall tradeoff, strengthening it applicability to real world work of predictive tasks, such as stock price prediction and market trend analysis. Through optimizations of essential hyperparameters by means of swarm intelligence, the framework handles the non-linear dependencies as well as volatility of financial data. The study shows high robustness and adaptability of the proposed concept provides solutions to the shortcomings of conventional financial forecasting tools. This study furthers the state of intelligent financial analytics proposing a byword framework for additional studies fostering deep learning and optimisation technologies together. The results align with the potential application of swarm-optimizer models for overcoming the limitation of predictive reliability of financial forecasting systems and future research in machine learning driven economic modelling and risk analysis.",2025
Machine Learning for Real Estate Time Series Prediction,"Several researchers have demonstrated that real estate investments have improved the risk-adjusted performance of mixed-asset portfolios belonging to institutional investors. In order for these portfolio strategies to be more effective, one could use price predictions (instead of historical data) to optimize weights. The goal of this paper is to investigate the predictive performance on price time series of REITs (real estate investment trusts), stocks and bonds, of five different machine learning (ML) algorithms. These algorithms are: linear regression; support vector regression; gradient boosting; long short-term memory neural networks; and k-nearest neighbour. We run experiments on 90 datasets and compare the ML results to those of an ARIMA model, which is a popular econometric benchmark used in financial time series predictions. Our results show that machine learning algorithms statistically outperform ARIMA. In addition, we find that all machine learning algorithms are able to produce very low root mean square errors, with linear regression and long short-term memory obtaining the lowest error values.",2024
A Deep Convolutional Neural Network Based Risk Identification Method for E-Commerce Supply Chain Finance,"With the popularity of the Internet, the rise of e-commerce platforms has led to the rapid development of supply chain (SC) financial services in China, and the competitiveness of commercial banks and core enterprises in the supply chain is now gradually increasing, rapidly expanding into an important area of competition between the two. As an emerging force rebounding from the economic downturn, e-commerce platform transactions, with their unique characteristics of informatization, diversification, and convenience, have provided a broad space for Internet SC finance. The article mainly analyzes the risk identification method of e-commerce SC finance, analyzes its risk from the financing process, gives corresponding data support for the matters or processes that may cause financing risk based on DCNN model, and takes Jingdong SC finance as an example and analyzes its main financing methods and risk identification process; based on different experimental comparisons, a multigroup experimental study shows that the accuracy of supply chain finance risk identification using deep convolutional neural network models can reach 95.36%, which demonstrates the effectiveness of the proposed method by providing better performance compared to traditional BP and SVM networks.",2022
RETRACTED: Research on Enterprise Financial Management and Prediction System Based on SaaS Model (Retracted Article),"In order to supervise and forewarn the sustainable operation ability of enterprises efficiently and accurately, this paper proposes an enterprise financial management and forecasting system based on SaaS model. First of all, in order to continue to effectively predict and analyze the enterprise finance, first analyze and extract the report data in the financial system. Then, by building a deep belief network model to predict the enterprise financial data, in order to reduce the cost of enterprises, the financial system designed in this paper chooses the cloud technology service framework based on SaaS model. Finally, in order to analyze the risk identification performance of the financial management and prediction system in this paper, the risk sample data of an enterprise's financial system is selected for simulation test. The results show that the correct rate of risk identification of the financial management system designed in this paper is higher than other comparison systems, which speeds up the speed of risk identification of the financial information management system, and has certain practical application value.",2022
Detecting Predictable Segments of Chaotic Financial Time Series via Neural Network,"In this study, a new idea is proposed to analyze the financial market and detect price fluctuations, by integrating the technology of PSR (phase space reconstruction) and SOM (self organizing maps) neural network algorithms. The prediction of price and index in the financial market has always been a challenging and significant subject in time-series studies, and the prediction accuracy or the sensitivity of timely warning price fluctuations plays an important role in improving returns and avoiding risks for investors. However, it is the high volatility and chaotic dynamics of financial time series that constitute the most significantly influential factors affecting the prediction effect. As a solution, the time series is first projected into a phase space by PSR, and the phase tracks are then sliced into several parts. SOM neural network is used to cluster the phase track parts and extract the linear components in each embedded dimension. After that, LSTM (long short-term memory) is used to test the results of clustering. When there are multiple linear components in the m-dimension phase point, the superposition of these linear components still remains the linear property, and they exhibit order and periodicity in phase space, thereby providing a possibility for time series prediction. In this study, the Dow Jones index, Nikkei index, China growth enterprise market index and Chinese gold price are tested to determine the validity of the model. To summarize, the model has proven itself able to mark the unpredictable time series area and evaluate the unpredictable risk by using 1-dimension time series data.",2020
Financial Engineering and Computer Science: Application of Deep Learning in the Field of Big Data Finance: Taking Stock Forecasting Analysis for Example,"With the advent of the cloud era, big data technology has become more and more important strategic significance. People apply massive data analysis to various industries and functional fields. Financial markets are known for the volatility of risk and reward. Centering on the new research direction of deep learning, this paper analyzes the internal rules of sample data, specifically applies it to BP neural network model, and discusses its role in stock prediction and analysis, so as to promote its application to the financial field.",2024
Forecasting price in a new hybrid neural network model with machine learning,"A key aspect of asset investment and risk management is the study of forecasting stock prices. We investigate the machine learning stock price prediction in a new hybrid neural network model and put forth a forecasting method based on machine learning, composite data preprocessing method and the proposed new neural network model. To address the challenge of predicting stock prices in the face of market complexity and noise, we use the complete ensemble empirical mode decomposition with adaptive noise (CEEMDAN) algorithm and the Savitzky-Golay (SG) filter to de -noise and enhance the data, and employ a neural network with three convolutional layers and a long short-term memory (LSTM) layer that enables it to capture complex temporal patterns in the data. We propose a new hybrid neural network prediction model (CEEMDAN-SC-LSTM) and adopt a machine learning approach to compare it with the benchmark model using CSI 300 index data. The empirical results validate the effectiveness of the frequency decomposition algorithm and the convolutional layer, and demonstrate that our proposed model outperforms the benchmark model. Compared to the best benchmark model, the CEEMDAN-S-C-LSTM model proposed in this study demonstrates a significant improvement in performance. Specifically, it shows a 45.33% reduction in mean absolute error (MAE), 43.44% reduction in root mean square error (RMSE), 45.01% reduction in mean absolute percentage error (MAPE), and 3.90% improvement in coefficient of determination (R 2 ). The study also explores the effect of different numbers of convolution layers and SG filters on the hybrid model. Our research expands on the use of neural networks and machine learning, offering a novel technical approach to making investment decisions and managing risks in financial systems.",2024
Forecasting Bitcoin Volatility and Value-at-Risk Using Stacking Machine Learning Models With Intraday Data,"This paper proposes a novel stacking machine learning model designed for the accurate forecasting of Bitcoin volatility and value-at-risk (VaR). The model incorporates various volatility measures and machine learning techniques to enhance forecasting accuracy. Additionally, the model utilizes intraday return data as input features for the machine learning models. The study employs five individual models including Artificial Neural Network (ANN), Support Vector Regression (SVR), Long Short-Term Memory (LSTM), Random Forest (RF), Neural Basis Expansion Analysis with Exogenous Variables (NBEATSx), Heterogeneous Autoregressive (HAR) model, and Generalized Auto-Regressive Conditional Heteroscedasticity (GARCH). These models are subsequently integrated using a stacking machine learning approach. The findings indicate that the stacking models outperform individual models in terms of forecasting. Our approach also contributes to VaR prediction within the complex realm of cryptocurrency markets, enhancing forecasting performance through the utilization of high-frequency Bitcoin data. Additionally, we implement a k-means clustering method combined with stacking machine learning models to further enhance prediction accuracy. This research offers practical applications for investors and financial institutions, facilitating more informed investment decisions and effective risk exposure management. It is worth noting that different machine learning models exhibit varying behavior when employed within the stacking modeling architecture, highlighting the need for further research to ascertain the generalizability and applicability of this proposed method across diverse cryptocurrency markets.",2024
Forecasting and Inventory Planning: An Empirical Investigation of Classical and Machine Learning Approaches for Svanehoj's Future Software Consolidation,"Challenges related to effective supply and demand planning and inventory management impose critical planning issues for many small and medium-sized enterprises (SMEs). In recent years, data-driven methods in machine learning (ML) algorithms have provided beneficial results for many large-scale enterprises (LSE). However, ML applications have not yet been tested in SMEs, leaving a technological gap. Limited recourse capabilities and financial constraints expose the risk of implementing an insufficient enterprise resource planning (ERP) setup, which amplifies the need for additional support systems for data-driven decision-making. We found the forecasts and determination of inventory management policies in SMEs are often based on subjective decisions, which might fail to capture the complexity of achieving performance goals. Our research aims to utilize the leverage of ML models for SMEs within demand and inventory management by considering various key performance indicators (KPI). The research is based on collaboration with a Danish SME that faced issues related to forecasting and inventory planning. We implemented the following ML models: Artificial Neural Network (ANN), Long Short-Term Memory (LSTM), Support Vector Regression (SVR), Random Forest (RF), Wavelet-ANN (W-ANN), and Wavelet-LSTM (W-LSTM) for forecasting purposes and reinforcement learning approaches, namely Q-learning and Deep Q Network (DQN) for inventory management. Results demonstrate that predictive ML models perform superior concerning the statistical forecasting approaches, but not always if we focus on industrial KPIs. However, when ML models are solely considered, the results indicate careful consideration must be regarded, given that model evaluation can be perceived from an academic and managerial perspective. Secondly, Q-learning is found to yield preferable economic results in terms of inventory planning. The proposed models can serve as an extension to modern ERP systems by offering a data-driven approach to demand and supply planning decision-making.",2023
OPTIMIZED DEEP LEARNING MODEL ARCHITECTURE FOR THE FEATURE EXTRACTION TO PREDICT TREND IN STOCK MARKET,"Predicting stock trends is a complex task influenced by various factors such as market sentiment, economic indicators, and company performance. Analysts often employ technical analysis, studying historical price patterns and trading volumes, as well as fundamental analysis, assessing financial statements and industry trends. Deep Learning models have also gained popularity for predicting stock trends, using algorithms to identify patterns and relationships in large datasets. Deep learning algorithms, particularly neural networks, excel at recognizing intricate patterns and relationships within complex datasets, making them well-suited for predicting stock prices, identifying trends, and managing risk. Hence, this paper proposed a Bird Swarm Optimization ARIMA LSTM (BSO-ARIMA-DL) model for stock trend prediction. The proposed BSO-ARIMA-DL model performance is applied in the company datasets Apple, Amazon, and Infosys for stock trend prediction. With the proposed BSO-ARIMA-DL model features are optimized for the identification of features in the dataset for the evaluation of optimal features. Upon the estimation of features, the ARIMA model with the LSTM architecture is implemented for the stock trend analysis. The proposed BSO-ARIMA-DL model deep learning model is implemented for the stock trend prediction in the companies. The results demonstrated that the proposed BSO-ARIMA-DL model exhibits a minimal error of similar to 10% minimal to the conventional ARIMA model.",2024
Analysis on innovation management of power financial transaction strategy integrating BO-BERT-GRNN model,"This paper addresses the innovation management problem of financial trading strategies for power system planning through the utilization of the BO-BERT-GRNN model. The BO-BERT-GRNN model, which combines Bayesian optimization, BERT model, and gated recurrent neural network, is divided into three parts to optimize hyperparameters, extract features from historical data, and model and predict power system planning. The objective is to achieve electricity asset allocation, market risk management, and revenue maximization. Experimental analysis demonstrates that the BO-BERT-GRNN model outperforms in power system planning price prediction, energy transaction risk management, and energy asset allocation, showcasing its potential for practical application. This paper addresses the innovation management problem of financial trading strategies for power system planning through the utilization of the BO-BERT-GRNN model. The BO-BERT-GRNN model, which combines Bayesian optimization, BERT model, and gated recurrent neural network, is divided into three parts to optimize hyperparameters, extract features from historical data, and model and predict power system planning. The objective is to achieve electricity asset allocation, market risk management, and revenue maximization. Experimental analysis demonstrates that the BO-BERT-GRNN model outperforms in power system planning price prediction, energy transaction risk management, and energy asset allocation, showcasing its potential for practical application.",2023
Forecasting the impact of financial stress on hedging between the oil market and GCC financial markets,"PurposeThis paper investigates the predictive impact of Financial Stress on hedging between the oil market and the GCC stock and bond markets from January 1, 2007, to December 31, 2020. The authors also compare the hedging performance of in-sample and out-of-sample analyses.Design/methodology/approachFor the modeling purpose, the authors combine the GARCH-BEKK model with the machine learning approach to predict the transmission of shocks between the financial markets and the oil market. The authors also examine the hedging performance in order to obtain well-diversified portfolios under both Financial Stress cases, using a One-Dimensional Convolutional Neural Network (1D-CNN) model.FindingsAccording to the results, the in-sample analysis shows that investors can use oil to hedge stock markets under positive Financial Stress. In addition, the authors prove that oil hedging is ineffective in reducing market risks for bond markets. The out-of-sample results demonstrate the ability of hedging effectiveness to minimize portfolio risk during the recent pandemic in both Financial Stress cases. Interestingly, hedgers will have a more efficient hedging performance in the stock and oil market in the case of positive (negative) Financial Stress. The findings seem to be confirmed by the Diebold-Mariano test, suggesting that including the negative (positive) Financial Stress in the hedging strategy displays better out-of-sample performance than the in-sample model.Originality/valueThis study improves the understanding of the whole sample and positive (negative) Financial Stress estimates and forecasts of hedge effectiveness for both the out-of-sample and in-sample estimates. A portfolio strategy based on transmission shock prediction provides diversification benefits.",2024
Forecasting financial signal for automated trading: An interpretable approach,"Traders can now use online trading applications to increase their capital by benefiting from financial markets fluctuations. The foreign exchange (forex) market, the silver and gold exchange markets, and stock indices (e.g. S&P 500) are among the most famous financial markets. Traders must identify the correct trends in any given market and take appropriate actions to increase their earnings. High levels of knowledge and competency are required to conduct profitable transactions. Deep learning and data clustering were employed in this study to propose an interpretable automated financial market trading model. In the proposed method, feature vectors are first extracted from the market price index and the values of useful indicators (e.g., RSI and MA). Data labeling is then performed through clustering. After that, a dataset is created to train a deep learning model in order to identify and adopt the best action (buy, sell, or no action). In financial markets, prices may change drastically and disrupt the performance of learning models. Therefore, an autoencoder network was designed to identify drastic fluctuations (outliers) in the market and avoid trading at such cases. This could prevent a steep drawdown. Experiments were performed on different markets to compare the proposed approach with the state-of-the-arts. The results indicate higher profitability with respect to the trading risk in comparison with other methods.",2023
Mining Financial Risk Events from News and Assessing their Impact on Stocks,"The impact of financial risk events on stock market is a fairly established area of research in the financial domain. However, the analysts require these events to be represented in a structured form in order to carry out statistical analysis. In this work, we aim is to identify and extract various financial risk events from news articles along with associated organizations to facilitate integrated analysis with structured business data. We propose a two-phase risk extraction algorithm involving a CNN based semi-supervised risk event identification and gradient boosting based entity association algorithm to extract risk events from news and associate them to their target organizations. We have analyzed large volumes of past available data using Granger causality to assess the impact of these events on various stock indices. Further, the utility of extracted risk events in predicting stock movement has been shown using a Bi-LSTM network based prediction model. The proposed system outperforms state of the art linear SVM on data for different stock indices.",2020
Financial Management of Listed Companies Based on Convolutional Neural Network Model in the Context of Epidemic,"The goal of financial management is to manage the purchase and sale of assets, the rational financing of funds, the management of cash flow in operations, and finally, the reasonable distribution of company profits in a certain task situation, which is simply the management of the three statements of the enterprise. The core issue of the financial mechanism is how to choose a centralized or decentralized management model, which requires the company to consider the internal and external environment, and according to the development of the company, the quality of employees and business characteristics of various factors, in order to make the best choice of the company's financial management model. Therefore, in the context of the epidemic, this article conducts research related to the financial management of listed companies based on convolutional neural network models (radial basis neural network, generalized regression neural network, wavelet neural network, and fuzzy neural network). This article, firstly, discusses the basic theories of macro- and micro-financial management of enterprises and financial management of listed enterprises, secondly, examines the overall financial management model of listed enterprises in China through methods such as the convolutional neural network model research method introduced in this article, and then, after an overall examination and analysis of the financial management situation of X-listed enterprises, finds the macro- and micro-status quo of financial management of listed enterprises in China under the epidemic, and in the sub. On the basis of the status quo, suggestions are made to build a financial management model that combines centralization and decentralization and to build a group financial risk management system.",2022
An early prediction model on systemic risk under global risk: Using FinBERT and temporal fusion transformer to multimodal data fusion framework,"Several United States banks went bankrupt in 2023, and the total scale exceeded the subprime 2008 mortgage crisis. Thus, determining how to better predict banks' systemic risks is crucial. While past research used quantitative data and statistical methods, rarely incorporated qualitative data, and lacked research exploring the impact of public confidence on systemic risk. This study examined 445,500 daily multimodal quantitative and qualitative data to analyze financial news. We obtained data on public confidence through finance bidirectional encoder representations from transformers (hereafter FinBERT) to explore the relationship between public confidence and systemic risk through temporal fusion transformers (TFTs). We established an early prediction model that predicts the next 5 and 20 days, achieving more accurate prediction performance than linear regression, LSTM (long short-term memory), and XGB (eXtreme gradient boosting). Based on the model that uses the past 20 days to predict the next five days, we found that positive and negative public confidence had a greater impact on systemic risk. In comparison, neutral public confidence had a lesser effect. Macro data such as carbon dioxide emissions also impact systemic risk. By expanding the time range to 60 days to predict 20 days, we found that the most significant impact on systemic risk factors was month, negative public information, interest rate, quasi-leverage, and the GDP growth rate. The findings indicate that public confidence deserves more attention than macro variables in preventing systemic risks in the banking industry. Negative public confidence significantly affects systemic risk, echoing the adage that Bad news has wings.",2025
Estimating the Severity of Oral Lesions Via Analysis of Cone Beam Computed Tomography Reports: A Proposed Deep Learning Model,"Objectives: Several factors such as unavailability of specialists, dental phobia, and financial difficulties may lead to a delay between receiving an oral radiology report and consulting a dentist. The primary aim of this study was to distinguish between high-risk and low-risk oral lesions according to the radiologist's reports of cone beam computed tomography (CBCT) images. Such a facility may be employed by dentist or his/her assistant to make the patient aware of the severity and the grade of the oral lesion and referral for immediate treatment or other follow-up care. Methods: A total number of 1134 CBCT radiography reports owned by Shiraz University of Medical Sciences were collected. The severity level of each sample was specified by three experts, and an annotation was carried out accordingly. After preprocessing the data, a deep learning model, referred to as CNN-LSTM, was developed, which aims to detect the degree of severity of the problem based on analysis of the radiologist's report. Unlike traditional models which usually use a simple collection of words, the proposed deep model uses words embedded in dense vector representations, which empowers it to effectively capture semantic similarities. Results: The results indicated that the proposed model outperformed its counterparts in terms of precision, recall, and F1 criteria. This suggests its potential as a reliable tool for early estimation of the severity of oral lesions. Conclusions: This study shows the effectiveness of deep learning in the analysis of textual reports and accurately distinguishing between high-risk and low-risk lesions. Employing the proposed model which can Provide timely warnings about the need for follow-up and prompt treatment can shield the patient from the risks associated with delays. Clinical significance: Our collaboratively collected and expert-annotated dataset serves as a valuable resource for exploratory research. The results demonstrate the pivotal role of our deep learning model could play in assessing the severity of oral lesions in dental reports. (c) 2024 The Authors. Published by Elsevier Inc. on behalf of FDI World Dental Federation. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/)",2025
A Novel Implementation of Siamese Type Neural Networks in Predicting Rare Fluctuations in Financial Time Series,"Stock trading has tremendous importance not just as a profession but also as an income source for individuals. Many investment account holders use the appreciation of their portfolio (as a combination of stocks or indexes) as income for their retirement years, mostly betting on stocks or indexes with low risk/low volatility. However, every stock-based investment portfolio has an inherent risk to lose money through negative progression and crash. This study presents a novel technique to predict such rare negative events in financial time series (e.g., a drop in the S&P 500 by a certain percent in a designated period of time). We use a time series of approximately seven years (2517 values) of the S&P 500 index stocks with publicly available features: the high, low and close price (HLC). We utilize a Siamese type neural network for pattern recognition in images followed by a bootstrapped image similarity distribution to predict rare events as they pertain to financial market analysis. Extending on literature about rare event classification and stochastic modeling in financial analytics, the proposed method uses a sliding window to store the input features as tabular data (HLC price), creates an image of the time series window, and then uses the feature vector of a pre-trained convolutional neural network (CNN) to leverage pre-event images and predict rare events. This research does not just indicate that our proposed method is capable of distinguishing event images from non-event images, but more importantly, the method is effective even when only limited and strongly imbalanced data is available.",2022
Deep learning framework for predictive modeling of crude oil price for sustainable management in oil markets,"Crude oil price predictability has continually been considered as a fundamental argument of finance literature, given its critical propositions for risk management, investment decisions, and commercial and financial policymaking. This work presents an innovative learning framework for efficient predictive modeling of daily and weekly crude oil price (COP) information, which aims to enable sustainable management in oil markets. Firstly, an optimized version of variation mode decomposition (OVMD) is proposed to adaptively decompose the original COP time series into multiple modes based on a set of optimized parameters calculated with a Tree-structured Parzen Estimator (TPE) algorithm. Secondly, an AdaBoost algorithm is redesigned using random forest (RF) to model the future price information in the modes with the high frequency. Thirdly, a new deep network is presented to develop automatically learn spatial-temporal representations from decomposed COP data, where a novel Conv-former module is designed to efficiently extract local as well as global spatial representations without incurring extra computational costs. Followingly, Multiple Long short-term Memory (LSTM) networks are stacked to learn temporal representations from input modes. To further empower the representation power of our framework, a new bidirectional learning module is presented to stack the LSTM layer to learn from COP data in the forward and backward directions. To validate the efficiency of the proposed framework, this work performs experimental simulations and analyses based on a case study from Brent crude oil prices at both daily and weekly scales. The experimental findings show up the competent predictive modeling capabilities of the proposed framework over the cutting-edge methods rendering it as a promising solution to enable sustainable management in crude oil markets. The proposed framework can be generalized to different predictive modeling tasks and hence qualified to be used as a valuable tool for oil portfolio creation, property pricing, and risk management in Crude Oil Markets.",2023
Effective Return Rate Prediction of Blockchain Financial Products Using Machine Learning,"In recent times, financial globalization has drastically increased in different ways to improve the quality of services with advanced resources. The successful applications of bitcoin Blockchain (BC) techniques enable the stockholders to worry about the return and risk of financial products. The stockholders focused on the prediction of return rate and risk rate of financial products. Therefore, an automatic return rate bitcoin prediction model becomes essential for BC financial products. The newly designed machine learning (ML) and deep learning (DL) approaches pave the way for return rate predictive method. This study introduces a novel Jellyfish search optimization based extreme learning machine with autoencoder (JSO-ELMAE) for return rate prediction of BC financial products. The presented JSO-ELMAE model designs a new ELMAE model for predicting the return rate of financial products. Besides, the JSO algorithm is exploited to tune the parameters related to the ELMAE model which in turn boosts the classification results. The application of JSO technique assists in optimal parameter adjustment of the ELMAE model to predict the bitcoin return rates. The experimental validation of the JSO-ELMAE model was executed and the outcomes are inspected in many aspects. The experimental values demonstrated the enhanced performance of the JSO-ELMAE model over recent state of art approaches with minimal RMSE of 0.1562.",2023
The impact of technology optimisation incorporating machine learning algorithms on the financial sustainability of new energy companies,"New energy companies in the industry have differences in financial performance from traditional companies. To help new energy companies develop sustainably, it is necessary to analyse and monitor their financial characteristics. To optimise the financial technology of new energy enterprises, this research uses GoogleNet convolutional neural network to construct a financial risk analysis model, which can judge financial risks and issue early warnings based on enterprise financial data. The experimental results of the financial risk analysis model show that the test loss value of the model is as low as 2.97%, which is very close to the loss value of the training set. The financial risk analysis model shows a large advantage over similar models, with an accuracy rate of 91.14%. In addition, the model's predictive ability and the actual situation are well fitted with an overall accuracy of 85%. In general, the outstanding performance of this model is that its judgment accuracy is significantly higher than that of similar models, and the timeliness of early warning is significantly higher than that of human early warning.",2023
The Impact of Financial Enterprises' Excessive Financialization Risk Assessment for Risk Control based on Data Mining and Machine Learning,"The purpose is to make full use of data mining and machine learning technology under big data to improve the ability of trade financial enterprises to cope with the risk of excessive financialization. In view of the above needs, based on previous studies, genetic algorithm (GA), neural network and principal component analysis (PCA) methods are used to collect and process the data, and build a risk assessment model of excessive financialization of financial enterprises. The performance of the model is analyzed through the data of specific cases. The results suggest that the data mining technology based on back propagation neural network (BPNN) can optimize the input variables and effectively extract the hidden information from the data. The specific examples show that most of the current enterprises do not have greater financial risk. However, most of the financial enterprise indexes show that the actual enterprise assets are gradually financialized. The total accuracy rate of financial risk assessment model based on deep belief network (DBN) is over 91%, and the accuracy of the model can reach 80% even if the sample size is small. Therefore, the financial risk assessment model proposed can effectively analyze the relevant financial data, and provide reference for the financial decision-making research of financial enterprises.",2022
An asymmetric PROMETHEE II for cryptocurrency portfolio allocation based on return prediction,"Portfolio allocation, portfolio selection, and portfolio optimization are recognized as three crucial problems in the financial field. Using different criteria in addition to return and risk in the portfolio allocation problem based on the multi-criteria decision-making (MCDM) methods makes it more practical in the real world. The emergence of new and volatile assets such as cryptocurrencies has recently increased the need to use portfolio allocation models. In order to reduce inequalities and alleviate poverty as one of the sustainable development goals, cryptocurrency portfolio construction leads to sustainable income and wealth. This paper proposes a cryptocurrency portfolio allocation model based on the asymmetric Preference Ranking Organization Method for Enrichment Evaluation (PROMETHEE II) method using eight criteria and nine cryptocurrencies. To reduce the uncertainty of the problem, the return prediction obtained from the Auto-Regressive Integrated Moving Average (ARIMA), the Long Short-Term Memory (LSTM), and the Random Forest Regression (RFR) models as return-related criteria and has been used from the SlideVaR, along with the Value at Risk (VaR) and the Conditional Value at Risk (C-VaR) as risk-related criteria to consider investor insight from the market situation. It is also proposed that an asymmetric preference function be proposed to consider gain and loss asymmetry as a behavioral phenomenon in the model. The out-of-sample performance of the proposed model in the last three months of 2021 confirms the superiority of the proposed model in terms of average return (= 0.017) and standard deviation (= 0.036) among other proposed models.(c) 2022 Elsevier B.V. All rights reserved.",2022
Jump detection in financial time series usingmachine learning algorithms,"In this paper, we develop a new Hybrid method based on machine learning algorithms for jump detection in financial time series. Jump is an important behavior in financial time series, since it implies a change in volatility. Ones can buy the volatility instrument if ones expect the volatility will bloom up in the future. A jump detection model attempts to detect short-term market instability, since it could be jumping up or down, instead of a directional prediction. The directional prediction can be considered as a momentum or trend following, which is not the focus of this paper. A jump detection model is commonly applied in a systematic fast-moving strategy, which reallocates the assets automatically. Also, a systematic opening position protection strategy can be driven by a jump detection model. For example, for a tail risk protection strategy, a pair of long call and put option order could be placed in the same time, in order to protect the open position given a huge change in volatility. One of the key differentiations of the proposed model with the classical methods of time-series anomaly detection is that, jump threshold parameters are not required to be predefined in our proposed model. Also the model is a combination of a Long short-term memory (LSTM) neural network model and a machine learning pattern recognition model. The LSTM model is applied for time series prediction, which predicts the next data point. The historical prediction errors sequence can be used as the information source or input of the jump detection model/module. The machine learning pattern recognition model is applied for jump detection. The combined model attempts to determine whether the current data point is a jump or not. LSTM neural network is a type of Recurrent Neural Networks (RNNs). LSTM records not only the recent market, but also the historical status. A stacked RNN is trained on a dataset which is mixed with normal and anomalous data. We compare the performance of the proposed Hybrid jump detection model and different pattern classification algorithms, such as k-nearest neighbors algorithm identifier, Hampel identifier, and Lee Mykland test. The model is trained and tested using real financial market data, including 11 global stock market in both developed and emerging markets in US, China, Hong Kong, Taiwan, Japan, UK, German, and Israel. The experiment result shows that the proposed Hybrid jump detection model is effective to detect jumps in terms of accuracy, comparing to the other classical jump detection methods.",2020
Securing the economic management and service infrastructure of banks via the use of artificial intelligence (MO-ILSTM),"The banking industry has been a key player in economic growth, but the development of economic management and service infrastructures has not significantly reduced the current financial crisis. In service infrastructure or economic management, the challenge of making judgments and processing data inefficiently in unpredictable markets is the drawback of the existing approach. Technology-related constraints, such as scalability and connectivity issues, can hinder the application's functionality and ability to adapt to changing market conditions. Scalability and connectivity constraints can impact applications related to online banking, digital transactions, and financial data processing. This study explores the use of Mothfly Optimized Improved Long Short-Term Memory (MO-ILSTM) as a data classification technique to improve data sharing and processing effectiveness. The proposed approach overcomes the above mentioned constraints. The capacity of LSTM to identify long-range relationships in sequential data is restricted. By boosting data processing and decision-making in service infrastructure or economic management amid market volatility, MO-ILSTM aims to increase long-range dependency capture. The ILSTM approach is extended from binary data classification to various classifications, addressing the inability of economic management or service infrastructure to efficiently handle complex data processing needs and ensure prompt decision-making. The proposed research is to better predict risk, process data more efficiently, integrate economic services into the banking sector, and improve economic management and service infrastructure to lessen the effects of the financial crisis. Tests show that the ILSTM-based economic management and service infrastructure can decrease economic threat by 18 %, increase service quality by 32 %, and increase the degree of integrated economic service by 45 %. The platform can also effectively forecast financial risks, with a prediction accuracy of 75.6 % due to information exchange and interaction. Thus, the ILSTM algorithm can significantly reduce economic risks and enhance the effectiveness of economic management and service infrastructure.",2025
MAPPING OF URBAN FLOOD INUNDATION USING 3D DIGITAL SURFACE MODEL AND SENTINEL-1 IMAGES,"Flooding in urban areas poses serious risks to citizens, infrastructures, and transportation. Precise and real-time delineation of the inundated areas is crucial for a better understanding of the extent of damage and high-risk areas and people evacuation actions. It also increases citizens' awareness that living in areas with high flood risk. Yazd city is characterized by low rainfall (<70 mm/yr) and the desert climate is considered the study area of this research. This city encountered a flash flood event that was generated by severe rainfall with a depth of 75 mm in 3hr (i.e., the intensity of 25 mm/hr) on July 29, 2022. Many strategic infrastructures of this city especially the railway station were flooded, which caused heavy casualties and financial losses. This study aims to monitor the flood inundated areas of Yazd city due to this flood event using remote sensing. In this research, the Sentinel-1 polarimetric radar images and the 3D model of the Yazd city surf ace were used to delineate the flooded areas. The field information of the flooded areas and the available Sentinel-1 images during or near the occurrence time of maximum flood extension were adopted. The Convolutional Neural Network (CNN) model in combination with the 3D model of the studied area was used to identify the flooded pixels in the city of Yazd. The results showed that the adopted 3D model and CNN algorithm indicated a good ability to identify flooded areas with an accuracy of 88% and a kappa coefficient of 0.83.",2023
Intelligent Asset Allocation Portfolio Division and Recommendation: Based on Deep Learning and Knowledge Graphs,"With the continuous development of financial markets, intelligent asset allocation has become a topic of great concern in the investment field. However, traditional asset allocation methods often face difficulties in grasping the relationship between diversity, risk and return, which limits its application in complex market environments. To solve this problem, this study introduces deep learning and knowledge graphs and proposes an intelligent asset allocation model. Our model makes full use of the advantages of the Knowledge Graph Embedding Model (KGE), LSTM, and Genetic Algorithm (GA) to build a multi-level and multi-dimensional asset allocation model. KGE helps capture the complex relationships between different assets, LSTM is used to learn key patterns of historical portfolio performance, and GA finds the optimal asset allocation combination by simulating natural selection and genetic mechanisms. Experimental findings indicate that our model has demonstrated substantial improvements across various performance metrics and outperforms conventional approaches.",2024
Dynamic Prediction Model of Financial Asset Volatility Based on Bidirectional Recurrent Neural Networks,"Predicting financial market volatility is essential for investors and risk management. This study proposes a dynamic prediction model for financial asset volatility, with a Bi-directional Recurrent Neural Network (Bi-RNN) utilized to cleverly address market complexity. Our framework integrates Bi-RNN and gated recurrent units (GRU) to perform global optimization via particle swarm optimization algorithm (PSO). Bi-RNN combines historical data and future expectations, while GRU effectively solves long-term dependency issues through a gating mechanism, which enhances model generalization. Experimental results show that the model exhibits significant performance advantages on different financial datasets, along with strong learning and generalization capabilities superior to traditional methods. This research provides advanced and practical solutions for financial asset fluctuation prediction and is of positive significance for the greater accuracy of investment decisions and risk mitigation.",2024
Anti-Money Laundering Risk Identification of Financial Institutions based on Aspect-Level Graph Neural Networks,"The contemporary financial industry is a highly information-based industry. The digital system can establish a complete information system around various attributes and behaviors of bank accounts. In the core business system, most of this information is constantly changing and recorded in real time. Therefore, we can achieve the goal of monitoring the money laundering risk of the account by analyzing the relevant element data and specific characteristics of the account. The risk assessment and customer classification indicator system for accounts is composed of four basic elements: customer characteristics, location, business development and industry conditions. Account money laundering risk indicators are composed of various basic elements and their risk sub-items. We propose an aspect-based (aspect-level) graph convolutional neural network, starting from different perspectives, to quantify the risk of money laundering in financial institutions.",2022
ARIMA-SVR-based risk aggregation modeling in the financial behavior,"PurposeOnce regional financial risks erupt, they not only affect the stability and security of the financial system in the region, but also trigger a comprehensive financial crisis, damage the national economy, and affect social stability. Therefore, it is necessary to regulate regional financial risks through artificial intelligence methods.Design/methodology/approachIn this manuscript, we scrutinize the loan data pertaining to aggregated regional financial risks and proffer an ARIMA-SVR loan data regression model, amalgamating traditional statistical regression methods with a machine learning framework. This model initially employs the ARIMA model to accomplish historical data fitting and subsequently utilizes the resultant error as input for SVR to refine the non-linear error. Building upon this, it integrates with the original data to derive optimized prediction results.FindingsThe experimental findings reveal that the ARIMA-SVR (Autoregress Integrated Moving Average Model-Support Vector Regression) method advanced in this discourse surpasses individual methods in terms of RMSE (Root Mean Square Error) and MAE (Mean Absolute Error) indices, exhibiting superiority to the deep learning LSTM method.Originality/valueAn ARIMA-SVR framework for the financial risk recognition is proposed. This presentation furnishes a benchmark for future financial risk prediction and the forecasting of associated time series data.",2024
Environmental Risk Identification and Green Finance Development Based on Multi-scale Fusion Recognition Network,"This paper aims to enhance the resilience of financial enterprises against environmental risks by leveraging financial data analysis tools. The approach involves designing environmental risk assessment indicators and rating criteria. The study utilizes a convolutional neural network model extended by a multi-scale feature fusion module to analyze environmental risk information in the industry. The proposed model achieves impressive results with accuracy (Acc), precision (P), recall (R), and F1 scores reaching 99.09, 96.31, 95.32, and 95.64, respectively. These metrics outperform those of comparison models. The success of this model is anticipated to pave the way for the transformation of green finance through automated industry-level environmental risk assessment. Furthermore, the method's adaptability extends beyond environmental risks, offering a scalable solution for identifying and assessing environmental risks in various contexts.",2024
A novel deep reinforcement learning framework with BiLSTM-Attention networks for algorithmic trading,"The financial market, as a complex nonlinear dynamic system frequently influenced by various factors, such as international investment capital, is very challenging to build trading strategies from the obtained market information. Deep Reinforcement Learning (DRL) combines the perceptual capability of deep learning and the control decision making capability of reinforcement learning to learn the mapping between financial market states and trading decisions by interacting with the environment. In this paper, an enhanced stock trading strategy, denominated efficient deep State-Action-Reward-State-Action (SARSA), is presented to tackle the algorithmic trading problem of determining optimal trading positions in the daily trading activities of the stock market. This algorithm is recognized for its properties of stable learning and convergence, attributes of critical significance within the financial domain, where stability assumes paramount importance, and excessive risk-taking should be averted. Furthermore, a novel deep network architecture called Bidirectional Long Short -Term Memory (BiLSTM)-Attention is introduced to address the challenge of accurately presenting the complex and volatile stock market. The BiLSTM-Attention greatly enhances the network's capacity to recognize key features and patterns in stock market data, allowing agents to focus on the most relevant aspects of the data. Evaluations on DJI, SP500, GE, IXIC datasets from January 1, 2008 to December 31, 2022 show that our efficient deep SARSA algorithm outperforms a wide range of traditional strategies (B&H, S&H, MR, TF) and DRL-based strategies (TDQN, DQN-Vanilla). For example, on the IXIC dataset, the efficient deep SARSA strategy achieves an attractive Cumulative Return (CR) of 582.17% and a Sharpe Ratio (ShR) of 1.86, outperforming all other methods. These experimental results prove the performance of our method in enhancing stock trading strategies.",2024
Smart Financial Investor's Risk Prediction System Using Mobile Edge Computing,"The financial system has reached its pinnacle because of economic and social growth, which has propelled the financial sector into another era. Public and corporate financial investment operations have significantly risen in this climate, and they now play a significant part in and impact the efficient use of market money. This finance sector will be affected by high-risk occurrences because of the cohabitation of dangers and passions, which will cause order to become unstable and definite financial losses. An organization's operational risk is a significant barrier to its growth. A bit of negligence could cause the business's standing to erode rapidly. Increasing funding management and forecasting risks is essential for the successful development of companies, enhancing their competitiveness in the marketplace and minimizing negative effects. As a result, this study takes the idea of mobile edge computing. It creates an intelligent system that can forecast different risks throughout the financial investment process based on the operational knowledge of important investment platforms. The CNN-LSTM approach, based on knowledge graphs, is then used to forecast financial risks. The results are then thoroughly examined through tests, demonstrating that the methodology can accurately estimate the risk associated with financial investments. Finally, a plan for improving the system for predicting financial risk is put out.",2023
Quantitative Stock Selection Model Using Graph Learning and a Spatial-Temporal Encoder,"In the rapidly evolving domain of finance, quantitative stock selection strategies have gained prominence, driven by the pursuit of maximizing returns while mitigating risks through sophisticated data analysis and algorithmic models. Yet, prevailing models frequently neglect the fluid dynamics of asset relationships and market shifts, a gap that undermines their predictive and risk management efficacy. This oversight renders them vulnerable to market volatility, adversely affecting investment decision quality and return consistency. Addressing this critical gap, our study proposes the Graph Learning Spatial-Temporal Encoder Network (GL-STN), a pioneering model that seamlessly integrates graph theory and spatial-temporal encoding to navigate the intricacies and variabilities of financial markets. By harnessing the inherent structural knowledge of stock markets, the GL-STN model adeptly captures the nonlinear interactions and temporal shifts among assets. Our innovative approach amalgamates graph convolutional layers, attention mechanisms, and long short-term memory (LSTM) networks, offering a comprehensive analysis of spatial-temporal data features. This integration not only deciphers complex stock market interdependencies but also accentuates crucial market insights, enabling the model to forecast market trends with heightened precision. Rigorous evaluations across diverse market boards-Main Board, SME Board, STAR Market, and ChiNext-underscore the GL-STN model's exceptional ability to withstand market turbulence and enhance profitability, affirming its substantial utility in quantitative stock selection.",2024
RETRACTED: A Convolutional Neural Network-Based Model for Supply Chain Financial Risk Early Warning (Retracted Article),"At present, there are widespread financing difficulties in China's trade circulation industry. Supply chain finance can provide financing for small- and medium-sized enterprises in China's trade circulation industry, but it will produce financing risks such as credit risks. It is necessary to analyze the causes of the risks in the supply chain finance of the trade circulation industry and measure these risks by establishing a credit risk assessment system. In this article, a supply chain financial risk early warning index system is established, including 4 first-level indicators and 29 third-level indicators. Then, on the basis of the supply chain financial risk early warning index system, combined with the method of convolution neural network, the supply chain financial risk early warning model of trade circulation industry is constructed, and the evaluation index is measured by the method of principal component analysis. Finally, the relevant data of trade circulation enterprises are selected to make an empirical analysis of the model. The conclusion shows that the supply chain financial risk early warning model and risk control measures established in this article have certain reference value for the commercial circulation industry to carry out supply chain finance. It also provides guidance for trade circulation enterprises to deal with supply chain financial risks effectively.",2022
Cryptocurrency direction forecasting using deep learning algorithms,"Recently, the deep learning architecture has been used with an increasing rate for forecasting in financial markets. In this paper, the LSTM model is used to forecast the daily closing price direction of the BTC/USD. Both model accuracy and the profit or loss of the trades made based on the proposed model are analyzed. In addition, the effects of the MACD indicator and the input matrix dimension on forecasting accuracy are evaluated. The potential risks and actual risks encountered by the trader who trades based on the proposed model were also analyzed. The obtained results indicate that the optimization of the LSTM parameters using the Bayesian optimization model has enhanced the model's accuracy. The results obtained from analyzing the drawdown and reward/risk resulting from the trades made based on the model show that the model enables the trader to trade with peace of mind due to the low level of actual risks and potential risks.",2021
Forecasting Stock Market Volatility Using Housing Market Indicators: A Reinforcement Learning-Based Feature Selection Approach,"This study tackles the complex challenge of accurately predicting stock market volatility through indicators from the housing market. We propose a sophisticated Early Warning System (EWS) designed to forecast stock market instability by leveraging the predictive power of housing market bubbles. Current EWS methods often face significant hurdles, including model generalization, feature selection, and hyperparameter optimization challenges. To directly address these issues, our innovative approach utilizes a spatial attention-based Transductive Long Short-Term Memory (TLSTM) model combined with a Reinforcement Learning (RL) strategy, which is further enhanced by a novel scope loss function for refined feature selection and an Artificial Bee Colony (ABC) algorithm for hyperparameter optimization. The TLSTM model surpasses traditional LSTM models by effectively capturing subtle temporal shifts and prioritizing data points proximate to the test sample, thereby enhancing model generalization. The RL component actively refines feature selection through continuous data interaction, ensuring the model captures the most significant features and effectively mitigates the risk of overfitting. The introduction of the scope loss function strategically manages the trade-off between exploiting known data and exploring new patterns, thereby maintaining a healthy balance between accuracy and generalizability. Additionally, the customized ABC algorithm specifically optimizes hyperparameters to increase the adaptability and performance of the model under varying market conditions. We validated our EWS using data from the Korean market, achieving an impressive accuracy of 90.427%. This validation demonstrates the robust capability of the system to forecast market dynamics. Our study significantly contributes to financial analytics by providing deeper insights into the interactions between housing and stock markets, particularly during periods of market bubbles. This research not only enhances predictive accuracy but also aids in understanding complex market behaviors, thereby offering valuable tools for financial risk management and decision-making.",2025
Automated Trading System for Stock Index Using LSTM Neural Networks and Risk Management,"Financial time series predictions are a challenge due to their nonlinear and chaotic nature. In recent decades, many researchers and investors have studied methods to improve quantitative analysis. In the field of artificial intelligence, sophisticated machine learning techniques, such as deep learning showed better performance. In this paper, an automated trading system is built to predict future trends of stock index prices. Using an LSTM-based agent to learn temporal patterns in the data, the algorithm triggers automatic trades according to the historical data, technical analysis indicators, and risk management. The results demonstrate that the proposed method, called LSTM-RMODV, shows better performance when compared with other methods, including the buy-and-hold technique. The proposed method also works in bear or bull market conditions, showing a rate over net income based on invested capital of 228.94%. That is, despite the low accuracy, the algorithm is capable of generating consistent profits when all the transaction costs are considered.",2020
Integrating AI and OR for investment decision-making in emerging digital lending businesses: a risk-return multi-objective optimization approach,"This study investigates the application of operational research techniques to optimize investment decisions in peer-to-peer (P2P) lending platforms, focusing on balancing risk and return for investors. The study proposes a multi-objective decision-making model that leverages data from the Lending Club, the largest P2P marketplace in the United States, to minimize risk and maximize returns. To address the data imbalance, the model uses classification techniques including logistic regression, decision trees, random forests, and light gradient boosting machines (LGBM), which are supported by the synthetic minority oversampling technique (SMOTE). While a convolutional neural network (CNN) predicts net present value (NPV), logistic regression is used to assess risk. The nondominated sorting genetic algorithm II (NSGA-II) is then used for portfolio optimization, producing returns of over 7% with risk levels that are comparable with conventional methods. Sensitivity analysis highlights the importance of investment allocation strategies by emphasizing that portfolio returns are more sensitive to changes in investments than risk. This study contributes to the operational research literature on risk management, investment modeling, and practical decision support systems in financial services by integrating advanced AI-based computational methods and optimization tools. HIGHLIGHTSThe multi-objective model seeks to balance risk reduction with return maximization.The LGBM, logistic regression, random forest, and decision tree models are assessed.The NSGA-II algorithm is used to optimize the portfolio model.A sensitivity analysis is used to evaluate the investment amounts.The results provide wisdom on return optimization and risk reduction in P2P lending.",2025
Forecasting cryptocurrencies volatility using statistical and machine learning methods: A comparative study,"Forecasting cryptocurrency volatility can help investors make better-informed investment decisions in order to minimize risks and maximize potential profits. Accurate forecasting of cryptocurrency price fluctuations is crucial for effective portfolio management and contributes to the stability of the financial system by identifying potential threats and developing risk management strategies. The objective of this paper is to provide a comprehensive study of statistical and machine learning methods for predicting daily and weekly volatility of the following four cryptocurrencies: Bitcoin, Ethereum, Litecoin, and Monero. Several models and forecasting methods are compared in terms of their forecasting accuracy, i.e., HAR (heterogeneous autoregressive), ARFIMA (autoregressive fractionally integrated moving average), GARCH (generalized autoregressive conditional heteroscedasticity), LASSO (least absolute shrinkage and selection operator), RR (ridge regression), SVR (support vector regression), MLP (multilayer perceptron), FNM (fuzzy neighbourhood model), RF (random forest), and LSTM (long short-term memory). The realized variance calculated from intraday returns is used as the input variable for the models. In order to assess the predictive power of the models considered, the model confidence set (MCS) procedure is applied. Our experimental results demonstrate that there is no single best method for forecasting volatility of each cryptocurrency, and different models may perform better depending on the specific cryptocurrency, choice of the error metric and forecast horizon. For daily forecasts, the method that is always found in a set of best models is linear SVR, while for weekly forecasts, there are two such methods, namely FNM and RR. Furthermore, we show that simple linear models such as HAR and ridge regression, perform not worse than more complex models like LSTM and RF. The research provides a useful reference point for the development of more sophisticated models.",2024
A novel decision ensemble framework: Attention-customized BiLSTM and XGBoost for speculative stock price forecasting,"Forecasting speculative stock prices is essential for effective investment risk management and requires innovative algorithms. However, the speculative nature, volatility, and complex sequential dependencies within financial markets present inherent challenges that necessitate advanced techniques. In this regard, a novel framework, ACB-XDE (Attention-Customized BiLSTM-XGB Decision Ensemble), is proposed for predicting the daily closing price of speculative stock Bitcoin-USD (BTC-USD). The proposed ACB-XDE framework integrates the learning capabilities of a customized Bi-directional Long Short-Term Memory (BiLSTM) model with a novel attention mechanism and the XGBoost algorithm. The customized BiLSTM leverages its learning capabilities to capture complex sequential dependencies and speculative market trends. Meanwhile, the new attention mechanism dynamically assigns weights to influential features based on volatility patterns, thereby enhancing interpretability and optimizing effective cost measures and volatility forecasting. Moreover, XGBoost handles nonlinear relationships and contributes to the proposed ACB-XDE framework's robustness. Furthermore, the error reciprocal method improves predictions by iteratively adjusting model weights based on the difference between theoretical expectations and actual errors in the individual attention-customized BiLSTM and XGBoost models. Finally, the predictions from both the XGBoost and attention-customized BiLSTM models are concatenated to create a varied prediction space, which is then fed into the ensemble regression framework to improve the generalization capabilities of the proposed ACB-XDE framework. Empirical validation of the proposed ACB-XDE framework involves its application to the volatile Bitcoin market, utilizing a dataset sourced from Yahoo Finance (Bitcoin-USD, 10/01/2014 to 01/08/2023). The proposed ACB-XDE framework outperforms state-of-the-art models with a MAPE of 0.37%, MAE of 84.40, and RMSE of 106.14. This represents improvements of approximately 27.45%, 53.32%, and 38.59% in MAPE, MAE, and RMSE respectively, over the best-performing attention-BiLSTM. The proposed ACB-XDE framework presents a technique for informed decision-making in dynamic financial landscapes and demonstrates effectiveness in handling the complexities of BTC-USD data.",2025
Bankruptcy Risk Prediction using Artificial Intelligence: An Empirical Study of the Slovak Chemical Industry,"Research background: Bankruptcy prediction is important in business management, especially in the context of increasing competitiveness. Assessing the financial health of business entities using various models is an important area in not only scientific research, but also business practice. Comparing financial results and bankruptcy risk estimation is also important in economic practice. Purpose of the article: This study aims to apply an artificial neural network ( ANN) to predict the bankruptcy of non-financial corporations in the chemical industry of the Slovak Republic. We compared the results of artificial neural network with logistic regression. Methods: We used multi-layer perceptron artificial neural network (ANN-MLP) with feed-forwarded connections and back-propagation (BP) type of learning for prediction the bankruptcy of non-financial corporations in the chemical industry of Slovakia. We tested nine prediction models on a sample of 663 chemical companies in Slovakia from 2020 and 2021, while we used five financial indicators. The results were compared with logistic regression. Findings & Value added: An optimal neural network model was created for predicting risk bankruptcy in the chemical industry of the Slovak Republic. Our model can be applied in countries with undeveloped capital markets. We constructed an optimal network for the chemical industry using five financial indicators on the input layer in combination with one hidden layer (eight hidden nodes). All models achieved high accuracy.",2023
An Improved Ensemble Method With Data Resampling for Credit Risk Prediction,"The increasing complexity and dynamic nature of financial data present significant challenges in accurately predicting credit risk, a critical task in the banking and finance sector. The application of machine learning (ML) in credit risk prediction has been hindered by the imbalanced nature of credit datasets. This study proposes an improved approach for predicting credit risk using a stacked ensemble method combined with a hybrid data resampling technique. The ensemble comprises random forests, logistic regression, and a convolutional neural network (CNN) as base learners, with the multilayer perceptron (MLP) serving as a meta-learner. To address the data imbalance, the Synthetic Minority Over-sampling Technique and Edited Nearest Neighbors (SMOTE-ENN) technique were applied. The proposed approach is benchmarked against other well-performing classifiers, including random forest, logistic regression, MLP, and CNN. The integration of hybrid data resampling with a robust stacking ensemble significantly enhanced credit risk prediction, with the proposed approach achieving sensitivity and specificity of 0.921 and 0.946 for the Australian dataset and 0.928 and 0.891 for the German dataset. Also, the stacked classifier achieved a sensitivity and specificity of 0.000 and 1.000 before data resampling for the Credit Risk Classification dataset with an accuracy of 0.7644. After data resampling, the accuracy, sensitivity, and specificity are 0.8056, 0.7989 and 0.8125, respectively. On the other hand, using the credit risk analysis for the extended banking loans dataset, the accuracy, sensitivity and specificity of the stacked classifier before data resampling are 0.8429, 0.6316, and 0.9216, respectively. After data resampling, the accuracy, sensitivity and specificity scores of the stacked classifier trained using the credit risk analysis for the extended banking loans dataset are 0.9632, 1.0000, and 0.9242, respectively. This shows that after data resampling, the performance of the stacked classifier trained using the credit risk analysis for the extended banking loans dataset outperformed other models.",2025
RETRACTED: Deep Learning-Driven Financial Management Innovation Upgrade for Universities (Retracted Article),"This study aims to improve the quality of college financial management and reduce the risk of college financial management, and a college financial system based on multiscale deep learning is designed in this paper. This paper designs a university financial system based on multiscale deep learning. In the hardware design, the system adds multiple sensors and scans all the information in the financial database using a coordinator. In the software design, the weights that can connect the financial information of the same attribute are set by establishing a database form; according to the multilayer perceptual network topology, a full interconnection model based on multiscale deep learning is designed to realize the system's deep extraction of data. The experimental results show that the financial risk is based on the risk warning capability for university finance, and compared with the system under the traditional design, the university finance system designed at this time has the most categories of financial information parameters extracted.",2022
GARCHNet: Value-at-Risk Forecasting with GARCH Models Based on Neural Networks,"This paper proposes a new GARCH specification that adapts the architecture of a long-term short memory neural network (LSTM). It is shown that classical GARCH models generally give good results in financial modeling, where high volatility can be observed. In particular, their high value is often praised in Value-at-Risk. However, the lack of nonlinear structure in most approaches means that conditional variance is not adequately represented in the model. On the contrary, the recent rapid development of deep learning methods is able to describe any nonlinear relationship in a clear way. We propose GARCHNet, a nonlinear approach to conditional variance that combines LSTM neural networks with maximum likelihood estimators in GARCH. The variance distributions considered in the paper are normal, t and skewed t, but the approach allows extension to other distributions. To evaluate our model, we conducted an empirical study on the logarithmic returns of the WIG 20 (Warsaw Stock Exchange Index), S&P 500 (Standard & Poor's 500) and FTSE 100 (Financial Times Stock Exchange) indices over four different time periods from 2005 to 2021 with different levels of observed volatility. Our results confirm the validity of the solution, but we provide some directions for its further development.",2024
Token-Based Adaptive Time-Series Prediction by Ensembling Linear and Non-Linear Estimators: A Machine Learning Approach for Predictive Analytics on Big Stock Data,"With technological advancements, big data can be easily generated and collected in many applications. Embedded in these big data are useful information and knowledge that can be discovered by machine learning and data mining models, techniques or algorithms. A rich source of big data is stock exchange. The ability to effectively predict future stock prices improves the economic growth and development of a country. Traditional linear approaches for prediction (e.g., Kalman filters) may not be practical in handling big data like stock prices due to highly nonlinear and chaotic nature. This lead to the exploitation of various nonlinear estimators such as the extended Kalman filters, expert systems, and various neural network architectures. Moreover, to lessen the potential shortcomings of individual algorithms, ensemble approaches have been created by averaging values across different algorithms. Existing ensemble techniques mostly basket-together a collection of sample-based algorithms that are catered to nonlinear functions. To the best of our knowledge, traditional linear estimators have not yet been incorporated into such an ensemble. Hence, in this paper, we propose a machine learning (\specifically, token-based ensemble) algorithm that utilizes both linear and nonlinear estimators to predict big financial time-series data. Our ensemble consists of a traditional Kalman filter, long short-term memory (\LSTM) network, and the traditional linear regression model. We also explore the adaptive properties in short-term high-risk trading in the presence of noisy data like stock prices and demonstrate the performance of our ensemble.",2018
Modeling Price and Risk in Chinese Financial Derivative Market with Deep Neural Network Architectures,"As rapid growth, Chinese financial derivative market is holding increasingly large proportions in entire domestic capital market as well as in global shares. To the nature of derivative instruments, plenty of market data features (such as prices and trading volumes) and off-market factors (such as financial news and policies) can directly impact on the price and risk in Chinese financial derivative markets, which is becoming more and more infeasible to model by using only traditional financial models and hand-crafted features. To alleviate the issue, in this paper we introduce some state-of-art deep neural network architectures and model two significant futures market price and risk indicators that are widely used by Chinese regulators, which are turn-over ratio (ratio of daily trading volumes and daily open interest volumes) and price basis (gap between futures price and corresponding spot product price). The extensive experimental results show that deep learning methods perform better prediction accuracy than traditional methods, among which convolutional LSTM achieves better results in most cases as it can capture local time-variant patterns. In addition, we also propose methods to exploit alternative off-market features (such as social media emotions and Baidu Search Index) with DNN models, which are proven beneficial to the price and risk prediction by rendering extra information than only market data.",2020
Explainable Model of Credit Risk Assessment Based on Convolutional Neural Networks,"Credit Risk Assessment estimates the probability of loss due to a borrower's failure to repay a loan or credit. Therefore, one of the principal challenges of financial institutions is to lower the losses generated by leading financial resources to possible default clients. Current models for Credit Risk Assessment used by the industry are based on Logistic regression (LR), thanks to their operational efficiency and interpretability. However, Deep Learning (DL) Algorithms have become more attractive than conventional Machine Learning due to their best general accuracy. However, Models for Credit Risk Assessment based on DL have a problem because their complexity makes them difficult for humans to interpret. Additionally, international regulations for financial institutions require that models be interpretable. In this work, we propose the use of a model based on Convolutional Neural Networks (CNN) and SHapley Additive exPlanations (SHAP) to generate a more accurate and explainable model than LR models. In order to demonstrate its efficacy, we use four datasets commonly used to benchmark classification algorithms for credit scoring. The results show that the method proposed is more accurate than LR for large datasets (more than 5900 samples), with an improvement in accuracy up to 12.3%.",2022
Innovation in Financial Enterprise Risk Prediction Model: A Hybrid Deep Learning Technique Based on CNN-Transformer-WT,"In the context of predicting financial risks for enterprises, traditional methods are inadequate in capturing complex multidimensional data features, resulting in suboptimal prediction performance. Although existing deep learning techniques have shown some improvements, they still face challenges in processing time series data and detecting extended dependencies. To address these issues, this paper proposes an integrated deep learning framework utilizing Convolutional Neural Network (CNN), Transformer model, and Wavelet Transform (WT). The proposed model leverages CNN to derive local features from the data, employs the Transformer to capture long-term dependencies, and uses WT for multiscale analysis, thereby enhancing the accuracy and stability of predictions. Experimental results demonstrate that the CNN-Transformer-WT model performs excellently across various datasets, including Kaggle Dataset (Credit Card Fraud Detection Dataset), Bank Marketing Dataset, and Yahoo Finance Historical Stock Market Dataset.",2024
Privacy-Secured Early Detection of Smartphone Users in Danger at Stations Using Depth Sensor and Deep Learning,"The installation of platform doors at train stations has been widely adopted as a preventative measure against the increasing incidents of falls from station platforms. Despite this safety initiative, financial constraints mean that only approximately 10% of stations in countries like Japan are currently equipped with these doors. Over the years, there has been a noticeable reduction in the number of accidents related to platform falls; however, the incidence of falls attributed to smartphone usage has remained consistently high, without any significant reduction. In response to this persistent issue, our research team has investigated the potential of utilizing depth cameras to detect and alert smartphone users at risk of accidents. To achieve this, we gathered and analyzed data from both individuals using smartphones and those who were not, employing advanced deep learning techniques to accurately distinguish between the two groups. Our approach leveraged the capabilities of the Dynamic Graph Convolutional Neural Network (DGCNN), which excels in capturing intricate local patterns in data that traditional models like PointNet often miss. Remarkably, the DGCNN demonstrated high precision in identifying smartphone users who might be at greater risk of accidents due to their distraction. Moreover, we optimized the learning process by incorporating a downsampling technique into our methodology, which significantly enhanced the model's efficiency and accuracy. This was particularly effective in reducing the number of training epochs needed, thereby speeding up the training process without compromising the quality of the results. Our findings confirmed that this approach not only improves the accuracy of detecting at-risk individuals but also reduces the overall training time, making it a practical solution for real-world applications.",2024
A hybrid model integrating artificial neural network with multiple GARCH-type models and EWMA for performing the optimal volatility forecasting of market risk factors,"The 2008 financial crisis has highlighted the lack of precision in the market risk metrics that financial institutions must report to the regulator. The use of Machine Learning techniques in stock markets and the treasury (Front-Back Office) of financial institutions is a key tool for optimizing its own resources, internal processes and risk measures. We propose a hybrid methodology to better capture the volatility of market risk factors with Value-at-risk models in periods of stress, but also in periods of stability compared to traditional metrics. This hybrid model uses different types of artificial neural networks and traditional metrics to perform the optimal forecast of volatility applied to the main market risk nodes of the Spanish stock market. We use data from the following main market risk factors: returns on Santander Bank shares, the Spanish Stock Market Index, Euro/Dollar exchange rates and the index that measures the total return performance of a funded long credit position in the on-the-run iTraxx Crossover 5-Year-Index. Our contribution is a hybrid model that combines correct sequential pattern learnings with an improved prediction performance in the volatility of market risk factors. Our findings show that the Support Vector Machine and the Long-Short-Term Memory Model present better prediction results in all factors in the stability periods. Therefore, the proposed method is promising for application in risk management systems.",2024
Abnormal behavior identification of enterprise cloud platform financial system based on artificial neural network,"This paper presents an effective and accurate method to analyze the network traffic risk of enterprise public cloud financial system by using deep learning algorithm. To build the analytical model, the collected data is preprocessed to extract relevant features that contribute to risk analysis. The pre-processed data is used to train the deep learning model. The model is designed to learn patterns and relationships in network traffic data. The network traffic risk analysis module is constructed by combining the deep learning model with the system architecture of the enterprise public cloud financial system. Through a trained deep learning model, the module is able to accurately identify abnormal behavior in network traffic and provide corresponding risk assessments. The results show that the proposed system module can accurately identify abnormal behavior in network traffic and provide risk assessment.",2024
SF-Transformer: A Mutual Information-Enhanced Transformer Model with Spot-Forward Parity for Forecasting Long-Term Chinese Stock Index Futures Prices,"The complexity in stock index futures markets, influenced by the intricate interplay of human behavior, is characterized as nonlinearity and dynamism, contributing to significant uncertainty in long-term price forecasting. While machine learning models have demonstrated their efficacy in stock price forecasting, they rely solely on historical price data, which, given the inherent volatility and dynamic nature of financial markets, are insufficient to address the complexity and uncertainty in long-term forecasting due to the limited connection between historical and forecasting prices. This paper introduces a pioneering approach that integrates financial theory with advanced deep learning methods to enhance predictive accuracy and risk management in China's stock index futures market. The SF-Transformer model, combining spot-forward parity and the Transformer model, is proposed to improve forecasting accuracy across short and long-term horizons. Formulated upon the arbitrage-free futures pricing model, the spot-forward parity model offers variables such as stock index price, risk-free rate, and stock index dividend yield for forecasting. Our insight is that the mutual information generated by these variables has the potential to significantly reduce uncertainty in long-term forecasting. A case study on predicting major stock index futures prices in China demonstrates the superiority of the SF-Transformer model over models based on LSTM, MLP, and the stock index futures arbitrage-free pricing model, covering both short and long-term forecasting up to 28 days. Unlike existing machine learning models, the Transformer processes entire time series concurrently, leveraging its attention mechanism to discern intricate dependencies and capture long-range relationships, thereby offering a holistic understanding of time series data. An enhancement of mutual information is observed after introducing spot-forward parity in the forecasting. The variation of mutual information and ablation study results highlights the significant contributions of spot-forward parity, particularly to the long-term forecasting. Overall, these findings highlight the SF-Transformer model's efficacy in leveraging spot-forward parity for reducing uncertainty and advancing robust and comprehensive approaches in long-term stock index futures price forecasting.",2024
An Optimized BP Neural Network Model and Its Application in the Credit Evaluation of Venture Loans,"With the rapid development of entrepreneurship loans in China, the construction of a credit evaluation system of risk loans has become an important financial safeguard measure. This paper mainly studies the following three aspects. Firstly, in view of the subjective factors in the approval process of venture loans, based on the credit evaluation system of commercial banks and the data characteristics of venture loans, a credit evaluation system based on venture loans is constructed. Secondly, the randomized uniform design method is used to improve the population initialization method to realize the uniform distribution of the individual population. Finally, aiming at the problem of low efficiency of venture loan audit, this paper proposes an optimized BP neural network to evaluate the venture loan. Especially, through data processing, a credit index system is constructed, and then the optimized BP neural network model is determined in parameters. The model contains 15 input nodes, 1 hidden layer, and 2 output layers. Finally, the simulation shows that the optimized BP neural network model has obvious advantages in the loan evaluation. This paper includes the development status of credit evaluation of venture loans is empirically studied by using an optimized BP neural network model of nonexpected output.",2022
An Intelligent Market Capitalization Predictive System Using Deep Learning,"Business forecast is a biggest factor which generally affects the economical condition of any Financial Industry. If the forecast model is not a better one then it can cause liquidation and spoil the trust of customers in the market. Early predictions based on social media clients' opinion plays a major role in order to reduce risk on business and keep the trust of customer. According to the survey done by Fintech's world topic analysis is treated as one of the vital factor used for the determination of client's trends and for forecast analysis. Here we have performed a comparative analysis upon the social media data provide by Twitter in order to get an idea about the perception and understanding of clients' requirements across the world. For the experimentation purpose we have used Tweeter data for tweet analysis, for stock price we have yahoo finance data and for number of stocks we have used morning star data set. For the processing of Tweets given by the clients we have built an automated system using Deep Learning. Here the problem is divided in to 2 parts. In first part Text classification is done using Tensorflow and Keras, Latent Dirichlet allocation (LDA), Natural Language Toolkit (NLTK-NLP).In this part using topic analysis the past tweet history is analyzed. In second part we are predicting forecastto identify multiple key business factors using Long Short term Memory (LSTM) using python/Rto. The actual aim of the system is to discover the effect of 3 fundamental parameters like security breaches, innovation, and stock exchange which are present in tweet given by the customers. Here the analysis is done on the last ten years tweets given by the clients for prediction of upcoming seven-day as well as monthly Market Cap. The actual intention of the work done here is to uncover the major diversity among two banks and bridge up the 3 gaps data breach, innovation and stock exchange in the available models. The latest information obtained in the system offers advantages to both Bank and customers to forecast Market value for the unbeaten estimation. We have obtained a prediction accuracy of 70.74% and 54.55% for monthly prediction and for weekly prediction we have obtained accuracy of 83.44% and 76.06% for Bank A and Bank B.",2018
A Novel Risk-Perception Model Based on Blockchain for Supply Chain Finance of China Real Estate,"More than 220 enterprises in China's real estate industry have gone bankrupt, causing serious losses. The National Bureau of Statistics of China showed that the country's investment in property development fell by 8.5% year -on -year, while domestic lending dropped by 11.5% and the use of foreign capital fell by 43%. Upon this, the development of supply chain finance can alleviate the pressure on enterprise funds and stabilize the real estate market. However, risk in supply chain finance is the biggest obstacle to the development of supply chain finance and current researches on risk assessment of supply chain finance face problems such as imprecise classification, slow assessment speed, a small number of samples, and data that is easily tampered with. Therefore, this study integrated graph convolutional neural networks into the smart contracts of the contract layer of blockchain. This integration established a novel intelligent perception model for supply chain finance risk. Based on a consortium chain with the government and enterprises as nodes, the model was established, including risk monitoring, assessment, and categorized early warnings. In the risk assessment part, we compared the graph convolutional neural network with multilayer perceptron and support vector machine finding that the accuracy rate of the graphic convolutional neural network is 94%, which is higher than the above models. The intelligent risk -perception model proposed in this paper operates faster than expert judgment assessments used by banks. It also provides accurate risk levels and quantifies the probability of enterprises being classified as high -risk, offering technical support to regulatory authorities in controlling supply chain financial risk.",2024
NMal-Droid: network-based android malware detection system using transfer learning and CNN-BiGRU ensemble,"Currently, malware activities pose a substantial risk to the security of Android applications. These risks are capable of stealing important information and causing chaos in the economy, social structure, and financial sector. Malicious network traffic targets Android applications due to their constant connectivity. This study develops the NMal-Droid approach for network-based Android malware detection and classification. First, we designed a packet parser algorithm that filters the combination of HTTP traces and TCP flows from PCAPs (Packet Capturing) files. Second, the fine-tune embedding approach is developed that uses a word2vec pre-trained model to analyze features' embeddings in three different ways, i.e., random, static, and dynamic. It is used to learn and extract feature-matrix matrices with related meanings. Third, The Convolutional Neural Network (CNN) is used to extract effective features from embedded information. Fourth, the Bi-directional Gated Recurrent Unit (Bi-GRU) neural network is designed to compute gradient computation in the context of time-forward and time-reversed. Finally, a multi-head ensemble of CNN-BiGRU is developed for accurate malware classification and detection. The proposed approach is evaluated on five different activation functions with 100 filters and a range of 1-5 kernel sizes for in-depth investigation. An explainable AI-based experiment is conducted to interpret and validate the proposed approach. The proposed method is tested using two big Android malware datasets, CIC-AAGM2017 and CICMalDroid 2020, which comprise a total of 10.2k malware and 3.2K benign samples. It is shown that the proposed approach outperforms as compared to the state-of-the-art methods.",2024
A multi-scale convolutional neural network-based model for clustering economic risk detection,"After the public health event of COVID-19, more academics are looking into how to predict combined economic hazards associated with public health incidents. There are currently just a few approaches for detecting aberrant behaviour in aggregated financial risk, and most only work after the economic risk has already been inappropriately aggregated. As a result, we provide a multi-scale convolutional neural network-based model for clustering financial risk anomaly detection (MCNN). First, we use MCNN to train a model for counting economic risks that are used to evaluate aberrant risk aggregating data. Second, we can use the test results to extract the financial risk statistics and economic risk precursor coordinate points. Then, we calculate the economic risk distribution entropy, distance, potential energy and density. To train the three elements of the development state and create the prediction model, we finally use the particle swarm optimization-based extreme learning machine (PSO-ELM). The results of the experiments demonstrate that, in comparison to existing algorithms, our model can efficiently realize early warning and detect abnormal behaviours of aggregated economic risks with high timeliness. Additionally, our method achieves a forecast accuracy of 97.68% and can give additional time to take emergency action.",2023
Crop Disease Diagnosis using Deep Learning Models,"Diseases and pesticides are the most common problems of wheat being faced by the farmers. These are commonly formed due to improper land preparation, unconditional rains, variable climate conditions, and irregular watering. The impact of these factors on the wheat crop could ultimately affect the economy of the country. Timely detection of the diseases could avoid many financial and time-based losses and help in applying relevant disease management methods. The old manual methods of detecting the diseases are based on personal observations. These have not much contributed due to: a) High frequency of errors, b) Time consuming, c) In case of detecting the large area of the crop by the humans, the observation may not be accurate, d) Risk of spreading disease while applying manual methods. User-friendly applications with self-learning ability are primarily required to help the farmers to deal with the disease problems. In this paper, an effective and efficient approach has been presented for the timely diagnosis of wheat disease and to provide relevant management methods. This user-friendly application facilitates various types of users in the management of crop diseases. The data set has been obtained from online sources and Convolutional Neural Network (CNN) has been used to train the data. The proposed approach has gained significant accuracy in the detection of diseases.",2020
Predicting the Distress of Financial Intermediaries using Convolutional Neural Networks,"Over the past 15 years, the United States has faced two major economic events - the 2008 financial meltdown and the 2019 Shadow Bank crisis. Now, it faces a new financial emergency brought on by COVID-19. Financial intermediaries comprise institutions such as banks, mutual funds, insurance companies, real estate investment trusts, among others, and are a significant part of economic stability. Too big to fail has become a well-known phrase. Therefore, being able to predict the financial distress of a financial intermediary is very important. Traditionally, the Altman Z-score (or a variation thereof), has been used to predict bankruptcy. It uses 5 key financial ratios to create an index score, or Z-score. Predicting financial distress, however, also accounts for companies that may not be currently on the path to bankruptcy, but may be in the future. Contemporary research has shown that combining sentiment analysis with ratio analysis improves the prediction. Our methodology uses both financial ratios and sentiment, but also includes the London Interbank Offered Rate (LIBOR), and the keywords Going Concern and Concentration Risk. Using a Convolutional Neural Network, we classified financial intermediaries as either distressed or not distressed with an accuracy of 88.24%.",2021
A Deep Learning Model for Pediatric Patient Risk Stratification,"OBJECTIVES: Current models for patient risk prediction rely on practitioner expertise and domain knowledge. This study presents a deep learning model-a type of machine learning that does not require human inputs-to analyze complex clinical and financial data for population risk stratification. STUDY DESIGN: A comparative predictive analysis of deep learning versus other popular risk prediction modeling strategies using medical claims data from a cohort of 112,641 pediatric accountable care organization members. METHODS: Skip-Gram, an unsupervised deep learning approach that uses neural networks for prediction modeling, used data from 2014 and 2015 to predict the risk of hospitalization in 2016. The area under the curve (AUC) of the deep learning model was compared with that of both the Clinical Classifications Software and the commercial DxCG Intelligence predictive risk models, each with and without demographic and utilization features. We then calculated costs for patients in the top 1% and 5% of hospitalization risk identified by each model. RESULTS: The deep learning model performed the best across 6 predictive models, with an AUC of 75.1%. The top 1% of members selected by the deep learning model had a combined healthcare cost $5 million higher than that of the group identified by the DxCG Intelligence model. CONCLUSIONS: The deep learning model outperforms the traditional risk models in prospective hospitalization prediction. Thus, deep learning may improve the ability of managed care organizations to perform predictive modeling of financial risk, in addition to improving the accuracy of risk stratification for population health management activities.",2019
CNC milling cutters condition monitoring based on empirical wavelet packet decomposition,"Machining is a versatile field in the manufacturing industry. In milling operations, tool wear is considered the most critical factor affecting the surface quality of the milled piece. Furthermore, the gradual tool wear impacts the milling process, leading to significant downtime, which has serious financial consequences. Unavoidably, a sustainable and reliable condition monitoring system must be developed to reduce the risk of downtime and enhance production quality. The deployment of prognostic and health management (PHM) solutions is becoming increasingly important. It is regarded as one of the main levers for monitoring tool wear status. In this paper, a novel methodology is proposed for extracting pertinent health indicators (HIs) that reflect the degradation behavior of a set of milling cutters and estimating their remaining useful lives (RULs). First, a new time-frequency signal-analysis approach, titled empirical wavelet packet decomposition (EWPD), is proposed to scrutinize the data collected via multi-sensor acquisition. This technique provides a new segmentation of the signal's Fourier spectrum, distributed on levels, to investigate a broader variety of frequency bands and enhance the traditional segmentation structure's performance. Second, a new health indicator is designed based on an innovative selection of the time-domain features computed for each frequency band over each level. Finally, the long short-term memory (LSTM) network is used to estimate the RUL of each cutter. A comparison between the suggested processing method and the wavelet packet transform (WPT) is made to support the hypothesis regarding the effectiveness of the proposed technique. Experimental outcomes seem to be satisfying.",2023
Bagging Supervised Autoencoder Classifier for credit scoring,"Automatic credit scoring, a crucial risk management tool for banks and financial institutes, has attracted much attention in the past few decades. As such, various approaches have been developed to accurately and efficiently estimate defaults in loan applicants and seamlessly improve and facilitate decision-making in the lending process. However, the imbalanced nature of credit scoring datasets, as well as the heterogeneous nature of features in credit scoring task pose many challenges in developing and implementing effective credit scoring models, targeting the generalization power of classification models on unseen data. To mitigate these challenges, in this paper, we propose the Bagging Supervised Autoencoder Classifier (BSAC). BSAC is a learning model which simultaneously leverages the superior power of supervised autoencoders and representation learning in classification, as well as the Bagging mechanism to handle the irregularities in feature space. Supervised autoencoder has been exploited to learn an optimal latent space from heterogeneous features and perform classification on top of the learned latent space. In particular, the Bagging mechanism has been employed in the learning process to construct various samples of original data to tackle the problem that arises from imbalanced data and irregularities of features in latent space. Extensive experiments on various real-world and benchmark datasets validate the superiority and robustness of the proposed method in predicting the outcome of loan applications.",2023
Deep learning for finance: deep portfolios,"We explore the use of deep learning hierarchical models for problems in financial prediction and classification. Financial prediction problems - such as those presented in designing and pricing securities, constructing portfolios, and risk management - often involve large data sets with complex data interactions that currently are difficult or impossible to specify in a full economic model. Applying deep learning methods to these problems can produce more useful results than standard methods in finance. In particular, deep learning can detect and exploit interactions in the data that are, at least currently, invisible to any existing financial economic theory. Copyright (c) 2016 John Wiley & Sons, Ltd.",2017
Forecasting volatility index by temporal convolutional neural network,"Forecasting volatility is essential to avoiding the risk caused by the uncertainties of an financial asset. Complicated financial volatility features such as ambiguity between non-stationarity and stationarity, asymmetry, long-memory, sudden fairly large values like outliers bring great challenges to volatility forecasts. In order to address such complicated features implicity, we consider machine leaning models such as LSTM (1997) and GRU (2014), which are known to be suitable for existing time series forecasting. However, there are the problems of vanishing gradients, of enormous amount of computation, and of a huge memory. To solve these problems, a causal temporal convolutional network (TCN) model, an advanced form of 1D CNN, is also applied. It is confirmed that the overall forecasting power of TCN model is higher than that of the RNN models in forecasting VIX, VXD, and VXN, the daily volatility indices of S&P 500, DJIA, Nasdaq, respectively.",2023
Financial Volatility Forecasting: A Sparse Multi-Head Attention Neural Network,"Accurately predicting the volatility of financial asset prices and exploring its laws of movement have profound theoretical and practical guiding significance for financial market risk early warning, asset pricing, and investment portfolio design. The traditional methods are plagued by the problem of substandard prediction performance or gradient optimization. This paper proposes a novel volatility prediction method based on sparse multi-head attention (SP-M-Attention). This model discards the two-dimensional modeling strategy of time and space of the classic deep learning model. Instead, the solution is to embed a sparse multi-head attention calculation module in the network. The main advantages are that (i) it uses the inherent advantages of the multi-head attention mechanism to achieve parallel computing, (ii) it reduces the computational complexity through sparse measurements and feature compression of volatility, and (iii) it avoids the gradient problems caused by long-range propagation and therefore, is more suitable than traditional methods for the task of analysis of long time series. In the end, the article conducts an empirical study on the effectiveness of the proposed method through real datasets of major financial markets. Experimental results show that the prediction performance of the proposed model on all real datasets surpasses all benchmark models. This discovery will aid financial risk management and the optimization of investment strategies.",2021
Deep Learning-Based Intelligent Image Recognition and Its Applications in Financial Technology Services,"The financial technology service industry involves a large number of image and text information processing tasks. By automatically processing images and text information, financial institutions can greatly reduce labor costs, improve overall operational efficiency, and help financial institutions identify and predict risks more accurately, thereby improving risk management capabilities. The existing image symbol recognition and scene text detection methods may be affected in terms of recognition accuracy when processing complex scenes, low-resolution images or texts affected by obstacles, distortions and other factors. To this end, this study conducts an in-depth study on the application of deep learning-based intelligent image recognition in financial technology services. It elaborates the application scenarios of image symbol recognition and scene text detection in financial technology services. The ASTER model is improved, and the combination of attention mechanism sequential decoding can effectively capture local information and global dependencies in the feature sequence, thereby improving the recognition accuracy of the image symbol recognition model. By focusing on the center point position information of the text, pixels with the same center point are aggregated to reduce the interference between adjacent texts to some extent, achieving more accurate text segmentation. Experimental results validate the effectiveness of the method in this study.",2023
DESIGNING A DEEP LEARNING-BASED FINANCIAL DECISION SUPPORT SYSTEM FOR FINTECH TO SUPPORT CORPORATE CUSTOMER'S CREDIT EXTENSION,"In the banking business, Machine Learning (ML) is critical for averting financial losses. Credit risk evaluation is perhaps the most important prediction task that may result in billions of dollars in damages each year (i.e., the risk of default on debt). Gradient Boosted Decision Tree (GBDT) models are now responsible for a large portion of the improvements in ML for predicting credit risk. However, these improvements begin to stagnate without adding pricey new data sources or carefully designed features. In this work, we describe our efforts to develop a unique Deep Learning (DL)-based technique for assessing credit risk that does not rely on additional model inputs. We present a new credit decision support approach with Gated Recurrent Unit (GRU) and Convolutional Neural Networks (CNN) that uses lengthy historical sequences of financial data while requiring few resources. We show that our DL technique, which uses Term Frequency-Inverse Document Frequency (TF-IDF) pre-classifiers, outperforms the benchmark models, resulting in considerable cost savings and early credit risk identification. We also show how our method may be utilized in a production setting, where our sampling methodology allows sequences to be effectively kept in memory and used for quick online learning and inference.",2022
Can public opinions improve the effect of financial early warning ? -- an empirical study on the new energy industry,"Public opinion will significantly affect investor decision -making and stock prices, which ultimately has an impact on the long-term development of the new energy industry. This paper mainly aims to delve in the impact of public opinion on the efficacy of financial risk early warning effect and try to establish an enhanced financial risk early warning model for the new energy list companies. To achieve this, we collect the financial data and public evaluation texts of 185 new energy listed companies, converting the text into emotional indicators which are combined with financial indicators to build a financial risk early warning model for new energy listed companies. The contributions of this paper are as follows: (1) The experiment validation demonstrates that the combination of 7 deep learning models and Bagging algorithm highly improves the accuracy of the sentiment analysis model, achieving an accuracy of 84.09%. (2) The accuracy of financial early warning models is generally enhanced after adding sentiment indicators, among which the accuracy of the BP neural network model reached 95.78%. (3) Through clustering analysis, the evaluation models can productively divide the warning intervals, thereby bolstering the interpretability and applicability of early warning results. Therefore, we suggest that when establishing the financial early warning system, it ' s necessary to take public opinions into consideration. Aside from improving the early warning effect, it also can be used as a separate indicator for daily monitoring.",2024
A new fusion neural network model and credit card fraud identification,"Credit card fraud identification is an important issue in risk prevention and control for banks and financial institutions. In order to establish an efficient credit card fraud identification model, this article studied the relevant factors that affect fraud identification. A credit card fraud identification model based on neural networks was constructed, and in-depth discussions and research were conducted. First, the layers of neural networks were deepened to improve the prediction accuracy of the model; second, this paper increase the hidden layer width of the neural network to improve the prediction accuracy of the model. This article proposes a new fusion neural network model by combining deep neural networks and wide neural networks, and applies the model to credit card fraud identification. The characteristic of this model is that the accuracy of prediction and F1 score are relatively high. Finally, use the random gradient descent method to train the model. On the test set, the proposed method has an accuracy of 96.44% and an F1 value of 96.17%, demonstrating good fraud recognition performance. After comparison, the method proposed in this paper is superior to machine learning models, ensemble learning models, and deep learning models.",2024
Adoption of deep learning Markov model combined with copula function in portfolio risk measurement,"In order to accurately describe the risk dependence structure and correlation between financial variables, carry out scientific financial risk assessment, and provide the basis for accurate financial decision-making, first the basic theory of Copula function is established and the mixed Copula model is constructed. Then the hybrid Copula model is nested in a hidden Markov model (HMM), the risk dependences among banking, insurance, securities and trust industries are analysed, and the Copula-Garch model is constructed for empirical analysis of investment portfolio. Finally, the deep learning Markov model is adopted to predict the financial index. The results show that the mixed Copula model based on HMM is more effective than the single Copula and the mixed Copula models. The empirical structure shows that among the four major financial industries in China, the banking and insurance industries have strong interdependence and high probability of risk contagion. The investment failure rate under 95%, 97.5% and 99% confidence intervals calculated by Copula-Garch model are 4.53%, 2.17% and 1.08%, respectively. Moreover, the errors of deep learning Markov model in stock price prediction of Shanghai Pudong Development Bank (sh600000), Guizhou Moutai (sh600519) and China Ping An Insurance (sh601318) are 2.56%, 2.98% and 3.56% respectively, which indicates that the four major financial industries in China have strong interdependence and risk contagion, so that the macro or systemic risks may arise, and the deep-learning Markov model can be adopted to predict the stock prices.",2022
Securing Linux Cloud Environments: Privacy-Aware Federated Learning Framework for Advanced Malware Detection in Linux Clouds,"Cloud computing is integral to modern IT infrastructure, with Linux-based virtual machines (VMs) comprising 95% of public cloud environments. This widespread use makes Linux VMs a prime target for cyberattacks, particularly advanced malware designed for financial gain, data theft, or operational sabotage. Traditional malware detection methods, despite their sophistication, often operate directly on the VMs they protect, making them susceptible to evasion by advanced malware-based threats. Furthermore, these methods are limited by their reliance on data confined to individual VMs, hindering their ability to generalize across different environments. While machine learning (ML) algorithms are frequently used to enhance malware detection, they typically require extensive data sharing, which poses significant risks to data confidentiality and user privacy. To overcome these challenges, we propose a federated learning-based framework for detecting unknown malware in Linux cloud environments. This framework allows a community of VMs, each equipped with a trusted local malware detection mechanism, to collaborate and enhance detection capabilities without sharing the underlying data, thus preserving privacy. The approach involves continuously capturing and converting volatile memory dumps into images, which are then used to train a federated convolutional neural network (CNN) in a decentralized manner. This eliminates the need for manual feature extraction and mitigates the risk of a single point of failure. Experimental results on widely-used Linux VMs demonstrate the framework's effectiveness, achieving an AUC of up to 98.3% in detecting unknown malware, providing a robust and privacy-preserving solution for cloud security.",2025
Uncertainty-Aware Reinforcement Learning for Portfolio Optimization,"We explored the use of Reinforcement Learning (RL) combined with risk assessment for optimizing investment portfolios. The dynamic nature of trading, compounded by market frictions, the responses of other market participants, and uncertainties, poses challenges to portfolio optimization. The financial market's intricacies make it difficult to model accurately, compounded by regulatory requirements and internal risk policies mandating risk-averse decisions to avoid catastrophic outcomes. To address this, we proposed risk estimation for investor's risk tolerance threshold. Moreover, modern Deep Learning models are adept at approximating complex relationship between abundant data, however, the main drawback we face now a day is generalization of the relationship to the unseen data. Therefore, the epistemic uncertainty can pose risk to the decision making system. This uncertainty is further addressed using a Variational Autoencoder (VAE) to estimate, and Cost Network to backpropogate riskiness through the model to learn actions with safe results. The actions with stable result or lower reward will be avoided due to reward optimization of RL. Consequently, we successfully managed to reduce the risk and uncertainties in the agent testing process. Our risk-constrained RL algorithm demonstrated zero violation of the constraint in the testing phase. This suggests that adopting a risk-averse RL approach could be beneficial for portfolio optimization, particularly for risk-averse investors.",2024
Application of artificial intelligence for nutrient estimation in surface water bodies of basins with intensive agriculture,"Eutrophication is one of the most relevant concerns due to the risk to water supply and food security. Nitrogen and phosphorus chemical species concentrations determined the risk and magnitude of eutrophication. These analyses are even more relevant in basins with intensive agriculture due to agrochemical discharges. However, analyzing these nutrients is labor intensive, as sampling to intercalibration in the laboratory requires considerable financial and human resources. Currently, artificial intelligence allows the modeling of phenomena and variables in various fields. This research focuses on the exploration of other machine learning methods, including multilayer perceptron (MLP), k-nearest neighbor (KNN), convolutional neural network (CNN), and random forest (RF) for the estimation of nutrients in surface waters of Sinaloa, Mexico (11 model basins), the states with the highest exports of agricultural products. Nutrients were considered in all possible chemical forms, such as total nitrogen, Kjeldahl nitrogen, ammonia nitrogen, total phosphorus, and orthophosphate. For estimation, the selected input parameters are characterized by pH, dissolved oxygen, conductivity, water temperature, and total suspended solids, which do not require chemical reagents and can be measured in real time. The parameter information was obtained from the National Network for Water Quality Monitoring database (6,200 data recorded since 2012). Finally, hyperparameter normalization and optimization (HPO) methods were implemented to maximize the best-performing model. Each model obtained different coefficient of determination values (R2): MLP between 0.64 and 0.77, CNN from 0.65 to 0.76, KNN from 0.64 to 0.79, and RF from 0.79 to 0.85. The latter is considered the best performer, with values of 0.95 in training and 0.94 in validation after applying HPO. Notably, the models are valid for any surface water body and in any climatic season in the state of Sinaloa, M & eacute;xico. Therefore decision-makers can use them for science-based environmental regulation of land use and pesticide application.",2025
Enhancing Portfolio Performance through Financial Time-Series Decomposition-Based Variational Encoder-Decoder Data Augmentation,"The objective of portfolio diversification is to reduce risk and potentially enhance returns by spreading investments across different asset classes. Existing portfolio diversification models have traditionally been trained on historical financial time series data. However, several issues arise with historical financial time series data, making it challenging to train models effectively to achieve the portfolio diversification objective: an insufficient amount of training data and the uncertainty deficiency problem, wherein the uncertainty that existed in the past is not visible in the present. Insufficient datasets, characterized by small data size, result in information asymmetry and compromise portfolio performance. This limitation underscores the importance of adopting a pattern-centric data augmentation approach, capable of unveiling hidden patterns and structures within the financial time series data. To address these challenges, this paper introduces the financial time series decomposition-based variational encoder-decoder (FED) method to augment financial time series data, overcoming the limitations of insufficient training data and providing a more realistic and dynamic simulation of the financial market environment. By decomposing the data into distinct components, such as trend, dispersion, and residual, FED leverages pattern-centric data augmentation within the financial time series data. In the environment generated using the FED method, this paper proposes a two-class portfolio diversification, called FED2Port. It integrates stochastic elements into the reward function, enabling a reinforcement learning algorithm to learn from a comprehensive spectrum of financial market uncertainties. The experimental results demonstrate that the proposed model significantly enhances portfolio performance.",2024
Adoption of deep learning Markov model combined with copula function in portfolio risk measurement,"In order to accurately describe the risk dependence structure and correlation between financial variables, a scientific financial risk assessment was carried out, and the basis for accurate financial decision-making was provided; the basic theory of copula function is established first, and the mixed copula model is constructed; then, the hybrid copula model is nested in a hidden Markov model (HMM); the risk dependences among banking, insurance, securities and trust industries are analysed, and the Copula-Garch model is constructed for empirical analysis of investment portfolio; finally, the deep learning Markov model is adopted to predict the financial index. The results show that the mixed copula model based on the HMM is more effective than the single copula model and the mixed copula model. The empirical structure shows that among the four major financial industries in China, banking and insurance industries have strong interdependence and a high probability of risk contagion. The investment failure rate under 95%, 97.5% and 99% confidence intervals calculated by the Copula-Garch model is 4.53%, 2.17% and 1.08%, respectively. Moreover, the errors of the deep learning Markov model in stock price prediction of Shanghai Pudong Development Bank (sh600000), Guizhou Moutai (sh600519) and China Ping An Insurance (sh601318) are 2.56%, 2.98% and 3.56%, respectively, which indicates that the four major financial industries in China have strong interdependence and risk contagion so that the macro or systemic risks may arise, and the deep learning Markov model can be adopted to predict the stock prices.",2021
Application of Machine Learning in Enterprise Financial Risk Assessment: A Study About China's A-Share Listed Manufacturing Companies,"Based on the financial data of domestic A-share listed firms from 2000 to 2022, this paper aims to explore the effectiveness of machine learning in identifying the financial risk of Chinese A-share listed manufacturing firms. To this end, a variety of machine learning models, including logistic regression, decision tree, random forest, XGBoost, SVM, and LSTM, are used to assess the financial risk of enterprises, and the key attributes of enterprise financial risk are extracted through the interpretability exploration and importance coefficient measurement. From this paper, the following conclusions are drawn: (i) XGBoost model performs the best on all attributes, showing its strong ability in dealing with complex financial datasets, and LSTM, which adds time-series factors, performs poorly, which is speculated that it may be related to the incompatibility of the characteristics of the financial data, the reliance on the time-series features, and the need for financial fine features. (ii) Audit opinion, Net Profit and ROA are key influencing factors.",2025
The Use of Machine Learning Combined with Data Mining Technology in Financial Risk Prevention,"In order to improve the ability of enterprises to deal with financial risks, reduce labor costs, reduce financial losses, increase investors' trust in enterprise finance, and establish a comprehensive enterprise financial risk evaluation index system, the deep learning technology and data mining method under the artificial intelligence environment are applied to the financial risk analysis of listed companies. Under this background, an analysis method of financial risk prevention based on interactive mining is put forward. Around the various financial risks faced by listed companies, a special risk analysis model is established to analyze the key factors. Through the empirical analysis of 21 listed companies, rules with high trust are found, and the financial crisis of listed companies is forewarned in time. The results show that the financial risk evaluation index system of four dimensions of solvency, operation ability, profitability, growth ability and cash flow ability can affect the financial risk of enterprises. Compared with the traditional data mining algorithm, the algorithm of financial risk index evaluation model constructed in this exploration has the best performance, and the average detection accuracy is 90.27%. The accuracy of the model can be improved by 30%. The results show that the weight of each variable is good, and all of them pass the consistency test. The evaluation effect is high, and the relative error is 1.55%, which proves the rationality and accuracy of the model. The financial risk prevention model based on deep learning and data mining technology can provide a theoretical basis for the research of enterprise financial risk prevention.",2022
An in-depth investigation of five machine learning algorithms for optimizing mixed-asset REITs,"Real estate is a favored investment option as it allows investors to diversify their portfolios and minimize risk. Investors can invest in real estate directly by purchasing a property, or through real estate investment funds (REITs) where they can purchase shares in companies that own and manage real estate. Investing in REITs has become increasingly popular because it eliminates some of the disadvantages associated with direct real estate investment, such as the need for a large upfront payment. When investing in mixed asset portfolios, it is crucial to predict future prices accurately to ensure profitable and less risky asset allocation. However, literature on price prediction often focuses on only one or two algorithms, and there is no research that explores REITs' price prediction in the context of portfolio optimization. To address this gap, we conducted a thorough evaluation of 5 machine learning algorithms (ML), including Ordinary Least Squares Linear Regression (LR), Support Vector Regression (SVR), k-Nearest Neighbors Regression (KNN), Extreme Gradient Boosting (XGBoost), and Long/Short-Term Memory Neural Networks (LSTM), as well as other financial benchmarks like Holt's Exponential Smoothing (HES), Trigonometric Seasonality, Box-Cox Transformation, ARMA Errors, Trend, and Seasonal Components (TBATS), and Auto-Regression Integrated Moving Average (ARIMA). We applied these algorithms to predict future prices for 30 REITs from the US, UK, and Australia, as well as 30 stocks and 30 bonds. The assets were then used as part of a portfolio, which we optimized using a genetic algorithm. Our results showed that using ML algorithms for price prediction provided at least three times the return over benchmark models and reduced risk by almost two-fold. For REITs, we observed that the use of ML algorithms led to a higher allocation to REITs diversified by country. In particular, our results showed that SVR was the best-performing algorithm in terms of risk-adjusted returns across different time horizons, as confirmed by our Friedman test results (Sharpe ratio). Overall, our study highlights the effectiveness of ML algorithms in predicting asset prices and optimizing portfolio allocation.",2024
Optimization of venture portfolio based on LSTM and dynamic programming,"A rational investor always pursues a portfolio with the greatest possible return and the least possible risk. Therefore, a core issue of investment decision analysis is how to make an optimal investment choice in the market with fuzzy information and realize the balance between maximizing the return on assets and minimizing the risk. In order to find optimal investment portfolios of financial assets with high volatility, such as gold and Bitcoin, a mathematical model for formulating investment strategies based on the long short-term memory time series and the dynamic programming model combined with the greedy algorithm has been proposed in this paper. The model provides the optimal daily strategy for the five-year trading period so that it can achieve the maximum expected return every day under the condition of a certain investment amount and a certain risk. In addition, a reasonable risk measure based on historical increases is established while considering the weights brought by different investment preferences. The empirical analysis results show that the optimal total assets and initial capital obtained by the model change in the same proportion, and the model is relatively stable and has strong adaptability to the initial capital. Therefore, the proposed model has practical reference value and research significance for investors and promotes a better combination of computer technology and financial investment decision.",2023
Potentials and challenges of deep-learning- assisted porosity prediction based on thermo- graphic in situ monitoring in laser powder bed fusion,"Laser powder bed fusion is one of the most promising additive manufacturing techniques for printing complex-shaped metal components. However, the formation of subsurface porosity poses a significant risk to the service lifetime of the printed parts. In situ monitoring offers the possibility to detect porosity already during manufacturing. Thereby, process feedback control or a manual process interruption to cut financial losses is enabled. Short-wave infrared thermography can monitor the thermal history of manufactured parts which is closely connected to the probability of porosity formation. Artificial intelligence methods are increasingly used for porosity prediction from the obtained large amounts of complex monitoring data. In this study, we aim to identify the potential and the challenges of deep-learning-assisted porosity prediction based on thermographic in situ monitoring. Therefore, the porosity prediction task is studied in detail using an exemplary dataset from the manufacturing of two Haynes282 cuboid components. Our trained 1D convolutional neural network model shows high performance (R-2 score of 0.93) for the prediction of local porosity in discrete sub-volumes with dimensions of (700 x 700 x 40) mu m(3). It could be demonstrated that the regressor correctly predicts layer-wise porosity changes but presumably has limited capability to predict differences in local porosity. Furthermore, there is a need to study the significance of the used thermogram feature inputs to streamline the model and to adjust the monitoring hardware. Moreover, we identified multiple sources of data uncertainty resulting from the in situ monitoring setup, the registration with the ground truth X-ray-computed tomography data and the used preprocessing workflow that might influence the model's performance detrimentally.",2023
Portfolio Learning Based on Deep Learning,"Traditional portfolio theory divides stocks into different categories using indicators such as industry, market value, and liquidity, and then selects representative stocks according to them. In this paper, we propose a novel portfolio learning approach based on deep learning and apply it to China's stock market. Specifically, this method is based on the similarity of deep features extracted from candlestick charts. First, we obtained whole stock information from Tushare, a professional financial data interface. These raw time series data are then plotted into candlestick charts to make an image dataset for studying the stock market. Next, the method extracts high-dimensional features from candlestick charts through an autoencoder. After that, K-means is used to cluster these high-dimensional features. Finally, we choose one stock from each category according to the Sharpe ratio and a low-risk, high-return portfolio is obtained. Extensive experiments are conducted on stocks in the Chinese stock market for evaluation. The results demonstrate that the proposed portfolio outperforms the market's leading funds and the Shanghai Stock Exchange Composite Index (SSE Index) in a number of metrics.",2020
DEEP STOCK REPRESENTATION LEARNING: FROM CANDLESTICK CHARTS TO INVESTMENT DECISIONS,"We propose a novel investment decision strategy (IDS) based on deep learning. The performance of many IDSs is affected by stock similarity. Most existing stock similarity measurements have the problems: (a) The linear nature of many measurements cannot capture nonlinear stock dynamics; (b) The estimation of many similarity metrics (e.g. covariance) needs very long period historic data (e.g. 3K days) which cannot represent current market effectively; (c) They cannot capture translation-invariance. To solve these problems, we apply Convolutional AutoEncoder to learn a stock representation, based on which we propose a novel portfolio construction strategy by: (i) using the deeply learned representation and modularity optimisation to cluster stocks and identify diverse sectors, (ii) picking stocks within each cluster according to their Sharpe ratio (Sharpe 1994). Overall this strategy provides low-risk high-return portfolios. We use the Financial Times Stock Exchange 100 Index (FTSE 100) data for evaluation. Results show our portfolio outperforms FTSE 100 index and many well known funds in terms of total return in 2000 trading days.",2018
Development of Model to Predict Natural Disaster-Induced Financial Losses for Construction Projects Using Deep Learning Techniques,"This study goals to develop a model for predicting financial loss at construction sites using a deep learning algorithm to reduce and prevent the risk of financial loss at construction sites. Lately, as the construction of high-rise buildings and complex buildings increases and the scale of construction sites surges, the severity and frequency of accidents occurring at construction sites are swelling, and financial losses are also snowballing. Singularly, as natural disasters rise and construction projects in urban areas increase, the risk of financial loss for construction sites is mounting. Thus, a financial loss prediction model is desired to mitigate and manage the risk of such financial loss for maintainable and effective construction project management. This study reflects the financial loss incurred at the actual construction sites by collecting claim payout data from a major South Korean insurance company. A deep learning algorithm was presented in order to develop an objective and scientific prediction model. The results and framework of this study provide critical guidance on financial loss management necessary for sustainable and successful construction project management and can be used as a reference for various other construction project management studies.",2021
Catalyzing Financial Risk Control Excellence: A Novel Fusion Model - PSO-Boost-Trans,"In today's financial landscape, characterized by the rapid growth of fintech and the extensive application of big data, the volume and complexity of financial transaction data are increasing. This has heightened the need for intelligent risk control models, posing significant challenges to traditional methods. In this case, research on intelligent risk control models based on deep learning has emerged as a new solution. This paper proposes a PSO-Xgboost-Transformer fusion deep learning model designed to enhance the performance of traditional risk control approaches in managing financial risks. The model integrates the Particle Swarm Optimization (PSO) algorithm, the Xgboost model, and the Transformer model to leverage their respective strengths. Initially, the PSO algorithm is employed to select and optimize features, thereby enhancing the model's robustness and generalization capabilities. Subsequently, the Xgboost model uses these optimized features for prediction and evaluation, generating preliminary risk prediction results.",2024
GLAD: Global-Local Approach; Disentanglement Learning for Financial Market Prediction,"Accurate prediction of financial market trends can have a great impact on maximizing profits and avoiding risks. Conventional methods, e.g., regression or SVR, or end-to-end training approaches, coined as deep learning algorithms, have restraints as a consequence of capturing noisy and unnecessary data. Financial market's data are composed of stock's price time series that are correlated, and each time series has both global and local dynamics. Inspired by recent advancements in disentanglement representation learning, in this paper, we present a promising model for predicting financial markets that learn disentangled representations of features and eliminate those features that cause interference. Our model uses the informer encoder to extract features, capturing global-local patterns by using the time and frequency domains, augmenting the clean features with time and frequency-based features, and using the decoder to predict. To be more specific, we adopt contrastive learning in the time and frequency domains to learn both global and local patterns. We argue that our methodology, disentangling and learning the influential factors, holds the potential for more accurate predictions and a better understanding of how time series move and behave. We conducted our experiments using the S&P 500, CSI 300, Hang Seng, and Nikkei 225 stock market datasets to predict their next-day closing prices. The results showed that our model outperformed existing methods in terms of prediction error (mean squared error and mean absolute error), financial risk measurement (volatility and max drawdown), and prediction net curves, which means that it may enhance traders' profits.",2023
Hidden-layer configurations in reinforcement learning models for stock portfolio optimization,"In the rapidly evolving field of artificial intelligence and financial markets, efficient and adaptive portfolio management strategies are becoming increasingly critical. This study explores the impact of hidden-layer configurations in reinforcement learning models for stock portfolio optimization. Using a portfolio of 45 actively traded stocks in the Indonesian stock market, the performance of four reinforcement learning algorithms-Advantage Actor-Critic (A2C), Deep Deterministic Policy Gradient (DDPG), Proximal Policy Optimization (PPO), and Twin Delayed Deep Deterministic Policy Gradient (TD3)-is evaluated with zero, one, and two hidden layers. The results show that A2C and DDPG models perform effectively without hidden layers, with A2C achieving the highest Cumulative Return (CuR) and Annualized Return Rate (ARR) among all configurations. Adding hidden layers to A2C improved risk management, resulting in a lower Maximum Drawdown (MDD) and a higher Annualized Sharpe Ratio (ASR). DDPG exhibited consistently strong performance, with its zero hidden- layer model showing the highest ASR. Conversely, PPO underperformed across all configurations, with negative returns in the zero-layer setup and marginal improvements with added complexity. Introducing additional hidden layers improved TD3 ' s performance, enhancing risk-adjusted returns. These findings suggest that the effectiveness of hidden-layer configurations depends on the specific algorithm used. While A2C and DDPG benefit from increased complexity, simpler architectures may be more suitable for PPO and TD3. This study offers new insights into optimizing reinforcement learning models for stock portfolio management by adjusting hidden-layer structures to balance returns and risk.",2025
Attention-based CNN-LSTM for high-frequency multiple cryptocurrency trend prediction,"With the price of Bitcoin, Ethereum, and many other cryptocurrencies climbing, the cryptocurrency market has become the most popular investment area in recent years. Unlike other relatively more stable financial derivatives, the cryptocurrency market has high volatility which requires a high-frequency prediction model for quantitative trading. However, the excessive number of trading becomes a critical issue due to the instability of the prediction results and high error rate. To relieve such a problem, based on the observation of high frequency data, we use local minimum series to replace the original series and propose a more stable triple trend labeling method that reduces the number of trades by potentially influencing the training of the model. In addition, a new attention-based CNN-LSTM model for multiple cryptocurrencies (ACLMC) is proposed to optimize model effects by exploiting correlations across frequencies and currencies, and to smooth out the investment risk associated with prediction errors by supporting simultaneous multi-currency predictions. Experiments show that our labeling method with ACLMC can achieve much better financial metrics and fewer number of transactions than traditional baselines.",2024
Credit scoring with a feature selection approach based deep learning,"In financial risk, credit risk management is one of the most important issues in financial decision -making. Reliable credit scoring models are crucial for financial agencies to evaluate credit applications and have been widely studied in the field of machine learning and statistics. Deep learning is a powerful classification tool which is currently an active research area and successfully solves classification problems in many domains. Deep Learning provides training stability, generalization, and scalability with big data. Deep Learning is quickly becoming the algorithm of choice for the highest predictive accuracy. Feature selection is a process of selecting a subset of relevant features, which can decrease the dimensionality, reduce the running time, and improve the accuracy of classifiers. In this study, we constructed a credit scoring model based on deep learning and feature selection to evaluate the applicant's credit score from the applicant's input features. Two public datasets, Australia and German credit ones, have been used to test our method. The experimental results of the real world data showed that the proposed method results in a higher prediction rate than a baseline method for some certain datasets and also shows comparable and sometimes better performance than the feature selection methods widely used in credit scoring.",2016
Forecasting long-term stock prices of global indices: A forward-validating Genetic Algorithm optimization approach for Support Vector Regression,"Predicting long-term stock index prices is a challenging and debatable task. Most of the studies focus on predicting next-day stock prices. However, those are not useful to long-term investors and traders. In this paper, we attempt to predict up to a year's daily prices of global stock indices using daily close prices data. This study fills a gap in the existing literature by focusing on long-term stock index price forecasting, which is crucial for practical applications in the financial markets. Moreover, The empirical analysis highlights the superior performance of a rolling forward-validation approach over cross validation in predicting long-term stock prices. A forward-validating Genetic Algorithm Optimization for Support Vector Regression (OGA-SVR) is used to efficiently forecast multi-step ahead long-term global stock indices. Further, the performance of the model is compared with that of Support Vector Regression (SVR), Grid Search based Support Vector Regression (GS-SVR), Genetic algorithm-based Support Vector regression (GA-SVM), and state-of-the-art Long Short-Term Memory (LSTM) algorithms. The models are empirically tested on five global stock indices time series daily data, namely Nifty, Dow Jones Industrial Average (DJIA), DAX performance index (DAX), Nikkei 225 (NI225), and Shanghai Stock Exchange composite index (SSE). Root Mean Square Error (RMSE) and Mean Absolute Percentage Error (MAPE) are used for the evaluation The result shows the OGA-SVR model outperforms other models in predicting the long-term prices of global indices. Further, the OGA-SVR model has the potential to forecast the long-term underlying future pattern of index prices which can be used to build trading and risk mitigation systems by investors and traders.& COPY; 2023 Elsevier B.V. All rights reserved.",2023
Portfolio trading system of digital currencies: A deep reinforcement learning with multidimensional attention gating mechanism,"As a hot topic in the financial engineering, the portfolio optimization aims to increase investors' wealth. In this paper, a portfolio management system based on deep-reinforcement learning is proposed. In contrast to inflexible traditional methods, the proposed system achieves a better trading strategy through Reinforcement learning. The reward signal of Reinforcement learning is updated by action weights from Deep learning networks. Low price, high price and close price constitute the inputs, but the importance of these three features is quite different. Traditional methods and the classical CNN can't deal with these three features separately, but in our method, a designed depth convolution is proposed to deal with these three features separately. In a virtual currency market, the price rise only occurs in a flash. Traditional methods and CNN networks can't accurately judge the critical time. In order to solve this problem, a three-dimensional attention gating network is proposed and it gives higher weights on rising moments and assets. Under different market conditions, the proposed system achieves more substantial returns and greatly improves the Sharpe ratios. The short-term risk index of the proposed system is lower than those of the traditional algorithms. Simulation results show that the traditional algorithms (including Best, CRP, PAMR, CWMR and CNN) are unable to perform as well as our approach. (C) 2020 Elsevier B.V. All rights reserved.",2020
Intelligent auditing techniques for enterprise finance,"With the need of social and economic development, the audit method is also continuously reformed and improved. Traditional audit methods have defects of comprehensively considering various risk factors, and cannot meet the needs of enterprise financial work. To improve the effectiveness of audit work and meet the financial needs of enterprises, a solution for intelligent auditing of enterprise finance is proposed, including intelligent analysis of accounting vouchers and of audit reports. Then, Bi-directional Long Short-Term Memory (BiLSTM) neural network is used to classify the audit problems under three text feature extraction methods. The test results show that the accuracy, recall rate, and F1 value of the COWORDS-IOM algorithm in the aggregate clustering of accounting vouchers are 85.12, 83.28, and 84.85%, respectively, which are better than the self-organizing map algorithm before the improvement. The accuracy rate, recall rate, and F1 value of Word2vec TF-IDF LDA-BiLSTM model for intelligent analysis of audit reports are 87.43, 87.88, and 87.66%, respectively. This shows that the proposed method has good performance in accounting voucher clustering and intelligent analysis of audit reports, which can provide guidance for the development of enterprise financial intelligence software to a certain extent.",2023
Loan Repayment Prediction Using Logistic Regression Ensemble Learning With Machine Learning Algorithms,"Lending activities are an important part of the credit activities of financial institutions and banks. This is an area that brings great potential for development as well as a sustainable source of profit for financial institutions and banks. However, lending to customers also brings high risks. Therefore, predicting the ability to repay on time and understanding the factors affecting the repayment ability of customers is extremely important and necessary, to help financial institutions and banks enhance their ability to pay debts. customers' ability to identify and pay debts on time, contributing to minimizing bad debts and enhancing credit risk management. In this study, Machine Learning models will be used: Proposing a method to combine Logistic Regression with Random Forest, Logistic Regression with K-Nearest Neighbor, Logistic Regression with Support Vector Machine, Logistic Regression with Artificial Neural Network, Logistic Regression with Long short-term memory and finally Logistic Regression with Decision Tree to predict customers' ability to repay on time and compare and evaluate the performance of Machine Learning models. As a result, the Logistic Regression with the Random Forest model ensemble is found as the optimal predictive model and it is expected that Fico Score and annual income significantly influence the forecast.",2022
Traditional Prediction Techniques and Machine Learning Approaches for Financial Time Series Analysis,"Accurate financial time series forecasting is critical for effective decision making in areas such as risk management, portfolio optimization, and trading. Given the complexity and volatility of financial markets, traditional forecasting methods often fail to capture the underlying dynamics. Recent advances in artificial neural network (ANN) forecasting research indicate that ANNs present a valuable alternative to traditional linear methods, such as autoregressive integrated moving average (ARIMA). However, time series are typically influenced by a combination of factors which require to consider both linear and non-linear characteristics. This paper proposes a new hybrid model that integrates ARIMA and ANN models such as long short-term memory and gated recurrent unit neural network to leverage the distinct strengths of both linear and non-linear modeling. Moreover, the goodness of the proposed model is evaluated through a comparative analysis of the ARIMA, ANN and Zhang hybrid model, using three financial datasets (i.e., Unicredit SpA stock price, EUR/USD exchange rate and Bitcoin closing price). Various absolute and relative error metrics, computed to evaluate the performance of models, can support the use of the proposed approach. The Diebold-Mariano (DM) test is also implemented to asses the significance of the obtained differences of the hybrid model with respect to the other competing models.",2025
1D-CNN-IDS: 1D CNN-based Intrusion Detection System for IIoT,"The demand for Internet of Things (IoT) has seen a rapid increase. These advances have been made possible by technological advances in artificial intelligence, cloud computing, and edge computing. However, these developments present a number of challenges, including cyber threats, security and privacy concerns, and the risk of potential financial losses. For this reason, this study developed a computationally inexpensive one-dimensional convolutional neural network (1DCNN) algorithm for cyber-attack classification. The proposed study achieved an accuracy of 99.90% to classify nine cyber-attacks. Several other performance metrics are evaluated to validate the effectiveness of the proposed scheme. In addition, a comparison has been made with the existing state-of-the-art schemes. The findings of the proposed study can significantly contribute to the development of secure intrusion detection for IIoT systems.",2024
Credit Risk Evaluation with Extreme Learning Machine,"Credit risk evaluation has become an increasingly important field in financial risk management for financial institutions, especially for banks and credit card companies. Many data mining and statistical methods have been applied to this field. Extreme learning machine (ELM) classifier as a type of generalized single hidden layer feed-forward networks has been used in many applications and achieve good classification accuracy. Thus, we use ELM (kernel based) as a classification tool to perform the credit risk evaluation in this paper. The simulations are done on two credit risk evaluation datasets with three different kernel functions. Simulation results show that the kernel based ELM is more suitable for credit risk evaluation than the popular used Support Vector Machines (SVMs) with consideration of overall, good and bad accuracies.",2012
CARROT: Simultaneous prediction of anomalies from groups of correlated cryptocurrency trends,"Cryptocurrencies are virtual currencies that exploit cryptography to perform secure financial transactions. They gained widespread popularity in recent years due to their decentralized nature, (pseudo-)anonymity, and ability to facilitate cross-border transactions without the need for intermediaries. However, their price on the market exhibits a huge volatility, that makes them prone to market anomalies. Therefore, predicting anomalies in cryptocurrency time series can be considered an important task for financial institutions, traders, and investors, to maximize their profit or minimize losses. In this paper, we propose a novel approach for predicting anomalies in cryptocurrency time series by exploiting temporal correlations among different cryptocurrencies. Our approach, called CARROT, is based on the idea that groups of cryptocurrencies exhibit similar trends, possibly due to common influencing factors. CARROT analyzes the temporal correlation between different cryptocurrencies, and identifies clusters showing similar patterns that can be useful for gaining insights into future anomalies. Subsequently, CARROT exploits multiple (i.e., one for each cluster) multi-target LSTM models to predict anomalies. Our experiments, performed on a dataset of 17 cryptocurrencies, proved that CARROT outperforms single- target LSTM models of up to 20%, as well as other approaches based on neural networks, i.e., MLP and CNN, in terms of macro F1-score. Therefore, the proposed approach can be considered as a promising tool for predicting anomalies in cryptocurrency time series data and can potentially be used to improve risk management and trading strategies in the cryptocurrency market.",2025
Attention-enhanced graph neural network for financial distress and bankruptcy risk prediction,"Accurate prediction of financial distress and bankruptcy risk is crucial for informed investment decisions and effective risk management. Traditional predictive approaches, which primarily rely on linear models or shallow machine learning techniques, often fail to capture the intricate non-linear interdependencies. To address this limitation, this paper proposes an attention-enhanced graph neural network (AE-GNN) model that integrates an advanced attention mechanism to enhance predictive accuracy. By structuring corporate financial data as a feature-based graph, AE-GNN effectively processes complex financial relationships through graph neural networks, employing feature aggregation and a multi-attention mechanism. Extensive experimental evaluations conducted on three benchmark datasets demonstrate that AE-GNN significantly outperforms traditional models in predictive performance, highlighting its potential as a powerful tool for financial risk assessment.",2025
Predicting distresses using deep learning of text segments in annual reports,"Corporate distress models are central to regulators and financial institutions that need to evaluate the default risk of corporate firms. They are traditionally only based on the numerical financial variables in the firms' annual reports. In this paper we develop a model that employs the unstructured textual data in the reports as well, namely the auditors' reports and managements' statements. Our model consists of a convolutional recurrent neural network which, when concatenated with the numerical financial variables, learns a descriptive representation of the text that is suited for corporate distress prediction. We find that the unstructured data provides a statistically significant enhancement of the distress prediction performance, in particular for large firms where accurate predictions are of the utmost importance. Furthermore, we find that auditors' reports are more informative than managements' statements and that a joint model including both managements' statements and auditors' reports displays no enhancement relative to a model including only auditors' reports. Our model demonstrates a direct improvement over existing state-of-the-art models in the field of distress modelling. (C) 2019 Elsevier Ltd. All rights reserved.",2019
Detection of Disease in Calves using Artificial Intelligence,"Background: Livestock farming is experiencing a digital transformation and is becoming more information-driven. However, this type of data is often kept in separate storage towers, making it incapable of practicing its potential to boost animal welfare. Lumpy Skin Disease (LSD) is a serious threat to the health of cattle worldwide and has caused financial problems for many cattle farming enterprises. It has been shown that combining machine learning (ML) and artificial intelligence (AI) with biosensor data and conventional visual inspections can improve the identification and diagnosis of this serious condition. Methods: This study presents an extremely precise livestock farming framework that combines data streams from a wide array of disciplines of dairy cattle to see if ever wider/vast data sources enhance the overall projections for diseases and if using the more complicated prediction models can reimburse for less diverse data to some extent. Using images from the farming landscape, this study highlights the utility of convolutional neural networks (CNNs) in the identification of the Lumpy Skin Disease Virus (LSDV) in animals. Result: An analysis of the relative weight given to individual factors in predicting accuracy shows that disease in dairy cattle results from the intricate interactions between many life domains/parameters, such as housing, nutrition and climate; that prediction performance is enhanced by incorporating a wider range of data sources and that current information can be repurposed to produce useful information for vaccine development. The study highlights the potential of data-driven dairy interventions, focusing on artificial intelligence for disease prediction in cattle, to improve animal welfare and reduce the risk of disease. A Convolutional Neural Network (CNN) based model effectively classified skin conditions with an overall accuracy of 73.89% after 27 training epochs. This study demonstrates CNN's useful applications in the field of veterinary medicine by highlighting its potential for early detection of Lumpy Skin Disease (LSD).",2024
FINANCIAL TIME SERIES PREDICTION MODEL BASED RECURRENT NEURAL NETWORK,"Financial time series prediction is usually considered as one of the most difficult challenges because of huge external factors, which are usually stochastic and sensitive so that we can hardly recognize the patterns from historical information. Besides, traditional time series prediction models cannot adapt to the changes in financial circumstances. To overcome these problems, we design a prediction model based on recurrent neural network with gating units, which can learn historical information and adapt the market changes through a specific inner structure. Experiments carried on the Shanghai Securities Composite Index show that the prediction results of our model have more competitive performance compared to those of other traditional models. Our model has good interpretability, and the effects of model hyperparameters on prediction accuracy are also analyzed. On the basis, we proceed with the long-term trend analysis and estimate precisely the tipping points of the stock market. These results give application prospects in risk assessment and portfolio management for the finance industry.",2020
A Stock Market Decision-Making Framework Based on CMR-DQN,"In the dynamic and uncertain stock market, precise forecasting and decision-making are crucial for profitability. Traditional deep neural networks (DNN) often struggle with capturing long-term dependencies and multi-scale features in complex financial time series data. To address these challenges, we introduce CMR-DQN, an innovative framework that integrates discrete wavelet transform (DWT) for multi-scale data analysis, temporal convolutional network (TCN) for extracting deep temporal features, and a GRU-LSTM-Attention mechanism to enhance the model's focus and memory. Additionally, CMR-DQN employs the Rainbow DQN reinforcement learning strategy to learn optimal trading strategies in a simulated environment. CMR-DQN significantly improved the total return rate on six selected stocks, with increases ranging from 20.37% to 55.32%. It also demonstrated substantial improvements over the baseline model in terms of Sharpe ratio and maximum drawdown, indicating increased excess returns per unit of total risk and reduced investment risk. These results underscore the efficiency and effectiveness of CMR-DQN in handling multi-scale time series data and optimizing stock market decisions.",2024
PreBit-A multimodal model with Twitter FinBERT embeddings for extreme price movement prediction of Bitcoin,"Bitcoin, with its ever-growing popularity, has demonstrated extreme price volatility since its origin. Extreme price fluctuations have been known to occur due to tweets from Elon Musk, Michael Saylor, and others. In this paper, we aim to investigate whether we can leverage Twitter data to predict these extreme price movements. Existing social media models often take a shortcut and include sentiment extracted from tweets. In this work, however, we want to embed the actual tweets in a domain-informed way, and investigate whether they have an impact. Hence, we propose a multimodal deep learning model for predicting extreme price fluctuations that takes as input candlestick data, prices of a variety of correlated assets, technical indicators, as well as Twitter content. To train the model, a new dataset of 5,000 tweets per day containing the keyword 'Bitcoin' was collected from 2015 to 2021. This dataset, called PreBit, is made available online1, as is our model.2 Our proposed hybrid multimodal model consists of an SVM model based on price data, which is fused with a text-based Convolutional Neural Network. In the text-based model, we use the sentence-level FinBERT embeddings, pretrained on financial lexicons, so as to capture the full contents of the tweets and feed it to the model in an understandable way. In an ablation study, we explore whether adding social media data from the general public on Bitcoin improves the model's ability to predict extreme price movements. Finally, we propose and backtest a trading strategy based on the predictions of our models with varying prediction threshold and show that it can be used to build a profitable trading strategy with a reduced risk over a 'hold' or moving average strategy.",2023
Financial time-series analysis of Brazilian stock market using machine learning,"The recent profound changes in technological development have allowed the application of complex computational techniques for modeling and predicting price movements in the Stock Market. In this context, this paper compares the performance of different Machine Learning classifiers in predicting the trend of future financial asset price movements, in addition to performing the stock market trading simulation to assess financial gains provided by the trading strategy that considers the predictions as buying and selling signals. The paper considers five single classifiers, three ensemble classifiers that use Decision Tree as weak classifiers and four ensemble classifiers that combine the eight other classifiers, in addition to two benchmark classifiers. The simulation uses the best classifier and compares its efficiency with the buy and hold strategy. Results show that the precision of the Convolutional Neural Network surpasses that of the other classifiers and the simulation indicates that the use of classification as a trading strategy can reduce the potential for greater gains, but also avoids large losses, reducing the risk of investment.",2020
Along short-term memory enhanced realized conditional heteroskedasticity model,"This paper examines the potential of using realized volatility measures for capturing financial markets' uncertainty. Earlier studies show the usefulness of the high-frequency data based Generalized AutoRegressive Conditional Heteroskedasticity (RealGARCH) model for enhancing volatility forecasting accuracy; however, this model focuses only on linear and short-term dependencies of realized volatility measures on the underlying volatility. Recognizing the critical economic implications of this limitation, the long short-term memory neural network is integrated into RealGARCH, aiming to explore the full impact of realized volatility on volatility modeling and forecasting via capturing the nonlinear and long-term effects. A comprehensive empirical study using 31 indices from 2004 to 2021 is conducted. The results demonstrate that our proposed framework achieves superior in-sample and out-of-sample performance compared to several benchmark models. Importantly, it retains interpretability and effectively adapts to the stylized facts observed in volatility, emphasizing its significant potential for enhancing economic decision-making and risk management.",2025
Data-Driven Anomaly Detection in High-Voltage Transformer Bushings with LSTM Auto-Encoder,"The reliability and health of bushings in high-voltage (HV) power transformers is essential in the power supply industry, as any unexpected failure can cause power outage leading to heavy financial losses. The challenge is to identify the point at which insulation deterioration puts the bushing at an unacceptable risk of failure. By monitoring relevant measurements we can trace any change that occurs and may indicate an anomaly in the equipment's condition. In this work we propose a machine-learning-based method for real-time anomaly detection in current magnitude and phase angle from three bushing taps. The proposed method is fast, self-supervised and flexible. It consists of a Long Short-Term Memory Auto-Encoder (LSTMAE) network which learns the normal current and phase measurements of the bushing and detects any point when these measurements change based on the Mean Absolute Error (MAE) metric evaluation. This approach was successfully evaluated using real-world data measured from HV transformer bushings where anomalous events have been identified.",2021
RETRACTED: Study on the Practice of Enterprise Financial Management System under the Epidemic Norm Based on Artificial Neural Network (Retracted Article),"The sudden arrival of the new crown epidemic has had a significant and long-lasting impact on the division's economic environment as well as the production and operation activities of businesses. As far as the financial management is concerned, opportunities and difficulties are faced by enterprises of all types. With reference to the available research data, enterprises have an important contribution to GDP and jobs, but they still face a series of difficulties and challenges in their development in the context of the normalization of the epidemic. By analyzing the impact of the new crown pneumonia epidemic on the financial management work of enterprises, this paper proposes an artificial neural network-based enterprise financial forecasting and early warning method to provide an effective method for enterprise financial management. For the time-series characteristics of enterprise finances, a prediction model based on long- and short-term memory networks is developed which acknowledges the necessity of combining the temporal dimension with the spatial dimension for forecasting. This model incorporates time qualities into the data to the existing forecasting model. It also considers both working and nonworking day data and thoroughly considers the factors influencing corporate finance. Then, using BP neural network for financial risk prediction, nonfinancial index factors should be added to the financial early warning model thus eliminating the limitations of the financial early warning model. At the same time, the accuracy of the prediction can be improved which is more suitable for enterprises to apply in practice. The experimental results demonstrate that the financial prediction model built by multilayer feed forward neural networks and recurrent neural networks based on error back propagation training is inferior to the prediction model built by long- and short-term memory network. Regardless of the degree of fitting or prediction accuracy, the BP neural network model outperforms the conventional model for enterprise financial warning. Under the normalization of the pandemic, the combined use of both can offer an efficient technique for enterprise management.",2022
Cross-Domain Disentanglement: A Novel Approach to Financial Market Prediction,"Profit maximization and risk mitigation require good financial market predictions. Financial markets have a correlated nature, which means that there are some shared patterns between them; therefore, learning about one market might help understand the behavior of others. End-to-end training techniques have proven successful in financial markets, but they have flaws, such as picking up noise and failing to account for the complicated relationships across markets. We present a promising model for predicting financial markets using the correlation between the two markets, which draws inspiration from the recent progress in disentanglement learning. This model learns to disentangle representations of features shared between markets from specific representations, and removes features that cause interference. We utilized a dilated convolutional neural network as an encoder to extract features while using self-attention and cross-attention to capture specifics and shared patterns. Our model uses Dynamic Time Warping (DTW) to minimize the similarity between specific and shared patterns. It also combines DTW's alignment-based similarity with the Mean Square Error (MSE) to determine the optimal balance between alignment and prediction accuracy. We conducted our experiments using datasets that included the closing prices of Apple, Samsung, Bitcoin, Ethereum, Meta platforms, and the X platform. Spearman's rank correlation coefficient was used to evaluate the disentanglement by describing the relationship between the extracted representations. The findings confirm that our model surpasses state-of-the-art approaches in prediction error, financial risk assessment, correlation evolution, and prediction net curves, thereby giving market participants more trust in their decisions.",2024
Desensitized Financial Data Generation Based on Generative Adversarial Network and Differential Privacy,"Artificial intelligence has been widely used in the financial field, such as credit risk assessment, fraud detection, and stock prediction. Training deep learning models requires a significant amount of data, but financial data often contains sensitive information, some of which cannot be disclosed. Acquiring large amounts of financial data for training deep learning models is a pressing issue that needs to be addressed. This paper proposes a Noise Visibility Function-Differential Privacy Generative Adversarial Network (NVF-DPGAN) model, which generates privacy preserving data similar to the original data, and can be applied to data augmentation for deep learning. This study conducts experiments using financial data from China Stock Market & Accounting Research (CSMAR) database. It compares the generated data with real data from various perspectives, including mean, probability density distribution, and correlation. The experimental results show that the two datasets exhibit similar characteristics. A time series forecasting model is trained on the generated data and the real data separately, and their prediction results are closely aligned. NVF-DPGAN model is feasible and practical in terms of financial data enhancement and privacy protection. This method can also be generalized to other fields, such as the privacy protection of medical data.",2025
Accuracy of artificial intelligence in prediction of osteoporotic fractures in comparison with dual-energy X-ray absorptiometry and the Fracture Risk Assessment Tool: A systematic review,"BACKGROUND Osteoporotic fractures, whether due to postmenopausal or senile causes, impose a significant financial burden on developing countries and diminish quality of life. Recent advancements in artificial intelligence (AI) algorithms have demonstrated immense potential in predicting osteoporotic fractures. AIM To assess and compare the efficacy of AI models against dual-energy X-ray absorptiometry (DXA) and the Fracture Risk Assessment Tool (FRAX) in predicting fragility fractures. METHODS We conducted a literature search in English using electronic databases, including PubMed, Web of Science, and Scopus, for studies published until May 2024. The keywords employed were fragility fractures, osteoporosis, AI, deep learning, machine learning, and convolutional neural network. The inclusion criteria for selecting publications were based on studies involving patients with proximal femur and vertebral column fractures due to osteoporosis, utilizing AI algorithms, and analyzing the site of fracture and accuracy for predicting fracture risk using SPSS version 29 (Chicago, IL, United States). RESULTS We identified 156 publications for analysis. After applying our inclusion criteria, 24489 patients were analyzed from 13 studies. The mean area under the receiver operating characteristic curve was 0.925 +/- 0.69. The mean sensitivity was 68.3% +/- 15.3%, specificity was 85.5% +/- 13.4%, and positive predictive value was 86.5% +/- 6.3%. DXA showed a sensitivity of 37.0% and 74.0%, while FRAX demonstrated a sensitivity of 45.7% and 84.7%. The P value for sensitivity between DXA and AI was < 0.0001, while for FRAX it was < 0.0001 and 0.2. CONCLUSION This review found that AI is a valuable tool to analyze and identify patients who will suffer from fragility fractures before they occur, demonstrating superiority over DXA and FRAX. Further studies are necessary to be conducted across various centers with diverse population groups, larger datasets, and a longer duration of follow-up to enhance the predictive performance of the AI models before their universal application.",2025
Joint loan risk prediction based on deep learning-optimized stacking model,"In recent years, China's automobile industry has undergone rapid development, creating new opportunities for the auto loan industry. Currently, auto financing companies are actively seeking to expand their cooperation with banks. Therefore, improving the approval rate and scale of joint loan business is of significant practical importance. In this paper, we propose a Stacking-based financial institution risk approval model and select the optimal stacking model by comparing its performance with other models. Additionally, we construct a bank approval model using deep learning techniques on a biased data set, with feature extraction performed using convolution neural networks (CNN) and feature-based counterfactual augmentation used for balanced sampling. Finally, we optimize the model of the prediction of auto finance companies by selecting the optimal coefficients of loss function based on the features and results of the bank approval model. The proposed approach leads to an approximately 6% increase in the joint loan approval rate on the actual data set, as demonstrated by experimental results.",2024
Enhancing Auto Insurance Risk Evaluation With Transformer and SHAP,"The evaluation of auto insurance risks is a fundamental task for financial institutions, crucial for setting equitable premiums and managing risks effectively. Traditional machine learning algorithms often struggle to capture the intricate relationships necessary for accurate risk assessment. In contrast, deep learning methods, while capable of processing complex data structures, lack the ability to model feature interactions and provide interpretability, which are essential for transparent decision-making in the insurance industry. To address these challenges, we introduce the Actuarial Transformer (AT)-a pioneering model that leverages the self-attention mechanism of the Transformer architecture to meticulously map feature interactions. The AT integrates advanced residual models with tree-based methods, enhancing its predictive accuracy. Additionally, it incorporates the SHAP (SHapley Additive exPlanations) model, which uses Shapley values from cooperative game theory to ensure interpretability and transparency in its risk assessments. Our empirical analysis, conducted on a representative dataset of auto insurance risks, demonstrates the AT's superior performance in risk prediction. The SHAP analysis further validates the model's ability to prioritize features logically, providing clear insights into the decision-making process. The AT not only improves the precision of auto insurance risk evaluations but also enhances the interpretability of these evaluations, making it a valuable tool for both industry practitioners and clients.",2024
Cognitive Compliance: Assessing Regulatory Risk in Financial Advice Documents,"This paper describes Cognitive Compliance - a solution that automates the complex manual process of assessing regulatory compliance of personal financial advice. The solution uses natural language processing (NLP), machine learning and deep learning to characterise the regulatory risk status of personal financial advice documents with traffic light rating for various risk factors. This enables comprehensive coverage of the review and rapid identification of documents at high risk of non-compliance with government regulations.",2020
Financial Risk Early Warning Model of Listed Companies Under Rough Set Theory Using BPNN,"In order to reduce the risk of enterprise management, the financial risk early warning methods of listed companies are mainly studied. The financial risk characteristics of listed companies are analysed. With the help of rough set theory, the financial risk indicators are selected, and the financial risk early warning index system is established. The financial risk early warning model is constructed by using back propagation neural network (BPNN) algorithm based on deep learning. Finally, the accuracy and feasibility of the constructed neural network model are verified. The results show that rough set theory can be used to screen financial risk indicators and select important indicators, which can simplify the data and reduce the complexity of calculation. BPNN can calculate the simplified data and identify and evaluate the financial risk. Empirical analysis shows that the proposed method can shorten the training time of the model to a certain extent and improve the accuracy of financial risk prediction.",2022
Novel Financial Capital Flow Forecast Framework Using Time Series Theory and Deep Learning: A Case Study Analysis of Yu'e Bao Transaction Data,"Appropriate monetary liquidity is important for financial institutions. When institutions lack adequate cash flow for customer redemption, their income will decrease, their reputation will be affected, and they may even go bankrupt. However, the opposite extreme in which more cash is reserved than needed may result in lost opportunities to make successful investments. This study uses Yu'e Bao transaction data to investigate a method for forecasting financial capital flow. Yu' e Bao, which is a financial product launched by Alibaba, faces the core challenge of maximizing commercial profits to reduce investment risks. Liquidity risk is considered the main factor in Yu'e Bao's investment strategy. First, a linear model called YEB_ARIMA is proposed by determining the autocorrelation (ACF) and partial autocorrelation (PACF) parameters, which are optimized by the grid search method. Second, a deep learning model called YEB_LSTM is introduced to strengthen the expressiveness of the model that yields nonlinear transaction features. Then, a hybrid learning method called YEB_Hybrid is applied to improve the original weak classifiers. This model includes both a linear combination and logistic regression learning. Third, a set of experiments and analyses are conducted based on subscription and redemption datasets to demonstrate that the hybrid model achieves an accuracy of 84.39% and 84.36%, respectively, under a variety of evaluation indexes. Finally, various proposed fund reserve ratios are provided based on capital forecasts.",2019
COMPUTATION INTELLIGENCE BASED DAILY ALGORITHMIC STRATEGIES FOR TRADING IN THE FOREIGN EXCHANGE MARKET,"Successful trading in financial markets is not possible without a support system that manages the preparation of the data, prediction system, and risk management and evaluates the trading efficiency. Selected orthogonal data was used to predict exchange rates by applying recurrent neural network ( RNN) software based on the open source framework Keras and the graphical processing unit (GPU) NVIDIA GTX1070 to accelerate RNN learning. The newly developed software on the GPU predicted ten high-low distributions in approximately 90 minutes. This paper compares different daily algorithmic trading strategies based on four methods of portfolio creation: split equally, optimisation, orthogonality, and maximal expectations. Each investigated portfolio has opportunities and limitations dependent on market state and behaviour of investors, and the efficiencies of the trading support systems for investors in foreign exchange market were tested in a demo FOREX market in real time and compared with similar results obtained for risk-free rates.",2018
Advancing Forex prediction through multimodal text-driven model and attention mechanisms,"The Forex market, characterized by high volatility and complexity, presents a significant challenge for accurate prediction of currency price movements. Traditional approaches often rely on either technical indicators or sentiment analysis, limiting their ability to capture the interplay between diverse data modalities. This research work introduces a novel multimodal deep learning framework that integrates technical analysis and sentiment analysis through a cross-modal attention mechanism, enabling a comprehensive understanding of market dynamics. The proposed model leverages innovative alignment techniques to synchronize sentiment from news articles with historical price trends, facilitating robust multiclass prediction of Forex price directions. To evaluate its effectiveness, the model was tested on three major currency pairs-EUR/USD, GBP/USD, and USD/JPY-using k-fold cross-validation. Multiple attention configurations, including no attention, self-attention, bi-cross attention, and a hybrid approach, were implemented to assess the impact of attention mechanisms on prediction performance. Experimental results highlight the superiority of the hybrid attention mechanism, which consistently outperformed single-modality models and other configurations across key metrics, such as Matthew's correlation coefficient, accuracy, directional accuracy, and F1-score. These findings underscore the importance of integrating sentiment and technical data for enhanced Forex prediction. This study contributes to the growing field of multimodal financial forecasting, offering a foundation for future research incorporating advanced risk metrics, real-time trading systems, and broader market applications.",2025
Financial Risk Prediction and Management using Machine Learning and Natural Language Processing,"With the continuous development and changes in the global financial markets, financial risk management has become increasingly important for the stable operation of enterprises. Traditional financial risk management methods, primarily relying on financial statement analysis and historical data statistics, show clear limitations when dealing with largescale unstructured data. The rapid development of machine learning and Natural Language Processing (NLP) technologies in recent years offers new perspectives and methods for financial risk prediction and management. This paper explores and conducts empirical analysis financial risk management using these advanced technologies, with a particular focus on the application of NLP in measuring financial risk tendencies, and the financial risk prediction and management based on a Deep neural network- Factorization Machine (DeepFM) model. Through in-depth analysis and research, this paper proposes a new financial risk management model that combines NLP and deep learning technologies, aimed at improving the accuracy and efficiency of financial risk prediction. This study not only broadens the theoretical horizons of financial risk management but also provides effective technical support and decision-making references for practical operations.",2024
Innovative Risk Early Warning Model Based on Internet of Things Under Big Data Technology,"An innovative financial risk early warning model based on the Internet of Things (IoT) big data technology is proposed to maintain the long-term stable development of Internet finance. The Internet credit finance is introduced, a financial risk identification method based on the big data technology is proposed, and a risk assessment method for Internet finance based on back propagation neural network (BPNN) is put forwarded in this study. The actual Internet financial data is selected for verification and analysis. The results reveal that the identification and prediction model of Internet credit finance risk based on big data technology can realize risk analysis of online credit in the Internet credit finance, and can give corresponding credit ratings to new customers on credit platforms. The training error is the lowest when the number of hidden layer nodes is 14; and the training error is the smallest when the learning rate is 0.06; Based on the BPNN, it can accurately assess the financial risks of the Internet credit platform, and the accuracy of its risk level prediction has reached 100%. This study can provide a theoretical basis for the application of IoT big data technology and neural network models in the financial field, and also give an important reference for the risk management of Internet finance.",2021
Enterprise Tax Assessment and Risk Avoidance Based on Deep Learning,"Business tax assessments ensure financial solidity and regulatory adherence. Inaccurate or late tax returns can harm an organization's reputation and economic health. Conventional tax risk appraisal techniques usually fail to estimate taxable input risks and future fiscal burdens correctly and hence are left with ineffective mitigation of risks. The proposed method forecasts the possibilities of taxable inputs and their depreciation, which results in risks over different financial quarters. The cumulative taxable input risks are updated based on the previous inputs and their claimable part to improve the risk prediction. In this prediction process, deep learning is employed; this learning model is designed with two conditional layers. The first conditional layer is responsible for identifying the taxable inputs, and the second is responsible for determining the risks due to external input changes. These two factors are combined using the previous risk factor impact to verify their existence. Based on this existing factor, the number of assessments is increased or benchmarked for further audit. The topic model accurately predicts taxable input risk by financial quarters, continuously refining risk estimates based on the incorporation of prior data. Continuous learning and benchmarking enable the model to adapt to changing tax conditions. By incorporating deep learning into tax evaluation, businesses can enhance financial stability, streamline risk management, and facilitate improved compliance. The approach simplifies business complexity and allows for more precise tax planning.",2025
Interpretable Stock Anomaly Detection Based on Spatio-Temporal Relation Networks With Genetic Algorithm,"Instability in financial markets represents a considerable risk to investors; examples of instability include a market crash caused by systematic risks and abnormal stock price volatility caused by artificial hype. The early detection of abnormal behavior can help investors adjust their strategy and reduce investment risks. We proposed a spatiotemporal convolutional neural network-based relational network (STCNN-RN) model that can learn the complex correlations between multiple financial time-series data sets, and we used genetic algorithms with a constrained gene to discover the time points for outlier companies by fitting the STCNN-RN model; we used these outlier points to identify abnormal situations. Most research on identifying anomalous patterns has been unable to sufficiently explain the reason for anomalies to investors. We applied an interpretability model to enable investors to understand these anomalous time points in relation to companies and discover the key factors giving rise to the anomalies. The experiment results revealed that the proposed model can be used to model multiple financial time-series data sets and to capture anomalous situations in relevant companies. Because this study explored the discovery of anomaly phenomena in all transaction data and the explanation of these abnormalities, investors can understand a stock market situation holistically.",2021
Neural networks versus Logistic regression for 30 days all-cause readmission prediction,"Heart failure (HF) is one of the leading causes of hospital admissions in the US. Readmission within 30 days after a HF hospitalization is both a recognized indicator for disease progression and a source of considerable financial burden to the healthcare system. Consequently, the identification of patients at risk for readmission is a key step in improving disease management and patient outcome. In this work, we used a large administrative claims dataset to (1) explore the systematic application of neural network-based models versus logistic regression for predicting 30 days all-cause readmission after discharge from a HF admission, and (2) to examine the additive value of patients' hospitalization timelines on prediction performance. Based on data from 272,778 (49% female) patients with a mean (SD) age of 73 years (14) and 343,328 HF admissions (67% of total admissions), we trained and tested our predictive readmission models following a stratified 5-fold cross-validation scheme. Among the deep learning approaches, a recurrent neural network (RNN) combined with conditional random fields (CRF) model (RNNCRF) achieved the best performance in readmission prediction with 0.642 AUC (95% CI, 0.640-0.645). Other models, such as those based on RNN, convolutional neural networks and CRF alone had lower performance, with a non-timeline based model (MLP) performing worst. A competitive model based on logistic regression with LASSO achieved a performance of 0.643 AUC (95% CI, 0.640-0.646). We conclude that data from patient timelines improve 30 day readmission prediction, that a logistic regression with LASSO has equal performance to the best neural network model and that the use of administrative data result in competitive performance compared to published approaches based on richer clinical datasets.",2019
Learning about tail risk: Machine learning and combination with regularization in market risk management,"High-quality risk management is the key to ensuring the safe, efficient, and stable operation of the financial system. The current Basel Accord requires financial institutions to regularly calculate and disclose Value at Risk (VaR) and Expected Shortfall (ES) measures. However, the inaccuracy and instability of traditional risk models have reduced users' confidence. Therefore, we propose two new probabilistic deep learning frameworks for estimating VaR and ES. The trained first framework can output expectiles that are more sensitive to tail risks to map VaR and ES measures. In the second framework, we propose to approximate VaR and ES measures with spline quantile function and estimate the parameters by designing various deep learning architectures. To ensure the effectiveness of the proposed architectures, we derived the training loss and constraints for them. In addition, we solve the problem that existing machine learning risk models are difficult to estimate ES. In this way, combining various individual risk models has great potential for risk management. Therefore, we propose a regularization-based combination framework that adaptively selects and shrinks individual risk models. The developed individual methods and combinations outperform existing methods in backtesting, assisting financial institutions to allocate capital more effectively according to the Basel Capital Accord.",2025
A Deep Learning-Based Approach to Constructing a Domain Sentiment Lexicon: a Case Study in Financial Distress Prediction,"Financial text mining has been widely viewed as a promising approach to analyzing questions related to financial issues. However, only a few studies have ever emphasized constructing financial domain sentiment lexicons, especially in a Chinese financial context. In light of this gap in research, the purpose of this study is to generate a Chinese financial domain sentiment lexicon (CFDSL). Then, that lexicon is applied to financial distress prediction (FDP). This study proposes a deep learning-based framework to construct a domain sentiment lexicon, employing words vector models and deep learning-based classifiers in the process. To evaluate the effectiveness of the CFDSL, this study applies the lexicon to analyzing annual reports; sentiment features are also regarded as predictive factors in FDP. The experiment results indicate that deep learning-based models can achieve satisfactory results in generating a CFDSL that mainly covers four aspects of sentiment words, including capital markets, stock markets, companies' internal business conditions and politics. This study also discovers that sentiment features that are calculated four years prior to the predicted benchmark year enable the optimum performance. In addition, CFDSL-based sentiment features show advantages in FDP, compared with other lexicons. This study makes a novel contribution to existing research, as it expands the method of constructing financial domain sentiment lexicons. This paper also provides new findings that can have significant implications for the provision of early warning signals of Chinese listed companies' financial risk.",2021
Early warning model and prevention of regional financial risk integrated into legal system,"In order to improve the laws and regulations of the financial system, in the construction of laws and regulations, the traditional financial risk Early Warning (EW) model is optimized. The financial prevention and control measures with legal protection are implemented to warn the financial risks, which plays an important role in the construction of the rule of law in the Financial Market (FM) and the establishment of financial risk prevention and control laws and regulations. This paper combines the deep learning model and the Markov regime Switching Vector Auto Regression (MS-VAR) model and constructs a regional financial risk EW model from the following aspects: macroeconomic operation EW indicators, regional economic risk EW indicators, regional financial institution risk EW indicators. The model is empirically researched and analyzed. The results show that the fluctuation trend of the macroeconomic pressure index in the time series is relatively large, and the overall fluctuation of the regional economic pressure index is small, and fluctuates around 0 in most periods. After the financial crisis, local governments stepped up their supervision of non-performing corporate and household loans. From 2011 to 2018, the non-performing loan ratio began to decline, and the overall fluctuation of the regional financial comprehensive stress index was small, fluctuating around 0. Due to the lack of legal regulation, from the perspective of the regional economy, the risk level is more likely to change from low risk to moderate risk, while the risk status is less likely to change from high risk to moderate risk. From the perspective of regional financial institutions, the probabilities of maintaining low risk and moderate risk are 0.98 and 0.97, respectively, which is stronger than maintaining the stability of high risk. From the perspective of the state transition of the regional financial risk composite index, the probability of maintaining low risk and high risk is 0.97 and 0.93, which is higher than maintaining the stability of medium risk. The Deep Learning (DL) regional financial risk EW MS-VAR model has strong risk prediction ability. The model can better analyze the conversion probability of regional financial risk EW index and has better risk EW ability. This paper enhances the role of legal systems in financial risk prevention and control. The regional financial risk EW model incorporating financial legal indicators can better describe the regional financial risk level, and the EW results are basically consistent with the actual situation. In order to effectively prevent financial risks and ensure the safety of the financial system, it is recommended that the government improve local debt management, improve financial regulations and systems, and improve the legislative level of financial legal supervision.",2023
Financial Management Early Warning Based on Three BP-NNs Improved Algorithms,"Enterprises face more and more risks, including policy risk, market risk, employment risk and financial risk. In order to avoid the occurrence of corporate crisis, it is necessary to monitor corporate financial risks and adopt possible early warning systems. The purpose of this paper is to study early financial management warnings based on three advanced BP-NNs algorithms. On the basis of the standard BP-NNs prediction model, three different training modes of additional momentum term, additional momentum term and LM optimization method (Levenberg-Marquardt) are adopted as the technology to optimize the BP network algorithm. Improved analysis of company sample data. By comparing the training process and simulation results of the three advanced algorithms, it is found that LM-BP is significantly better than the additional shock enhancement method and the conjugate enhancement method in terms of network speed, training error and result satisfaction, and the average recognition rate of LM-BP is as high as 97%. %.",2022
Machine learning-driven credit risk: a systemic review,"Credit risk assessment is at the core of modern economies. Traditionally, it is measured by statistical methods and manual auditing. Recent advances in financial artificial intelligence stemmed from a new wave of machine learning (ML)-driven credit risk models that gained tremendous attention from both industry and academia. In this paper, we systematically review a series of major research contributions (76 papers) over the past eight years using statistical, machine learning and deep learning techniques to address the problems of credit risk. Specifically, we propose a novel classification methodology for ML-driven credit risk algorithms and their performance ranking using public datasets. We further discuss the challenges including data imbalance, dataset inconsistency, model transparency, and inadequate utilization of deep learning models. The results of our review show that: 1) most deep learning models outperform classic machine learning and statistical algorithms in credit risk estimation, and 2) ensemble methods provide higher accuracy compared with single models. Finally, we present summary tables in terms of datasets and proposed models.",2022
Enhancing Auto Insurance Fraud Detection Using Convolutional Neural Networks,"With the increasing number of vehicles in the global fleet, the size of the auto insurance market is projected to reach $ 1.3 billion USD by 2030. While this growth in the issuance of auto insurance policies brings prosperity to the industry, it also amplifies the risk of fraudulent activities. These fraudulent practices have a significant impact on the industry, resulting in the loss of billions of USD annually. Despite efforts to prevent such activities, the expertise available is often overwhelmed by the sheer volume of cases. In this paper, we propose an auto insurance fraud detection system that leverages a one-dimensional Convolution Neural Network (1D-CNN) model in combination with two data augmentation techniques, Synthetic Minority Over-sampling Technique (SMOTE) and Conditional Tabular Generative Adversarial Networks (CTGAN), to address the class imbalance problem prevalent in fraud detection datasets. Furthermore, we also employ Focal Loss as the loss function in our deep learning model to effectively tackle the difficulty in classifying the minority class. By combining the 1D-CNN model with these imbalance manipulation techniques and the Focal Loss function, we aim to enhance the system's ability to accurately identify fraudulent activities, even in the presence of highly imbalanced data. Our proposed approach seeks to mitigate the financial losses incurred by the auto insurance industry due to fraud and provide a more robust and efficient fraud detection system.",2024
Design and Application of Intelligent Financial Accounting Model Based on Knowledge Graph,"With the continuous progress of science and technology, economic globalization has become an important direction for the development of enterprises. In the process of enterprise development, artificial intelligence and machine learning techniques have greatly improved the efficiency of enterprise accounting and financial management and have gradually shifted traditional financial accounting to modern financial management and accounting. Owing to the existing problems of inefficiency, large consumption of time and resources, and low degree of intelligence in the existing computerized financial data prediction systems, this study proposes an intelligent financial accounting and a financial risk monitoring and early warning model based on knowledge graph and deep learning techniques. To validate its performance, the model is trained using financial data of 120 listed companies, and the model is applied to establish the prediction of whether the listed companies are facing a financial crisis, using another 60 companies as the test sample. Results show that the use of deep learning and knowledge graph techniques can significantly improve the regulatory model, enhance regulatory penetration, and alleviate regulatory time lag, thus improving the ability of regulation to detect enterprise problems and prevent risks.",2022
Deep learning-based risk management of financial market in smart grid,"Smart grid control systems (SGCSs) become more vulnerable to cyber-attacks because of the combination of the Internet of Things and communication systems. Conventional intrusion detection systems (IDSs) that have been essentially improved in order to secure information technology systems. Since SGCS datasets are asymmetric, the majority of IDSs suffer from poor precision and significant false-positive rates. A deep learning (DL) layout for constructing novel symmetric presentations of the asymmetric datasets is proposed in the present study. It is incorporated into a model created particularly for detecting attacks using DL in a SGCS environment. Deep Neural Networks and Decision Tree classifiers are utilized in the suggested attack detection model. By performing 10-fold cross-validation using 2 actual SGCS datasets, this suggested model has been assessed for its efficiency. According to the outcomes, the suggested approach is more effective than traditional schemes such as Random Forest, Support Vector Machine.",2022
DeepScalper: A Risk-Aware Reinforcement Learning Framework to Capture Fleeting Intraday Trading Opportunities,"Reinforcement learning (RL) techniques have shown great success in many challenging quantitative trading tasks, such as portfolio management and algorithmic trading. Especially, intraday trading is one of the most profitable and risky tasks because of the intraday behaviors of the financial market that reflect billions of rapidly fluctuating capitals. However, a vast majority of existing RL methods focus on the relatively low frequency trading scenarios (e.g., day-level) and fail to capture the fleeting intraday investment opportunities due to two major challenges: 1) how to effectively train profitable RL agents for intraday investment decision-making, which involves high-dimensional fine-grained action space; 2) how to learn meaningful multi-modality market representation to understand the intraday behaviors of the financial market at tick-level. Motivated by the efficient workflow of professional human intraday traders, we propose DeepScalper, a deep reinforcement learning framework for intraday trading to tackle the above challenges. Specifically, DeepScalper includes four components: 1) a dueling Q-network with action branching to deal with the large action space of intraday trading for efficient RL optimization; 2) a novel reward function with a hindsight bonus to encourage RL agents making trading decisions with a long-term horizon of the entire trading day; 3) an encoder-decoder architecture to learn multi-modality temporal market embedding, which incorporates both macro-level and micro-level market information; 4) a risk-aware auxiliary task to maintain a striking balance between maximizing profit and minimizing risk. Through extensive experiments on real-world market data spanning over three years on six financial futures (2 stock index and 4 treasury bond), we demonstrate that DeepScalper significantly outperforms many state-of-the-art baselines in terms of four financial criteria. Furthermore, we conduct a series of exploratory and ablative studies to analyze the contributions of each component in DeepScalper.",2022
Deep-learning models for forecasting financial risk premia and their interpretations,"The measurement of financial risk premia, the amount that a risky asset will outperform a risk-free one, is an important problem in asset pricing. The noisiness and non-stationarity of asset returns makes the estimation of risk premia using machine learning (ML) techniques challenging. In this work, we develop ML models that solve the problems associated with risk premia forecasting by separating risk premia prediction into two independent tasks, a time series model and a cross-sectional model, and using neural networks with skip connections to enable their deep neural network training. These models are tested robustly with different metrics, and we observe that our models outperform several existing standard ML models. A known issue with ML models is their 'black box' nature, i.e. their opaqueness to interpretability. We interpret these deep neural networks using local approximation-based techniques that provide explanations for our model's predictions.",2023
Systematic Financial Risk Identification and Dynamic Evolution Based on Deep Learning,"A perfect financial market is the physical manifestation of a developed country, and the rational transfer and distribution of capital resources can significantly improve the real economy's operational efficiency. In the era of sharing economy, the traditional linear systematic financial risk early warning model based on the Internet can no longer meet the early warning and identification of nonlinear systematic financial risk brought on by the embeddedness of the Internet network. The improved loss function is used to optimize the model to identify and monitor systemic financial risks in this paper. DL is used to identify systemic financial risks, a classification model based on DNN is built, and the improved loss function is used to optimize the model to identify and monitor systemic financial risks. The experimental results show that this model can achieve a recall rate of 93.2 percent and an accuracy rate of 95.4 percent. The results of the experiments show that the DL-based identification model is both effective and practical. The use of DL not only improves identification and analysis methods in the field of financial risk management, but it also encourages empirical research to shift from linear to nonlinear, from a focus on parameter salience to a focus on model structure and dynamic characteristics, while also better capturing tail risks.",2022
Predicting financial losses due to apartment construction accidents utilizing deep learning techniques,"This study aims to generate a deep learning algorithm-based model for quantitative prediction of financial losses due to accidents occurring at apartment construction sites. Recently, the construction of apartment buildings is rapidly increasing to solve housing shortage caused by increasing urban density. However, high-rise and large-scale construction projects are increasing the frequency and severity of accidents occurring inside and outside of construction sites, leading to increases of financial losses. In particular, the increase in severe weather and the surge in abnormal weather events due to climate change are aggravating the risk of financial losses associated with accidents occurring at construction sites. Therefore, for sustainable and efficient management of construction projects, a loss prediction model that prevents and reduces the risk of financial loss is essential. This study collected and analyzed insurance claim payout data from a main insurance company in South Korea regarding accidents occurring inside and outside of construction sites. Deep learning algorithms were applied to develop predictive models reflecting scientific and recent technologies. Results and framework of this study provide critical guidance on financial loss management necessary for sustainable and efficacious construction project management. They can be used as a reference for various other construction project management studies.",2022
Design and Research of Accounting Automation Management System Based on Swarm Intelligence Algorithm and Deep Learning,"the current research, the application verification of traditional algorithms in actual accounting management is insufficient, and deep learning data processing capabilities need to be fully optimized in complex accounting scenarios. Given the challenges of efficiency and accuracy faced by the current accounting industry in the context of big data, this study creatively combines the swarm intelligence algorithm and deep learning technology to design and implement an efficient and accurate accounting automation management system. The research aims to investigate the potential of swarm intelligence algorithms and deep learning techniques in developing an automated accounting management system, with a focus on improving efficiency, accuracy, and scalability. Key research questions include exploring the optimal configuration of swarm intelligence algorithms for accounting tasks and assessing the performance of deep learning models in automating various accounting processes. Through experimental verification, the system is tested with the financial data of a large enterprise for three consecutive years. The results show that the system can significantly shorten the time of financial statement generation by 65%, reduce the error rate to less than 0.5%, and increase the accuracy of abnormal data recognition by as much as 90%. These data not only reflect the significant improvement of the efficiency and accuracy of the system but also prove its great potential in early warning of financial risk, providing intelligent and automated solutions for the accounting industry.",2025
Machine Learning Prediction of Fall Risk in Older Adults Using Timed Up and Go Test Kinematics,"Falls among the elderly population cause detrimental physical, mental, financial problems and, in the worst case, death. The increasing number of people entering the higher risk age-range has increased clinicians' attention to intervene. Clinical tools, e.g., the Timed Up and Go (TUG) test, have been created for aiding clinicians in fall-risk assessment. Often simple to evaluate, these assessments are subject to a clinician's judgment. Wearable sensor data with machine learning algorithms were introduced as an alternative to precisely quantify ambulatory kinematics and predict prospective falls. However, they require a long-term evaluation of large samples of subjects' locomotion and complex feature engineering of sensor kinematics. Therefore, it is critical to build an objective fall-risk detection model that can efficiently measure biometric risk factors with minimal costs. We built and studied a sensor data-driven convolutional neural network model to predict older adults' fall-risk status with relatively high sensitivity to geriatrician's expert assessment. The sample in this study is representative of older patients with multiple co-morbidity seen in daily medical practice. Three non-intrusive wearable sensors were used to measure participants' gait kinematics during the TUG test. This data collection ensured convenient capture of various gait impairment aspects at different body locations.",2021
Enhancing Predictive Capabilities for Identifying At-Risk Stocks Using Multivariate Time-Series Classification: A Case Study of the Thai Stock Market,"This study proposes a multivariate time-series classification approach using deep learning to predict stocks likely to be flagged by the Market Surveillance Measure List in the Thai stock market. Formulated as a binary classification problem, the model distinguishes At-Risk and Normal stocks based on two primary datasets: End-of-Day stock prices and Market Surveillance Measure List records, incorporating trading volumes and technical indicators. To address data imbalance, concept drift, and long-term dependencies, the framework integrates feature engineering, cost-sensitive learning, and rolling window training. Experimental results show deep learning models significantly outperform traditional baseline methods in capturing financial risk patterns. The study identifies models that effectively balance predictive accuracy with computational efficiency, with performance varying based on forecasting horizons. Despite improvements from specialized techniques, the study identifies challenges in long-term financial risk prediction. These findings support market surveillance, algorithmic trading, and portfolio risk management, with future work exploring explainable AI, adaptive learning, and alternative data sources to enhance interpretability and long-term forecasting.",2025
Risk measurement in Bitcoin market by fusing LSTM with the joint-regression-combined forecasting model,"Purpose The purpose of the paper is to better measure the risks and volatility of the Bitcoin market by using the proposed novel risk measurement model. Design/methodology/approach The joint regression analysis of value at risk (VaR) and expected shortfall (ES) can effectively overcome the non-elicitability problem of ES to better measure the risks and volatility of financial markets. And because of the incomparable advantages of the long- and short-term memory (LSTM) model in processing non-linear time series, the paper embeds LSTM into the joint regression combined forecasting framework of VaR and ES, constructs a joint regression combined forecasting model based on LSTM for jointly measuring VaR and ES, i.e. the LSTM-joint-combined (LSTM-J-C) model, and uses it to investigate the risks of the Bitcoin market. Findings Empirical results show that the proposed LSTM-J-C model can improve forecasting performance of VaR and ES in the Bitcoin market more effectively compared with the historical simulation, the GARCH model and the joint regression combined forecasting model. Social implications The proposed LSTM-J-C model can provide theoretical support and practical guidance to cryptocurrency market investors, policy makers and regulatory agencies for measuring and controlling cryptocurrency market risks. Originality/value A novel risk measurement model, namely LSTM-J-C model, is proposed to jointly estimate VaR and ES of Bitcoin. On the other hand, the proposed LSTM-J-C model provides risk managers more accurate forecasts of volatility in the Bitcoin market.",2023
Harnessing Cognitively Inspired Predictive Models to Improve Investment Decision-Making,"In the last years, researchers and practitioners have focused on defining portfolio optimization approaches. This task aims to identify a suitable distribution of assets for maximizing profits and minimizing risks, also offering protection against unexpected market behaviors. Nevertheless, the state-of-the-art approaches encounter significant limitations due to the complex nature of the task: (1) forecasting of non-stationary, non-linearity and volatile stock price; (2) budget allocation over different stocks satisfying multi-objective objective function; (3) risk costs can significantly affect the effectiveness of the designed approaches. In this paper, we propose a cognitively inspired framework for portfolio optimization by integrating deep learning-based stock forecasting for maximizing the revenue and portfolio diversification and Shape Ratio for minimizing the risk. Furthermore, the cognitively inspired forecasting module relies on the LSTM-based approach which combines historical financial data and technical indicators. Hence, this approach addresses the portfolio optimization task with the aim of designing more and more cognitive agents that perform autonomous actions for supporting decision-making. To make these agents cognitive, we further integrate stock forecasting into the portfolio optimization model, also investigating the main factors affecting both stock forecasting and portfolio optimization tasks. The proposed framework has been evaluated in two stages on a real-world dataset, composed of four years of information about stocks from six different areas. Firstly, we compare the proposed forecasting models based on LSTM and GRU, pointing out that the former achieves higher effectiveness results although the latter has a shorter training time. Finally, the proposed framework has been compared with different baselines, obtaining a net difference of $168 at the maximum. Finally, we compare the proposed approach w.r.t. several baselines in terms of total revenue, also providing an ablation analysis to investigate how stock prediction might support investors in dealing with portfolio optimization task.",2024
A multi-agent reinforcement learning framework for optimizing financial trading strategies based on TimesNet,"An increasing number of studies have shown the effectiveness of using deep reinforcement learning to learn profitable trading strategies from financial market data. However, a single-agent model is not sufficient to handle complex financial scenarios. To address this problem, a novel approach called Multi-Agent Double Deep Q-Network (Later called MADDQN) is proposed in this study, which reasonably balances the pursuit of maximum revenue and the avoidance of risk under the multi-agent reinforcement learning framework by innovatively employing two different agents represented respectively by two time-series feature extraction networks, TimesNet, and the Multi-Scale Convolutional Neural Network. Furthermore, to achieve a more generalized model suitable for different underlying assets, a mixed dataset containing three major U.S. stock indexes is collected. And the proposed model has been pre-trained in this dataset and subsequently refined for the specified asset. The results from experiments on five different stock indices show that the proposed MADDQN has an average cumulative return of 23.08%, outperforming the other baseline methods. Besides, the multi-agent model demonstrates its advantage in balancing the risk and revenue, in comparison with the single-agent models. Additionally, The generalization experiments confirm that the proposed MADDQN method after pre-training in the proposed mixed dataset could be stably transferred to the other underlying assets with a refinement. These findings indicate that the proposed framework not only achieves good performance in complex financial market environments but also is able to generalize robustly across different scenarios in various markets.",2024
Inductive Representation Learning on Dynamic Stock Co-Movement Graphs for Stock Predictions,"Co-movement among individual firms' stock prices can reflect complex inter-firm relationships. This paper proposes a novel method to leverage such relationships for stock price predictions by adopting inductive graph representation learning on dynamic stock graphs constructed based on historical stock price co-movement. To learn node representations from such dynamic graphs for better stock predictions, we propose the hybrid-attention dynamic graph neural network, an inductive graph representation learning method. We also extended mini-batch gradient descent to inductive representation learning on dynamic stock graphs so that the model can update parameters over mini-batch stock graphs with higher training efficiency. Extensive experiments on stocks from different markets and trading simulations demonstrate that the proposed method significantly improves stock predictions. The proposed method can have important implications for the management of financial portfolios and investment risk.",2022
Financial warning for coal mining investments: Evidence from the fruit fly optimisation algorithm with backpropagation neural networks,"Venture capital firms may be unable to withstand the high investments and risks associated with coal mining exploration due to limitations in the funding scale. Risk control capability is also a challenge for venture capital companies. Finding a balance between high-risk and high-return coal mining exploration projects is a problem that venture capital companies must face. We propose a financial risk-warning model for coal mining investment enterprises based on the fruit fly optimisation algorithm (FOA) with the backpropagation neural network (BPNN). The fusion of standardised and dimensionless sample data through factor analysis reduces the input dimension of the BPNN and improves its stability. The financial warning algorithm of the model has been effectively validated through experiments. The research results indicate that its accuracy has reached a high level of financial warning, reaching a level of 95%.",2024
Credit risk assessment of P2P lending platform towards big data based on BP neural network,"Peer-to-peer (P2P) lending platform plays a significant role in modern financial systems. However, due to improper supervision, credit risk is inevitable. In this paper, we analyze the traditional financial risk and information technology risk of P2P lending platform. In order to evaluate the performance of assessment algorithms, we present a BP neural network-based algorithm for lending risk assessment. To achieve our task, we crawled large-scale lending data for 2015-2019. Logistic regression is used to compare with BP neural network method. Experimental results show that BP neural network-based algorithm outperforms traditional Logistic regression algorithm and the proposed method can effectively reduce investor risk. (c) 2020 Elsevier Inc. All rights reserved.",2020
Power purchase agreements for plus energy neighbourhoods: Financial risk mitigation through predictive modelling and bargaining theory,"This paper introduces a continuous 24/7 power purchase agreement (PPA) designed for contracting photovoltaic (PV) generation within sustainable plus energy neighbourhoods (SPENs) or local energy communities, aiming to ensure a stable economic revenue stream for community stakeholders. The PPA involves the sale of solar PV generation, auctioned at a fixed strike price, to an external off -taker. Employing statistical prediction tools such as long short-term memory and auto -regressive modelling, the proposed framework allows hour -tohour power delivery commitments between seller and buyer, accurately estimating the agreed -upon volume of renewable energy to be exchanged. A fixed PPA price is negotiated utilizing Nash Bargaining Theory, aiming to optimize revenue for the SPEN while minimizing procurement costs for the buyer, thus achieving an economic equilibrium that mitigates the long-term price risk prevalent in wholesale energy markets. Additionally, the proposed methodology includes utilization of a battery energy storage system (BESS) to store excess power or address supply-demand contractual disparities during periods of low PV generation. Simulation results obtained under varying climatic conditions and energy market dynamics across different countries, demonstrate that the proposed PPA framework, by combining risk assessment strategies and statistical learning methods, can effectively reduce associated financial risks while maximizing payoff for the community.",2024
Blockchain data with Ransomware detection based on deep feed forward Maxout network,"The widespread use of the internet and technology has become more common and essential in daily life. The main risk to the network is malware, and ransomware is considered a destructive kind of malware. The ransomware resulted in massive data losses and produced huge financial losses. In order to overcome this issue, the Deep Feed Forward Maxout Network (DFFMN) is developed to detect ransomware using blockchain data in this study. To accomplish this, initially, the input data from the blockchain is given to feature extraction to extract features. Then, data normalization is performed and the extracted features are fused together using a Deep Belief Network (DBN) with Lorentzian similarity. Lastly, ransomware detection is executed by utilizing the DFFMN technique, which is created by the integration of Deep Maxout Network and Deep Feedforward Neural Network. The experimental results exemplify that the proposed DFFMN acquired accuracy value of 91.57 %, sensitivity value of 91.04 %, precision value of 89.35 %, False Negative Rate (FNR) of 0.086, False Positive Rate (FPR) of 0.090 and F-Measure of 89.44 %.",2025
Deep Learning for Systemic Risk Measures,"The aim of this paper is to study a new methodological framework for systemic risk measures by applying deep learning method as a tool to compute the optimal strategy of capital allocations. Under this new framework, systemic risk measures can be interpreted as the minimal amount of cash that secures the aggregated system by allocating capital to the single institutions before aggregating the individual risks. This problem has no explicit solution except in very limited situations. Deep learning is increasingly receiving attention in financial modelings and risk management and we propose our deep learning based algorithms to solve both the primal and dual problems of the risk measures, and thus to learn the fair risk allocations. In particular, our method for the dual problem involves the training philosophy inspired by the well-known Generative Adversarial Networks (GAN) approach and a newly designed direct estimation of Radon-Nikodym derivative. We close the paper with substantial numerical studies of the subject and provide interpretations of the risk allocations associated to the systemic risk measures. In the particular case of exponential preferences, numerical experiments demonstrate excellent performance of the proposed algorithm, when compared with the optimal explicit solution as a benchmark.",2022
Predicting Credit Ratings using Deep Learning Models - An Analysis of the Indian IT Industry,"Due to the complexity of transactions and the availability of Big Data, many banks and financial institutions are reviewing their business models. Various tasks get involved in determining the credit worthiness like working with spreadsheets, manually gathering data from customers and corporations, etc. In this research paper, we aim to automate and analyze the credit ratings of the Information and technology industry in India. Various Deep-Learning models are incorporated to predict the credit rankings from highest to lowest separately for each company to find the best fit Margin, inventory valuation, etc., are the parameters that contribute to the credit rating predictions. The data collected for the study spans between the years FY-2015 to FY-2020. As per the research been carried out with efficiencies of different Deep Learning models been tested and compared, MLP gained the highest efficiency for predicting the same. This research contributes to identifying how we can predict the ratings for several IT companies in India based on their Financial risk, Business risk, Industrial risk, and Macroeconomic environment using various neural network models for better accuracy. Also it helps us understand the significance of Artificial Neural Networks in credit rating predictions using unstructured and real time Financial data consisting the influence of COVID-19 in Indian IT industry.",2022
Predicting stock market crashes in MENA regions: study based on the irrationality of investor behavior and the NARX model,"PurposeThis study aims to predict stock market crises in the Middle East North Africa (MENA) regions by leveraging the nonlinear autoregressive neural network with exogenous inputs (NARX) model with two measures of investor sentiment: the ARMS indicator and Google Trends' search volume of positive and negative words.Design/methodology/approachEmploying a novel approach, this study utilizes the NARX model with ten neurons in the hidden layer and the Levenberg-Marquardt training algorithm. It evaluates model performance through learning, validation and test errors, as well as correlation analysis between predicted and actual crises.FindingsThe NARX model, incorporating investor sentiment, has proven to be a reliable tool for forecasting crises, helping market participants understand data complexity and avoid crisis consequences. The divergence in how investors interpret market news, with some focusing solely on negative developments and others valuing positive outcomes, highlights the predictive nature of the optimistic and pessimistic sentiments captured by the model.Research limitations/implicationsThis study advocates for integrating behavioral approaches into stock market crisis prediction, highlighting the significance of investor sentiment and deep learning. It advances crisis mechanism understanding and opens avenues in behavioral finance. Integration of these findings into finance and economics education could enhance students' risk understanding and mitigation strategies.Practical implicationsThe adoption of NARX models, incorporating investor sentiment, empowers market participants to proactively manage crises, adjust strategies, enhance asset protection and make informed decisions. These models enable them to minimize losses, maximize returns and diversify portfolios effectively in response to market fluctuations. These insights also guide policymakers such as governments, regulatory institutions and financial organizations in formulating crisis prevention and mitigation policies, bolstering economic and financial stability.Social implicationsThis research reduces economic uncertainty, safeguards individuals' savings and investments and promotes a stable financial climate.Originality/valueThis study is one of the first attempts to demonstrate the detection and prediction of stock market crises, specifically in the MENA stock market, using the NARX model. It offers a robust forecasting model using machine learning and investor sentiment, providing decision-making support for investment strategies and policy development aimed at enhancing financial and economic stability.",2024
Incorporating textual and management factors into financial distress prediction: A comparative study of machine learning methods,"Financial distress prediction (FDP) has been widely considered as a promising approach to reducing financial losses. While financial information comprises the traditional factors involved in FDP, nonfinancial factors have also been examined in recent studies. In light of this, the purpose of this study is to explore the integrated factors and multiple models that can improve the predictive performance of FDP models. This study proposes an FDP framework to reveal the financial distress features of listed Chinese companies, incorporating financial, management, and textual factors, and evaluating the prediction performance of multiple models in different time spans. To develop this framework, this study employs the wrapper-based feature selection method to extract valuable features, and then constructs multiple single classifiers, ensemble classifiers, and deep learning models in order to predict financial distress. The experiment results indicate that management and textual factors can supplement traditional financial factors in FDP, especially textual ones. This study also discovers that integrated factors collected 4 years prior to the predicted benchmark year enable a more accurate prediction, and the ensemble classifiers and deep learning models developed can achieve satisfactory FDP performance. This study makes a novel contribution as it expands the predictive factors of financial distress and provides new findings that can have important implications for providing early warning signals of financial risk.",2020
A forecast model based on RBF neural network for local financial revenue,"The revenue forecast of local financial is critically important since agency budgets, debt evaluation and risk warning all depend on their accuracy. This paper present a nonlinear model based on RBF neural network. There are some ameliorated measures in leaning algorithm of RBF neural network. The number and the centric value of hidden layer are determined by using immune algorithm. The supervisory algorithm is taken as method of adjustable weight of output layer. Using above measures, the network is optimized, and the forecast model obtains the precise and objective solution.",2006
Systemic financial risk early warning of financial market in China using Attention-LSTM model,"We propose an Attention-LSTM neural network model to study the systemic risk early warning of China. Based on text mining, the network public opinion index is constructed and used as a training set to be incorporated into the early warning model to test the early warning effect. The results show that: (i) the network public opinion is the non-linear Granger causality of systemic risk. (ii) The Attention-LSTM neural network has strong generalization ability. Early warning effects have been significantly improved. (iii) Compared with the BP neural network model, the SVR model and the ARIMA model, the LSTM neural network early warning model has a higher accuracy rate, and its average prediction accuracy for systemic risk indicators has been improved over short, medium and long terms. When the attention mechanism is included in the LSTM, the Attention-LSTM neural network model is even more accurate in all the cases.",2021
Deep learning-based image processing for financial audit risk quantification in healthcare,"Recently, deep learning technology has gradually penetrated various fields. Today, the field of healthcare is also closely linked to deep learning technology. Image processing technology based on deep learning can accurately segment medical images, which is convenient for medical research and pathological analysis. Accurate distribution of images can effectively save medical resources. Therefore, image processing techniques can contribute to the quantification and assessment of economic audit risks. In recent years, medical image segmentation has achieved many research results. However, with the improvement of accuracy, the segmentation standards of medical images are also becoming more and more stringent. For medical images, they tend to have rough and fuzzy boundaries and noise disturbances of different shapes. The above problems pose challenges for accurate localization and segmentation of lesion regions. On the other hand, in the field of medical images, there are also problems such as unbalanced number of samples and scarcity of large medical image datasets. In response to these problems, this paper conducts research work and proposes an Attention Mechanism and Multi-Scale spatial Pooling-based conditional Adversarial Network (AM-MSP-cGAN) model to achieve automatic segmentation of medical images. AM-MSP-cGAN can learn more detailed features from fuzzy boundaries, and effectively solve the problem of data lack, thereby promoting economic audit risk quantification and assessment in the healthcare field.",2025
Real-Time Monitoring and Image Recognition System for Abnormal Activities in Financial Markets Based on Deep Learning,"As the complexity and dynamic changes in financial markets continue to increase, real-time monitoring of abnormal activities has become a critical task in financial regulation and risk management. Traditional monitoring methods, which rely on rules and experience, struggle to handle the nonlinear and highly volatile nature of financial markets, especially when dealing with large-scale and multidimensional data. In recent years, the rapid development of deep learning technology has provided new solutions for real-time monitoring of abnormal activities in financial markets. By transforming time-series data into images and leveraging the pattern recognition capabilities of deep learning, abnormal market fluctuations can be more accurately detected, enabling efficient early-warning systems. However, existing research still faces challenges such as inadequate data adaptability, difficulties in integrating multidimensional information, lack of real-time performance, and poor interpretability of warning systems. This paper proposes a deep learning-based realtime monitoring and early-warning system for abnormal activities in financial markets, which consists of two main components: first, a real-time monitoring model for financial market time-series curve patterns based on information block recognition, aimed at extracting key features from time-series data for precise market fluctuation monitoring; second, an early-warning method for abnormal activities based on the changes in time-series curve trends, designed to identify potential abnormal activities in real time and issue earlywarning signals. The core value of this study lies in the proposed innovative monitoring model and warning mechanism, which overcome the limitations of traditional methods and provide aAmore accurate and real-time tool for abnormal activity monitoring and early warning, with significant theoretical and practical value.",2024
Analysis of Enterprise Financial and Economic Impact Based on Background Deep Learning Model under Business Administration,"Enterprise finance has become an indispensable financial channel for people to invest in their lives, and business management can provide a better economic environment for the development of enterprise finance. The structure of enterprises is gradually becoming more and more complex, and business administration shoulders considerable responsibilities and obligations in the organization and supervision of today's social management structure. How can China play its functions under the new situation after the world economic exchanges are more frequent is an important link to promote the stable development of financial markets. In view of the problems of economic activity behavior and certainty of financial index system under the background of existing business administration, this paper puts forward the deep learning model to make risk analysis, income analysis, profit and loss analysis, and so on. The formula of deep learning model is used to calculate the data graph of financial economy, and finally, various data are compared to get the research of several business management methods on the development of enterprise financial economy. Among them, the model of current management mode belongs to two modes: e-commerce and EPR management. They not only have very unique management characteristics but also greatly promote the development of modern management, and their roles also well interpret the characteristics of modern management. The experiment also analyzes the financial data under the four algorithms for uncertainty comparison, profit and loss comparison, discreteness comparison, volatility comparison, and possibility analysis. Finally, after the source of uncertainty, the risk prediction and risk management are carried out by constructing decision trees, and these structural models are used to bring comprehensive analysis to the financial economy of enterprises and to build the impact of good trends and development prospects.",2021
An Optimized Hybrid Model for Price Deviation Evaluation based on Neural Network,"As a strong displaying approach, neural networks have been broadly utilized in finance and financial forecasting. Scientific and fair trading-type open-end index fund (ETF) option pricing is favorable to maximizing the risk hedging function of the ETF, but it is also a sophisticated modelling procedure that necessitates a thorough understanding of market laws and economic importance. Based on China SSE 50 ETF, Harvest CSI 300 ETF, and high-frequency option data of 300ETF from Berry, this paper proposes another hybrid modelling method that consolidates the settled long-short-term memory neural network model (NLSTM) with the Heston model to acknowledge dynamic rectification of ETF choice price deviations. The research results show that the volatility characteristics of different types of ETF option prices are significantly different. Whether it is based on the BS pricing model or the Heston pricing model, it is difficult to accurately describe the complex changes in ETF option prices. By combining the NLSTM neural network model with the Heston model, it can effectively capture the dynamic changes of different types of ETF options, thereby improving the accuracy of ETF option pricing.",2023
Fraud Detection in Banking Using Deep Reinforcement Learning,"Deep learning and machine learning are hot topics in the financial services nowadays. They allow financial entities to define products and segment clients, efficiently manage risk and detect fraud in banks. The theory of Deep Reinforcement. Learning (DRL) was originally motivated by animal learning of sequential behavior, but has been developed and extended in the field of machine learning as an approach to Markov decision processes. Recently, a number of financial risk analysis and fraud detection studies have suggested a relationship between reward-related activities in the brain and functions necessary for DRL. Regarding the history of DRL, we introduce in this article the theory of DRL and present two applications in banking. Then we will discuss possible implementations.",2017
A deep learning-based financial hedging approach for the effective management of commodity risks,"The development of deep learning technique has granted firms with new opportunities to substantially improve their risk management strategies for sustainable growth. This paper introduces a novel deep learning-based financial hedging (DL-HE) strategy to leverage the salient ability of deep learning in extracting nonlinear features from complex high dimensional data, thus boosting the management of inventory risks arising from erratic commodity prices. Using real-world data, we find that the average annualized economic benefit of the proposed strategy is at least 1.21 million CNY for a typical aluminum firm carrying an average level of inventory in China, as compared with those of the traditional hedging strategies. Further analysis reveals that such an economic benefit can largely be explained by the efficacy of the proposed DL-HE strategy in terms of significantly improving return while still effectively controlling risk. Moreover, the superior of this strategy remains robust when extending to copper and zinc.",2024
A Machine Learning Method for Prediction of Stock Market Using Real-Time Twitter Data,"Finances represent one of the key requirements to perform any useful activity for humanity. Financial markets, e.g., stock markets, forex, and mercantile exchanges, etc., provide the opportunity to anyone to invest and generate finances. However, to reap maximum benefits from these financial markets, effective decision making is required to identify the trade directions, e.g., going long/short by analyzing all the influential factors, e.g., price action, economic policies, and supply/demand estimation, in a timely manner. In this regard, analysis of the financial news and Twitter posts plays a significant role to predict the future behavior of financial markets, public sentiment estimation, and systematic/idiosyncratic risk estimation. In this paper, our proposed work aims to analyze the Twitter posts and Google Finance data to predict the future behavior of the stock markets (one of the key financial markets) in a particular time frame, i.e., hourly, daily, weekly, etc., through a novel StockSentiWordNet (SSWN) model. The proposed SSWN model extends the standard opinion lexicon named SentiWordNet (SWN) through the terms specifically related to the stock markets to train extreme learning machine (ELM) and recurrent neural network (RNN) for stock price prediction. The experiments are performed on two datasets, i.e., Sentiment140 and Twitter datasets, and achieved the accuracy value of 86.06%. Findings show that our work outperforms the state-of-the-art approaches with respect to overall accuracy. In future, we plan to enhance the capability of our method by adding other popular social media, e.g., Facebook and Google News etc.",2022
Evolving Deep Neural Networks for Movie Box-office Revenues Prediction,"Reliable prediction of movie box-office revenues can greatly reduce the financial risk in the film industry, but accurate prediction is not easy to obtain. Recently, deep neural networks has been applied on movie box-office revenues prediction problems as a promising solution. However, the architecture has a significant impact on its performance, and generally involves a heavy burden of manually designing which is unable to traverse the space of possible architectures efficiently. As a result, the applicability and performance of deep neural networks are severely limited. This paper proposes a new evolutionary algorithm for evolving deep neural networks for movie box-office revenues prediction. In particular, a deep neural network that fuses features extracted from movie posters by a convolutional neural network is introduced first, then a set of novel genetic operators are designed correspondingly. The proposed method can automate the deep neural network architecture designing and aim to search the optimal architecture for movie box-office revenues prediction. Experiments carried out on the Internet Movie Database (IMDB) dataset show that the proposed algorithm achieves superior performance compare to other competitive approaches.",2018
AlphaStock: A Buying-Winners-and-Selling-Losers Investment Strategy using Interpretable Deep Reinforcement Attention Networks,"Recent years have witnessed the successful marriage of finance innovations and AI techniques in various finance applications including quantitative trading (QT). Despite great research efforts devoted to leveraging deep learning (DL) methods for building better QT strategies, existing studies still face serious challenges especially from the side of finance, such as the balance of risk and return, the resistance to extreme loss, and the interpretability of strategies, which limit the application of DL-based strategies in real-life financial markets. In this work, we propose AlphaStock, a novel reinforcement learning (RL) based investment strategy enhanced by interpretable deep attention networks, to address the above challenges. Our main contributions are summarized as follows: i) We integrate deep attention networks with a Sharpe ratio-oriented reinforcement learning framework to achieve a risk-return balanced investment strategy; ii) We suggest modeling interrelationships among assets to avoid selection bias and develop a cross-asset attention mechanism; iii) To our best knowledge, this work is among the first to offer an interpretable investment strategy using deep reinforcement learning models. The experiments on long-periodic U.S. and Chinese markets demonstrate the effectiveness and robustness of AlphaStock over diverse market states. It turns out that AlphaStock tends to select the stocks as winners with high long-term growth, low volatility, high intrinsic value, and being undervalued recently.",2019
Innovative Risk Early Warning Model under Data Mining Approach in Risk Assessment of Internet Credit Finance,"The financial risks of commercial banks are classified and evaluated through the Internet of Things (IoT) technology and big data technology to reduce the financial risk loss of commercial banks in the context of Internet finance. Firstly, based on the analysis of financial risks in the context of IoT technology, an IoT tail loss mathematical model of financial operation risk is constructed to classify the operation risks of commercial banks. Secondly, the BP neural network algorithm is applied to determine the number of nodes, activation function, learning rate, and other parameters of each BP neural network layer. Also, many data samples are used to build an early warning model of Internet credit risk. The constructed model is trained and tested. Finally, the genetic algorithm (GA) is used to optimize the neural network to improve early warning accuracy. The results show that introducing Internet technology can reduce the risk loss of commercial banks. In addition, based on 450 data samples of 90 companies in 5 years and the risk interval divided by the 3 sigma rule, the Internet credit risk level was initially determined. Then, the neural network is trained and tested. The prediction accuracy of the neural network reaches 85%. In order to avoid the defects of BP neural network falling into local extreme values, GA is used to optimize the neural network. The warning is more accurate and the error is smaller, and the accuracy rate can reach 97%. Therefore, the use of BP neural network for early warning and assessment of Internet credit risk has good accuracy and computing efficiency, which expands the application of BP neural network in the field of Internet finance, and provides a new development direction for the early warning and assessment of Internet credit risk.",2022
Portfolio optimization using predictive auxiliary classifier generative adversarial networks,"In financial engineering, portfolio optimization has been of consistent interest. Portfolio optimization is a process of modulating asset distributions to maximize expected returns and minimize risks. Despite numerous studies on shallow learning models, they have shown limited success in analyzing the complex nature of massive stock data, a task where recent deep learning models excel. However, the deterministic nature of conventional deep learning models impedes their consideration of portfolio risk due to an inherent lack of uncertainty quantification in their predictions. This paper proposes a novel portfolio weighting strategy, incorporating both risk and return considerations within a deep learning framework. We propose the Predictive Auxiliary Classifier Generative Adversarial Networks (PredACGAN), a probabilistic deep learning model, to measure prediction uncertainty. The PredACGAN generator leverages latent vectors and historical stock prices to predict future returns. The model synthesizes predictive distributions from various latent vectors and past prices. The associated risk is produced via the entropy of these distributions, facilitating portfolio optimization through both return and risk considerations. The proposed algorithm removes high-risk assets from the investment universe at rebalancing moments, enabling PredACGAN to optimize portfolios considering both return and risk. We evaluated PredACGAN and the accompanying algorithm with S & P 500 stocks from 1990 to 2020, with portfolios rebalanced monthly based on PredACGAN predictions and risk measures. The PredACGAN portfolios yielded 9.123% annual returns and a 1.054 Sharpe ratio, outperforming a risk-agnostic portfolio yielding 1.024% annual returns and a 0.236 Sharpe ratio. The PredACGAN portfolio also exhibited lower maximum drawdowns, highlighting its effectiveness.",2023
RETRACTED: Evaluating and forecasting the risks of small to medium-sized enterprises in the supply chain finance market using blockchain technology and deep learning model,"The present work applies deep learning and blockchain technology to evaluate and control the risk of the supply chain finance market, to cope with the diversifications of the financial market development mode. Firstly, based on the relevant monetary inward theory, the potential risks are analyzed in the supply chain finance market. Besides, under the background of financial technology, the risk of the supply chain finance market is predicted and managed by intelligent technology. Secondly, the financing model of supply chain finance is analyzed to discuss the possible credit risk of supply chain finance. Meanwhile, the credit evaluation model of supply chain finance based on deep learning technology is constructed to predict the potential credit risk. Thirdly, blockchain technology is adopted to control and optimize the credit evaluation model to establish a credit system for supply chain enterprises with high credit and reliability and reduce potential supply chain financial risks. Finally, the designed model is simulated and tested. The experimental results show that the credit evaluation model of supply chain finance has a fitting effect of 0.989 on the sample data, indicating that it can effectively analyze the data. Result analysis shows that the designed model can effectively predict the potential credit risk of the enterprise. Moreover, a stable and reliable credit relationship network is established for supply chain finance by blockchain technology, which enhances the reliability of logistics transactions, and reduces potential risks faced by supply chain finance. The model provides effective technical means for studying the credit risk of supply chain finance.",2022
Multi-grained and multi-layered gradient boosting decision tree for credit scoring,"Credit scoring is an important process for banks and financial institutions to manage credit risk. Tree-based ensemble algorithms have made promising progress in credit scoring. However, tree-based ensemble algorithms lack representation learning, making them cannot well express the potential distribution of loan data. In this study, we propose a multi-grained and multi-layered gradient boosting decision tree (GBDT) for credit scoring. Multi-layered GBDT considers the advantages of the explicit learning process of tree-based model and the representation learning ability to discriminate good/bad applicants; multi-grained scanning augments original credit features while enhancing the representation learning ability of multi-layered GBDT. The experimental results on 6 credit scoring datasets show that the hierarchical structure can effectively reduce the intra-class distance and increase the inter-class distance of the credit scoring dataset. In addition, Multi-grained feature augmentation effectively increases the diversity of prediction and further improves the performance of credit scoring, providing more precise credit scoring results.",2022
"Financial time series prediction using l2,1 RF-ELM","Financial time series forecasting is a complicated task because the behavior of investors can be influenced by lots of tiny and unpredictable factors. In this paper, in order to maximize the return of capital and manage liquidity risk effectively, an l(2,1)-norm and Random Fourier Mapping based Extreme Learning Machine(l(2,1) RF-ELM) is applied to the problem of financial time series prediction. The advantages of ELM in efficiency and generalization performance over traditional fuzzy neural network( FNN) algorithms have been demonstrated on a wide range of problems from different fields, thanks to the integration of l(2,1)-norm, the l(2,1) RF-ELM is able to automatically prune the irrelevant and redundant hidden neurons to form a more discriminative and compact hidden layer. The performance of the l(2,1) RF-ELM is compared with other hidden layer enforcement algorithms, two long-term time series data sets, including TianChi and BCS, are used for this comparison. The performance of the l(2,1) RF-ELM was comparable to those of other widely used machine learning techniques like support vector machines (SVM), artificial neural networks (ANN) and other popular ELM method. The experiments demonstrate favorable prediction results of the l(2,1) RF-ELM in terms of annualized return, prediction error and running time. In addition, we also find that the underlying rules of the correlation between cash inflow and outflow that can help us improve accuracy, which is valuable for financial institutions to predict the trend of liquidity. (C) 2017 Elsevier B.V. All rights reserved.",2018
Influences of mobile edge computing-based service preloading on the early-warning of financial risks,"The present work aims to apply the Internet of Things (IoT) to help enterprises improve financial management, timely discover hidden financial risks, and enhance the ability to resist risks. Firstly, the traditional financial risk early-warning model based on accounting information is analyzed. Accordingly, a corporate risk early-warning model is put forward from the perspective of cash flow, and the financial risk early-warning indicator system is established. Secondly, the Backpropagation neural network (BPNN) is employed to mine the financial data of the enterprise. After pre-processing, the data are input into the model according to the type of financial risk early-warning indicators to obtain the financial risk prediction result of the company. Thirdly, the mobile edge computing (MEC) service is introduced into the corporate financial management to improve the calculation performance of the corporate financial information processing and strengthen the timeliness of cash flow information and risk warning cooperating with IoT. Finally, an edge service preloading optimization model is established based on the Geographic Point of Interest Information and BPNN. According to the feature vector of the user location, the next service probability of the user is predicted, and the service preloading is carried out on the accessed edge server. Finally, the effect of this model is verified by experiments. The experimental results indicate that the prediction accuracy of the risk early-warning model designed here for financial health and crisis is 91.6% and 75%, respectively, and the response rate of the service preloading optimization model is between 2.1% and 5%. Therefore, service preloading can improve the response speed of corporate financial risk early-warning to a certain extent. This exploration provides a reference for the study of the corporate financial risk early-warning model based on MEC and IoT.",2022
Enterprise Financing Risk Analysis and Internal Accounting Management Based on BP Neural Network Model,"A BP neural network-based model is proposed to study corporate financial risk analysis and internal accounting management. Using MATLAB software and the BP neural network model, it is possible to obtain enterprise financing risk situations over a period by simulating and predicting enterprise financing risks by creating an early warning model for enterprise financing risks. Finally, from the point of view of the company's internal and external operations, the company's financial risk prevention measures and proposals are proposed to improve the financing efficiency of the companies and to prevent financial risks. This study predicts the financing risk of companies listed on the Mongolian Stock Exchange and analyzes the causes of the risk status. According to the test results, the learning speeds for successive substitutions are as follows: 0.005, 0.01, 0.02, 0.03, and 0.04. Finally, it was found that the error was minimal and the stability was best when the learning speed was exactly 0.01. The error is 0.0031011, and the step size is 157, which is only slightly lower than the target error value, which indicates that the learning speed is good. In addition, the novelty of this study is the use of the BP neural network model to conduct an early warning study of corporate financial risks. The BP neural network assessment model for corporate lending risk in this document is highly accurate. In addition to providing theoretical insights to researchers, it can be a good tool for banks to realistically assess the credit risk of SME supply chain financing.",2022
Enhancing climate resilience in businesses: The role of artificial intelligence,"The abrupt rise in extreme weather events (floods, heat waves, droughts, etc.) due to changing climate in the last decades has increased the level of threats to various sectors (agriculture, energy, transportation, etc.) globally. The climate projections from global circulation models indicate even more intense and frequent extreme events in the future, which in turn pose more risks to socioeconomic infrastructure. The enhanced understanding of the climate-related financial risk associated with businesses has driven efforts to include critical information on probable risks associated with climate change in financial decision-making. In this study, we have presented a framework to assess the need of incorporating climate risk assessment as an integral part of business operations. We also reviewed revealed literature to understand the possible impacts of climate change on various sectors and presented key strategies to assess the climate risk associated with them. Also, a framework incorporating probable climate threats to business ecology with principles of robustness, resourcefulness, redundancy, and rapidity has been proposed to adapt and mitigate associated risks for a climate-resilient business ecosystem. The integration of Artificial Intelligence in managing risk could be a promising tool for enhancing business resilience to climate change and could be used as a tool. Robust and accurate predictions of climate and weather extremes from deep learning algorithms at a significant lead time can help in minimizing the associated risk with a business infrastructure. Atmospheric Rivers (ARs), a weather extreme cause huge socioeconomic risk by triggering floods and droughts in various continents of mid-latitude regions. We have presented a case study investigating the ability of deep learning algorithms to predict ARs. The results from the analysis advocate the application of deep learning algorithms to predict weather and climate extremes in decision support systems to enhance the climate resilience of a business ecosystem.",2023
Research on the Development of Hospital Intelligent Finance Based on Artificial Intelligence,"Based on the development background of the interweaving and integration of computer technology and Internet technology, China's artificial intelligence industry is quietly rising. In the social life of the information age, the artificial intelligence industry represented by machine deep learning is playing a very important role. This study in combination with the background of the new health reform, in view of the reform of the medical industry, analyzes the connotation of financial wisdom based on the important role of the hospital financial development problems, puts forward the development direction of artificial intelligence hospital financial wisdom development measures, designed to meet the changing external environment demand, reduces human costs, and improves the overall efficiency of hospital financial fund management. Based on the evaluation results, this paper proposes the correct direction for the development of hospital intelligence finance by using the BP neural network model. After the analysis, it is found that the development of artificial intelligence is an important measure to promote the development of hospital intelligent finance. In other words, hospital intelligent financial management is the product of the continuous progress of artificial intelligence technology. At the present stage, the intelligent financial management problems of hospitals are mainly as follows: (1) lack of financial informatization, (2) lack of perfect financial risk early warning system, and (3) the phenomenon of information island in the financial system. After analyzing the above problems, the research believes that the development of hospital intelligent finance based on artificial intelligence needs to solve the above thorny problems, so as to improve the outcome of hospital intelligent finance development. The following work should be done: (1) strengthen the design of information sharing module, (2) intelligent control of the cost of hospitals, and (3) intelligent treatment of hospital accounting. Combining the development of artificial intelligence and hospital intelligent finance theory, combined with the actual trend of financial intelligence development under the background of artificial intelligence development in the new era, it provides scientific basis for the development of hospital intelligent finance.",2022
A Study on the Impact of Corporate Financial Accounting Management System on Corporate Innovation Under Sustainable Development Strategy,"In the complex and changeable macro-economy, the sustainable development of enterprises is closely related to their ability to resist risks. To analyze the influencing factors of listed enterprises' anti risk ability, this study constructs an indicator system of influencing variables through principal component analysis. The financial risk early warning method based on improved RBF neural network is constructed. Afterwards, the relevance of the indicator system was confirmed by the Kaiser-Meyer-Olkin (KMO) test. And in simulation experiments, it compared the classification performance of the BP neural network and the improved RBF model combined with the clustering algorithm. In the training dataset, the classification accuracy of the BP neural network was 79.6% while that of the improved RBF model was as high as 93.6%. In the 30 test datasets, the BP neural network appeared to have seven false positives. In the 30 test datasets, the BP neural network produced seven false judgments, while the proposed method only had three judgment errors. Several experiments showed that the BGD-RBF financial risk early warning model effectively maintained a high performance in the classification accuracy of enterprise financial status. It is more reliable than the traditional BP neural network method.",2024
BP neural network-based early warning model for financial risk of internet financial companies,"We built an early warning model for financial risk using a back propagation neural network. To this end, the financial data of 136 listed Internet financial companies in the People's Republic of China were selected, spanning from 2010-2019, as the sample for the empirical test. We categorized the financial status of enterprises as either healthy or early warning by the K-means clustering algorithm. Furthermore, factor analysis was performed to obtain seven common factors for building the early warning model. Overall, we confirmed the model's excellent comprehensive accuracy and prediction efficiency, with accuracy, precision, recall, and specificity rates of 99.51%, 99.71%, 99.71%, and 98.30%, respectively. Thus, the model obtained by training and simulation using the back propagation neural network algorithm can effectively screen enterprises with hidden financial conditions and will not misclassify enterprises with good financial conditions. Notably, the misjudgment and omission rates are considerably low. The model is highly capable of identifying the financial status of Internet financial companies and has good predictive power.",2023
PRoFET: Predicting the Risk of Firms from Event Transcripts,"Financial risk, defined as the chance to deviate from return expectations, is most commonly measured with volatility. Due to its value for investment decision making, volatility prediction is probably among the most important tasks in finance and risk management. Although evidence exists that enriching purely financial models with natural language information can improve predictions of volatility, this task is still comparably underexplored. We introduce PRoFET, the first neural model for volatility prediction jointly exploiting both semantic language representations and a comprehensive set of financial features. As language data, we use transcripts from quarterly recurring events, so-called earnings calls; in these calls, the performance of publicly traded companies is summarized and prognosticated by their management. We show that our proposed architecture, which models verbal context with an attention mechanism, significantly outperforms the previous state-of-the-art and other strong baselines. Finally, we visualize this attention mechanism on the token-level, thus aiding interpretability and providing a use case of PRoFET as a tool for investment decision support.",2019
Diffusion Variational Autoencoder for Tackling Stochasticity in Multi-Step Regression Stock Price Prediction,"Multi-step stock price prediction over a long-term horizon is crucial for forecasting its volatility, allowing financial institutions to price and hedge derivatives, and banks to quantify the risk in their trading books. Additionally, most financial regulators also require a liquidity horizon of several days for institutional investors to exit their risky assets, in order to not materially affect market prices. However, the task of multi-step stock price prediction is challenging, given the highly stochastic nature of stock data. Current solutions to tackle this problem are mostly designed for single-step, classification-based predictions, and are limited to low representation expressiveness. The problem also gets progressively harder with the introduction of the target price sequence, which also contains stochastic noise and reduces generalizability at test-time. To tackle these issues, we combine a deep hierarchical variational-autoencoder (VAE) and diffusion probabilistic techniques to do seq2seq stock prediction through a stochastic generative process. The hierarchical VAE allows us to learn the complex and low-level latent variables for stock prediction, while the diffusion probabilistic model trains the predictor to handle stock price stochasticity by progressively adding random noise to the stock data. To deal with the additional stochasticity in the target price sequence, we also augment the target series with noise via a coupled diffusion process. We then perform a denoising process to clean the prediction outputs that were trained on the stochastic target sequence data, which increases the generalizability of the model at test-time. Our Diffusion-VAE (D-Va) model is shown to outperform state-of-the-art solutions in terms of its prediction accuracy and variance. Through an ablation study, we also show how each of the components introduced helps to improve overall prediction accuracy by reducing the data noise. Most importantly, the multi-step outputs can also allow us to form a stock portfolio over the prediction length. We demonstrate the effectiveness of our model outputs in the portfolio investment task through the Sharpe ratio metric and highlight the importance of dealing with different types of prediction uncertainties. Our code can be accessed through https://github.com/koa-fin/dva.",2023
Classifying payment patterns with artificial neural networks: An autoencoder approach,"Payments and market infrastructures are the backbone of modern financial systems and play a key role in the economy. One of their main goals is to manage systemic risk, especially in the case of systemically important payment systems (SIPS) serving interbank funds transfers. We develop an autoencoder for the Sistema de Pagos Interbancarios (SPI) of Ecuador, which is the largest SIPS, to detect potential anomalies stemming from payment patterns. Our work is similar to Triepels et al. (2018) and Sabetti and Heijmans (2020). We train four different autoencoder models using intraday data structured in three time-intervals for the SPI settlement activity to reconstruct its related payments network. We introduce bank run simulations to feature a baseline scenario and identify relevant autoencoder parametrizations for anomaly detection. The main contribution of our work is training an autoencoder to detect a wide range of anomalies in a payment system, ranging from the unusual behavior of individual banks to systemic changes in the overall structure of the payments network. We also found that these novel techniques are robust enough to support the monitoring of payments' and market infrastructures' functioning, but need to be accompanied by the expert judgement of payments overseers.",2020
Development of an adaptive business insolvency classifier prototype (AVICENA) using hybrid intelligent algorithms,"Confronted by an increasingly competitive environment and chaotic economy conditions, businesses are facing with the need to accept greater risk. Businesses do not become insolvent overnight, rather many times creditors, investors and the financial community will receive either direct or indirect indications that a company is experiencing financial distress. Thus, this paper analyzed the ability of AVICENA in classifying business insolvency performance events. Neural networks (Multi layer Perceptron - Backpropagation) serves as a classifier mechanism while Apriori algorithms (Auto Association Rules) supports the decision made by the neural networks, in which rules are generated. The conventional model in predicting business performances, called as Altman- Z Scores model is used for performance comparison.",2002
Multidimensional Financial Metrics for Corporate Financial Risk Assessment and Early Warning Mechanisms,"By constructing a comprehensive multi-dimensional financial index evaluation system, this study effectively identifies, evaluates, and forewarns the financial risks of enterprises. Utilizing public financial data from S&P Global and Alpha Vantage, a BP neural network-based enterprise financial risk assessment framework is built, and the KMO method analyzes different risk factors. This comprehensive evaluation model, paired with a risk warning mechanism, assesses financial and cash flow indicators. The example analysis shows: 1) The RMSE value ranges from 46.71 to 64.94, indicating high accuracy and stability in predicting financial risk; 2) The R value is very close to 1, demonstrating high stability.",2024
A Review of Natural Language Processing for Financial Technology,"In the past few years, the development of natural language processing has been able to deal with many issues such as emotional analysis, semantic analysis, and so on. This review first introduces the development of natural language processing, and then summarizes their applications in financial technology, which mainly focuses on public opinion analysis, financial prediction and analysis, risk assessment, intelligent question answering, and automatic document generation. The analysis shows that natural language processing can give full play to its advantages in the financial field. Moreover, this paper also discusses the problems and challenges for financial technology that are developed based on natural language processing. Finally, this paper presents two developing trends of natural language processing in financial technology: deep learning and knowledge graph.",2021
Multi-Sensor Temporal Fusion Transformer for Stock Performance Prediction: An Adaptive Sharpe Ratio Approach,"Accurate prediction of the Sharpe ratio, a key metric for risk-adjusted returns in financial markets, remains a significant challenge due to the complex and stochastic nature of stock price movements. This paper introduces a novel deep learning model, the Temporal Fusion Transformer with Adaptive Sharpe Ratio Optimization (TFT-ASRO), designed to address this challenge. The model incorporates real-time market sensor data and financial indicators as input signals, leveraging multiple data streams including price sensors, volume sensors, and market sentiment sensors to capture the complete market state. Using a comprehensive dataset of US historical stock prices and earnings data, we demonstrate that TFT-ASRO outperforms traditional methods and existing deep learning models in predicting Sharpe ratios across various time horizons. The model's multi-task learning framework, which simultaneously predicts returns and volatility, provides a more nuanced understanding of risk-adjusted performance. Furthermore, our adaptive optimization approach effectively balances the trade-off between return maximization and risk minimization, leading to more robust predictions. Empirical results show that TFT-ASRO achieves a 18% improvement in Sharpe ratio prediction accuracy compared to state-of-the-art baselines, with particularly strong performance in volatile market conditions. The model also demonstrates superior uncertainty quantification, providing reliable confidence intervals for its predictions. These findings have significant implications for portfolio management and investment strategy optimization, offering a powerful tool for financial decision-makers in the era of data-driven investing.",2025
Intelligent Optimization Model of Enterprise Financial Account Receivable Management,"As a key component of enterprise assets, accounts receivable play an important role in enterprise financial management and determine the long-term development of enterprises in the later period. In order to minimize the financial risk brought by the credit sales of enterprises, this subject studies the intelligent optimization of enterprise financial account receivable management. BP neural network and K-means clustering algorithm are used to evaluate the risk of account receivable and the owner's credit, respectively. The account balance accounts for 45.20% of the total amount, and the risk rating of accounts receivable is 4. The training result of BP neural network algorithm has high accuracy. With K-means clustering algorithm, accurate evaluation of owner's credit can be achieved, which can provide reference for optimization of enterprise account receivable management mode.",2024
Early Warning Research on Financial Risks of Listed Companies in Real Estate Industry Based on BP NeuralNetworks,"In recent years, with the frequent outbreak of financial crisis of Chinese real estate enterprises, the financial risk of real estate industry has become more and more prominent, which has aroused extensive attention from all walks of life. In the face of the complex and changing market environment and potential financial risks, the establishment of an effective financial risk early warning model has become a key initiative for real estate enterprises to prevent and resolve risks. Taking listed real estate companies in 2018-2023 as the research object, this paper establishes a set of comprehensive and accurate financial risk early warning model by constructing an early warning indicator system containing financial and non-financial indicators, and applying BP (back propagation) neural network algorithm in the field of artificial intelligence. The model takes into full consideration of the financial status of real estate enterprises, operational performance, market environment and other factors, and can effectively capture the potential financial risk signals, providing an important basis for enterprise risk management and decision-making. Through empirical research, this paper verifies that the constructed BP neural network financial risk early warning model has good predictive ability and practical application value. The model can accurately identify all kinds of financial risks faced by real estate enterprises, including liquidity risk, debt service risk, profitability risk, etc., which provides scientific guidance for enterprises to adjust their business strategies and optimize resource allocation in time. The research results of this paper provide valuable theoretical references and practical guidance for the prevention and control of financial risks in the real estate industry, and are of great significance to the promotion of the healthy and sustainable development of the real estate industry.",2024
A Fuzzy Neural Network-Based Intelligent Warning Method for Financial Risk of Enterprises,"The fast warning for financial risk of enterprises has always been a realistic demand for their managers. Currently, this mainly relies on expert experience to make comprehensive analysis from massive business data. Benefitting from the strong computational performance of deep learning, this paper proposes a fuzzy neural network (FNN)-based intelligent warning method for financial risk of enterprises. An improved FNN structure with time-varying coefficients and time-varying time lags is established to extract features of enterprises from complex financial context. The algorithm of fuzzy C-means and fuzzy clustering based on sample data are studied. In this paper, the fuzzy C-means algorithm is used to cluster the samples, the input sample set is preprocessed, a new set of learning samples is formed, and then the neural network is trained. The enterprise financial risk sample and its modular FNN model are established, and the evaluation of the enterprise financial risk sample is simulated. Then, a decision part is added following the FNN part to output the warning results. After that, we have also conducted a case study as simulation experiments to evaluate the proposed technical framework. The obtained results show that it can perform well in the fast warning of financial risk for enterprises.",2024
HIVE: Hierarchical Information Visualization for Explainability,"In this demonstration, we develop an interactive tool, HIVE, to demonstrate the ability and versatility of an explainable risk ranking model with a special focus on financial use cases. HIVE is a web-based tool that provides users with automated highlighted financial statements, and HIVE is designed for making comparing statements rather more efficient. Moreover, with the proposed tool, users can find related reports at ease, and we believe that HIVE can benefit both academics and practitioners in finance as they can work around deep learning models with their newly gained insights.",2021
The Accounting Early Warning System of China's Petrochemical Public Company Based on The BP neural network,"The accumulating financial risk of the enterprises is the dominant factor that leading companies to crisis. The main measures to prevent corporate crisis are to enhance the elimination and the management of the financial risk. The early warning of the financial risk is the process which carries out multi-angle analysis of judgments to the likelihood of the corporate financial risk and timely issue the crisis warnings. Based on BP Neural Network Model and the listed company's annual report data, this paper built the financial early warning system of the listed companies in China's petrochemical industry. The results showed that the early warning system of the financial risk constructed in this article has effectively forecast for the financial risk of China's petrochemical industry and the high accuracy.",2010
Portfolio constructions in cryptocurrency market: A CVaR-based deep reinforcement learning approach,"Cryptocurrency markets have much larger tail risk than traditional financial markets, and constructing portfolios with such large tail risk assets would be challenging. Therefore, cryptocurrency funds demand new superior risk management models and Conditional Value at Risk (CVaR) is a prevailing risk measure for constructing portfolios in stock markets with large tail risk. Consequently, our paper contributes to the literature by developing a new cryptocurrency portfolio model framework based on the CVaR risk measure and a deep reinforcement learning optimization framework. We use the data from cryptocurrency market starting 2015 to 2021, unfolding that CVaR measure with deep learning outperforms the traditional portfolio construction technique. Compared with traditional economic parameter-based portfolio models, our model free based approach can capture the nonlinear compounding effect of multiple risk shocks by deep reinforcement learning on the risk distribution with economic structural breakdown. It can guide investments in financial markets with high tail risks.",2023
Analyzing Firm Reports for Volatility Prediction: A Knowledge-Driven Text-Embedding Approach,"Predicting stock return volatility is the key to investment and risk management. Traditional volatility-forecasting methods primarily rely on stochastic models. More recently, many machine-learning approaches, particularly text-mining techniques, have been implemented to predict stock return volatility, thus taking advantage of the availability of large amounts of unstructured data such as firm financial reports. Most existing studies develop simple but effective models to analyze text, such as dictionary-based matching algorithms that use a set of manually constructed keywords. However, the latent and deep semantics encoded in text are usually neglected. In this study, we build on recent progress in representation learning and propose a novel word-embedding method that incorporates external knowledge from a well-known finance-domain lexicon (the Loughran and McDonald word list), which helps us learn semantic relationships among words in firm reports for better volatility prediction. Using over 10 years of annual reports from Russell 3000 firms, we empirically show that, compared with cutting-edge benchmarks, our proposed method achieves significant improvement in terms of prediction error, for example, a 28.4% reduction on average. We also discuss the practical and methodological implications of our findings. Our financial-specific word-embedding program is available as open-source information so that researchers can use it to analyze financial reports and assess financial risks. Summary of Contribution: Predicting stock return volatility is the key to investment and risk management. Traditional volatility-forecasting methods primarily rely on stochastic models. More recently, many machine-learning, especially text-mining, techniques have been developed to predict stock return volatility given the availability of a large amount of unstructured data, such as firm annual reports. Most existing research develops simple but effective approaches, for example, manually constructing a set of keywords to analyze texts. However, the latent and deep semantics encoded in texts are usually ignored. In this research, we build on recent progress in representation learning and propose a novel word-embedding method that incorporates external knowledge from the finance-domain lexicon of Loughran and McDonald word list, which helps us learn the semantic relationships among words in firm annual reports for better volatility prediction. In this study, we make the following contributions. First, methodologically, we are among the first to incorporate finance-specific lexicon into representation learning for stock volatility prediction. We propose a novel knowledge-driven text-embedding model that is trained on a large amount of unstructured textual data to learn high quality word embedding. Our proposed approach is effective in predicting stock return volatility, and the approach can potentially have broader applications. Second, substantively, we empirically show that the domain lexicon enhanced text representation learning can indeed significantly improve the performance, compared with bag-of-words models and generic word embedding for volatility prediction. Domain knowledge combined with text learning plays a critical enabling role in understanding financial reports. Third, our method adds on to existing literature on designing financial information systems by incorporating ontology knowledge, common-sense knowledge, and general prior knowledge.",2022
Applications of Machine and Deep Learning in Funding Decision: A Review,"In corporate finance, a number of conventional techniques are being replaced by machine and deep learning algorithms as a result of artificial intelligence advancements. These tools of artificial intelligence will continue to revolutionize society and various aspects of the economy, including corporate finance. This paper is dedicated to a review of the applications of machine and deep learning algorithms in corporate finance decisions throughout the funding process. These algorithms can be used to assess current or future funding needs, explore the various funding options available to the company, choose the most appropriate funding method, prepare the funding file, and manage the risks inherent in funding. These modern technological tools are indispensable for navigating an increasingly complex and competitive financial environment. Their strategic use helps optimize financial decisions and maximize growth opportunities, from the beginning stages of planning to continuous risk management. By using them, decision-making is enhanced, resource allocation is optimized, and profitable growth is guaranteed.",2024
Evaluation of market risk and resource allocation ability of green credit business by deep learning under internet of things,"The research expects to evaluate the capital market risk and resource allocation ability of green credit business exploration based on neural network algorithm by deep learning in the context of the Internet of things, increase the funds flowing to green environmental protection industry, accelerate the development of real economy and stabilize China's market economy. On the basis of previous studies, the research takes the credit business in the capital market as the research object, and improves the ability of resource allocation by optimizing the financial transaction structure. On this basis, through comparative analysis, the grey system model is implemented. back propagation neural network model under deep learning is used to evaluate the capital market risk of green credit business exploration, and the data of different provinces in China from 2009 to 2019 are taken as an example to verify. The model is used to measure the relationship between green credit business and industrial structure. Additionally, it also analyzes the main factors affecting the efficiency of green credit. The results show that green credit mainly affects the industrial structure through enterprise capital and financing channels. China's overall green credit adjustment has had a significant upgrading effect on the industrial structure. The impact of green credit on industrial structure adjustment is different in the east, middle, and west regions. Optimizing the project capital structure, promoting seasonal financial transformation, setting up the function of innovation platform, and improving the internal governance structure of enterprises can improve financing efficiency and realize green and sustainable economic development in the future. The research results can provide a theoretical basis for the green development of China's financial market and the application of deep learning neural network algorithm under the background of Internet of things.",2022
Novel Resilient Model Risk Forecasts based on Neuro Volatility Models,"Recently, there has been a growing interest in using neuro volatility models in fuzzy forecasting and fuzzy option pricing. Neuro volatility models are used to model and predict financial market volatility by extending the neural network autoregressive (NNAR) model for nonlinear nonstationary times series data. In financial risk forecasting, various risk forecasting models for volatility are used to obtain the volatility forecasts, and the model risk ratio based on all the models is calculated to assess the stability of the financial system. However, the recently proposed neuro volatility models (based on neural networks such as LSTM, NNAR, etc.) are not used in evaluating the model risk. In this paper, novel 'neuro model risk forecasts' are obtained by including recently proposed neuro volatility models, and the resiliency of the financial system is studied. Unlike the existing model risk ratio forecasting based on linear volatility models, the driving idea is to use more appropriate nonlinear nonstationary neuro volatility forecasting models to obtain the model risk forecasts. The proposed model risk forecasts in this paper have been evaluated through extensive experiments, and it is shown that the model risk ratio can effectively serve as a metric for assessing the resilience and stability of the targeted financial system.",2024
Credit risk assessment in commercial banks based on multi-layer SVM classifier,"According to the analysis of credit risk assessment in commercial banks, a set of index system is established. The index system combines financial factors with non-financial factors for credit risk assessment. The credit rating is separated into five classes-normality, attention, sublevel, doubt and loss. To classify the credit risks of five classes, a multi-layer support vector machines (SVM) classifier is established to assess the credit risk. In order to verify the effectiveness of the method, a real case is given and BP neural network is also used to assess the same data. The experiment results show that multi-layer SVM classifier is effective in credit risk assessment and achieves better performance than BP neural network.",2006
Deep Learning in Model Risk Neutral Distribution for Option Pricing,"Option pricing has been studied extensively in recent years. An important issue in option pricing is the estimation of the risk neutral distribution of an underlying asset. Better estimation of this distribution can lead to a more rational investment, enabling one to earn an equal return with lower risk. To price options precisely and correctly, traditional financial engineering methods make some assumptions for the risk neutral distribution. However, some assumptions of traditional methods have proved inappropriate and insufficient in empirical option pricing analysis. To address these problems in option pricing, this study adopts a data-driven approach. Owing to advances in hardware and software, studies have been using deep learning methods to price options; however, these have not adequately considered the risk neutral distribution. This may cause an uncontrollable risk, thereby preventing the real-world application of the model. To overcome these problems, this study proposes a deep learning method with a mixture distribution model. Further, it generates a rational risk neutral distribution with accurate empirical pricing analysis.",2019
Predicting Corporate Financial Risk Using Artificial Bee Colony-Attention-Gated Recurrent Unit Model,"Corporate financial risk prediction is a critical task for ensuring the stability and success of businesses in today's dynamic economic landscape. However, existing models often fall short in accurately assessing and managing these risks. They often rely on historical financial data alone, which fails to account for sudden market fluctuations or unforeseen external events, leading to suboptimal risk assessments. Recognizing the paramount importance of time series analysis in financial risk prediction, we introduce a novel approach to the ABC-Attention-GRU combination model. This innovative model leverages the strengths of Artificial Bee Colony (ABC), the attention mechanism, and Gated Recurrent Unit (GRU) to enhance predictive accuracy and robustness. In our experiments, the ABCAttention-GRU model consistently outperformed state-of-the-art methods across various financial datasets. It effectively captured complex temporal dependencies, resulting in superior Precision, Recall, F1 Score, and AUC metrics.",2024
"Financial responsibility, financial context, and ambulatory blood pressure in early middle-aged African-American women","Background: African-American women have excess rates of elevated blood pressure (BP) and hypertension compared to women of all other racial/ethnic backgrounds. Several researchers have speculated that race and gender-related socioeconomic status (SES) stressors might play a role. Objective: To examine the association between a novel SES-related stressor highly salient among AfricanAmerican women, financial responsibility for one's household, and 48-h ambulatory BP. We further examined whether aspects related to African-American women's financial context (e.g., single parenthood, household income, marital status) played a role. Methods: Participants were N = 345 employed, healthy African-American women aged 30-46 from diverse SES backgrounds who underwent 48-h ambulatory BP monitoring. Linear regression analyses were conducted to examine associations between self-reported financial responsibility and daytime and nighttime BP, adjusting for age, SES and other sociodemographics, cardiovascular risk factors, financial strain and depressive symptoms. Interactions between financial responsibility and single parenthood, household income, and marital/partnered status were tested. Results: In age-adjusted analyses, reporting financial responsibility was associated with higher daytime systolic (beta = 4.42, S.E. = 1.36, p = 0.0013), and diastolic (beta = 2.82, S.E. = 0.98, p = 0.004) BP. Associations persisted in fully adjusted models. Significant associations were also observed for nighttime systolic and diastolic BP. There were no significant interactions with single parenthood, household income, nor marital/partnered status. Conclusion: Having primary responsibility for one's household may be an important driver of BP in early middleaged African-American women, independent of SES, financial strain, and across a range of financial contexts. Future studies examining prospective associations are needed, and policy interventions targeting structural factors contributing to financial responsibility in African-American women may be warranted.",2024
A Comparative Study of Financial Big Data Standard System Based on Deep Learning Algorithms,"The standard system of financial big data involves a wide range of contents and diversification. Financial institutions in the process of operation and social sectors constitute a huge interweaving network, precipitating a large number of data. In this context, data security is particularly important. Therefore, based on the deep learning algorithm, the author compares and studies the financial big data standard system. The in-depth learning model is introduced into the financial market and combined with the traditional statistical model to forecast the volatility of the financial market and calculate its risk value. Through the research and comparative analysis of the domestic and international financial big data standard norm system, it is found that part of the domestic financial big data standard specification is revised by reference, while the other part has the characteristics of Chinese financial market. However, there is still room for further development in terms of financial big data regulation, information security, financial enterprise big data platform construction and analytical capabilities.",2019
Prospects of Artificial Intelligence and Machine Learning Application in Banking Risk Management,"Artificial intelligence and machine learning have increasing influence on the financial sector, but also on economy as a whole. The impact of artificial intelligence and machine learning on banking risk management has become particularly interesting after the global financial crisis. The research focus is on artificial intelligence and machine learning potential for further banking risk management improvement. The paper seeks to explore the possibility for successful implementation yet taking into account challenges and problems which might occur as well as potential solutions. Artificial intelligence and machine learning have potential to support the mitigation measures for the contemporary global economic and financial challenges, including those caused by the COVID-19 crisis. The main focus in this paper is on credit risk management, but also on analysing artificial intelligence and machine learning application in other risk management areas. It is concluded that a measured and well-prepared further application of artificial intelligence, machine learning, deep learning and big data analytics can have further positive impact, especially on the following risk management areas: credit, market, liquidity, operational risk, and other related areas.",2021
Application of Big Data Unbalanced Classification Algorithm in Credit Risk Analysis of Insurance Companies,"The 2008 global financial crisis triggered by subprime mortgage crisis in the United States and the ongoing European debt crisis have urged governments and academics to pay high attention to financial industry risk supervision. The financial industry has actively implemented comprehensive risk management. As an important component of the financial industry, the insurance industry implements comprehensive risk management to control the risks of insurance companies. Propose an integrated learning model based on imbalanced dataset resampling and apply it to UCI dataset (University of California Irvine). First, resampling technology is used to preprocess the unbalanced dataset to obtain a relatively balanced training set. Then, use the classic backpropagation neural network, classic k-nearest neighbor, and classic Naive Bayes three algorithms as the base classifier and use the Bagging strategy to get the ensemble learning model. In order to verify its effectiveness, F-measure and G-mean methods are used to measure the performance of the classifier. The subject mainly focuses on the classification of relevance vector machine (RVM) in two types of large-scale datasets, imbalanced and balanced, and proposes solutions for these two types of data. This explains the effectiveness of the disequilibrium classification algorithm used in the risk analysis of insurance companies.",2022
A survey on uncertainty quantification in deep learning for financial time series prediction,"Investors make decisions about buying and selling a financial asset based on available information. The traditional approach in Deep Learning when trying to predict the behavior of an asset is to take a price history, train a model, and forecast one single price in the near future. This is called the frequentist perspective. Uncertainty Quantification is an alternative in which models manage a probability distribution for prediction. It provides investors with more information than the traditional frequentist way, so they can consider the risk of making or not making a certain decision. We systematically reviewed the existing literature on Uncertainty Quantification methods in Deep Learning to predict the behavior of financial assets, such as foreign exchange, stock market, cryptocurrencies and others. The article discusses types of model, categories of financial assets, prediction characteristics and types of uncertainty. We found that, in general terms, references focus on price accuracy as a metric, although other metrics, such as trend accuracy, might be more appropriate. Very few authors analyze both epistemic and aleatoric uncertainty, and none analyze in depth how to decouple them. The time period analyzed includes the years 2001 to 2022.",2024
Artificial Intelligence in Financial Risk Early Warning Systems: A Bibliometric and Thematic Analysis of Emerging Trends and Insights,"With the continuous development of financial markets worldwide, there has been increasing recognition of the importance of financial risk management. To mitigate financial risk, financial risk early warning serves as a risk uncovering mechanism enabling companies to anticipate and counter potential disruptions. The present review paper aims to identify the bibliometric analysis for exploring the growth and academic evolution of financial risk, financial risk management, and financial risk early warning concepts. Academic literature is surveyed from the Scopus database during the period 2010-2024. The network analysis, conceptual structure, and bibliographic analysis of the selected articles are employed using VOSviewer and Bibliometric R Package. The biblioshiny technique based on the bibliometric R package was used to draw journal papers' performance and scientific contributions by displaying distinctive features from the bibliometric method used in prior studies. The data was extracted from Scopus databases. In addition, this study comprehensively analyzes the evolution of financial risk early warning systems, highlighting significant trends and future directions. Thematic evaluation across 2010-2015, 2016-2021, and 2022-2024 reveals a shift from traditional statistical methods to advanced machine learning and AI techniques, with neural networks, random forests, and XGBoost being pivotal. Innovations like attention mechanisms and LSTM models improve prediction accuracy. The integration of sustainability factors, such as carbon neutrality and renewable energy, reflects a trend towards incorporating environmental considerations into risk management. The study underscores the need for interdisciplinary collaborations and advanced data analytics for comprehensive financial systems. Policy implications include promoting AI adoption, integrating environmental factors, fostering collaborations, and developing advanced data analytics frameworks.",2025
High-dimensional stochastic control models for newsvendor problems and deep learning resolution,"This paper studies continuous-time models for newsvendor problems with dynamic replenishment, financial hedging and Stackelberg competition. These factors are considered simultaneously and the high-dimensional stochastic control models are established. High-dimensional Hamilton-Jacobi-Bellman (HJB) equations are derived for the value functions. To circumvent the curse of dimensionality, a deep learning algorithm is proposed to solve the HJB equations. A projection is introduced in the algorithm to avoid the gradient explosion during the training phase. The deep learning algorithm is implemented for HJB equations derived from the newsvendor models with dimensions up to six. Numerical outcomes validate the algorithm's accuracy and demonstrate that the high-dimensional stochastic control models can successfully mitigate the risk.",2024
Comparative study on financial derivatives employed in the large international petroleum corporations' risk management,"Most international petroleum corporations have established fine risk management stem. They make risk management with financial derivatives, but there is great difference in the scale among them. Also, as a whole, most of them have conservative attitudes and use derivatives for hedging. Only a few firms speculate, such as BP. For the petroleum corporations that have not managed risk with financial derivatives, it is helpful to promote the ability of risk management if they employ some financial derivatives reasonably. But they have to control the conditions and scales to avoid extra risks.",2008
Contrastive Learning of Asset Embeddings from Financial Time Series,"Representation learning has emerged as a powerful paradigm for extracting valuable latent features from complex, high-dimensional data. In financial domains, learning informative representations for assets can be used for tasks like sector classification, and risk management. However, the complex and stochastic nature of financial markets poses unique challenges. We propose a novel contrastive learning framework to generate asset embeddings from financial time series data. Our approach leverages the similarity of asset returns over many subwindows to generate informative positive and negative samples, using a statistical sampling strategy based on hypothesis testing to address the noisy nature of financial data. We explore various contrastive loss functions that capture the relationships between assets in different ways to learn a discriminative representation space. Experiments on real-world datasets demonstrate the effectiveness of the learned asset embeddings on benchmark industry classification and portfolio optimization tasks. In each case our novel approaches significantly outperform existing baselines highlighting the potential for contrastive learning to capture meaningful and actionable relationships in financial data.",2024
Logistics Financial Risk Assessment Based on Hybrid Particle Swarm Optimization and Neural Network,"This article mainly introduces a set of perfect logistics financial evaluation system through particle swarm optimization and neural network, so as to avoid the internal and external various kinds of logistics enterprises in the process of logistics and financial services. Through the application of particle swarm optimization and neural network theory to establish the logistics financial risk evaluation model, using the structure form and training principle of BP particle swarm optimization and neural network, the survey data is the sample, and the network is fully trained and tested, thus the accurate risk assessment can be made to the logistics financial risk.",2018
Stock Volatility Forecast Base on Comparative Learning and Autoencoder Framework,"Volatility is an important indicator of derivatives pricing, financial risk measurement, and market panic sentiment measurement. A reasonable prediction of volatility is of great significance to market participants and regulators. This article proposes a new volatility forecast model. We use comparative learning and autoencoders to improve the accuracy and robustness of the model. Reduce the instability of financial data due to noise. And this article expands traditional machine learning research methods. The traditional model is compared with other deep learning models. Our model has made very competitive progress in accuracy and loss compared to other models.",2022
Early warning of systemic risk in stock market based on EEMD-LSTM,"With the increasing importance of the stock market, it is of great practical significance to accurately describe the systemic risk of the stock market and conduct more accurate early warning research on it. However, the existing research on the systemic risk of the stock market lacks multi-dimensional factors, and there is still room for improvement in the forecasting model. Therefore, to further measure the systemic risk profile of the Chinese stock market, establish a risk early warning system suitable for the Chinese stock market, and improve the risk management awareness of investors and regulators. This paper proposes a combination model of EEMD-LSTM, which can describe the complex nonlinear interaction. Firstly, 35 stock market systemic risk indicators are selected from the perspectives of macroeconomic operation, market cross-contagion and the stock market itself to build a comprehensive indicator system that conforms to the reality of China. Furthermore, based on TEI@I complex system methodology, an EEMD-LSTM model is proposed. The EEMD method is adopted to decompose the composite index sequence into intrinsic mode function components (IMF) of different scales and one trend term. Then the LSTM algorithm is used to predicted and model the decomposed sub-sequences. Finally, the forecast result of the composite index is obtained through integration. The empirical results show that the stock market systemic risk index constructed in this paper can effectively identify important risk events within the sample period. In addition, compared with the benchmark model, the EEMD-LSTM model constructed in this paper shows a stronger early warning ability for systemic financial risks in the stock market.",2024
Research on financial early warning of mining listed companies based on BP neural network model,"Mining industry is the basic industry of the national economy. However, in recent years, listed mining companies have suffered serious financial risks due to special reasons such as poor spot market liquidity of their products, strong policy dependence, and long investment payback periods. In the previous studies, most of the financial crisis prediction focused on the whole industry and manufacturing industry. The research on the financial risk of mining enterprises focuses more on how to adjust R&D activities, environmental performance to improve the financial performance of enterprises. There is still a lot of room for in-depth research on the systematic prevention and early warning of financial risks of listed mining companies. At the same time, in terms of research methods, many scholars used multivariate discriminant model, logistic regression model and support vector machine model. Compared with the Back-Propagation (BP) neural network model, these model methods have more or less defects. Therefore, we take mining listed companies as the research object, select the financial data of China's A-share mining listed companies in 2018, and construct the BP neural network financial early warning model, trying to provide more practical means for the financial risk early warning of mining companies. The research conclusions of this paper are as follows: (1) The BP neural network financial early warning model constructed in this paper has high prediction accuracy, which can be well used in the practice of financial early warning of mining listed companies; (2) The financial situation of China's A-share mining listed companies in 2018 is generally in a good state. The companies with good financial status can effectively control the cost and have good debt paying ability while earning income; (3) For companies with financial status that require early warning, the root cause is mainly that they do not pay attention to the risk of bad debt losses, which makes current credit sales income and accounts receivable are at high levels, and they also do not have good profitability.",2021
Application of Artificial Neural Network in Corporate Financial Risk Early-Warning,"The traditional financial risk warning model are all based on probability theory and statistical analysis, but the precisions of the results are usually not satisfied in practice. This paper studies the application of artificial neural network in corporate financial risk early-warning. It designs an early warning model of financial risk based on BP neural network. And then selects financial data from 30 enterprises as samples to train and test the network. The result indicates that the risk early warning model is very effective. It can solve some problems of the traditional early warning methods such as difficult to deal with highly non-linear and lack of adaptive capacity.",2013
The stressors of being young and Black: Cardiovascular health and Black young adults,"Objective: To examine the impact of stressors relevant to the lives of Black young adults including racial, financial, occupational, and general stress and psychological distress on cardiovascular disease (CVD) risk. Specifically, this study examined the relationship between multiple psychosocial stressors and two CVD risk indicators (i.e. obesity and blood pressure). Design: This study used a quantitative design which included surveys, the collection of anthropometric and blood pressure (BP) measures. Participants were 124 Black college students aged 18 to 27 years old. Main Outcome Measures: Participants completed measures to assess psychological distress, general, occupational, financial and racial stress. Measures of body mass index (BMI), waist-to-hip ratio (WHR) and BP were collected to assess CVD risk. Results: Findings indicated a significant effect of internalised racism on BMI and a significant effect of individual racial stress on diastolic BP. Also, depression was significantly associated with systolic BP. There were no significant results for WHR. Conclusion: Findings suggested that the relationship among racial stress, psychological distress and CVD be further explored.",2016
Household financial health: a machine learning approach for data-driven diagnosis and prescription,"Household finances are being threatened by unprecedented social and economic upheavals, including an aging society and slow economic growth. Numerous researchers and practitioners have provided guidelines for improving the financial status of households; however, the challenge of handling heterogeneous households remains nontrivial. In this study, we propose a new data-driven framework for the financial health of households to address the needs for diagnosing and improving financial health. This research extends the concept of healthcare to household finance. We develop a novel deep learning-based diagnostic model for estimating household financial health risk scores from real-world household balance sheet data. The proposed model can successfully manage the heterogeneity of households by extracting useful latent representations of household balance sheet data while incorporating the risk information of each variable. That is, we guide the model to generate higher latent values for households with risky balance sheets. We also show that the gradient of the model can be utilized for prescribing recommendations for improving household financial health. The robustness and validity of the new framework are demonstrated using empirical analyses.",2023
Convolutional LSTM Network for forecasting correlations between stocks based on spatiotemporal sequence,"The correlation between stocks is important for investment portfolio pricing and evaluation, risk management, and formulating trading and hedging strategies. The COVID-19 has led to a general increase in the degree of correlation between stocks, the market-wide allocation has lost its meaning, and the hedging strategy has failed. It is more necessary and urgent to predict the correlation between stocks under the influence of the epidemic. However, previous studies mostly focused on traditional financial models. There are problems such as too many assumptions and restrictions, the dimensional disaster of the estimated parameters, and the poor effect of fitting nonlinearity and tail risk, which cannot provide reliable and accurate estimates. In this paper, the covariance matrix for stock return is considered as a sequence with both time and space characteristics, to transform the problem into the study of spatiotemporal sequence prediction. We Innovatively apply the end-to-end Convolutional LSTM (ConvLSTM) to the correlation prediction between stocks and use random matrix theory (RMT) to improve mean squared error (MSE) to eliminate the influence of noise. Experiments show that the performance of ConvLSTM on this problem is better than that of traditional financial model, especially after de-nosing by Random Matrix Theory (RMT). Compared with Fully Connected LSTM (FC-LSTM), ConvLSTM acquired a better out-of-sample MSE and RMT_MSE, which proves the effectiveness of the method. Finally, we repeat experiments with other stock dataset to verify the robustness of the model.",2021
Predicting macro-financial instability-How relevant is sentiment? Evidence from long short-term memory networks,"This paper examines the relevance of sentiment in predicting overall financial system instability using long-run short-term memory networks. Weekly data on the US financial system, consumer sentiment, producer sentiment, and investor sentiment is collected from 21 January 1994 to 27 December 2019, and different models are developed to predict the one-week-ahead levels of financial stress in the US financial system. We find that models using sentiment indices outper-form those relying solely on historical financial stress and risk data. This result is robust to comparisons with an alternative deep learning method and out-of-sample predictions. It consti-tutes an argument in favor of behavioral finance and Minsky's (Knell, 2015) financial instability hypothesis against the Efficient Market Hypothesis. As it concretely identifies the main indicators for predicting US financial stress one week in advance, the study provides relevant recommen-dations for policymakers and investors in terms of macroprudential policies and portfolio management.",2023
The credit risk assessment of P2P lending based on BP neural network,"P2P lending is a new type of financial model under current Internet financial circumstance. The evaluation of P2P Internet loan has tremendous meaning since its credit risk is the leading factor of Internet finance stability. According to the characteristics of P2P loan, BP neural network model was introduced to evaluate the risk of credits quantitatively. We build an empirical model with the lending club data. Given the experimental result, P2P Internet loan credit risks are primarily determined by several key attributes. In addition, BP neural network method offers an evaluation result with 78.6% accuracy rate (type one falsification rate 4.8% while type two falsification rate 16.6% respectively), which indicates that risk evaluation method has a predominant performance.",2015
Association of frailty with outcomes of resection for colonic volvulus: A national analysis,"Background With limited national studies available, we characterized the association of frailty with outcomes of surgical resection for colonic volvulus. Methods Adults with sigmoid or cecal volvulus undergoing non-elective colectomy were identified in the 2010-2019 Nationwide Readmissions Database. Frailty was identified using the Johns Hopkins indicator which utilizes administrative codes. Multivariable models were developed to examine the association of frailty with in-hospital mortality, perioperative complications, stoma use, length of stay, hospitalization costs, non-home discharge, and 30-day non-elective readmissions. Results An estimated 66,767 patients underwent resection for colonic volvulus (Sigmoid: 39.6%; Cecal: 60.4%). Using the Johns Hopkins indicator, 30.3% of patients with sigmoid volvulus and 15.9% of those with cecal volvulus were considered frail. After adjustment, frail patients had higher risk of mortality compared to non-frail in both sigmoid (10.6% [95% CI 9.47-11.7] vs 5.7% [95% CI 5.2-6.2]) and cecal (10.4% [95% CI 9.2-11.6] vs 3.5% [95% CI 3.2-3.8]) volvulus cohorts. Frailty was associated with greater odds of acute venous thromboembolism occurrences (Sigmoid: AOR 1.50 [95% CI 1.18-1.94]; Cecal: AOR 2.0 [95% CI 1.50-2.72]), colostomy formation (Sigmoid: AOR 1.73 [95% CI 1.57-1.91]; Cecal: AOR 1.48 [95% CI 1.10-2.00]), non-home discharge (Sigmoid: AOR 1.97 [95% CI 1.77-2.20]; Cecal: AOR 2.56 [95% CI 2.27-2.89]), and 30-day readmission (Sigmoid: AOR 1.15 [95% CI 1.01-1.30]; Cecal: AOR 1.26 [95% CI 1.10-1.45]). Frailty was associated with incremental increase in length of stay (Sigmoid: +3.4 days [95% CI 2.8-3.9]; Cecal: +3.8 days [95% CI 3.3-4.4]) and costs (Sigmoid: +$7.5k [95% CI 5.9-9.1]; Cecal: +$12.1k [95% CI 10.1-14.1]). Conclusion Frailty, measured using a simplified administrative tool, is associated with significantly worse clinical and financial outcomes following non-elective resections for colonic volvulus. Standard assessment of frailty may aid risk-stratification, better inform shared-decision making, and guide healthcare teams in targeted resource allocation in this vulnerable patient population.",2022
BACKPROPAGATION NEURAL SCHEME FOR ESTIMATING THE RISK OF BANKRUPTCY OF THE ROMANIAN INSURANCE AND REINSURANCE COMPANIES,This work contains a new model for estimating the risk of bankruptcy of the Romanian insurance and reinsurance companies. The model is developed based on the neural architecture of type backpropagation with input dates represented by the values of indicators from the financial statements of insurances and reinsurances companies. The memory vector of the architecture neuronal will provide useful information about the risk of bankruptcy for the next years compared to the period referenced for insurance companies used to training the algorithm proposed. In the last part of the paper is performed the testing capacity for estimate the risk of bankruptcy for all insurance companies by applying neural function determined by our algorithm and establishing a synthetic report on risk levels associated with each company.,2016
Price spread prediction in high-frequency pairs trading using deep learning architectures,"High-Frequency Trading (HFT) leverages advanced algorithms and high-speed data transmission to execute a large volume of trades within extremely short timeframes and generate profit. However, predicting stock prices in this context is challenging due to the frequent fluctuations in bid and ask conditions within financial markets. Institutional investors often employ pairs trading strategies to mitigate the systemic risk associated with single products, simultaneously buying and selling highly correlated financial instruments to profit from fluctuations in abnormal price spreads. In this study, we utilized intraday continuous trading data from the Taiwan Stock Exchange, integrating commonly used stock market features relevant to HFT. By employing XGBoost for feature selection and combining it with deep learning models, we aimed to predict the relationship between price spreads and boundaries in pairs trading, thereby generating entry and exit signals. Although accurately predicting the relationship between price spreads and boundaries presents significant challenges, the model effectively learned the pattern of price spread changes. Applying the model's entry and exit signals in pairs trading demonstrated that this strategy can enhance win rates and achieve stable profits in the volatile intraday market environment. This research provides practical implications for those interested in high-frequency trading and deep learning models in the financial market, equipping them with valuable knowledge and insights.",2024
Multi-future Merchant Transaction Prediction,"The multivariate time series generated from merchant transaction history can provide critical insights for payment processing companies. The capability of predicting merchants' future is crucial for fraud detection and recommendation systems. Conventionally, this problem is formulated to predict one multivariate time series under the multi-horizon setting. However, real-world applications often require more than one future trend prediction considering the uncertainties, where more than one multivariate time series needs to be predicted. This problem is called multi-future prediction. In this work, we combine the two research directions and propose to study this new problem: multi-future, multi-horizon and multivariate time series prediction. This problem is crucial as it has broad use cases in the financial industry to reduce the risk while improving user experience by providing alternative futures. This problem is also challenging as now we not only need to capture the patterns and insights from the past but also train a model that has a strong inference capability to project multiple possible outcomes. To solve this problem, we propose a new model using convolutional neural networks and a simple yet effective encoder-decoder structure to learn the time series pattern from multiple perspectives. We use experiments on real-world merchant transaction data to demonstrate the effectiveness of our proposed model. We also provide extensive discussions on different model design choices in our experimental section.",2021
Fraud Detection Based on Credit Review Texts with Dual Channel Memory Networks,"With the rapid development of the automotive finance market in China, fraudulent behaviors present new characteristics such as intellectualization and high concealment. Graph neural networks and memory networks have strong capabilities for processing the textual data containing massive complex associations, providing a new perspective for fraud detection. During the operation of an automotive finance company, a large amount of credit review texts with recording the customers' multidimensional data are accumulated. These texts contain information that is helpful for risk management, but have not been well explored. In order to effectively identify fraud risks, we propose a fraud detection method based on credit review texts with dual-channel memory network, which combines graph and text memory networks. By utilizing pre-trained language models, the text data for credit review text is encoded into semantic vectors. The graph memory network module and the text memory network module are then employed to extract graph features and text features corresponding to the credit review text. Finally, the generated results from the three modules are fused and input into a classification network to obtain the final determination of financial fraud risk. Comparative experiments with baseline models demonstrate the validity of our model in fraud detection.",2024
Reducing dropout rate through a deep learning model for sustainable education: long-term tracking of learning outcomes of an undergraduate cohort from 2018 to 2021,"In recent years, initiatives and the resulting application of precision education have been applied with increasing frequency in Taiwan; the accompanying discourse has focused on identifying potential applications for artificial intelligence and how to use learning analytics to improve teaching quality and learning outcomes. This study used the established dropout risk prediction model to improve student learning effectiveness. The model was based on the academic portfolios of past students and built with statistical learning and deep learning methods. This study used this model to predict the dropout risk of 2205 freshmen enrolled in the fall semester of 2018 (graduated in June 2022) in the field of sustainable education. A total of 176 students with a dropout risk of more than 20% were considered high-risk students. After tracking and the appropriate guidance, the dropout risk of 91 students fell from > 20% to < 20%. To discuss the results from the perspective of gender and financial disadvantages, the improvement rate of the dropout risk for male students was 10.2% better than that of female students at 2.9%. The improvement rate in dropout risk for students with disadvantageous financial situations was as high as 12.0%, surpassing the 5.9% rate among general students. Overall, the dropout rate in the second year of the 2018 freshman cohort was lower than that of the 2016 and 2017 freshman cohorts. A predictive model established by statistical learning and deep learning methods was used as a tool to promote precision education, accurately and efficiently identifying students who are having difficulty learning, as well as leading to a better understanding of AI (artificial intelligence) in smart learning for sustainable education.",2023
GLOBAL PATTERNS AND EXTREME EVENTS IN SOVEREIGN RISK PREMIA: A FUZZY VS DEEP LEARNING COMPARATIVE,"Investment in foreign countries has become more common nowadays and this implies that there may be risks inherent to these investments, being the sovereign risk premium the measure of such risk. Many studies have examined the behaviour of the sovereign risk premium, nevertheless, there are limitations to the current models and the literature calls for further investigation of the issue as behavioural factors are necessary to analyse the investor's risk perception. In addition, the methodology widely used in previous research is the regression model, and the literature shows it as scarce yet. This study provides a model for a new of the drivers of the government risk premia in developing countries and developed countries, comparing Fuzzy methods such as Fuzzy Decision Trees, Fuzzy Rough Nearest Neighbour, Neuro-Fuzzy Approach, with Deep Learning procedures such as Deep Recurrent Convolution Neural Network, Deep Neural Decision Trees, Deep Learning Linear Support Vector Machines. Our models have a large effect on the suitability of macroeconomic policy in the face of foreign investment risks by delivering instruments that contribute to bringing about financial stability at the global level.",2024
Optimized polycystic ovarian disease prognosis and classification using AI based computational approaches on multi-modality data,"Polycystic Ovarian Disease or Polycystic Ovary Syndrome (PCOS) is becoming increasingly communal among women, owing to poor lifestyle choices. According to the research conducted by National Institutes of Health, it has been observe that PCOS, an endocrine condition common in women of childbearing age, has become a significant contributing factor to infertility. Ovarian abnormalities brought on by PCOS carry a high risk of miscarriage, infertility, cardiac problems, diabetes, uterine cancer, etc. Ovarian cysts, obesity, menstrual irregularities, elevated amounts of male hormones, acne vulgaris, hair loss, and hirsutism are some of the symptoms of PCOS. It is not easy to determine PCOS because of its different combinations of symptoms in different women and various criteria needed for diagnosis. Taking biochemical tests and ovary scanning is a time-consuming process and the financial expenses have become a hardship to the patients. Thus, early prognosis of PCOS is crucial to avoid infertility. The goal of the proposed work is to analyse PCOS symptoms based on clinical data for early diagnosis and to classify into PCOS affected or not. To achieve this objective, clinical features dataset and ultrasound imaging dataset from Kaggle is utilized. Initially 541 instances of 45 clinical features such as testosterone, hirsutism, family history, BMI, fast food, menstrual disorder, risk etc. are considered and correlation-based feature extraction method is applied to this dataset which results in 17 features. The extracted features are applied to various machine learning algorithms such as Logistic Regression, Na & iuml;ve Bayes and Support Vector Machine. The performance of each method is evaluated based on accuracy, precision, recall, F1-score and the result shows that among three models, Support Vector Machine model achieved high accuracy of 94.44%. In addition to this, 3856 ultrasound images are analysed by CNN based deep learning algorithm and VGG16 transfer learning algorithm. The performance of these models is evaluated using training accuracy, loss and validation accuracy, loss and the result depicts that VGG16 outperforms than CNN model with validation accuracy of 98.29%.",2024
Heteroscedastic ensemble deep random vector functional link neural network with multiple output layers for High Frequency Volatility Forecasting and Risk Assessment,"Accurate volatility forecasting is crucial for the efficient management of financial systems. However, the dynamic nature and significant variability in financial time series data pose substantial challenges to achieving these forecasts. The paper introduces a novel Heteroscedastic ensemble deep random vector functional link (HedRVFL) network with multiple output layers for high frequency volatility forecasting and risk assessment. The hidden layers of the model are hierarchical and stacked for deep representation learning to extract complex patterns within the data. The neuron pruning strategy is utilized to eliminate noisy information from random features, thereby improving the network's performance. The forecast is generated by combining the outputs of each layer through an ensemble method. A comparative analysis was conducted against several existing forecasting methods, utilizing error metrics and statistical tests on sixteen high frequency cryptocurrency time-series datasets, demonstrating that the proposed model outperforms others in terms of forecasting accuracy and risk assessment.",2025
High frequency volatility forecasting and risk assessment using neural networks-based heteroscedasticity model,"High frequency volatility forecasting is essential for timely risk management and informed decision-making in dynamic financial markets. However, accurate forecasting is challenging due to the rapid nature of market movements and the complexity of underlying economic factors. This paper introduces a novel architecture combining Generalized Autoregressive Conditional Heteroscedasticity (GARCH) and Multi-layer Perceptron (MLP)-based models for enhanced volatility forecasting and risk assessment, where input variables are processed through GARCH-type models for volatility forecasting. The proposed GARCH-based MLP-Mixer (GaMM) model incorporates the stacking of multi-layer perceptrons, enabling deep representation learning, facilitating the extraction of temporal and feature information through operations along both time and feature dimensions, and addressing the complexity of high-frequency time-series data. The proposed model is evaluated on three high frequency financial times series datasets over three different years. The computational results demonstrate the proposed model's superior performance over sixteen forecasting methods in three error metrics, Value-at-risk, and statistical tests for high frequency volatility forecasting and risk assessment tasks.",2025
Design of intelligent financial data management system based on higher-order hybrid clustering algorithm,"Amid the ever-expanding landscape of financial data, the importance of predicting potential risks through artificial intelligence methodologies has steadily risen. To achieve prudent financial data management, this manuscript delves into the domain of intelligent financial risk forecasting within the scope of system design. It presents a data model based on the variational encoder (VAE) enhanced with an attention mechanism meticulously tailored for forecasting a company's financial peril. The framework called the ATT-VAE embarks on its journey by encoding and enhancing multidimensional data through VAE. It then employs the attention mechanism to enrich the outputs of the VAE network, thereby demonstrating the apex of the model's clustering capabilities. In the experimentation, we implemented the model to a battery of training tests using diverse public datasets with multimodal features like AWA and CUB and verified with the local finance dataset. The results conspicuously highlight the model's commendable performance in comparison to publicly available datasets, surpassing numerous deep clustering networks at this juncture. In the realm of financial data, the ATT-VAE model, as presented within this treatise, achieves a clustering accuracy index exceeding 0.7, a feat demonstrably superior to its counterparts in the realm of deep clustering networks. The method outlined herein provides algorithmic foundations and serves as a pivotal reference for the prospective domain of intelligent financial data governance and scrutiny.",2024
MACROECONOMICS FRAMEWORK CONSIDERED RISK FACTORS: BASED ON DEFAULT DISTANCE,"This paper adopts the macro-financial engineering method, taking risk factors into account to build a new framework for macroeconomic research in the IS-LM-BP model. Based on the balance of commodity markets, currency markets and the international balance of payments, the framework studies the balance of the level of risk, and analyzes a series of changes of the BP curve under given risk factors. Meanwhile, this paper also conducts empirical study using Chinese data from years 2007-2010.",2013
Bank distress in the news: Describing events through deep learning,"While many models are purposed for detecting the occurrence of significant events in financial systems, the task of providing qualitative detail on the developments is not usually as well automated. We present a deep learning approach for detecting relevant discussion in text and extracting natural language descriptions of events. Supervised by only a. small set of event information, comprising entity names and dates, the model is leveraged by unsupervised learning of semantic vector representations on extensive text data. We demonstrate applicability to the study of financial risk based on news (6.6M articles), particularly bank distress and government interventions (243 events), where indices can signal the level of bank-stress-related reporting at the entity level, or aggregated at national or European level, while being coupled with explanations. Thus, we exemplify how text, as timely, widely available and descriptive data, can serve as a useful complementary source of information for financial and systemic risk analytics. (C) 2017 Elsevier B.V. All rights reserved.",2017
An Equilibrium Model of Macro Financial Risk Alert and Measurement,"An equilibrium model of macro-financial system is crucial to the stability of the wholly country and society, and an effective financial risk alert system is important for macro-economic policy formulation as it can detect and predict financial crisis. This paper designs an integrated equilibrium model through three aspects: choosing risk alert indicators on previous literatures, judging financial risk ranks by factor analysis and history data, applying BP neural network to design an equilibrium model and form an prediction of financial crisis in 2010, and the predication shows that the total macro-financial is running safely, but there are some insecure facts which still exist in the macro-economic sub-system and external financial sub-system. The research in this paper is very significant to our country and can provide certain reference for the investigation in the future.",2015
A multi-stage integrated model based on deep neural network for credit risk assessment with unbalanced data,"PurposeWith the rapid growth of the domestic lending industry, assessing whether the borrower of each loan is at risk of default is a pressing issue for financial institutions. Although there are some models that can handle such problems well, there are still some shortcomings in some aspects. The purpose of this paper is to improve the accuracy of credit assessment models.Design/methodology/approachIn this paper, three different stages are used to improve the classification performance of LSTM, so that financial institutions can more accurately identify borrowers at risk of default. The first approach is to use the K-Means-SMOTE algorithm to eliminate the imbalance within the class. In the second step, ResNet is used for feature extraction, and then two-layer LSTM is used for learning to strengthen the ability of neural networks to mine and utilize deep information. Finally, the model performance is improved by using the IDWPSO algorithm for optimization when debugging the neural network.FindingsOn two unbalanced datasets (category ratios of 700:1 and 3:1 respectively), the multi-stage improved model was compared with ten other models using accuracy, precision, specificity, recall, G-measure, F-measure and the nonparametric Wilcoxon test. It was demonstrated that the multi-stage improved model showed a more significant advantage in evaluating the imbalanced credit dataset.Originality/valueIn this paper, the parameters of the ResNet-LSTM hybrid neural network, which can fully mine and utilize the deep information, are tuned by an innovative intelligent optimization algorithm to strengthen the classification performance of the model.",2024
Integrated prediction of green bond return under the dual risks of climate change and energy crisis,"Prediction of bond return is a classic problem in financial area, providing an important basis for portfolio construction and risk management. The sustainable investment attribute of green bonds has been favored by investors, so that green bonds have become an important component for major asset allocation. However, due to the specific investment focus of green bonds, investors' return expectations are influenced not only by traditional corporate bond factors, but also by related factors such as climate change and energy transition. Against the backdrop of increasingly severe climate risks and the global energy crisis, this paper analyses the volatility characteristics of China's green bonds at multiple time scales, and introduces exogenous variables such as returns of the alternative financial assets, climate risks and returns of energy markets for prediction. Based on the LSTM model, the volatility of green bond yield at different time scales is separately predicted using optimal exogenous variable before integration. It is found that the new integrated prediction model can significantly improve the forecasting performance compared to traditional single LSTM models and simple decomposition-integrated models. Further, both climate risks and energy markets variables have a significant improvement effect on predicting green bond in low-frequency item, while energy markets variables also have a better predictive effect on trend items. Building on the use of only LSTM model, it could be further enhanced by integrating more algorithms to select the best single model for each component, further improve the prediction accuracy and provide a more effective quantitative tool for investment decision-making and risk management in related fields.",2023
Heavy metals prediction system in groundwater using online sensor and machine learning for water management: the case of typical industrial parK,"With the expansion of human industrial activities, heavy metal contamination in groundwater environments has become increasingly severe. Environmental management agencies invest significant financial resources into groundwater monitoring, primarily due to its inherent invisibility. Automatic monitoring is a new way to monitor groundwater, the existing sensors often can only achieve simple indicators, and it is difficult to achieve complex indicators such as heavy metals. This study integrated pH and conductivity online monitoring probes with machine learning algorithms to develop a real-time, automated heavy metal prediction system for groundwater. The predictive performance demonstrated that the highest R-2 values for chromium (Cr), nickel (Ni), and copper (Cu) were 0.73, 0.78, and 0.87, respectively, with mean absolute errors of 11.9, 0.83, and 1.02 mu g/L. While random forest and extreme gradient boosting (XGB) models demonstrate greater robustness. To enhance the practicality and management significance of the prediction system, interval prediction is employed. Uncertainty assessment results indicate that the performance order of prediction intervals across different models is XGB > Random Forest > Multiple Linear Regression (MLR) > Backpropagation neural network (BP). We proposed that Groundwater risk is acceptable when the prediction interval of pollutants falls below regional screening levels. The integration of automated sensors with machine learning algorithms can offer advanced recommendations for long-term environmental monitoring.",2025
TRACER: A Framework for Facilitating Accurate and Interpretable Analytics for High Stakes Applications,"In high stakes applications such as healthcare and finance analytics, the interpretability of predictive models is required and necessary for domain practitioners to trust the predictions. Traditional machine learning models, e.g., logistic regression (LR), are easy to interpret in nature. However, many of these models aggregate time-series data without considering the temporal correlations and variations. Therefore, their performance cannot match up to recurrent neural network (RNN) based models, which are nonetheless difficult to interpret. In this paper, we propose a general framework TRACER to facilitate accurate and interpretable predictions, with a novel model TITV devised for healthcare analytics and other high stakes applications such as financial investment and risk management. Different from LR and other existing RNN-based models, TITV is designed to capture both the time-invariant and the time-variant feature importance using a feature-wise transformation subnetwork and a self-attention subnetwork, for the feature influence shared over the entire time series and the time-related importance respectively. Healthcare analytics is adopted as a driving use case, and we note that the proposed TRACER is also applicable to other domains, e.g., fintech. We evaluate the accuracy of TRACER extensively in two real-world hospital datasets, and our doctors/clinicians further validate the interpretability of TRACER in both the patient level and the feature level. Besides, TRACER is also validated in a critical financial application. The experimental results confirm that TRACER facilitates both accurate and interpretable analytics for high stakes applications.",2020
Temporal Implicit Multimodal Networks for Investment and Risk Management,"Many deep learning works on financial time-series forecasting focus on predicting future prices/returns of individual assets with numerical price-related information for trading, and hence propose models designed for univariate, single-task, and/or unimodal settings. Forecasting for investment and risk management involves multiple tasks in multivariate settings: forecasts of expected returns and risks of assets in portfolios, and correlations between these assets. As different sources/types of time-series influence future returns, risks, and correlations of assets in different ways, it is also important to capture time-series from different modalities. Hence, this article addresses financial time-series forecasting for investment and risk management in a multivariate, multitask, and multimodal setting. Financial time-series forecasting, however, is challenging due to the low signal-to-noise ratios typical in financial time-series, and as intra-series and inter-series relationships of assets evolve across time. To address these challenges, our proposed Temporal Implicit Multimodal Network (TIME) model learns implicit inter-series relationship networks between assets from multimodal financial time-series at multiple time-steps adaptively. TIME then uses dynamic network and temporal encoding modules to jointly capture such evolving relationships, multimodal financial time-series, and temporal representations. Our experiments show that TIME outperforms other state-of-the-art models on multiple forecasting tasks and investment and risk management applications.",2024
Uncertainty Modelling in Deep Networks: Forecasting Short and Noisy Series,"Deep Learning is a consolidated, state-of-the-art Machine Learning tool to fit a function y = f(x) when provided with large data sets of examples {(x(i), y(i))}. However, in regression tasks, the straight-forward application of Deep Learning models provides a point estimate of the target. In addition, the model does not take into account the uncertainty of a prediction. This represents a great limitation for tasks where communicating an erroneous prediction carries a risk. In this paper we tackle a real-world problem of forecasting impending financial expenses and incomings of customers, while displaying predictable monetary amounts on a mobile app. In this context, we investigate if we would obtain an advantage by applying Deep Learning models with a Heteroscedastic model of the variance of a network's output. Experimentally, we achieve a higher accuracy than non-trivial baselines. More importantly, we introduce a mechanism to discard low-confidence predictions, which means that they will not be visible to users. This should help enhance the user experience of our product.",2019
Evaluate the sustainable reuse strategy of the corporate financial management based on the big data model,"Purpose The purposes are to explore corporate financial management optimization in the context of big data and provide a sustainable financial strategy for corporate development. Design/methodology/approach First, the shortcomings of the traditional financial management model are analyzed under the background of big data analysis. The big data analytic technology is employed to extract financial big data information and establish an efficient corporate financial management model. Second, the deep learning (DL) algorithm is applied to implement a corporate financial early-warning model to predict the potential risks in corporate finance, considering the predictability of corporate financial risks. Finally, a corporate value-centered development strategy based on sustainable growth is proposed for long-term development. Findings The experimental results demonstrate that the financial early-warning model based on DL has an accuracy of 90.7 and 88.9% for the two-year financial alert, which is far superior to the prediction effect of the traditional financial risk prediction models. Originality/value The obtained results can provide a reference for establishing a sustainable development pattern of corporate financial management under the background of big data.",2022
ModAugNet: A new forecasting framework for stock market index value with an overfitting prevention LSTM module and a prediction LSTM module,"Forecasting a financial asset's price is important as one can lower the risk of investment decision- making with accurate forecasts. Recently, the deep neural network is popularly applied in this area of research; however, it is prone to overfitting owing to limited availability of data points for training. We propose a novel data augmentation approach for stock market index forecasting through our ModAugNet framework, which consists of two modules: an overfitting prevention LSTM module and a prediction LSTM module. The performance of the proposed model is evaluated using two different representative stock market data (S&P500 and Korea Composite Stock Price Index 200 (KOSPI200)). The results confirm the excellent forecasting accuracy of the proposed model. ModAugNet-c yields a lower test error than the comparative model (SingleNet) in which an overfitting prevention LSTM module is absent. The test mean squared error (MSE), mean absolute percentage error (MAPE), and mean absolute error (MAE) for S&P500 decreased to 54.1%, 35.5%, and 32.7%, respectively, of the corresponding S&P500 forecasting errors of SingleNet, while the same for KOSPI200 decreased to 48%, 23.9%, and 32.7%, respectively, of the corresponding KOSPI200 forecasting errors of SingleNet. Furthermore, through the analyses of the trained ModAugNet-c, we found that test performance is entirely dependent on the prediction LSTM module. The contribution of this study is its applicability in various instances where it is challenging to artificially augment data, such as medical data analysis and financial time-series modeling. (C) 2018 Elsevier Ltd. All rights reserved.",2018
Multi-task Envisioning Transformer-based Autoencoder for Corporate Credit Rating Migration Early Prediction,"Corporate credit ratings issued by third-party rating agencies are quantified assessments of a company's creditworthiness. Credit Ratings highly correlate to the likelihood of a company defaulting on its debt obligations. These ratings play critical roles in investment decision-making as one of the key risk factors. They are also central to the regulatory framework such as BASEL II in calculating necessary capital for financial institutions. Being able to predict rating changes will greatly benefit both investors and regulators alike. In this paper, we consider the corporate credit rating migration early prediction problem, which predicts the credit rating of an issuer will be upgraded, unchanged, or downgraded after 12 months based on its latest financial reporting information at the time. We investigate the effectiveness of different standard machine learning algorithms and conclude these models deliver inferior performance. As part of our contribution, we propose a new Multi-task Envisioning Transformer-based Autoencoder (META) model to tackle this challenging problem. META consists of Positional Encoding, Transformer-based Autoencoder, and Multi-task Prediction to learn effective representations for both migration prediction and rating prediction. This enables META to better explore the historical data in the training stage for one-year later prediction. Experimental results show that META outperforms all baseline models.",2022
Bundled Payment vs. Fee-for-Service: Impact of Payment Scheme on Performance,"Healthcare reimbursements in the United States have been traditionally based on a fee-for-service (FFS) scheme, providing incentives for high volume of care, rather than efficient care. The new healthcare legislation tests new payment models that remove such incentives, such as the bundled payment (BP) system. We consider a population of patients (beneficiaries). The provider may reject patients based on the patient's cost profile and selects the treatment intensity based on a risk-averse utility function. Treatment may result in success or failure, where failure means that unforeseen complications require further care. Our interest is in analyzing the effect of different payment schemes on outcomes such as the presence and extent of patient selection, the treatment intensity, the provider's utility and financial risk, and the total system payoff. Our results confirm that FFS provides incentives for excessive treatment intensity and results in suboptimal system payoff. We show that BP could lead to suboptimal patient selection and treatment levels that may be lower or higher than desirable for the system, with a high level of financial risk for the provider. We also find that the performance of BP is extremely sensitive to the bundled payment value and to the provider's risk aversion. The performance of both BP and FFS degrades when the provider becomes more risk averse. We design two payment systems, hybrid payment and stop-loss mechanisms, that alleviate the shortcomings of FFS and BP and may induce system optimum decisions in a complementary manner.",2017
Chinese Value Investing Theory and Quantitative Technology,"After nearly three decades of a hard journey, China's capital market has more and more clearly demonstrated the right value of value investing. A-share market participants - retail investors and institutions - are in urgent need of a value investing theory in line with China's national conditions. We realize that China's value investing system must be the joint value investing of China and the world. This paper proposes a value investing theory and quantitative realizing technology system with China as the main body and taking both China and the world conditions into account. The main contents include: 1) under the framework of big data, using the credit risk analysis for filtering out stocks with mediocre or poor credit; 2) multi-factor models of quantitative investment for selection of value and growth stocks; 3) deep learning financial market prediction model for capturing dynamic margin of safety and profit opportunities; 4) deep intelligent portfolio trading technology for implementing value investing into super intelligent systems of quantitative investment. The characteristics and innovations of the theory are: expanding the big data holographic credit risk analysis for Chinese enterprises to value investing analysis; developing comprehensive multi-factor models for selecting value and growth stocks into portfolios; developing big data-driven deep learning financial market prediction models; innovating and developing deep intelligent trading strategies and systems.",2021
A New Model of Enterprise Credit Risk Assessment Based on BP Neural Network,"Enterprise credit risk assessment is a very important problem in the financial field. Its deficiency was revealed because of singly using BP neural network. In this paper, a new assessment model is proposed which is based on an optimized BP Neural Network. In this model, first, dimensions of data were reduced by principal component analysis (PCA); second, Quantum-behaved particle swarm optimization (QPSO) was used for optimizing parameters of BP neural network. The experiment results show that the new model reduces the training time and has a very small error; it can satisfy the demand of credit risk assessment of enterprise.",2008
Credit Scoring to Classify Consumer Loan Using Machine Learning,"Credit risk is a potential loss caused by the inability of the debtor to the obligations of debt repayment of either principal or interest debt or both. The classification of credit risk in the financial sector has an essential role in mapping the consumer risk. The wrong classification raises chain effects such as the emergence of bad credit, disruption of financial stability, which lead to banking losses. Classification in credit risk categories the customer loan into two types, good payers or bad payers (default). The aim of this research is to classify consumer's risk to minimize the risk of default. In the past decades, credit scoring using parametric techniques has been applied in the financial field, namely Discriminant Analysis and Binary Logistic Regression. In the last two decades, the non-parametric machine learning approaches, such as Neural Network and Support Vector Machine. Recently, Deep Learning era has been studied widely in credit scoring, like Deep Neural Network. This study is comparing the performance of several methods of non-parametric machine learning and parametric statistics to classify customer loans. Best method to classify customer loan is DNN with number of neuron in h(1) = 10, h(2) = 3 with value of AUC is 0.638 in testing dataset.",2019
Empirical Study on China's Financial Risk Early Warning under the New Normal,"In this paper, we construct the financial risk early warning model based on BP neural network, make an empirical analysis of the data between January 2004 and October 2015, proves the reliability of the model prediction results through the training and test of the financial risk early warning model and finally put forward the following suggestions for preventing China's financial risks under the new normal: to reform the current financial supervision mode, to adapt to the mixed operation management demand; to construct the financial risk early warning system suitable for China's reality; the one bank and three commissions (which refers to the People's Bank of China, China Banking Regulatory Commission, China Securities Regulatory Commission and China Insurance Regulatory Commission) should constantly improve supervision means and technology, strengthen inter-departmental coordination and enhance financial supervision efforts.",2017
Recognizing the pattern of systematic risk based on financial ratios and rough set - Neural network system,"Systematic risk that is presented by beta is the avoidless risk on the stock market. (Beta is calculated by linear analysis between the daily prices of stocks and the security index of stock market. However, many studies have showed there are stronger relationships between beta and financial ratios. In this paper, a hybrid intelligent system is applied to recognize the clusters of beta with financial ratios, combining rough set approach and BP neural network. We can get reduced information table with no information loss by rough set approach. And then, this reduced information is used to develop classification rules and train network to infer appropriate parameters. The rationale of our hybrid system is using rules developed by rough sets for an object that matches any of the rules and BP neural network for one that dose not match any of them. The effectiveness of our methodology was verified by experiments comparing BP neural networks with our approach.",2006
A Research on the Financial Distress Model for Listed Tourism Companies based on Adaboost-BPNN,"Since the 2007 financial crisis, many crises took huge impacts on the operation of tourism enterprises and seriously affected the development of the Chinese tourism industry. Financial crisis warning is an effective way to find a company's potential business risk and financial risk. Because of small sample size of listed tourism companies and low classification precision of BP neural network, Adaboost algorithm was proposed to enhance BPNN precision. In this paper, the author built a financial distress model for listed tourism companies based on Adaboost-BPNN. By selecting listed tourism firms from Shanghai and Shenzhen A-share stock market, the empirical research verified the validity of the new model.",2012
Construction of Enterprise Financial Early Warning Model Based on Logistic Regression and BP Neural Network,"At present, the number of enterprises in financial crisis in China is rising sharply, and the ability of enterprises to resist risks is generally weak. Therefore, it is necessary to establish a corporate financial crisis early warning system, to detect the signs of corporate financial crisis before it arrives and to inform managers in advance, so that effective measures can be taken as soon as possible to eliminate hidden dangers. This paper selects the two-year data of 40 companies from 2017 to 2019 as training samples and the data of 20 companies as prediction samples. After testing, 12 index variables that can reflect the financial problems of energy companies are finally selected as the basis for modeling. Then, we use Logistic and BP neural network modeling, respectively, to study and compare the data from 2017 to 2019 to predict the financial risk in the following year. The results show that the BP neural network model in the two models is better than the Logistic model in terms of fitting degree or prediction accuracy for enterprise financial early warning. Therefore, the BP neural network model has a better effect and is more suitable for the practical application of enterprises in China.",2022
Credit risk assessment of small and medium-sized enterprises in supply chain finance based on SVM and BP neural network,"Our country's market economy is composed of enterprises. However, due to their inherent credit deficiencies and high risks of management, it is very difficult for them to obtain financing support. Based on this, this article studies Error Back Propagation (BP) to establish (SMEs). Based on the relevant concepts of the supply chain management budget model, it explores the main factors influencing the financial impact of SMEs and the benefits of the supply chain budget in solving problems expenditure of SMEs, support vector machine is mainly based on solving the main credit risks of small and medium-sized enterprises, such as poor information transparency, low credit and various risk unknown factors. BP neural network is an algorithm that takes into account the components of supply chain financial financing. This article first gives a simple background and theoretical introduction to the under the current supply chain finance model, and then proposes to use SVM and BP neural network algorithms to build and the model has been trained and tested. After collecting relevant references, we will establish authoritative risk assessment rules in accordance with this article according to these standards. These experts are mainly people with many years of experience in the financial industry, and they also have a certain influence in the industry. The risk assessment established for this can be the analysis of factors such as risk indicators and government intervention in this experiment.",2022
Logistics Finance Risk Evaluation Model for Coastal Free Trade Cities,"This article introduces the possible risks that might be encountered during the process of logistics financial services in coastal free trade and analyzes the main factors of risk to construct an integrated logistics finance risk evaluation index system. Then, illustrated by certain coastal port city, we adopt BP neural network to establish the logistics risk evaluation model. The network gets full training and testing using the structure, form and training principle of BP neural network. Therfore, the model can provide accurate evaluation on logistics finance risk of this area and provide successful experiences for the development of logistics enterprises.",2017
Developing the value of legal judgments of supply chain finance for credit risk prediction through novel ACWGAN-GPSA approach,"Predicting the credit risk for enterprises in Supply Chain Finance (SCF) often presents substantial challenges in supply chain management community. Considering the huge information asymmetry, we introduce the Bidirectional Encoder Representations from Transformers (BERT) technology in the fields of Deep Learning and Natural Language Processing (NLP) to extract textual insights from legal judgments related to enterprises in SCF business. By integrating legal judgments-extracted information with the financial and corporate attributes of these enterprises, we aim to enhance the prediction accuracy of credit risk. Our empirical results show that the amalgamation of multi-source information significantly reinforces the predictive accuracy of credit risk. Furthermore, we effectively identify critical predictive factors for credit risk, demonstrating the important role of legal judgment content in default prediction situations. Additionally, considering the issue of imbalanced data categories, we propose a novel imbalanced data processing technique called ACWGAN-GPSA to address the generation of unrealistic samples, thereby significantly improving the performance of credit risk prediction models for enterprises in SCF. The strategic insights obtained from our findings offer valuable guidance for both lenders and financial institutions.",2025
The Relationship between Individual investor Supervisory Sentiment and Default Risk of Listed Real Estate Enterprises: A Study Based on Text Big Data and Machine Learning Methods,"In recent years, the frequent occurrence of real estate default incidents has become a focal point for risk prevention and mitigation efforts. Previous research has predominantly focused on the roles of institutions and media, overlooking the influence of individual investors. This study leverages textual big data from investor interaction platforms and employs a bi-LSTM model to extract sentiment and supervisory information, thereby constructing an index for individual investor sentiment monitoring. We analyze its impact on the default risk of real estate firms. Based on the results of a dual-machine learning model, we find that individual investor supervisory sentiment contributes to reducing the default risk of listed real estate firms. Moreover, it can alleviate financing constraints for these firms, thus further mitigating default risk. Additionally, individual investor monitoring complements government regulation. This discovery offers a novel perspective for financial regulation and provides evidence of the role of micro-level forces in financial oversight.",2024
A new financial risk prediction model based on deep learning and quasi-oppositional coot algorithm,"Incorporating ground-breaking technologies such as deep learning (DL) has revolutionized predictive modelling in the rapidly evolving landscape of the finance sector. DL approaches, capable of extracting complex patterns from vast data collections, become an efficient approach for predicting financial trends. By integrating the complex neural network architecture with comprehensive datasets, including investor sentiment, market indicators, and economic variables, finance experts have introduced prediction models well known for their ability to capture the nuanced dynamics of financial markets with remarkable performance. Incorporating DL approaches within the finance sector provided the basis for more informed decision-making, enabling institutions, investors, and analysts to capitalize on emerging opportunities with greater confidence and precision and navigate market volatility. This study develops a novel quasi-oppositional coot algorithm with a deep learningbased predictive method on the financial sector (QOCODL-PMFC) technique. The QOCODL-PMFC technique aims to perform a prediction process on the financial sector. The QOCODL-PMFC method applies min-max normalization to measure the input dataset into a meaningful format to achieve this. Next, the QOCODL-PMFC method designs the QOCO technique for selecting an optimal set of features. The QOCODL-PMFC technique applies the attention bidirectional gated recurrent unit (ABiGRU) model for the prediction process. The Harris Hawks Optimization (HHO) model is utilized to boost the performance of the ABiGRU network. The simulation evaluation of the QOCODL-PMFC technique is tested under a benchmark finance dataset. The experimental values of the QOCODL-PMFC technique exhibit a minimal MSE of 0.7452 over other models.",2024
RETRACTED: Research on Digital Economy of Intelligent Emergency Risk Avoidance in Sudden Financial Disasters Based on PSO-BPNN Algorithm (Retracted Article),"In recent years, disasters have seriously affected the normal development of financial business in some regions. At the time of disaster, how to effectively integrate resources of all parties, deal with sudden financial disasters efficiently, and restore financial services in time has become an important task. Therefore, this paper adopts Particle Swarm Optimization (PSO) to improve the traditional BP Neural Network (BPNN) and finally constructs a Particle Swarm Optimization powered BP Neural Network (PSO-BPNN) model for the intelligent emergency risk avoidance of sudden financial disasters in digital economy. At the same time, the proposed algorithm is also compared to GA-BPNN and BPNN algorithms, which are also intelligent algorithms. Experimental results show that the hybrid PSO-BPNN algorithm is superior to GA-BPNN algorithm and BPNN algorithm in simulation and prediction effect. It can accurately predict the sudden financial disaster in recent period, so the model has a good application prospect.",2021
Deep Learning-Based Adaptive Online Intelligent Framework for a Blockchain Application in Risk Control of Asset Securitization,"Blockchain and distributed ledger technologies have attracted massive attention from both legal communities and businesses. Asset securitization is the procedure in which an issuer designs a financial instrument that is marketable by combining or merging different financial assets into one group. However, most securitization occurs with loans and other assets that generate receivables, such as consumer or business debt of various types. This article discusses the possible benefits of blockchain during the securitization process using the deep learning-based adaptive online intelligent framework (DLAOIF). The benefits can be significant, from reduced costs, time, and fraud risks to increased safety, trust, and accuracy. Tracking financial assets on a blockchain can reduce dependence on credit rating organizations and allow investors to monitor asset performance and the associated risk more carefully. It should improve investor confidence and increase secondary market interest.",2023
IMPROVING FRACTALS FINANCIAL CREDIT RISK EVALUATION BASED ON DEEP LEARNING TECHNIQUES AND BLOCKCHAIN-BASED ENCRYPTION,"Predicting a client's affluence is essential in financial services. This task is the unity of the most important danger factors in groups and additional economic institutions. Typically, credit risk evaluation relies on black box models. However, these models often need to clarify the hidden information within the data. Moreover, few clear models focus on being easy to understand and accessible. This paper proposes a fractal credit risk assessment model that uses deep techniques like self-attention generative adversarial networks (SA-GAN) and deep multi-layer perceptron (DMLP). We use blockchain technology with the Brakerski-Gentry-Vaikuntanathan (BGV) encryption method to bolster safekeeping. Additionally, the scheme is designed for the Edge-of-things network, enabling communication through a LoRaWAN server. The proposed solution was tested on the German retail credit dataset. We assessed its performance using accuracy, F1 score, precision, and recall as metrics. Notably, our hybrid deep model, which combines SA-GAN with DMLP, achieved an impressive accuracy of 97.8% - outperforming existing methods in works.",2025
Forecasting the risk at infractions: an ensemble comparison of machine learning approach,"Purpose The infraction of securities regulations (ISRs) of listed firms in their day-to-day operations and management has become one of common problems. This paper proposed several machine learning approaches to forecast the risk at infractions of listed corporates to solve financial problems that are not effective and precise in supervision. Design/methodology/approach The overall proposed research framework designed for forecasting the infractions (ISRs) include data collection and cleaning, feature engineering, data split, prediction approach application and model performance evaluation. We select Logistic Regression, Naive Bayes, Random Forest, Support Vector Machines, Artificial Neural Network and Long Short-Term Memory Networks (LSTMs) as ISRs prediction models. Findings The research results show that prediction performance of proposed models with the prior infractions provides a significant improvement of the ISRs than those without prior, especially for large sample set. The results also indicate when judging whether a company has infractions, we should pay attention to novel artificial intelligence methods, previous infractions of the company, and large data sets. Originality/value The findings could be utilized to address the problems of identifying listed corporates' ISRs at hand to a certain degree. Overall, results elucidate the value of the prior infraction of securities regulations (ISRs). This shows the importance of including more data sources when constructing distress models and not only focus on building increasingly more complex models on the same data. This is also beneficial to the regulatory authorities.",2022
The evaluation of agricultural enterprise's innovative borrowing capacity based on deep learning and BP neural network,"The purpose is to solve the financing difficulties of agricultural enterprises with the assistance of deep learning and neural network model, improve the overall borrowing ability of enterprises and effectively evaluate enterprise risks. First, the concepts of deep learning and neural network are introduced. On the basis of sorting out and summarizing the existing relevant research, multiple financial indexes are selected as variables, and a risk control model of innovative lending of agricultural enterprises based on back propagation neural network (BPNN) is established. The data of some listed agricultural enterprises are selected for empirical analysis. The performance of the proposed model algorithm is compared with that of the previous model. The results show that the evaluation error of BPNN algorithm is less than 1.8%, and its accuracy is as high as 94.04%. The algorithm shows excellent performance in the training process, the actual output value is very close to the expected value, and can effectively classify related enterprises. The research results can provide reference for solving the loan problem of agricultural enterprises and improving the risk management ability of agricultural enterprises.",2022
Electricity demand error corrections with attention bi-directional neural networks,"Reliable forecast of electricity demand is crucial to stability, supply, and management of electricity grids. Shortterm hourly and sub -hourly demand forecasts are difficult due to the stochastic nature of electricity demand. To improve the electricity demand forecasts, artificial neural networks are combined with attention -based bidirectional neural network as well as Error Correction methods, and Bayesian hyperparameter optimizations. As part of the hybrid VMD-CABLSTM-ANN-EC model, the intrinsic mode functions, representing distinct predictive features, are separated from electricity demand data using variational mode decomposition algorithm. For predicting each intrinsic mode function and respective error time series, convolutional neural networks -bidirectional long short-term memory algorithms are applied. In a second stage, error time series are split, followed by a model to predict the error series' intrinsic mode functions, and a final integration stage to predict the error. The results of the proposed VMD-CABLSTM-ANN-EC model are benchmarked against decompositionbased and standalone models at substations in Queensland, Australia. The proposed VMD-CABLSTM-ANN-EC model outperformed all benchmark models. By splitting the predictor and target variables, it will be shown that the variational model decomposition method improves error corrections by revealing key features of historical demand data. Using error correction method in short-term electricity demand modelling can provide greater confidence in the prediction of electricity demand. The models can be used by energy providers for market analysis and insight research, to manage power failure risk, and make financial decisions.",2024
Prediction of Stock Performance Using Deep Neural Networks,"Stock performance prediction is one of the most challenging issues in time series data analysis. Machine learning models have been widely used to predict financial time series during the past decades. Even though automatic trading systems that use Artificial Intelligence (AI) have become a commonplace topic, there are few examples that successfully leverage the proven method invented by human stock traders to build automatic trading systems. This study proposes to build an automatic trading system by integrating AI and the proven method invented by human stock traders. In this study, firstly, the knowledge and experience of the successful stock traders are extracted from their related publications. After that, a Long Short-Term Memory-based deep neural network is developed to use the human stock traders' knowledge in the automatic trading system. In this study, four different strategies are developed for the stock performance prediction and feature selection is performed to achieve the best performance in the classification of good performance stocks. Finally, the proposed deep neural network is trained and evaluated based on the historic data of the Japanese stock market. Experimental results indicate that the proposed ranking-based stock classification considering historical volatility strategy has the best performance in the developed four strategies. This method can achieve about a 20% earning rate per year over the basis of all stocks and has a lower risk than the basis. Comparison experiments also show that the proposed method outperforms conventional methods.",2020
Interpretable Operational Risk Classification with Semi-Supervised Variational Autoencoder,"Operational risk management is one of the biggest challenges nowadays faced by financial institutions. There are several major challenges of building a text classification system for automatic operational risk prediction, including imbalanced labeled/unlabeled data and lacking interpretability. To tackle these challenges, we present a semi-supervised text classification framework that integrates multi-head attention mechanism with Semi-supervised variational inference for Operational Risk Classification (SemiORC). We empirically evaluate the framework on a real-world dataset. The results demonstrate that our method can better utilize unlabeled data and learn visually interpretable document representations. SemiORC also outperforms other baseline methods on operational risk classification.",2020
Learning Model for Assessing Loss Severity of Operational Risk,"Risks, deficiencies and other issues identified within the organization should be evaluated and assessed with regard to their severity and significance. Operational risk is one of the risk categories within the banking and financial services community. It is defined as the risk of loss resulting from inadequate or failed internal processes, people and systems or from external events. Scenario analyses and risk assessments based on expert opinion should be frequently validated and reassessed by comparing them to actual loss data available over time. Alternatively, this paper presents an approach to assessing loss severity of operational risk using the technique of backpropagation neural network. The multiple risk causes and resulting loss form a network of interdependencies as a learning model. The risk scenarios collected from expert judgment represents the training instances of causal chains and effects. The output model could be used as the substitute of expert assessments for the mature organizations where operational loss data are available.",2014
Strategy for financing mode optimization in international trade supply chain based on deep learning model,"With the development of economy and the advance of society, the quality of life of the masses has been improved to a certain extent. Meanwhile, new approaches have emerged in the financial industry, such as the supply chain mode. This paper modeled the coupling relationship of financial markets based on deep learning model and proposed the supply chain financing strategy of financial markets in different countries. The experimental results show that when the minimum value of supply chain finance is 0.5577, the loss risk has not reached the boundary of the effectiveness of the risk control standard. Therefore, this paper aims to systematically analyze the financing mode of international trade supply chain, comprehensively perfect the international trade governance mode, and thus realize the freedom of trade, and at the same time, provide new ideas for enterprises' financing difficulties, and probe into the ways of supply chain financing mode in improving enterprises' financing difficulties, so as to help solve the financing difficulties of a large number of enterprises and optimize the financing strategy of international trade.",2023
An empirical study of preventive healthcare policy under the synergy of education and corporate financial monitoring,"Introduction Preventive healthcare policies are critical for improving public health outcomes and reducing the socioeconomic burden of diseases, aligning closely with the theme of enhancing residents' health welfare through robust social security systems. However, traditional approaches often overlook the dynamic interplay between economic factors and health outcomes, limiting their effectiveness in designing sustainable interventions.Methods To address these gaps, this study leverages corporate financial monitoring as a novel lens for assessing the effectiveness of preventive healthcare policies. Utilizing the Advanced Financial Monitoring Neural Framework (AFMNF) and the Dynamic Risk-Adaptive Framework (DRAF), we integrate deep learning techniques with dynamic risk modeling to analyze the financial and health impacts of such policies. Our methodology involves monitoring corporate financial metrics, anomaly detection, and trend analysis to identify correlations between policy implementation and economic indicators.Results and discussion The results demonstrate that integrating financial insights with health policy evaluation improves prediction accuracy of socioeconomic outcomes by 40% and enhances anomaly detection in policy performance by 30%. This adaptive framework offers a scalable, real-time approach to monitoring, providing actionable insights for policymakers to optimize preventive healthcare strategies. This study underscores the importance of interdisciplinary methods in advancing public health outcomes through innovative, data-driven frameworks.",2025
Harnessing probabilistic neural network with triple tree seed algorithm-based smart enterprise quantitative risk management framework,"Enterprise risk management (ERM) frameworks convey vital principles that help create a consistent risk management culture, irrespective of employee turnover or industry standards. Enterprise Management System (EMS) are becoming a popular research area for assuring a company's long-term success. Statistical pattern recognition, federated learning, database administration, visualization technology, and social networking are all used in this field, which includes artificial intelligence (AI), data science, and statistics. Risk assessment in EMS is critical for enterprise decision-making to be effective. Recent advancements in AI, machine learning (ML), and deep learning (DL) concepts have enabled the development of effective risk assessment models for EMS. This special issue seeks groundbreaking research articles that showcase the application of applied probability and statistics to interdisciplinary studies. This study offers Improved Metaheuristics with a Deep Learning Enabled Risk Assessment Model (IMDLRA-SES) for Smart Enterprise Systems. Using feature selection (FS) and DL models, the provided IMDLRA-SES technique estimates business risks. Preprocessing is used in the IMDLRA-SES technique to change the original financial data into a usable format. In addition, an FS technique based on oppositional lion swarm optimization (OLSO) is utilized to find the best subset of features. In addition, the presence or absence of financial hazards in firms is classified using the triple tree seed algorithm (TTSA) with a probabilistic neural network (PNN) model. The TTSA is used as a hyperparameter optimizer to improve the efficiency of the PNN-based categorization. An extensive set of experimental evaluations is performed on German and Australian credit datasets to illustrate the IMDLRA-SES model's improved performance. The performance validation of the IMDLRA-SES model portrayed a superior accuracy value of 95.70% and 96.09% over existing techniques.",2024
Hesitant fuzzy linguistic portfolio model with variable risk appetite and its application in the investment ratio calculation,"Qualitative evaluation information is important for financial decision-making and investment when quantitative data are unavailable. Although an alternative ranking is available, specific portfolio and optimal investment ratios cannot be obtained by using the qualitative decision-making methods. To address this issue, this paper proposes a hesitant fuzzy linguistic portfolio model based on the max-score rule and the hesitant fuzzy linguistic element with variable risk appetite (HFLE-RA). The HFLE-RA is able to express qualitative evaluation information by using the hesitant fuzzy linguistic term set and describe the variable investor risk appetites by introducing the asymmetric sigmoid semantics. Thus, different investors can be distinguished by the risk appetite parameters according to the asymmetric sigmoid semantics, and the optimal investment ratios can be obtained by applying the proposed portfolio model. Moreover, the investment opportunities and efficient frontiers of the hesitant fuzzy linguistic portfolio model are investigated. Also, a value-at-risk fitting approach is introduced to calculate the risk appetite parameters. Based on these works, a qualitative investment ratio calculation process is provided in the HFLE-RA environment. Lastly, a real example of calculating the optimal investment ratios for four newly listed stocks in the Growth Enterprises Market board of the Shenzhen Stock Exchange is provided to demonstrate the proposed approaches. (C) 2019 Elsevier B.V. All rights reserved.",2019
Application of AdaBound-Optimized XGBoost-LSTM Model for Consumer Credit Assessment in Banking Industries,"Consumer credit assessment has always been a crucial concern in the financial industry. It involves evaluating an individual's credit history and their ability to repay loans, playing a pivotal role in the risk management and lending decisions made by credit institutions. In the present landscape, traditional credit assessment methods confront various shortcomings. Firstly, they typically only consider static features and are unable to capture the dynamic changes in an individual's credit profile over time. Secondly, traditional methods struggle with processing complex time series data, failing to fully exploit the importance of time-related information. To address these challenges, we propose an innovative solution - the XGBoost-LSTM model optimized with the AdaBound algorithm. This hybrid model combines two powerful machine learning techniques, XGBoost and LSTM, to leverage both static and dynamic features effectively.",2024
Deep Learning Models for Predicting Monthly TAIEX to Support Making Decisions in Index Futures Trading,"Futures markets offer investors many attractive advantages, including high leverage, high liquidity, fair, and fast returns. Highly leveraged positions and big contract sizes, on the other hand, expose investors to the risk of massive losses from even minor market changes. Among the numerous stock market forecasting tools, deep learning has recently emerged as a favorite tool in the research community. This study presents an approach for applying deep learning models to predict the monthly average of the Taiwan Capitalization Weighted Stock Index (TAIEX) to support decision-making in trading Mini-TAIEX futures (MTX). We inspected many global financial and economic factors to find the most valuable predictor variables for the TAIEX, and we examined three different deep learning architectures for building prediction models. A simulation on trading MTX was then performed with a simple trading strategy and two different stop-loss strategies to show the effectiveness of the models. We found that the Temporal Convolutional Network (TCN) performed better than other models, including the two baselines, i.e., linear regression and extreme gradient boosting. Moreover, stop-loss strategies are necessary, and a simple one could be sufficient to reduce a severe loss effectively.",2021
PsyCredit: An interpretable deep learning-based credit assessment approach facilitated by psychometric natural language processing,"With the prosperity of the social web, individuals' social media information alleviates the information asymmetry between individuals and online financial institutions, e.g., online lending and has been applied to predict their credit scores. Most existing studies use semantic or sentiment-related information excavated from their textual postings to construct credit evaluation models. However, despite the essential role of borrowers' personalities on their financial decisions, psychological factors, which can also be mined from their personally written text, receive less attention in current literature. It is challenging to apply extant psychometric approaches for online credit assessment tasks. Specifically, under the chaotic social media environment, social media postings published by the borrowers may not be composed by themselves, and therefore their real psychological statuses are difficult to be uncovered through existing approaches. To solve this problem, guided by the design science methodology and grounded on the Systemic Functional Linguistic Theory, we propose a novel IT artifact, named as PsyCredit, which is a deep learning-based online risk assessment framework driven by a novel psychometric approach. Unlike traditional deep learning approaches, which is a black box, results given by PsyCredit are interpretable by leveraging the Layer-wise Relevance Propagation technique, for the sake of high usability. Based on a dataset from a real-world P2P lending company, our experiments verify that, by leveraging the proposed psychometric approach, the credit risk assessment performance gets promotion successfully.",2022
MODELLING CONDITIONAL VOLATILITY IN STOCK INDICES: A COMPARISON OF THE ARMA-EGARCH MODEL VERSUS NEURONAL NETWORK BACKPROPAGATION,"The analysis of conditional volatility is a key factor to correctly assess the risk of several financial assets such as shares, bonds or index as well as derivatives (futures and options). The econometric models from the GARCH family are traditionally the most widely used to predict conditional volatility. As an alternative to the econometric models, neural networks can be employed to this end. This paper compares the econometric model ARMA-EGARCH with the neuronal network Backpropagation. Both methodologies have been applied on diverse international stock indices. The main conclusion to be stressed is that the neuronal network can significantly better predict conditional volatility than the econometric model.",2014
Deep Convolutional Neural Networks for Classification of Mild Cognitive Impaired and Alzheimer's Disease Patients from Scalp EEG Recordings,"In spite of the worldwide financial and research efforts made, the pathophysiological mechanism at the basis of Alzheimer's disease (AD) is still poorly understood. Previous studies using electroencephalography (EEG) have focused on the slowing of oscillatory brain rhythms, coupled with complexity reduction of the corresponding time-series and their enhanced compressibility. These analyses have been typically carried out on single channels. However, limited investigations have focused on the possibility yielded by computational intelligence methodologies and novel machine learning approaches applied to multichannel schemes. The study at screening level on EEG recordings of subjects at risk could be useful to highlight the emergence of underlying AD progression (or at least support any further clinical investigation). In this work, the representational power of Deep Learning on Convolutional Neural Networks (CNN) is exploited to generate suitable sets of features that are then able to classify EEG patterns of AD from a prodromal version of dementia (Mild Cognitive Impairment, MCI) and from age-matched Healthy Controls (HC). The processing system here used enforces a series of convolutional-subsampling layers in order to derive a multivariate assembly of latent, novel patterns, finally used to categorize sets of EEG from different classes of subjects. The final processor here proposed is able to reach an averaged 80% of correct classification with good performance on both sensitivity and specificity by using a Multilayered Feedforward Perceptron (MLP) of the standard type as a final block of the procedure.",2016
An integrated deep-learning model for smart waste classification,"Efficient waste management is essential for human well-being and environmental health, as neglecting proper disposal practices can lead to financial losses and the depletion of natural resources. Given the rapid urbanization and population growth, developing an automated, innovative waste classification model becomes imperative. To address this need, our paper introduces a novel and robust solution - a smart waste classification model that leverages a hybrid deep learning model (Optimized DenseNet-121 + SVM) to categorize waste items using the TrashNet datasets. Our proposed approach uses the advanced deep learning model DenseNet-121, optimized for superior performance, to extract meaningful features from an expanded TrashNet dataset. These features are subsequently fed into a support vector machine (SVM) for precise classification. Employing data augmentation techniques further enhances classification accuracy while mitigating the risk of overfitting, especially when working with limited TrashNet data. The results of our experimental evaluation of this hybrid deep learning model are highly promising, with an impressive accuracy rate of 99.84%. This accuracy surpasses similar existing models, affirming the efficacy and potential of our approach to revolutionizing waste classification for a sustainable and cleaner future.",2024
FORECASTING STOCK RETURN VOLATILITY USING THE REALIZED GARCH MODEL AND AN ARTIFICIAL NEURAL NETWORK,"Volatility forecasting is required for risk management, asset allocation, option pricing, and financial market trading. It can be done by using various time series forecasting techniques and Artificial Neural Networks (ANN). T he current research focuses on the modeling and forecasting of stock market indices using high-frequency data. A recent high-frequency volatility model is called the Realized GARCH (RGARCH) model, where the key feature is an equation that relates the realized measure to the conditional variance of returns. This equation incorporates an asymmetric reaction to shocks, providing a highly flexible representation of market dynamics. This paper proposes an hybrid model where ANN and RGARCH are used to forecast stock return volatility. This model was established by entering the predicted Realized Volatility (RV), calculated using RGARCH, into the ANN. The choice of the input variables of the ANN is made using the Granger causality test in order to reduce the noise which would affect the prediction system and which could be generated by an input variable not statistically linked to stock market volatility. The results show that a hybrid model based on a recurrent neural network (RNN) outperforms the RGARCH and HAR-type models in out-of-sample evaluations according to the RMSE and the correlation coefficient.",2023
Industry credit spread forecasting based on time series data and industry relationships,"Credit spread is an important index in the financial market, as it captures the risk for the bond issuer and industry. As there are several types of connections among different industries, through which the risk may propagate from one industry to another, it may be helpful to take these connections into account for bond spread forecasting. In this paper, we propose a novel industry bond spread forecasting method based on LSTM and the temporal graph neural networks, which exploits the relations among different industries. The experimental results demonstrate that introducing industry relations can improve the prediction accuracy of the prediction.",2023
STGAT: Spatial-Temporal Graph Attention Neural Network for Stock Prediction,"Stock price prediction and portfolio optimization are critical research areas in financial markets, as they directly impact investment strategies and risk management. Traditional statistical methods and machine learning approaches have been widely applied to these tasks, but they often fail to fully capture the complex dynamics of financial markets. Traditional statistical methods typically rely on unrealistic assumptions or oversimplified models, neglecting the nonlinear and high-dimensional characteristics of market data. Additionally, deep learning methods, especially temporal convolution networks and graph attention networks, have been introduced in this area and have achieved significant improvements in both stock price prediction and portfolio optimization. Therefore, this study proposes a Spatial-Temporal Graph Attention Network (STGAT) that integrates STL decomposition components and graph structures to model both temporal patterns and asset correlations. By combining graph attention mechanisms with temporal convolutional modules, STGAT effectively processes spatiotemporal data, enhancing the accuracy of stock price predictions. Empirical experiments on the CSI 500 and S&P 500 datasets demonstrate that STGAT outperforms other deep learning models in both prediction accuracy and portfolio performance. The investment portfolios constructed based on STGAT's predictions achieve higher returns in real market scenarios, which validates the feasibility of spatiotemporal feature fusion for stock price prediction and highlights the advantages of graph attention networks in capturing complex market characteristics. This study not only provides a robust tool for portfolio optimization but also offers valuable insights for future research in intelligent financial systems.",2025
Randomized Controlled Trial Examining the Efficacy of Adding Financial Incentives to Best practices for Smoking Cessation Among pregnant and Newly postpartum Women,"We report results from a single-blinded randomized controlled trial examining financial incentives for smoking cessation among 249 pregnant and newly postpartum women. Participants included 169 women assigned to best practices (BP) or BP plus financial incentives (BP + FI) for smoking cessation available through 12-weeks postpartum. A third condition included 80 never-smokers (NS) sociodemographically-matched to women who smoked. Trial setting was Burlington, Vermont, USA, January, 2014 through January, 2020. Outcomes included 7-day point-prevalence abstinence antepartum and postpartum, and birth and other infant outcomes during 1st year of life. Reliability and external validity of results were assessed using pooled results from the current and four prior controlled trials coupled with data on maternal-smoking status and birth outcomes for all 2019 singleton live births in Vermont. Compared to BP, BP + FI significantly increased abstinence early- (AOR = 9.97; 95%CI, 3.32-29.93) and late-pregnancy (primary outcome, AOR = 5.61; 95%CI, 2.37-13.28) and through 12weeks postpartum (AOR = 2.46; CI,1.05-5.75) although not 24- (AOR = 1.31; CI,0.54-3.17) or 48-weeks postpartum (AOR = 1.33; CI,0.55-3.25). There was a significant effect of trial condition on small-for-gestational-age (SGA) deliveries (chi(2) [2] = 9.01, P =.01), with percent SGA deliveries (+SEM) greatest in BP, intermediate in BP + FI, and lowest in NS (17.65 + 4.13, 10.81 + 3.61, and 2.53 + 1.77, respectively). Reliability analyses supported the efficacy of financial incentives for increasing abstinence antepartum and postpartum and decreasing SGA deliveries; external-validity analyses supported relationships between antepartum cessation and SGA risk. Adding financial incentives to Best Practice increases smoking cessation among antepartum and postpartum women and improves other maternal-infant outcomes.",2022
Enhancing Enterprise Credit Risk Assessment with Cascaded Multi-level Graph Representation Learning,"The assessment of Enterprise Credit Risk (ECR) is a critical technique for investment decisions and financial regulation. Previous methods usually construct enterprise representations by credit-related indicators, such as liquidity and staff quality. However, indicators of many enterprises are not accessible, especially for the small-and medium-sized enterprises. To alleviate the indicator deficiency, graph learning based methods are proposed to enhance enterprise representation learning by the neighbor structure of enterprise graphs. However, existing methods usually only focus on pairwise relationships, and overlook the ubiquitous high -order relationships among enterprises, e.g., supply chain connecting multiple enterprises. To resolve this issue, we propose a Multi-Structure Cascaded Graph Neural Network framework (MS-CGNN) for ECR assessment. It enhances enterprise representation learning based on enterprise graph structures of different granularity, including knowledge graphs of pairwise relationships, homogeneous and heterogeneous hypergraphs of high -order relationships. To distinguish influences of different types of hyperedges, MS-CGNN redefine new type-dependent hyperedge weight matrices for heterogeneous hypergraph convolutions. Experimental results show that MS-CGNN achieves state-of-the-art performance on real-world ECR datasets.",2024
Systemic financial risk prediction using least squares support vector machines,"The systemic financial risk prediction problem has become a focus in the field of finance. This work applies a novel machine learning technique, that is, least squares support vector machines (LSSVM), to predict the systemic financial risk. To serve this purpose, the paper selects financial risk indicators of China from January 2006 to December 2016, and utilizes unit root test, principal component analysis (PCA) and self-exciting threshold autoregressive (SETAR) methods for data preprocessing. Furthermore, particle swarm optimization (PSO) has been used for parameters optimization of LSSVM by comparison with grid search (GS), and genetic algorithm (GA). The experimental results show that a better prediction performance and generalization can be achieved with the proposed LSSVM compared to the traditional strategies such as SVM, BP neural networks, and logistic regression. As a result, we can conclude that the LSSVM is more suitable for the practical use in systemic financial risk predicting.",2018
Design of a Personal Credit Risk Prediction Model and Legal Prevention of Financial Risks,"With the escalating demand for personal credit, banking financial institutions face the imperative to expand their user base and mitigate losses caused by non-performing loans (NPLs). This study addresses the necessity for accurate and efficient personal credit risk assessment systems, focusing on rectifying credit data imbalances and developing a high-performing credit risk prediction model. To tackle data imbalance, deep learning's Generative Adversarial Network (GAN) is employed for oversampling, learning the distribution of default samples within high-risk financial groups. New default samples are then integrated into the original dataset to achieve a balanced representation of default and normal samples. In the era of big data, marked by a surge in personal credit data dimensions and sample numbers, an advanced ensemble learning model, the Light Gradient Boosting Machine (LightGBM), is combined with the GAN model for credit risk prediction. The study utilizes six different imbalance ratio datasets from the Knowledge Extraction based on Evolutionary Learning platform to experiment with the GAN model's classification effectiveness. Additionally, consumer finance company credit data, consisting of 559 features, undergoes data preprocessing and feature extraction to validate the LightGBM-GAN model's effectiveness for credit risk prediction. Experimental results reveal that: (1) GAN significantly improves risk information classification (achieving an 86.7% accuracy), outperforming traditional oversampling methods on multiple datasets; (2) The LightGBM-GAN model excels in Area Under the Receiver Operating Characteristic Curve and Kolmogorov-Smirnov statistic values (averaging 0.86 and 0.87, respectively), establishing itself as an effective credit risk prediction model; (3) Feature importance identified by the LightGBM model underscores the predictive potential of financial weakly correlated variables, such as consumer behavior data. This study strives to equip financial institutions with efficient and precise credit risk assessment tools, ensuring compliance with laws and regulations, averting legal risks, reducing NPL risks, and fortifying the stability of the financial system.",2024
A Bankruptcy Prediction Model Based on Risk Feature Fusion and a Multihead Residual Self-Attention Mechanism,"With the continuous development of financial markets, the investment environment has become increasingly complex. Strengthening financial risk control and carrying out enterprise bankruptcy prediction have become increasingly important. Enterprise bankruptcy prediction can effectively assist investors in identifying companies at risk of bankruptcy and avoiding investment losses and plays an indispensable role in preventing extreme risks. Therefore, we propose a bankruptcy classification model that combines risk feature fusion and a multihead residual attention mechanism. Specifically, according to financial theory, the proposed model classifies enterprise indicators according to risk attributes and uses a neural network for major feature extraction. Then, the major risk characteristics are introduced into the multihead residual attention module to extract the comprehensive deep features of the data to achieve bankruptcy classification. To validate the effectiveness of this method, we compare it with eight bankruptcy prediction algorithms on public datasets. The experimental results show that our model achieves the best performance on the core indicators of bankruptcy prediction accuracy and F1-score. The results also show that the model has high practical value and can be used as a reliable tool for investors to manage investment and predict risks.",2025
A Strong Classifier Model Oriented to the Financial Risk Warning of Listed Company,"A strong classifier model oriented to the financial risk warning of listed company has played an important role in the risk analysis of enterprise finance. Based on the BP_Adaboost composed of BP neural network and Adaboost algorithm, a strong classifier model of enterprise finance is designed and established, and is verified with the actual data. In the first, the evaluation index has the largest correlation to the warning result of enterprise finance has been filtered through the significance analysis and factor analysis of typical data. After that, the data item corresponding to the evaluation index is taken into the strong BP_Adaboost classifier model, in order to compute the classification results. Finally, the classification result of the weak BP classifier is computed and compared with the one of the strong BP_Adaboost classifier model. The experimental results show that the accuracy of strong BP_Adaboost classifier is higher than the one of weak BP classifier, and the strong BP_Adaboost classifier has better stability and higher reliability.",2015
What is the value of the cross-sectional approach to deep reinforcement learning?,"Reinforcement learning (RL) for dynamic asset allocation is an emerging field of study. Total return, the common performance metric, is useful for comparing algorithms but does not help us determine how close an RL algorithm is to an optimal solution. In real-world financial applications, a bad decision could prove to be fatal. One of the key ideas of our work is to combine the two paradigms of the mean-variance optimization approach (Markowitz criteria) and the optimal capital growth approach (Kelly criteria) via the actor-critic approach. By using an actor-critic approach, we can balance optimization of risk and growth by configuring the actor to optimize the mean-variance while the critic is configured to maximize growth. We propose a Geometric Policy Score used by the critic to assess the quality of the actions taken by the actor. This could allow portfolio manager practitioners to better understand the investment RL policy. We present an extensive and in-depth study of RL algorithms for use in portfolio management (PM). We studied eight published policy-based RL algorithms which are preferred over value-based RL because they are better suited for continuous action spaces and are considered to be state of the art, Deterministic Policy Gradient (DPG), Stochastic Policy Gradients (SPG), Deep Deterministic Policy Gradient (DDPG), Trust Region Policy Optimization (TRPO), Proximal Policy Optimization (PPO), Twin Delayed Deep Deterministic Policy Gradient (TD3), Soft Actor Critic (SAC), and Evolution Strategies (ES) for Policy Optimization. We implemented all eight and we were able to modify all of them for PM but our initial testing determined that their performance was not satisfactory. Most algorithms showed difficulty converging during the training process due to the non-stationary and noisy nature of financial environments, along with other challenges. We selected the four most promising algorithms DPG, SPG, DDPG, PPO for further improvements. The modification of RL algorithms to finance required unconventional changes. We have developed a novel approach for encoding multi-type financial data in a way that is compatible with RL. We use a multi-channel convolutional neural network (CNN-RL) framework, where each channel corresponds to a specific type of data such as high-low-open-close prices and volumes. We also designed a reward function based on concepts such as alpha, beta, and diversification that are financially meaningful while still being learnable by RL. In addition, portfolio managers will typically use a blend of time series analysis and cross-sectional analysis before making a decision. We extend our approach to incorporate, for the first time, cross-sectional deep RL in addition to time series RL. Finally, we demonstrate the performance of the RL agents and benchmark them against commonly used passive and active trading strategies, such as the uniform buy-and-hold (UBAH) index and the dynamical multi-period Mean-Variance-Optimization (MVO) model.",2022
Algorithm Design for Asset Trading Under Multiple Factors,"For the strategy of investing in gold and Bitcoin, first collect the historical prices of two types of investment products in the market, and use the wavelet neural network model and WT-LSTM model to model and analyze to predict the future price trends of gold and Bitcoin. Second, considering the difference in price fluctuations between gold and Bitcoin, based on the GARCH-EVT model to increase the risk uncertainty of financial assets, proposes how to achieve the best trading strategy under risk characteristics. Finally, considering the influence of transaction rate on income, we use particle swarm algorithm and genetic algorithm to study what kind of transaction rate can achieve maximum income. The study found that although traders can predict future trends based on daily price changes, due to the different risk factors of gold and Bitcoin, and the different sensitivity of the two financial assets to transaction costs, trading strategies will be very different.",2022
DEEP NEURAL NETWORKS METHODS FOR ESTIMATING MARKET MICROSTRUCTURE AND SPECULATIVE ATTACKS MODELS: THE CASE OF GOVERNMENT BOND MARKET,"A sovereign bond market offers a wide range of opportunities for public and private sector financing and has drawn the interest of both scholars and professionals as they are the main instrument of most fixed-income asset markets. Numerous works have studied the behavior of sovereign bonds at the microeconomic level, given that a domestic securities market can enhance overall financial stability and improve financial market intermediation. Nevertheless, they do not deepen methods that identify liquidity risks in bond markets. This study introduces a new model for predicting unexpected situations of speculative attacks in the government bond market, applying methods of deep learning neural networks, which proactively identify and quantify financial market risks. Our approach has a strong impact in anticipating possible speculative actions against the sovereign bond market and liquidity risks, so the aspect of the potential effect on the systemic risk is of high importance.",2022
A qualitatively analyzable two-stage ensemble model based on machine learning for credit risk early warning: Evidence from Chinese manufacturing companies,"Constructing ensemble models has become a common method for corporate credit risk early warning, while as to deep learning model with better predictive ability, there have been no fixed theoretical models formed in corporate credit risk early warning, as such models often fail to conduct further qualitative analysis of the results. Thus, this article builds a new two-stage ensemble model using a variety of machine learning methods represented by deep learning for corporate credit risk early warning, which can not only effectively improve the prediction per-formance of the model, but also qualitatively analyze the source of corporate credit risk from multiple angles according to the results. At first stage, the improved entropy method is used to re-assign the instance weight in correlation degree based on grey correlation analysis. At second stage, this study adopts Bagging method to integrate multiple one-dimensional convolutional neural networks, and borrows idea of N-fold cross validation to expand the difference of the base classifier. Empirically, this article selects listed companies in Chinese manufacturing industry between 2012 and 2021 as datasets, including 467 samples with 51 financial indicators. The new ensemble model has the highest F1-score (87.29%) and G-mean (89.47%) among comparative models, and qualitatively analyzes corporate risk sources. Further, it also analyzes how to in-crease early warning effect from the angles of indicator number and time span.",2023
Electric Power Enterprise Financial Risk Evaluation Based On Rough Set and BP Network,"The comprehensive evaluation problem of electric power listed corporation has always been a focus since Market-oriented reform of the electric power industry, and financial risk evaluation play a key role to science investment decision of electric power listed corporation This paper presents a new composite forecasting method for financial risk of electric power corporation, modeling and forecasting based on Rough Set and Back-propagation Neural Network model. Combing reality financial data of electric power listed corporation and using Rough Set theory to select financial indexes, which are as modeling variables, then establishing financial risk estimation model based on Back-propagation Neural Network. Through training for the financial data, it shows that this model has a high accuracy to the results of financial risks evaluation, and it offers effective technical support to financial risk evading of electric power enterprise.",2008
STAGE framework: A stock dynamic anomaly detection and trend prediction model based on graph attention network and sparse spatiotemporal convolutional network,"As the financial market becomes increasingly complex, stock prediction and anomaly data detection have emerged as crucial tasks in financial risk management. However, existing methods exhibit significant limitations in handling the intricate relationships between stocks and addressing anomalous data. This paper proposes the STAGE framework, which integrates the Graph Attention Network (GAT), Variational Autoencoder (VAE), and Sparse Spatiotemporal Convolutional Network (STCN), to enhance the accuracy of stock prediction and the robustness of anomaly data detection. Experimental results show that the complete STAGE framework achieved an accuracy of 85% after 20 training epochs, which is 10% to 20% higher than models with key algorithms removed. In the anomaly detection task, the STAGE framework further improved the accuracy to 95%, demonstrating fast convergence and stability. This framework offers an innovative solution for stock prediction, adapting to the complex dynamics of real-world markets.",2025
The usage of logistic regression and artificial neural networks for evaluation and predicting property-liability insurers' solvency in Egypt,"Unlike prior solvency prediction studies conducted in Egypt, this study aims to set up a real picture of companies' financial performance in the Egyptian insurance market. Therefore, 11 financial ratios commonly used by NAIC, AM BEST Company, and S & P Global Ratings were calculated for all property-liability insurance companies in Egypt from 2010 to 2020. They have been used to measure those companies' financial performance efficiency levels by comparing these ratios with the international standard limits. The financial analysis results for those companies revealed that property-liability insurers in Egypt do not have the same level of financial performance efficiency where those companies are classified into three groups: excellent, good, and poor. Furthermore, this paper investigates using the stepwise logistic regression model to determine the most factors among these selected financial ratios that influence those companies' financial performance. The results suggest that only three ratios were statistically significant predictors: Risk retention rate, Insurance account receivable to total assets, and Net profit after tax to total assets. Finally, this paper presents the multi-layers artificial neural network with a backpropagation algorithm as a new solvency prediction model with perfect classifying accuracy of 100%. The trained ANN could predict the next fiscal year with a prediction accuracy of 91.67%, and this percent is a good and favorable result comparing to other solvency prediction models used in Egypt.",2021
Hedging using reinforcement learning: Contextual k-armed bandit versus Q-learning,"The construction of replication strategies for contingent claims in the presence of risk and market friction is a key problem of financial engineering. In real markets, continuous replication, such as in the model of Black, Scholes and Merton (BSM), is not only unrealistic but is also undesirable due to high transaction costs. A variety of methods have been proposed to balance between effective replication and losses in the incomplete market setting. With the rise of Artificial Intelligence (AI), AI-based hedgers have attracted considerable interest, where particular attention is given to Recurrent Neural Network systems and variations of the Q-learning algorithm. From a practical point of view, sufficient samples for training such an AI can only be obtained from a simulator of the market environment. Yet if an agent is trained solely on simulated data, the run-time performance will primarily reflect the accuracy of the simulation, which leads to the classical problem of model choice and calibration. In this article, the hedging problem is viewed as an instance of a risk-averse contextual k-armed bandit problem, which is motivated by the simplicity and sampleefficiency of the architecture, which allows for realistic online model updates from real-world data. We find that the k-armed bandit model naturally fits to the Profit and Loss formulation of hedging, providing for a more accurate and sample efficient approach than Q-learning and reducing to the Black-Scholes model in the absence of transaction costs and risks.",2023
CPP-ELM: Cryptographically Privacy-Preserving Extreme Learning Machine for Cloud Systems,"The training techniques of the distributed machine learning approach replace the traditional methods with a cloud computing infrastructure and provide flexible computing services to clients. Moreover, machine learning-based classification methods are used in many diverse applications such as medical predictions, speech/face recognition, and financial applications. Most of the application areas require security and confidentiality for both the data and the classifier model. In order to prevent the risk of confidential data disclosure while outsourcing the data analysis, we propose a privacy-preserving protocol approach for the extreme learning machine algorithm and give private classification protocols. The proposed protocols compute the hidden layer output matrix H in an encrypted form by using a distributed multi-party computation (or cloud computing model) approach. This paper shows how to build a privacy-preserving classification model from encrypted data.",2018
Financial Risk Prediction with Multi-Round Q&A Attention Network,"Financial risk is an essential indicator of investment, which can help investors to understand the market and companies better. Among the many influencing factors of financial risk, researchers find the earnings conference call is the most significant one. Predicting financial volatility after the earnings conference call has been critical to beneficiaries, including investors and company managers. However, previous work mainly focuses on the feature extraction from the word-level or document-level. The vital structure of conferences, the alternate dialogue, is ignored. In this paper, we introduced our Multi-Round Q&A Attention Network, which brings into account the dialogue form in the first place. Based on the data of earnings call transcripts, we apply our model to extract features of each round of dialogue through a bidirectional attention mechanism and predict the volatility after the earnings conference call events. The results prove that our model significantly outperforms the previous state-of-the-art methods and other baselines in three different periods.",2020
The Study on the Credit Risk Assessment of Borrower in P2P Network of China,"On account of the rapid development of modern network technology, more and more online financial services come to being. Take P2P network as an example. Now, such financial services model in our country is taking great risk. This is mainly a study on credit risk. Based on BP neural network, P2P network platform credit risk evaluation model were built to train and simulate. The results show that the final data generated by these models are of practical value. It is capable of using P2P network platform on personal credit risk evaluation scientifically. At the end of the article, some valuable suggestions are put forward in regard to P2P network loan personal credit risk evaluation system.",2017
Heart health meets cognitive health: evidence on the role of blood pressure,"The enormous societal and financial burden of Alzheimer's disease and related dementias requires the identification of risk factors and pathways to reduce dementia risk. Blood pressure (BP) management and control is one promising area, in which data have been inconclusive. Accumulating evidence over the past 5 years shows the effectiveness of BP management interventions among older individuals at risk, most notably from the SPRINT-MIND trial. These findings have been coupled with longitudinal observational data. However, to date, the results do not concur on the optimal timing and target of BP lowering, and further study in diverse populations is needed. Given the long preclinical phase of dementia and data supporting the importance of BP control earlier in the lifecourse, long-term interventional and observational studies in ethnically and racially diverse populations, with novel imaging and blood-based biomarkers of neurodegeneration and vascular cognitive impairment to understand the pathophysiology, are needed to advance the field.",2021
Detecting Anomalies in Financial Data Using Machine Learning Algorithms,"Bookkeeping data free of fraud and errors are a cornerstone of legitimate business operations. The highly complex and laborious work of financial auditors calls for finding new solutions and algorithms to ensure the correctness of financial statements. Both supervised and unsupervised machine learning (ML) techniques nowadays are being successfully applied to detect fraud and anomalies in data. In accounting, it is a long-established problem to detect financial misstatements deemed anomalous in general ledger (GL) data. Currently, widely used techniques such as random sampling and manual assessment of bookkeeping rules become challenging and unreliable due to increasing data volumes and unknown fraudulent patterns. To address the sampling risk and financial audit inefficiency, we applied seven supervised ML techniques inclusive of deep learning and two unsupervised ML techniques such as isolation forest and autoencoders. We trained and evaluated our models on a real-life GL dataset and used data vectorization to resolve journal entry size variability. The evaluation results showed that the best trained supervised and unsupervised models have high potential in detecting predefined anomaly types as well as in efficiently sampling data to discern higher-risk journal entries. Based on our findings, we discussed possible practical implications of the resulting solutions in the accounting and auditing contexts.",2022
A risk detection framework of Chinese high-tech firms using wide & deep learning model based on text disclosure,"High-tech firms have been recognized as a major source of earnings in most of countries in the world, especially in China. A high degree of information asymmetry has led to the problem of difficult financing, high interest rates, and complicated audit procedures for high-tech firms. However, little works focus on an efficient automated framework to improve risk detection accuracy for high-tech firms. Our work proposes a new framework using wide & deep learning model with annual report text and financial data to detect risk of high-tech firms. We examine the effects of the proposed framework by comparing them with other mature classification methods utilizing real firms data in China. The results showed that the proposed framework with text improve classification performance compared to baseline methods with financial data. The rate of increase in accuracy, recall, AUC is 12.2%, 100% and 44.4%. Moreover, the results suggests that the importance of unstructured data and soft information of high-tech firms should be emphasized to improve risk detection accuracy. (C) 2021 The Authors. Published by Elsevier B.V.",2022
Artificial neural network (ANN)-based estimation of the influence of COVID-19 pandemic on dynamic and emerging financial markets,"The COVID-19 pandemic is a serious global issue destroying financial markets awfully. The proper estimation effect of COVID-19 pandemic on dynamic emerging financial markets is a big challenge due to a complex multidimensional data. However, the present study proposes a Deep Neural Network (DNN)-based multivariate regression approach with backpropagation algorithm and structural learning-based Bayesian network with constraint-based algorithm to investigate the influence of COVID-19 pandemic on the currency and derivatives markets of an emerging economy. The output shows that the COVID-19 pandemic has negatively influenced the financial markets as indicated by sharply depreciating currency value around 10 % to 12 % and reducing short-position of futures derivatives around 3 % to 5 % for currency risk hedging. The robustness estimation shows that there have probabilistic distributed between Traded Futures Derivatives Contracts (TFDC), Currency Exchange Rate (CER), and Daily Covid Cases (DCC) and Daily Covid Deaths (DCD). Moreover, the output represents that the futures derivatives market conditionally depends on the currency market volatility given percentage of COVID-19 pandemic. This study may help to policymakers of financial markets in decision-making to control CER volatility that may promote currency market stability to enhance currency market activities and boost confidence of foreign investors in extreme financial crisis circumstances.",2023
Forecasting climate transition regulatory and market risk variables with machine learning,"The financial impacts of the consequences of climate change on organisations are not always clear. Therefore, for many organisations, assessing the potential impact of climate risk remains a challenge. This piece of research is geared towards selecting the best artificial intelligence technique for modelling and forecasting the operational costs related to climate transition risk, such as direct or indirect utility consumption, including the costs of electricity and fossil fuels. These costs can be affected, especially by regulatory and market risks that are part of transition risk. We train 17 deep learning and machine learning models to forecast electricity and diesel consumption indicators, as well as the corresponding prices of these variables. Our results show an average prediction accuracy of 90.36% and emphasise the importance of using such decision support tools to analyse the financial impacts of climate risks within organisations. This calls for organisations to improve data collection and availability, as performing this kind of analysis is promising but currently remains a challenge due to the scarcity of available information.",2023
iLoRE: Dynamic Graph Representation with Instant Long-term Modeling and Re-occurrence Preservation,"Continuous-time dynamic graph modeling is a crucial task for many real-world applications, such as financial risk management and fraud detection. Though existing dynamic graph modeling methods have achieved satisfactory results, they still suffer from three key limitations, hindering their scalability and further applicability. i) Indiscriminate updating. For incoming edges, existing methods would indiscriminately deal with them, which may lead to more time consumption and unexpected noisy information. ii) Ineffective node-wise long-term modeling. They heavily rely on recurrent neural networks (RNNs) as a backbone, which has been demonstrated to be incapable of fully capturing nodewise long-term dependencies in event sequences. iii) Neglect of re-occurrence patterns. Dynamic graphs involve the repeated occurrence of neighbors that indicates their importance, which is disappointedly neglected by existing methods. In this paper, we present iLoRE, a novel dynamic graph modeling method with instant node-wise Long-term modeling and Re-occurrence preservation. To overcome the indiscriminate updating issue, we introduce the Adaptive Short-term Updater module that will automatically discard the useless or noisy edges, ensuring iLoRE's effectiveness and instant ability. We further propose the Long-term Updater to realize more effective node-wise long-term modeling, where we innovatively propose the Identity Attention mechanism to empower a Transformer-based updater, bypassing the limited effectiveness of typical RNN-dominated designs. Finally, the crucial re-occurrence patterns are also encoded into a graph module for informative representation learning, which will further improve the expressiveness of our method. Our experimental results on real-world datasets demonstrate the effectiveness of our iLoRE for dynamic graph modeling.",2023
Dynamic Portfolio Optimization via Augmented DDPG with Quantum Price Levels-Based Trading Strategy,"With the development of deep learning, Dynamic Portfolio Optimization (DPO) problem has received a lot of attention in recent years, not only in the field of finance but also in the field of deep learning. Some advanced research in recent years has proposed the application of Deep Reinforcement Learning (DRL) to the DPO problem, which demonstrated to be more advantageous than supervised learning in solving the DPO problem. However, there are still certain unsolved issues: 1) DRL algorithms usually have the problems of slow learning speed and high sample complexity, which is especially problematic when dealing with complex financial data. 2) researchers use DRL simply for the purpose of obtaining high returns, but pay little attention to the problem of risk control and trading strategy, which will affect the stability of model returns. In order to address these issues, in this study we revamped the intrinsic structure of the model based on the Deep Deterministic Policy Gradient (DDPG) and proposed the Augmented DDPG model. Besides, we also proposed an innovative risk control strategy based on Quantum Price Levels (QPLs) derived from Quantum Finance Theory (QFT). Our experimental results revealed that our model has better profitability as well as risk control ability with less sample complexity in the DPO problem compared to the baseline models.",2023
Energy financial risk early warning model based on Bayesian network,"Oil is a global, non-renewable energy source, which plays a pivotal role in the development of the global economy and the strategic reserve system. With the expansion of crude oil futures trading scale, crude oil is no longer a pure energy commodity, but is increasingly controlled by the financial market. Based on Bayesian network, this paper studies and analyzes the financial risks of non renewable energy such as oil. Finally, the prediction models of BP neural network and Bayesian network are given. Neural network is a mathematical model based on neurons, a nonlinear adaptive dynamic system formed by the connection between neurons, and based on these two models, discusses the financial risk early warning method of petroleum in non-renewable energy. The test results of this paper show that the Bayesian network and BP neural network are used for early warning analysis based on the comprehensive oil financial risk data from 1987 to 2015. The prediction results of neural network show that there is 65% correlation between the two. From the fitting results of the prediction results and real data, the fitting effect of Bayesian network is better than that of BP neural network, and the fitting success rate is as high as 80%. The Bayesian network prediction model is analyzed by using the autoregressive movement of the model itself and the time series measurement results of the data itself. The results show that the prediction model is highly reliable. Therefore, it is very necessary to adopt Bayesian network prediction model in the risk early warning of petroleum finance.(c) 2023 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).",2023
Reinforcement learning for deep portfolio optimization,"Portfolio optimization is an important financial task that has received widespread attention in the field of artificial intelligence. In this paper, a novel deep portfolio optimization (DPO) framework was proposed, combining deep learning and reinforcement learning with modern portfolio theory. DPO not only has the advantages of machine learning methods in investment decision-making, but also retains the essence of modern portfolio theory in portfolio optimization. Additionaly, it was crucial to simultaneously consider the time series and complex asset correlations of financial market information. Therefore, in order to improve DPO performance, features of assets information were extracted and fused. In addition, a novel risk-cost reward function was proposed, which realized optimal portfolio decision-making considering transaction cost and risk factors through reinforcement learning. Our results showed the superiority and generalization of the DPO framework for portfolio optimization tasks. Experiments conducted on two real-world datasets validated that DPO achieved the highest accumulative portfolio value compared to other strategies, demonstrating strong profitability. Its Sharpe ratio and maximum drawdown also performed excellently, indicating good economic benefits and achieving a trade-off between portfolio returns and risk. Additionally, the extraction and fusion of financial information features can significantly improve the applicability and effectiveness of DPO.",2024
Financial Time Series Forecasting: A Comprehensive Review of Signal Processing and Optimization-Driven Intelligent Models,"Financial time series forecasting is pivotal in various sectors such as portfolio management investment allocation and risk assessment. However, traditional methods are not suitable to provide acceptable forecasting attributes of financial data. In response, intelligent algorithms like artificial neural networks, fuzzy logic, machine and deep learning techniques have emerged as promising tools for improving forecasting accuracy. This article provides a comprehensive review of different intelligent forecasting models, highlighting their advantages and limitations. Directly feeding historical data into these models is not reliable due to the volatile, nonlinear, and non-stationary nature of financial information, along with uncertainties in numerous independent parameters. Therefore, additional feature engineering and optimal parameter selection techniques are necessary. Integrating signal processing techniques enables the extraction of useful features from noisy financial data, while optimization algorithms aid in model refinement and parameter tuning. The article also discusses performance indicators, which are crucial for identifying optimal features and parameters in forecasting models. These integrated approaches not only enhances forecasting accuracy but also provides new possibilities in decision-making processes across various sectors.",2025
Applying deep learning method in TVP-VAR model under systematic financial risk monitoring and early warning,"In order to improve the effectiveness and accuracy of financial status indicators to measure the degree of fiscal tightening, financial market situation and systemic financial risk, the logistic regression method is used to screen the target variables of the indicators. The model improves the objectivity of the selection of target variables. The model chooses 18 alternative indicators such as three-month weighted average interest rate, national real estate prosperity index, money supply M2, declared effective exchange rate and Shenzhen Component Index, and establishes the financial status index. This model validates China' s financial situation from 2013 to 2017. The results indicate that the dynamic weighted financial condition index based on time-varying parameter vector autoregressive model includes five variables: interest rate, real estate price, money supply, exchange rate and stock price, which effectively reflect the actual financial situation of China. It also proves that the degree of fiscal tightening and financial market conditions can be measured and warned in advance by changes in financial indicators. To sum up, it can be concluded that it is necessary to pay attention to the changes of interest rates, real estate prices and stock prices when monitoring the systemic financial risks in China. In order to promote early warning and effectively control financial risks, China should establish an information system and a flexible macro-prudential supervision system. This study is of great significance to the prediction and supervision of systemic financial risks in China. (C) 2020 Elsevier B.V. All rights reserved.",2021
LS-SVM for Bad Debt Risk Assessment in Enterprises,"With the development of market economy in China, the problem of bad debt becomes increasingly serious in enterprises. In this paper, a bad-debt-risk evaluation model is established based on LS-SVM classifier, using a new set of index system which combines financial factors with non-financial factors on the basis of the 5C system evaluation method. The bad debt rating is separated into four classes- normality, attention, doubt and loss through analyzing accounts payable. Then the LS-SVM classifier is trained with 220 samples which are stochastically extracted from listed companies of China in industry, and the four classes are identified by the trained classifier using 80 samples. Then, BP neural network is also used to assess the same data. The experiment results show that LS-SVM has an excellent performance on training accuracy and reliability in credit risk assessment and achieves better performance than BP neural",2008
Harnessing logic heterograph learning for financial operational risks: A perspective of cluster and thin-tailed distributions,"Financial operational risks, alongside credit and market risks, represent a primary concern for commercial banks. However, the inherent complexity of these risks, coupled with the challenges in defining and labeling operational activities, has constrained data-driven analysis in this domain. This study introduces a deep learning framework incorporating operational logic into risk identification through a heterograph embedding network (HEN). The HEN effectively condenses complex, high-dimensional operational logic heterographs into a more manageable low-dimensional space. Within this simplified space, a Density Estimation Network (DEN) is employed to pinpoint risks, drawing on the clustering properties and thin-tailed characteristics of financial data. These components are harmoniously combined through a unified objective function, designed to optimize both dimensionality reduction and classification decisions. Experimental evaluation on a real-world financial dataset reveals that the proposed framework surpasses several cutting-edge algorithms in terms of both practicality and effectiveness. More importantly, our approach is generalizable and can be extended to learn the logical connections between features across various domains.",2025
Risk Prediction for Internet Financial Enterprises by Deep Learning Algorithm and Sustainable Development of Business Transformation,"It is necessary to find new ideas of business transformation of traditional financial enterprises under the background of internet finance. Based on DL (deep learning) algorithm, the BPNN (back propagation neural network) model and vector autoregression model are used to analyze the business conflict of commercial banks among traditional financial enterprises under internet finance. The business integration point of the two is found through the impulse response analysis of the impact of the internet financial business on the traditional financial industry. Then, the DL algorithm based on BPNN is used to obtain the optimal solution of business integration, to promote the transformation of traditional financial services under the background of internet finance. The results show that there is a close correlation between internet finance and traditional financial business. The initial conflicts between the two are serious, but as time passes, they have a trend of mutual integration.",2022
Natural Language Processing and Deep Learning for Bankruptcy Prediction: An End-to-End Architecture,"Machine and Deep Learning methods are widely adopted to predict corporate bankruptcy events for their effectiveness. Bankruptcy prediction is commonly modeled as a binary classification task over accounting data where the positive label is associated with companies with a high likelihood of bankruptcy and the negative label with a low risk of failure. Most of the models mainly focus on exploiting accounting, stock market data, and data augmentation to deal with the intrinsic unbalance of this task. More recently, financial reports such as the US SEC annual reports have been investigated for feature engineering to boost the accuracy of the classification task. However, these approaches only marginally leverage Natural Language Processing advanced techniques to improve the prediction, by usually only leveraging dictionary-based approaches and word frequencies for feature engineering. These fixed features suffer from concept drift over time leading to weaker predictive models by missing a data-driven architecture to extract text disclosures from financial reports to improve the task. This paper aims to fill the gap between the bankruptcy prediction domain and the recent advances in Natural Language Processing by proposing a Transformer-based architecture that combines: a) a text summarization module that extracts text disclosures from financial reports, over time, by leveraging the self-attention mechanism and learning which contents are more valuable for the prediction in a text communication; b) a multivariate time series modeling for accounting data that is aligned and optimized along with the text module. In this way, the architecture benefits from both data sources for the prediction and ensures continual model adaptation over time. We focused on public companies listed in the American stock market with a dataset including 6190 companies from 1999 to 2018. We have deeply analyzed the contribution of the two proposed modules, the accounting time series module (Accuracy 78%) and the text disclosures module (Accuracy 81%) to finally prove that a unique model that can leverage both data sources at the same time achieves better performance (Accuracy 87.5%). The architecture also outperforms the other baselines for Recall of default events (0.84) and for type II error (16.12).",2024
A hierarchical attention-based feature selection and fusion method for credit risk assessment,"A stable financial environment is requisite for the continuous growth of the E -business market, emphasizing the importance of credit risk assessment. Generally, credit risk assessment involves evaluating the creditworthiness of the economic entity and predicting the probability of defaulting on their financial obligations. Existing works mainly focus on exploring more features from various sources to help default prediction, but tend to overlook the feature cost and feature fusion problem. In this paper, we proposed a novel credit risk assessment model based on the hierarchical attention method, characterizing the ability to manage feature acquisition cost and adaptively integrate multi -view features. Particularly, to fulfill the utility of multi -source features, three segmenting standards are proposed to categorize multi -source features into different views according to their characteristics and statistical attributes. Then, a feature -level attention mechanism is proposed to estimate feature importance and guide feature selection, while a view -level attention mechanism is proposed to aggregate view representations and produce default predictions. The proposed method is capable of enhancing crucial features in a hierarchical way and undertaking feature selection to meet feature acquisition cost, thereby boosting the model performance with feature cost awareness. Experimental results show that the proposed method can approximate the best performance with 5% of selected features, and can also achieve a 1.1% AUC improvement compared with the best baseline method over the full feature set, demonstrating our effectiveness of enhancing default prediction performance while reducing feature costs.",2024
A Novel Deterministic Probabilistic Forecasting Framework for Gold Price with a New Pandemic Index Based on Quantile Regression Deep Learning and Multi-Objective Optimization,"The significance of precise gold price forecasting is accentuated by its financial attributes, mirroring global economic conditions, market uncertainties, and investor risk aversion. However, predicting the gold price is challenging due to its inherent volatility, influenced by multiple factors, such as COVID-19, financial crises, geopolitical issues, and fluctuations in other metals and energy prices. These complexities often lead to non-stationary time series, rendering traditional time series modeling methods inadequate. Our paper presents a multi-objective optimization algorithm that refines the interval prediction framework with quantile regression deep learning in response to this issue. This framework comprehensively responds to gold's financial market dynamics and uncertainties with a screening process of various factors, including pandemic-related indices, geopolitical indices, the US dollar index, and prices of various commodities. The quantile regression deep-learning models optimized by multi-objective optimization algorithms deliver robust, interpretable, and highly accurate predictions for handling non-linear relationships and complex data structures and enhance the overall predictive performance. The results demonstrate that the QRBiLSTM model, optimized using the MOALO algorithm, delivers excellent forecasting performance. The composite indicator AIS reaches -15.6240 and -11.5581 at 90% and 95% confidence levels, respectively. This underscores the model's high forecasting accuracy and its potential to provide valuable insights for assessing future trends in gold prices. The deterministic and probabilistic forecasting framework for gold prices captures the market dynamics with the new pandemic index and comprehensively sets a new benchmark for predictive modeling in volatile market commodities like gold.",2024
Hyperbolic Online Time Stream Modeling,"The rapidly rising ubiquity and dissemination of online information such as social media text and news improve user accessibility towards financial markets, however, modeling these vast streams of irregular, temporal data poses a challenge. Such temporal streams of information show power-law dynamics, scale-free characteristics, and time irregularities that sequential models are unable to accurately model. In this work, we propose the first Hierarchical Time-Aware Hyperbolic LSTM (HTLSTM), which leverages the Riemannian manifold for encoding the scale-free nature of a sequence of text in a time-aware fashion. Through experiments on three financial tasks: stock trading, equity price movement prediction, and financial risk prediction, we demonstrate HTLSTM's applicability for modeling temporal sequences of online information. On real-world data from four global stock markets and three stock indices spanning data in English and Chinese, we make a step towards time-aware text modeling via hyperbolic geometry.",2021
Deep Portfolio Optimization via Distributional Prediction of Residual Factors,"Recent developments in deep learning techniques have motivated intensive research in machine learning-aided stock trading strategies. However, since the financial market has a highly non-stationary nature hindering the application of typical data-hungry machine learning methods, leveraging financial inductive biases is important to ensure better sample efficiency and robustness. In this study, we propose a novel method of constructing a portfolio based on predicting the distribution of a financial quantity called residual factors, which is known to be generally useful for hedging the risk exposure to common market factors. The key technical ingredients are twofold. First, we introduce a computationally efficient extraction method for the residual information, which can be easily combined with various prediction algorithms. Second, we propose a novel neural network architecture that allows us to incorporate widely acknowledged financial inductive biases such as amplitude invariance and time-scale invariance. We demonstrate the efficacy of our method on U.S. and Japanese stock market data. Through ablation experiments, we also verify that each individual technique contributes to improving the performance of trading strategies. We anticipate our techniques may have wide applications in various financial problems.",2021
BP neural network-based mobile payment risk prediction in cloud computing environment and its impact on e-commerce operation,"The purpose is to improve the accuracy of e-commerce mobile payment risk prediction, and further analyze the characteristics of mobile payment users and their impact on e-commerce activities, to solve the problem of mobile payment in different business environments. Based on the preliminary exploration of cloud computing, first, the concept of mobile payment and related theories are elaborated, and the development and operation mode of e-commerce are discussed. Mobile payment based on financial technology, online shopping and social entertainment are analysed, respectively. Based on BP neural network and data mining technology, multi-dimensional e-commerce mobile payment risk time series are analyzed, and e-commerce mobile payment risk prediction model is constructed. The comparative experiment reveals that the risk prediction deviation of e-commerce mobile payment based on BP neural network is very small, which can track the change characteristics of e-commerce mobile payment risk with high precision, and the efficiency of e-commerce mobile payment risk prediction is very high. In the cloud computing environment, mobile payment can analyze financial products and improve transaction security. Moreover, it can carry out product research and analysis, solve the risk problem under the background of online shopping, and promote the diversified development of e-commerce under the background of social entertainment.",2022
The Model and Application of the Investment Risk Comprehensive Evaluation about the Electric Power Project Based on BP Neural Network,"The power projects face the uncertain external environment, they are complex of the projects themselves and the capabilities of the designers, erectors and operator are limited, which make the risk indicators of the power projects investment are extremely complicated, including financial risk, technology risk, production risk, market risk, management risk and environmental risk. In order to evaluate the risk investment projects scientifically and accurately, according to the principle of BP neural network, this paper proposes the BP neural network model for the risk evaluation of the power project investment. The model not only can simulate the expert in evaluating the investing risk, but also avoid the subjective mistakes in the evaluation process. The investment risk evaluation of 16 power projects in National Power Company shows that the results given by this model are reliable, and this method to forecast the power project investment risk is feasible.",2007
Generative artificial intelligence algorithms in Internet of Things blockchain-based fintech management,"Research background: Big data-driven artificial Internet of Things (IoT) fintech algorithms can provide real-time personalized financial service access, strengthen risk management, and manage, monitor, and mitigate transaction operational risks by operational credit risk management, suspicious financial transaction abnormal pattern detection, and synthetic financial data-based fraud simulation. Blockchain technologies, automated financial planning and investment advice services, and risk scoring and fraud detection tools can be leveraged in financial trading forecasting and planning, cryptocurrency transactions, and financial workflow automation and fraud detection. Algorithmic trading and fraud detection tools, distributed ledger and cryptocurrency technologies, and ensemble learning and support vector machine algorithms are pivotal in predictive analytics-based risk mitigation, customer behavior and preference-based financial product and service personalization, and financial transaction and fraud detection automation. Credit scoring and risk management tools can offer financial personalized recommendations based on customer data, behavior, and preferences, in addition to transaction history, by generative adversarial and deep learning recurrent neural networks. Purpose of the article: We show that blockchain and edge computing technologies, generative artificial IoT-based fintech algorithms, and transaction monitoring and credit scoring tools can be harnessed in financial decision-making processes and loan default rate mitigation for transaction, payment, and credit process efficiency. Generative and predictive artificial intelligence (AI) algorithmic trading systems can drive coherent customer service operations, provide tailored financial and investment advice, and influence financial decision processing, while performing real-time risk assessment and financial and trading risk scenario simulation across fluctuating market conditions. Fraud and money laundering prevention tools, block- chain and financial transaction technologies, and federated and decentralized machine learning algorithms can articulate algorithmic profiling-based transaction data patterns and structures, credit assessment, loan repaying likelihood prediction, and interest rate and credit lending risk management by real-time financial pattern and economic forecast-based credit analysis across investment payment and transaction record infrastructures. Methods: Research published between 2023 and 2024 was identified and analyzed across ProQuest, Scopus, and the Web of Science databases by use of screening and quality assessment software systems such as Abstrackr, AMSTAR, AXIS, CADIMA, CASP, Catchii, DistillerSR, Eppi-Reviewer, MMAT, Nested Knowledge, PICO Portal, Rayyan, ROBIS, and SRDR+. Findings & value added: The main value added derived from the systematic literature review is that generative AI-based operational risk management, fraud detection, and transaction monitoring tools can provide personalized financial support and services and clarify financial and credit decisions and operations by financial decision-making process automation in dynamic business environments based on fraud detection capabilities and transaction data analysis and assessment. The benefits for theory and current state of the art are that credit risk and financial forecasting tools, artificial IoT-based fintech and generative AI algorithms, and algorithmic trading and distributed ledger technologies can be deployed in financial decision- making and customer behavior pattern optimization, credit score assessment, and money laundering and fraudulent payment detection. Policy implications reveal that investment management and algorithmic credit scoring tools can streamline financial activity operational efficiency, design financial planning analysis and forecasting, and carry out financial service and transaction data analysis for informed transaction decision-making and fraudulent behavior pattern and incident detection, taking into account credit history and risk evaluation and improving personalized experiences.",2024
Leveraging principles of behavioural economics to encourage patient engagement with population health screening programmes,"Cardiovascular disease is a leading cause of morbidity and mortality worldwide. We leveraged behavioural economics principles to encourage screening for cardiovascular disease risk factors. In a pilot, 60 high-risk patients were offered a complimentary home BP monitor and a lipid test through more convenient means (local lab, home phlebotomy, or self-test), along with financial incentives. Of these, 43.3% submitted the required BP readings, compared with 30.0% in a historical control group; 30.0% completed the lipid panel, versus 18.1% historically. While these results suggest that convenience and incentives can increase participation, over half of participants still did not complete the screenings, indicating a need for additional strategies to fully engage at-risk populations.",2025
DEEP NEURAL NETWORKS FOR PROBABILITY OF DEFAULT MODELLING,". In this paper we develop Deep Neural Networks for the approximation of the solution to Partial Integro-Differential Equations (PIDE) that arise in the calculation of Probability of Default functions. We consider a modelling framework in compliance with the spirit and regulations of the International Financial Reporting Standard 9 and use the resulting Deep Learning models to estimate default probabilities that can be used to solve credit risk problems. Detailed comparisons with standard numerical analysis schemes for the solutions to these PIDEs are also reported, enhancing the understanding and adding to the discussion regarding the applicability of the related Machine Learning methodologies.",2024
"How cheap talk in climate disclosures relates to climate initiatives, corporate emissions, and reputation risk","Navigating the complex landscape of corporate climate disclosures and their real impacts is crucial for managing climate-related financial risks. However, current disclosures oftentimes suffer from imprecision, inaccuracy, and greenwashing. We introduce ClimateBert CTI , a deep learning algorithm, to identify climaterelated cheap talk in MSCI World index firms' annual reports. We find that only targeted climate engagement is associated with less cheap talk. Voluntary climate disclosures are associated with more cheap talk. Moreover, cheap talk correlates with increased negative news coverage and higher emissions growth. Hence, cheap talk helps assess climate initiatives' effectiveness and anticipate reputation and transition risk exposure.",2024
"Bankruptcy Prediction: Data Augmentation, LLMs and the Need for Auditor's Opinion","Predicting bankruptcy is crucial for managing financial risk in corporations. This study emphasizes incorporating the auditor's opinion text into prediction models to improve their ability to assess financial health. These opinions provide essential insights as they offer an independent assessment, complementing other predictive inputs like the management's discussion and analysis. However, the rarity of bankruptcy cases in the data introduces a challenging issue due to severe class imbalance. To address this, we propose a method to generate synthetic positive samples using a variational autoencoder and integrate the multi-source input in a late fusion setting. We showcase that both data augmentation and using multiple textual sources improve the performance of existing models on a related benchmark dataset. Additionally, we evaluate LLMs when used for data augmentation in the proposed method and in a zero-shot prediction setting, discussing important aspects to consider when incorporating them in a predictive pipeline.",2024
RETRACTED: A Hybrid Intelligent System for Company Financial Risk Detection Based on Tree-Based Model and Deep Neural Network (Retracted Article),"At present, the process of security issuance in China has changed from examination and approval system to approval system. With the increasing stock that enters the capital market through the IPO, establishing an effective financial risk monitoring and control system of listed companies has great practical significance and application value. In the perspective of big data, this paper constructs a new practical financial early warning integration model. A total of 32,283 financial statements of 3,025 listed companies are collected from 2000 to 2017. First, this paper collected and built a financial crisis prediction database: a total of 32,283 financial statements of 3,025 listed companies occurred from year 2000 to 2017 and corresponding financial indicators including 6 primary indicators and 25 secondary indicators are collected. Next, the financial crisis model based on financial indicators is proposed and trained by the classic machine learning method such as random forest and gradient boosting decision tree. And then, through natural language processing and deep learning technology, this paper also builds a financial crisis prediction model based on financial statement text. Finally, an ensemble model is proposed and its performances are evaluated; the results indicate that the proposed ensemble model performed the best and significantly outperforms other benchmark methods for financial crisis prediction and identification, indicating that it can be employed as an intelligent identification system to enhance identification accuracy for early warning and identification of financial crisis of listed companies in China stock marketing.",2022
Optimization Trading Strategy Model for Gold and Bitcoin Based on Market Fluctuation,"As a new type of digital currency, Bitcoin is considered as future gold by various scholars. Therefore, this study considers Bitcoin and gold as a group of hedging assets to conduct investment research and it also discusses the investment rules between Bitcoin and gold: prediction of the rise and fall of Bitcoin, comparison of the characteristics of Bitcoin and gold, and the impact of the transaction procedures of Bitcoin and gold on the final trading results, and formulates trading strategies through optimization algorithms. Then, four machine learning algorithms, i.e., LSTM, BP neural network, Adaboost, and Bagging, are introduced to predict the rise and fall of gold and Bitcoin the next day, and then, the entropy weight method is used to synthesize four predicted results to ensure the robustness of the predicted results. To establish the optimal trading strategy, this study considers the maximum expected return as the goal to develop a single-objective optimization model and historical five-day price volatility as a risk factor. In this study, ant colony, simulated annealing, and genetic algorithms are used to solve the single-objective optimization model. Finally, we conclude that Bitcoin, similar to other financial assets, e.g., gold, is sensitive to shocks and volatile and possesses a relatively quiet cycle. When Bitcoin has an asymmetric impact, Bitcoin and gold can equally treat transactions.",2023
Enterprise Financial Modeling Research based on Pattern Recognition Method,"The purpose of this study is to establish a set of accurate and useful financial early warning model for enterprises. In order to achieve this goal, theoretical analysis is combined with previous studies, on the basis of enterprise own characteristic, enterprise financial early warning index system of level 3 is put forward. BP neural network is used to predict financial risk, which is one kind of pattern recognition method. Samples are selected to train the neural network, and the testing samples are used for testing the trained network to verify the accuracy of the trained network. The empirical results confirm that the proposed enterprise financial early warning model can be quite effective for enterprise financial early warning.",2015
Neural network expression rates and applications of the deep parametric PDE method in counterparty credit risk,"The recently introduced deep parametric PDE method combines the efficiency of deep learning for high-dimensional problems with the reliability of classical PDE models. The accuracy of the deep parametric PDE method is determined by the best-approximation property of neural networks. We provide (to the best of our knowledge) the first approximation results, which feature a dimension-independent rate of convergence for deep neural networks with a hyperbolic tangent as the activation function. Numerical results confirm that the deep parametric PDE method performs well in high-dimensional settings by presenting in a risk management problem of high interest for the financial industry.",2024
Generative-CNN for Pattern Recognition in Finance,"Convolutional neural networks (CNNs) have achieved considerable success across a spectrum of computer vision tasks, with applications ranging from healthcare to automated driving. Recent literature has also explored its potential utility in trading and risk management within the finance industry. Despite their versatility, CNNs are substantially constrained by their data-hungry nature. The lack of well-labeled image datasets poses a major challenge to the widespread adoption of CNNs in financial machine learning research across academia and industry. To address these concerns, this work presents Generative-CNN, a novel approach that utilizes a generative adversarial network (GAN) to synthetically generate images to enhance the performance of a CNN with applications in trading.",2024
Forecasting the direction of daily changes in the India VIX index using deep learning,"The VIX index is an indicator of the market's perception of risk, and an accurate fore-cast of the movements in VIX can be very useful for investment risk management. So, the aim of this study is to predict the day-to-day movement of the India VIX using six deep learning archi-tectures. All six architectures performed well and achieved a higher level of accuracy with minor differences than in previous studies. The findings of the study are of great relevance for assessing short-term risk as well as long-term strategies for hedgers, risk-averse investors, volatility trad-ers, investors, and financial researchers.& COPY; 2023 Published by Elsevier Ltd on behalf of Indian Institute of Management Bangalore. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/ by-nc-nd/4.0/)",2023
Modeling Low-risk Actions from Multivariate Time Series Data Using Distributional Reinforcement Learning,"In recent years, investment strategies on financial markets using deep learning have attracted a significant amount of research attention. The objective of these studies is to obtain investment action that has a low risk and increases profit. On the other hand, Distributional Reinforcement Learning (DRL) expands the action-value function to a discrete distribution in reinforcement learning, which can control risk. However, DRL has not yet been used to learn investment action. In this study, we construct a low-risk investment trading model using DRL. This model is backtested on Nikkei 225 dataset and compared with Deep Q Network (DQN). We evaluate performance in terms of final asset amounts, their standard deviation, and the Sharpe ratio. The experimental results show that the proposed DRL-based method can learn low-risk actions with increasing profit, outperforming the compared method DQN.",2020
"Risk of liquidity and contagion of the crisis on the United States, United Kingdom and euro zone money markets","The financial crisis has produced a generalized rise of the liquidity risk on the money markets. The purpose of this article is to highlight the mechanisms of contagion between the money markets of the United States, the United Kingdom and the Euro Zone. To give an account of these mechanisms, a BEKK model, in which we introduce a structural break, is adopted. Thus, this model explicitly tests the spillover effects of the liquidity risk premium on money markets. The results show that before the financial crisis (i.e. the reference period), there is a recursive propagation process between the Euro epsilon and the BP zones, a propagation process between the BP pound and the US pound areas and an obvious spread of volatilities from the EU epsilon zone towards the US$ zone;. During the crisis period, the liquidity problems start from the US money market to the UK pound and EU epsilon money markets. Copyright (c) 2011 John Wiley & Sons, Ltd.",2012
Developing Image-Based Classification Techniques to Analyse Customer Behaviour,"Banks, investment firms and other financial service providers are required to safeguard customers from unsuitable financial products under Know Your Customer (KYC) regulation, such as FCA Sect. 5.2. Recent work has proposed to model a customer's risk profile as a heatmap, which can be used to calculate a risk score by classifying the image via a CNN and extracting geometric features from it using contour detection. This provides an interpretable approach to analysing customer spending behaviour. However, there is a lack of comparative evaluation in the literature of alternative classification techniques to the heatmap representation, which is the focus of our paper. The heatmap model evaluated by this study achieved an F1 score of 94.6% when classifying heatmap geometry, far outperforming other configurations, including state-of-the-art algorithms typically employed for TSC such as HIVE-COTE, as well as alternative image-transform techniques such as Gramian angular fields. Our experiments used a transactional dataset produced by Lloyds Banking Group, a major UK retail bank, via agent-based modelling (ABM). This data was computer generated and at no point was real transactional data shared. This study shows that a grouped CNN model paired with the heatmap representation is superior to conventional time series classification and image-transform methods at classifying customer spending.",2024
Forecasting Complex Systems with Shared Layer Perceptrons,"We present a recurrent neural network topology, the Shared Layer Perceptron, which allows robust forecasts of complex systems. This is achieved by several means. First, the forecasts are multivariate, i.e., all observables are forecasted at once. We avoid overfitting the network to a specific observable. The output at time step t, serves as input for the forecast at time step t+1. In this way, multi step forecasts are easily achieved. Second, training several networks allows us to get not only a point forecast, but a distribution of future realizations. Third, we acknowledge that the dynamic system we want to forecast is not isolated in the world. Rather, there may be a multitude of other variables not included in our analysis which may influence the dynamics. To accommodate this, the observable states are augmented by hidden states. The hidden states allow the system to develop its own internal dynamics and harden it against external shocks. Relatedly, the hidden states allow to build up a memory. Our example includes 25 financial time series, representing a market, i.e., stock indices, interest rates, currency rates, and commodities, all from different regions of the world. We use the Shared Layer Perceptron to produce forecasts up to 20 steps into the future and present three applications: transaction decision support with market timing, value at risk, and a simple trading strategy.",2011
Is there a strong rationale for deferring elective surgery in patients with poorly controlled hypertension?,"Hypertension remains one of the most common avoidable medical indications for deferring elective surgery, thereby increasing both the financial and emotional burden of having an operation. Although the evidence supporting the current guidelines on management of hypertension is among the best available in any field of medicine, our knowledge on whether high blood pressure (BP) is an independent perioperative risk factor is plagued by much uncertainty. Indeed, it is still unclear whether postponing surgery on the ground of elevated preoperative BP measurements will lead to a reduction in perioperative cardiac risk. Similarly, the importance of multiple versus isolated BP measurements in predicting perioperative complications has not yet been assessed. As most studies have evaluated the predictive value of diastolic BP, the risk of perioperative cardiovascular events associated with isolated systolic hypertension remains uncertain. With no controlled evidence to address these issues, no firm recommendations can be made to improve patients' safety. These important issues now need to be addressed by modern clinical trials. (C) 2005 Lippincott Williams Wilkins.",2005
RPS: Portfolio asset selection using graph based representation learning,"Portfolio optimization is one of the essential fields of focus in finance. There has been an increasing demand for novel computational methods in this area to compute portfolios with better returns and lower risks in recent years. We present a novel computational method called Representation Portfolio Selection by redefining the distance matrix of financial assets using Representation Learning and Clustering algorithms for portfolio selection to increase diversification. RPS proposes a heuristic for getting closer to the optimal subset of assets. Using empirical results in this paper, we demonstrate that widely used portfolio optimization algorithms, such as Mean-Variance Optimization, Critical Line Algorithm, and Hierarchical Risk Parity can benefit from our asset subset selection.",2024
Electric Power Enterprise Financial Risk Management Based On The Factor Analysis And BP Network,"The comprehensive evaluation problem of electric power listed corporation has always been a focus since Market-oriented reform of the electric power industry, and financial risk evaluation play a key role to science investment decision of electric power listed corporation This paper presents a new composite forecasting method for financial risk of electric power corporation, modeling and forecasting based on Factor Analysis and Back-propagation Neural Network model. Combing reality financial data of electric power listed corporation and using Factor Analysis theory to select financial indexes, which are as modeling variables, then establishing financial risk estimation model based on Back-propagation Neural Network. Through training for the financial data, it shows that this model has a high accuracy to the results of financial risks evaluation, and it offers effective technical support to financial risk evading of electric power enterprise.",2008
Randomized Trial of an Intervention to Improve Blood Pressure Control in Stroke Survivors,"Background: We conducted the first-of-its kind randomized stroke trial in Africa to test whether a THRIVES (Tailored Hospital-based Risk reduction to Impede Vascular Events after Stroke) intervention improved blood pressure (BP) control among patients with stroke. Methods and Results: Intervention comprised a patient global risk factor control report card, personalized phone text-messaging, and educational video. Four hundred patients recruited from 4 distinct medical facilities in Nigeria, aged >= 18 years with stroke-onset within one-year, were randomized to THRIVES intervention and control group. The control group also received text messages, and both groups received modest financial incentives. The primary outcome was mean change in systolic BP (SBP) at 12 months. There were 36.5% females, 72.3% with ischemic stroke; mean age was 57.2 +/- 11.7 years; 93.5% had hypertension and mean SBP was 138.33 (23.64) mm Hg. At 12 months, there was no significant difference in SBP reduction from baseline in the THRIVES versus control group (2.32 versus 2.01 mm Hg, P=0.82). In an exploratory analysis of subjects with baseline BP >140/90 mm Hg (n=168), THRIVES showed a significant mean SBP (diastolic BP) decrease of 11.7 (7.0) mm Hg while control group showed a significant mean SBP (diastolic BP) decrease of 11.2 (7.9) mm Hg at 12 months. Conclusions: THRIVES intervention did not significantly reduce SBP compared with controls. However, there was similar significant decrease in mean BP in both treatment arms in the subgroup with baseline hypertension. As text-messaging and a modest financial incentive were the common elements between both treatment arms, further research is required to establish whether these measures alone can improve BP control among stroke survivors.",2019
Research on the Application of Big Data Intelligence Technology in the Optimization of Accounts Receivable Management of E-commerce Enterprises Under the Financial Sharing Mode,"Accounts receivable management has always been an important part of the financial management of the financial sharing center. However, due to manual operation, problems like long working hours, uncontrollable errors and low efficiency of invoicing still exist. To solve this problem, we study K-means clustering method to grade customer credit, and use BP model to improve the clustering algorithm. Then, we study BP model to establish enterprise risk prediction model. Finally, we use RPA to make the billing process and reconciliation as well as write-off process optimized in accounts receivable. Through the above operations, an optimized model of account receivable management of e-commerce enterprises based on big data intelligent technology has been built. According to experimental analysis, the accuracy rate of risk prediction of e-commerce enterprise A is 95.63%. After applying the optimized management model, the ratio of accounts receivable balance to current assets has decreased from 34.3% to 28.5%. Studying and constructing models can effectively optimize corporate financial management and play a positive role in the stable development of enterprises. Applying this model to practical teaching can bring new vitality to the practical teaching of vocational education and provide new teaching methods for schools. The limitations of traditional accounts receivable management limit the effectiveness of teaching for financial students. This model effectively optimizes the management mode and brings more skilled knowledge to students.",2023
What do the AI methods tell us about predicting price volatility of key natural resources: Evidence from hyperparameter tuning,"Volatility plays a significant role in pricing derivatives, managing portfolio risk, and using hedging strategies in the financial markets. As a result, it is imperative to precisely estimate the volatility of key natural resources, including crude oil, gold, copper, natural gas, and silver. The likelihood of some countries' budget deficits exceeding permissible levels increased due to recent uncertainties brought on by geo-political threats. This article employs a hybrid model of LSTM-GJR-GARCH (1,1) with hyperparameter tuning to forecast the volatility of the prices of significant natural resources using daily closing prices for crude oil, natural gas, silver, copper, and gold from January 2012 to July 2022. Our results demonstrate that, compared to utilising standard LSTM-GJR-GARCH, employing hyperparameter adjustment increases volatility predictions by an average of 40%-70%. We also looked at the connection between the geo-political risk index and the overall connectedness of natural resources. Our findings suggest that geo-political risk uncertainty does not account for the overall intercon-nectedness of natural resources' prices. Because they may better understand future volatility and manage their portfolios and budgets by estimating the price volatility of natural resources, our findings are important for politicians, governments, and investors.",2023
Design of enterprise financial performance prediction model based on artificial intelligence algorithm,"With the rapid and sustainable development of China's economy, enterprises are faced with the dual challenges of structural and cyclical factors, and the uncertainty of business operations and the intensity of competition are getting higher and higher. Therefore, stakeholders will pay close attention to the company's financial status. Based on this background, forecasting and evaluating the company's financial performance has important research value and significance for realizing the sustainable development of the company. BP neural network can automatically learn historical experience from data samples, and automatically estimate the function that can best describe the law of sample data. Therefore, this paper first analyzes the basic principles of BP neural network and artificial intelligence technology, and then evaluates its benefits, anti-risk ability, development ability and turnover ability, and designs the financial performance prediction and evaluation model from the above four perspectives to evaluate the 12 of the index system. Two secondary indicators are used as the input vector, and the comprehensive performance score is used as the output vector to create the BP neural network model. Finally, using the data of four companies as test samples, model training and simulation verification are carried out on the comprehensive performance of the sample companies, and the comprehensive performance of the sample companies is analyzed and explained according to the comparison of the prediction results. The results show that the prediction and evaluation method of enterprise financial performance based on BP neural network is feasible. In this paper, the artificial intelligence algorithm is introduced into the design of the financial prediction model of enterprise performance and efficiency by studying the artificial intelligence algorithm, so as to effectively assist the enterprise management.",2023
Estimating the Value-at-Risk by Temporal VAE,"Estimation of the value-at-risk (VaR) of a large portfolio of assets is an important task for financial institutions. As the joint log-returns of asset prices can often be projected to a latent space of a much smaller dimension, the use of a variational autoencoder (VAE) for estimating the VaR is a natural suggestion. To ensure the bottleneck structure of autoencoders when learning sequential data, we use a temporal VAE (TempVAE) that avoids the use of an autoregressive structure for the observation variables. However, the low signal-to-noise ratio of financial data in combination with the auto-pruning property of a VAE typically makes use of a VAE prone to posterior collapse. Therefore, we use annealing of the regularization to mitigate this effect. As a result, the auto-pruning of the TempVAE works properly, which also leads to excellent estimation results for the VaR that beat classical GARCH-type, multivariate versions of GARCH and historical simulation approaches when applied to real data.",2023
Tensor Processing Units for Financial Monte Carlo,"Monte Carlo methods are critical to many routines in quantitative finance such as derivatives pricing, hedging and risk metrics. Unfortunately, Monte Carlo methods are very computationally expensive when it comes to running simulations in high-dimensional state spaces where they are still a method of choice in the financial industry. Recently, Tensor Processing Units (TPUs) have provided considerable speedups and decreased the cost of running Stochastic Gradient Descent (SGD) in Deep Learning. After highlighting computational similarities between training neural networks with SGD and simulating stochastic processes, we ask in the present paper whether TPUs are accurate, fast and simple enough to use for financial Monte Carlo. Through a theoretical reminder of the key properties of such methods and thorough empirical experiments we examine the fitness of TPUs for option pricing, hedging and risk metrics computation. In particular we demonstrate that, in spite of the use of mixed precision, TPUs still provide accurate estimators which are fast to compute when compared to GPUs. We also show that the Tensorflow programming model for TPUs is elegant, expressive and simplifies automated differentiation.",2020
Research on Credit Risk Assessment in Commercial Bank Based on Information Integration,"Credit risk is the main risk faced by commercial bank during operation, how to manage credit risk is a focus for financial specialists. Therefore effective assessment of credit risk is very important. The risks faced by banks during operation can be regarded as a kind of research of uncertain problems' study. The essence of multi-sensor data integration is as follows: to have a best decision according to much information from different sensors. A kind of credit risk assessment model based on information integration is developed depending on the idea of multi-sensor information integration. This model includes three algorithms, as follows: BP neural network, SVM and DS evidence theory. This model has not only the classifying capacity of BP neural network and SVM, but also the decision ability of DS evidence theory. The essence of the model has two key steps, first we can obtain elementary decision, then we depend on DS evidence theory has a integration of processed outputs data by BP neural network and SVM. Depending on some data of certain bank, we have a simulation aiming at three models: BP model, SVM model and new developed model. The results show the developed new model can obtain better assessment compared with two models at same conditions.",2009
Leveraging deep survival models to predict quality of care risk in diverse hospital readmissions,"Hospital readmissions rate is reportedly high and has caused huge financial burden on health care systems in many countries. It is viewed as an important indicator of health care providers' quality of care. We examine the use of machine learning-based survival analysis to assess quality of care risk in hospital readmissions. This study applies various survival models to explore the risk of hospital readmissions given patient demographics and their respective hospital discharges extracted from a health care claims dataset. We explore advanced feature representation techniques such as BioBERT and Node2Vec to encode high-dimensional diagnosis code features. To our knowledge, this study is the first to apply deep-learning based survival-analysis models for predicting hospital readmission risk agnostic of specific medical conditions and a fixed window for readmission. We found that modeling the time from discharge date to readmission date as a Weibull distribution as in the SparseDeepWeiSurv model yields the best discriminative power and calibration. In addition, embedding representations of the diagnosis codes do not contribute to improvement in model performance. We find dependency of each model's performance on the time point at which it is evaluated. This time dependency of the models' performance on the health care claims data may necessitate a different choice of model in quality of care issue detection at different points in time. We show the effectiveness of deep-learning based survival-analysis models in estimating the quality of care risk in hospital readmissions.",2023
STOCK MOVEMENT PREDICTION THAT INTEGRATES HETEROGENEOUS DATA SOURCES USING DILATED CAUSAL CONVOLUTION NETWORKS WITH ATTENTION,"The purpose of this research is to develop a high performing model for stock movement prediction utilizing financial indicators and news data. Until recently, the majority of prediction models have employed only the financial indicators, but they possess the risk of missing unconventional agitators that can be derived from other heterogeneous sources. To address this, few research studies began to explore the use of news data and other social features along with financial indicators. In this work, we propose a novel integrative approach to effectively blend views from the news and financial time series. We generate event-knowledge representations from news data by capturing direct and inverse relationships among event tuples, and then apply attention mechanism to infer inter-day relationships among the representations. To capture temporal dynamics of financial indicators, we further integrate an attention augmented dilated causal convolutional network. We report empirically that our model achieves a substantial 5% improvement from 68.81% to 74.29% in stock movement prediction for the Standard & Poor's 500 (S&P500) index and companies over existing models.",2020
Deep Nonlinear Ensemble Framework for Stock Index Forecasting and Uncertainty Analysis,"Stock index forecasting plays an important role in avoiding risk and increasing returns for financial regulators and investors. However, due to the volatility and uncertainty of the stock market, forecasting stock indices accurately is challenging. In this paper, a deep nonlinear ensemble framework is proposed for stock index forecasting and uncertainty analysis. (1) Singular spectrum analysis (SSA) is utilized to extract features from a raw stock index and eliminate the interference. (2) Enhanced weighted support vector machine (EWSVM) is proposed for forecasting each component that is decomposed, of which the penalty weights are based on the time order and the hyperparameters are optimized using the simulated annealing algorithm. (3) Recurrent neural network (RNN) is used to integrate the forecast of each component into the final point forecast. (4) Gaussian process regression (GPR) is applied to obtain the interval forecast of the original stock index. Two practical cases (Nikkei 225 Index, Japan and Hang Seng Index, Hong Kong, China) are utilized to evaluate the performance of the proposed model. In terms of the results of point forecasting, the MAE, R-2, MAPE, and RMSE of Nikkei 225 Index are 66.0745, 0.9972, 0.0066, and 80.0381, and those of Hang Seng Index are 79.2145,0.9968, 0.0073, and 96.7740. In terms of the results of interval forecasting, the CP95% , MWP95% , and MC95% of Nikkei 225 Index are 0.89979, 0.05746, and 0.06385, and those of Hang Seng Index are 0.97985, 0.28223, and 0.28803. Forecasting stock indices accurately is crucial for investment decision and risk management and is extremely meaningful to investors and financial regulators. In this paper, the SSA-EWSVM-RNN-GPR model is used to forecast the closing prices of stock indices, and compared with eight benchmark models, the proposed SSA-EWSVM-RNN-GPR model can be an effective tool for both point and interval forecasting of stock indices.",2021
Deep Learning-Based Risk Prediction in Power Sector Financial Management Using Transformer and Actor-Critic Reinforcement Learning,"Precise short-term electricity demand forecasting is crucial for the grid's operation and reliability management, while long-term forecasting is for future energy policymaking. However, the nonlinear and stochastic nature of economic and environmental impact on electricity demand is a great challenge for the forecasting models. Current time series forecasting models work on the historical demand and price data and ignore the driving economic and environmental features. In this study, we developed an Actor-Critic Reinforcement Learning model named Attention Deterministic Policy Gradient (ADPG) that employs the Transformer as a Critic network to leverage the advantage of self-attention to learn complex patterns over longer time horizon information dependencies for forecasting the electricity demand and price. Second, it introduces the multi-step year-ahead and day-ahead forecasting, and one-step hour-ahead forecasting for the long-term and short-term demand and price prediction based on the historical time series electricity demand and price data along with the prices of major electricity sources and economic features which drive the electricity price, and environmental features which impact the electricity demand. A comprehensive comparison between the ADPG and other RL and supervised forecasting models is also provided via different evaluation metrics. Results show that Transformer is better capable of forecasting due to its ability to learn longer dependencies. Against the hour-ahead actual demand and price, forecasting with the ADPG has reduced the demand and price difference between predicted and actual values to 0.17% and 2.06% respectively, as compared to 0.63% demand and 4.21% price difference in day-ahead prediction. In the year-ahead forecast, ADPG shows a 3.84% demand and a 5.99% price difference between the actual demand and price. All the other models remain way behind in year-ahead and day-ahead forecasts but come closer in the hours-ahead forecast, but remain below ADPG.",2024
NumHTML: Numeric-Oriented Hierarchical Transformer Model for Multi-Task Financial Forecasting,"Financial forecasting has been an important and active area of machine learning research because of the challenges it presents and the potential rewards that even minor improvements in prediction accuracy or forecasting may entail. Traditionally, financial forecasting has heavily relied on quantitative indicators and metrics derived from structured financial statements. Earnings conference call data, including text and audio, is an important source of unstructured data that has been used for various prediction tasks using deep earning and related approaches. However, current deep learning-based methods are limited in the way that they deal with numeric data; numbers are typically treated as plain-text tokens without taking advantage of their underlying numeric structure. This paper describes a numeric-oriented hierarchical transformer model (NumHTML) to predict stock returns, and financial risk using multi-modal aligned earnings calls data by taking advantage of the different categories of numbers (monetary, temporal, percentages etc.) and their magnitude. We present the results of a comprehensive evaluation of NumHTML against several state-of-the-art baselines using a real-world publicly available dataset. The results indicate that NumHTML significantly outperforms the current state-of-the-art across a variety of evaluation metrics and that it has the potential to offer significant financial gains in a practical trading context.",2022
RETRACTED: Financial Default Risk Prediction Algorithm Based on Neural Network under the Background of Big Data (Retracted Article),"With the macroeconomy entering a new normal, many new problems are exposed in all walks of life, and the risk of default in the financial sector is also being exposed at an accelerated pace. In the context of big data, internet finance, as an important part of the financial market, also faces many risks in the process of its rapid development. Reasonable, scientific, and effective prediction and prevention of financial default risk have become a key link in the process of risk management practice in the nancial industry. Based on the powerful prediction function of the neural network, this paper combined neural network and chaos theory to construct a chaotic RBF neural network. It was applied to financial default risk prediction, which made the prediction accuracy and efficiency higher.The chaotic neural network solves the shortcomings of unstable prediction in the basic neural network and can comprehensively and accurately predict the financial default risk, so as to take measures to prevent risks. The experimental results of this paper show that the accuracy rate of the chaotic RBF neural network reaches 95%, while the accuracy rates of the BP neural network and the RBF neural network are 67% and 78%, respectively. Although the prediction accuracy of these two methods is also high, it is still not as high as the chaotic RBF neural network. Therefore, it is very meaningful to choose the chaotic RBF neural network to predict financial default risk in this paper.",2022
The Investment Risk early-warning system Research on Hotel and Tourism Enterprises,"This article selects the data of 28 hotel and tourism enterprises on A-shares in china. The investment risk early-warning system construction is based on the information entropy method and the BP neural network. The results show that most of Chinese hotel and tourism enterprises have a high level of investment risk due to the effects of financial crisis and operation, and all of them need to enhance prevention measures.",2011
"Psychosocial, hemostatic, and inflammatory correlates of delayed poststress blood pressure recovery","Objective: Delayed poststress cardiovascular recovery has been associated with cardiovascular disease risk. This study assessed relationships between systolic blood pressure (BP) recovery, psychosocial risk factors, and delayed recovery of inflammatory and hemostatic variables. Method: Data were analyzed from 228 middle-aged men and women from the Whitehall Psychobiology study who performed color/word and mirror-tracing tasks. Systolic BP recovery was assessed as the difference between baseline and levels recorded 40 to 45 minutes poststress. Associations were analyzed with socioeconomic markers (grade of employment, education, income), psychosocial factors (social isolation, hostility, mental health, financial strain), and recovery of heart rate, heart rate variability, von Willebrand factor, factor VIII clotting activity, plasma fibrinogen, and plasma viscosity. Results: Systolic BP was on average 6.19 +/- 9.6 mm Hg higher on recovery than baseline. Delayed BP recovery was associated with lower grade of employment, lower education and lower income independently of age, gender, and systolic BP stress reactivity. Delayed BP recovery was related to social isolation and poor mental health independently of age, gender, socioeconomic position, and task reactivity. Delayed systolic BP recovery was also associated with delayed recovery in diastolic BP, heart rate, factor VIII, and plasma viscosity but not delayed heart rate variability recovery, independently of age, gender, body mass, and task reactivity. Conclusion: Socioeconomic and psychosocial risk factors for cardiovascular disease are related to delays in poststress recovery. Delayed systolic BP recovery may be a marker for prolonged responses in hemostatic variables that have a direct influence on cardiovascular disease pathogenesis.",2006
Using Artificial Intelligence to Predict the Financial Impact of Climate Transition Risks Within Organisations,"Addressing climate change represents one of the most pressing challenges for organisations in developing nations. This is particularly relevant for companies navigating the shift towards a low-carbon economy. This research leverages artificial intelligence (AI) methodologies to evaluate the financial implications of climate transition risks, encompassing both direct and indirect energy usage, including expenditures on electricity and fossil fuels. Advanced machine learning (ML) and deep learning (DL) models are employed to predict electricity and diesel consumption trends along with their associated costs. Findings from this study indicate an average prediction accuracy of 90.36%, underscoring the value of these tools in supporting organisational decision making related to climate transition risks. The study lays a foundation for comprehending not only the added costs linked to climate risks but also the potential advantages of transitioning to a low-carbon economy, particularly from an energy-focused perspective. Additionally, the proposed climate transition risk adjustment factor offers a framework for visualising the financial impacts of scenarios outlined by the Network for Greening the Financial System.",2024
Pragmatic considerations for fostering reproducible research in artificial intelligence,"Artificial intelligence and deep learning methods hold great promise in the medical sciences in areas such as enhanced tumor identification from radiographic images, and natural language processing to extract complex information from electronic health records. Scientific review of AI algorithms has involved reproducibility, in which investigators share protocols, raw data, and programming codes. Within the realm of medicine, reproducibility introduces important challenges, including risk to patient privacy, challenges in reproducing results, and questions regarding ownership and financial value of large medical datasets. Scientific review, however, mandates some form of resolution of these inherent conflicts. We propose several approaches to permit scientific review while maintaining patient privacy and data confidentiality.",2019
Stable Stock Market Prediction Using NARX Algorithm,"Computational technologies have offered faster and efficient solutions to many diverse areas including the financial sector. In the financial market, the advancements in computational field have been mainly achieved through the use of neural networks and machine learning tools that delivered a number of financial applications. These applications include: stock market prediction, bankruptcy prediction, risk assessment etc. Thus, in this paper, we are developing a technique to predict the stock market index for the Dow Jones using deep learning algorithms. We propose a model based on an adaptive NARX neural network that can predict the closing price of a moderately stable market. In our model, non-linear auto regressive exogenous input model inserts delays into the input as well as the output acting as memory slots thereby raising the accuracy of the prediction. This model uses a time series analysis to improve the prediction accuracy. In addition, Levenberg-Marquardt algorithm has been used for training the network. The accuracy of the model is determined by the mean squared error between the predicted and the actual prices.",2018
A Novel Risk Control Method for Commercial Bank,"On the basis of depth study of commercial bank credit risk control model literature, this paper introduced the concepts of credit risk and credit risk control. We research the main influencing factors of commercial bank credit risk control scientifically by artificial neural network theory, and then set a commercial bank credit risk control index system which contains 3 levels of 27 indexes. Improved BP Neural Networks is selected as the commercial bank credit risk control model on the basis of comparison among representative models. Finally, MATLAB software is used for empirical analysis with 144 companies' financial data. The results show that the discriminate accuracy rate of this model is higher than the standard BP neural network and Logistic regression model, which proves that this model could effectively control the credit risk of commercial banks corporate customers. The results of this research provides a useful method for the commercial bank credit risk control and has a certain reference.",2016
"A Systematic Approach to Portfolio Optimization: A Comparative Study of Reinforcement Learning Agents, Market Signals, and Investment Horizons","This paper presents a systematic exploration of deep reinforcement learning (RL) for portfolio optimization and compares various agent architectures, such as the DQN, DDPG, PPO, and SAC. We evaluate these agents' performance across multiple market signals, including OHLC price data and technical indicators, while incorporating different rebalancing frequencies and historical window lengths. This study uses six major financial indices and a risk-free asset as the core instruments. Our results show that CNN-based feature extractors, particularly with longer lookback periods, significantly outperform MLP models, providing superior risk-adjusted returns. DQN and DDPG agents consistently surpass market benchmarks, such as the S&P 500, in annualized returns. However, continuous rebalancing leads to higher transaction costs and slippage, making periodic rebalancing a more efficient approach to managing risk. This research offers valuable insights into the adaptability of RL agents to dynamic market conditions, proposing a robust framework for future advancements in financial machine learning.",2024
Novel hybrid model based on echo state neural network applied to the prediction of stock price return volatility,"The prediction of stock price return volatilities is important for financial companies and investors to help to measure and managing market risk and to support financial decision-making. The literature points out alternative prediction models - such as the widely used heterogeneous autoregressive (HAR) specification - which attempt to forecast realized volatilities accurately. However, recent variants of artificial neural networks, such as the echo state network (ESN), which is a recurrent neural network based on the reservoir computing paradigm, have the potential for improving time series prediction. This paper proposes a novel hybrid model that combines HAR specification, the ESN, and the particle swarm optimization (PSO) metaheuristic, named HAR-PSO-ESN, which combines the feature design of the HAR model with the prediction power of ESN, and the consistent PSO metaheuristic approach for hyperparameters tuning. The proposed model is benchmarked against existing specifications, such as autoregressive integrated moving average (ARIMA), HAR, multilayer perceptron (MLP), and ESN, in forecasting daily realized volatilities of three Nasdaq (National Association of Securities Dealers Automated Quotations) stocks, considering 1-day, 5-days, and 21-days ahead forecasting horizons. The predictions are evaluated in terms of r-squared and mean squared error performance metrics, and the statistical comparison is made through a Friedman test followed by a post-hoc Nemenyi test. Results show that the proposed HAR-PSO-ESN hybrid model produces more accurate predictions on most of the cases, with an average R-2 (coefficient of determination) of 0.635, 0.510, and 0.298, an average mean squared error of 5.78 x 10(-8,) 5.78 x 10(-8), and 1.16 x 10(-) (7), for 1, 5, and 21 days ahead on the test set, respectively. The improvement is statistically significant with an average rank of 1.44 considering the three different datasets and forecasting horizons.",2021
Research on Real Estate Appraisal Method Based on Feature Engineering and BP Neural Network,"With the rapid development and maturity of China's real estate industry, the financial risk of the real estate industry is crucial as the banking financial risk and the real estate mortgage evaluation system of the real estate market. Based on the GIS theme crawler framework, this paper collects data on related websites and combines the price theory of residential real estate to establish a Hedonic commodity housing price influencing factor model. The results of goodness-of-fit test and analysis of variance are performed on the various indicators of commodity housing. In order to study the influence of different factors on the price of commercial housing, and scientifically select the influence indicators that affect the price of commercial housing. According to the implementation steps of BP(Back Propagation) neural network prediction, explore the application of BP neural network in predicting the price of commercial housing in Hefei, obtain the price prediction value of commercial housing, and achieve high fitting accuracy. It has a certain guiding effect on the research of commercial housing prices in Hefei.",2021
Deep Learning-Based Model for Financial Distress Prediction,"Predicting bankruptcies and assessing credit risk are two of the most pressing issues in finance. Therefore, financial distress prediction and credit scoring remain hot research topics in the finance sector. Earlier studies have focused on the design of statistical approaches and machine learning models to predict a company's financial distress. In this study, an adaptive whale optimization algorithm with deep learning (AWOA-DL) technique is used to create a new financial distress prediction model. The goal of the AWOA-DL approach is to determine whether a company is experiencing financial distress or not. A deep neural network (DNN) model called multilayer perceptron based predictive and AWOA-based hyperparameter tuning processes are used in the AWOA-DL method. Primarily, the DNN model receives the financial data as input and predicts financial distress. In addition, the AWOA is applied to tune the DNN model's hyperparameters, thereby raising the predictive outcome. The proposed model is applied in three stages: preprocessing, hyperparameter tuning using AWOA, and the prediction phase. A comprehensive simulation took place on four datasets, and the results pointed out the supremacy of the AWOA-DL method over other compared techniques by achieving an average accuracy of 95.8%, where the average accuracy equals 93.8%, 89.6%, 84.5%, and 78.2% for compared models.",2025
Risk assessment method for guaranteeing safety in the train control system,"Recently, failure of equipment has been linked directly to human casualties or financial losses from the increasing use of train control equipment utilizing computers. These systems have to progress to guarantee safety during the system life-cycle. In this paper, we examine the methods for risk analysis and assessment of safety activities and propose an optimized method for risk estimation. In the comparison of the risk graph and the risk matrix method for safety estimation, the proposed BP (Best Practice)-risk method combines the most beneficial properties of commonly used approaches.",2007
Credit risk evaluation model based on self-organizing competitive network,"The paper first uses the method of principal component analysis to extract characteristic indexes from 7 financial ratios of management status of the applicants: debt ratio, liquidity ratio, quick ratio, net profit margin of principal business, return on equity, deposit turnover, accounts receivable turnover. Then it is utilized extracted the characteristic indexes to establish two-dimension credit-risk evaluation model based on self-organizing competitive network. The model is used to separate the 80 applicants of a commercial bank of our country into two patterns, which are credit good applicants and credit bad applicants respectively. The research shows that, the classification accuracy rate of the credit-risk evaluation model based on self-organization competitive network is 98.75%. The result is the same with the literature [11] which established the credit-risk evaluation model based on BP algorithm. The classification accuracy rate of the BP algorithm is also 98.75%. But from the part of the view of the algorithm, the convergence speed of the algorithm of the self-organization competitive network is fast than that of the BP algorithm so that it is better than the BP algorithm.",2007
Empirical Test of Credit Risk Assessment of Microfinance Companies Based on BP Neural Network,"In recent years, the chaos of internet finance has occurred frequently, especially P2P, with high risks. As a kind of financial innovation, small loan companies are challenging to avoid alone, and the issue of credit risk is also highly valued. This study selects the loan records of a small loan company (a daily loan record from September 1, 2016 to July 1, 2021 has seven indicators, each of which has 21299 data). It uses MATLAB programming to test the correctness of risk indicator selection and the accuracy of BP neural network classification and identification results. This study obtains the corresponding risk value. According to the corresponding risk value, the newly applied loans are classified, that is, rated, to verify the effectiveness and applicability of this method. Therefore, BP neural network has strong applicability, generalization ability, and portability and is an effective method for small loan companies to guide credit risk assessment.",2023
Efficiency of corporate debt financing based on machine learning and convolutional neural network,"For the digital age today, the attack of financial data has a great risk, so it is necessary to establish several specific procedures to ensure the security and privacy of our financial data. To consider the security and reliability of financial data, we should consider the security of financial data transaction. Using the form of nodes to retain the copy data of financial accounting, in this way to prevent the failure of the network. At present, a new type of network data backup method is proposed, which can be applied to financial transactions at the present stage. Using machines to classify and distribute financial accounts and backup data on each node, assuming that one node's backup fails, it will not affect the failure of adjacent nodes. No longer afraid of losing transaction data and other problems. The system is backed up by convolution neural network (CNN) and ledger. It also includes backup of credit and debit transactions and backup of transaction ID mode in timestamp and simulation.It is used to ensure the classification of accounts, including block information of chain area, hash value of previous block and latter block, etc.",2021
Quantitative study of storm surge risk assessment in an undeveloped coastal area of China based on deep learning and geographic information system techniques: a case study of Double Moon Bay,"Storm surges are a common natural hazard in China's southern coastal area which usually cause a great loss of human life and financial damages. With the economic development and population concentration of coastal cities, storm surges may result in more impacts and damage in the future. Therefore, it is of vital importance to conduct risk assessment to identify high-risk areas and evaluate economic losses. However, quantitative study of storm surge risk assessment in undeveloped areas of China is difficult, since there is a lack of building character and damage assessment data. Aiming at the problem of data missing in undeveloped areas of China, this paper proposes a methodology for conducting storm surge risk assessment quantitatively based on deep learning and geographic information system (GIS) techniques. Five defined storm surge inundation scenarios with different typhoon return periods are simulated by the coupled FVCOM-SWAN (Finite Volume Coastal Ocean Model-Simulating WAves Nearshore) model, the reliability of which is validated using official measurements. Building footprints of the study area are extracted through the TransUNet deep learning model and remote sensing images, while building heights are obtained through unoccupied aerial vehicle (UAV) measurements. Subsequently, economic losses are quantitatively calculated by combining the adjusted depth-damage functions and overlaying an analysis of the buildings exposed to storm surge inundation. Zoning maps of the study area are provided to illustrate the risk levels according to economic losses. The quantitative risk assessment and zoning maps can help the government to provide storm surge disaster prevention measures and to optimize land use planning and thus to reduce potential economic losses in the coastal area.",2024
A study of Taiwan's issuer credit rating systems using support vector machines,"By providing credit risk information, credit rating systems benefit most participants in financial markets, including issuers, investors, market regulators and intermediaries. In this paper, we propose an automatic classification model for issuer credit ratings, a type of fundamental credit rating information, by applying the support vector machine (SVM) method. This is a novel classification algorithm that is famous for dealing with high dimension classifications. We also use three new variables: stock market information, financial support by the government, and financial support by major shareholders to enhance the effectiveness of the classification. Previous research has seldom considered these variables. The data period of the input variables used in this study covers three years, while most previous research has only considered one year. We compare our SVM model with the back propagation neural network (BP), a well-known credit rating classification method. Our experiment results show that the SVM classification model performs better than the BP model. The accuracy rate (84.62%) is also higher than previous research. (c) 2005 Elsevier Ltd. All rights reserved.",2006
Readmission Prediction for Patients with Heterogeneous Medical History: A Trajectory-Based Deep Learning Approach,"Hospital readmission refers to the situation where a patient is re-hospitalized with the same primary diagnosis within a specific time interval after discharge. Hospital readmission causes $26 billion preventable expenses to the U.S. health systems annually and often indicates suboptimal patient care. To alleviate those severe financial and health consequences, it is crucial to proactively predict patients' readmission risk. Such prediction is challenging because the evolution of patients' medical history is dynamic and complex. The state-of-the-art studies apply statistical models which use static predictors in a period, failing to consider patients' heterogeneous medical history. Our approach - Trajectory-BAsed DEep Learning (TADEL) - is motivated to tackle the deficiencies of the existing approaches by capturing dynamic medical history. We evaluate TADEL on a five-year national Medicare claims dataset including 3.6 million patients per year over all hospitals in the United States, reaching an F1 score of 87.3% and an AUC of 88.4%. Our approach significantly outperforms all the state-of-the-art methods. Our findings suggest that health status factors and insurance coverage are important predictors for readmission. This study contributes to IS literature and analytical methodology by formulating the trajectory-based readmission prediction problem and developing a novel deep-learning-based readmission risk prediction framework. From a health IT perspective, this research delivers implementable methods to assess patients' readmission risk and take early interventions to avoid potential negative consequences.",2022
National treatment guidelines poorly achieved among older subjects with type 2 diabetes - call to action!,"Objective: To assess risk factors and factors associated with nonachievement of the treatment target levels among 75-year-old Finns with type 2 diabetes (T2D). Design: Cross-sectional study. Setting: Outpatient. Subjects: Seventy-five-year-old participants of the Turku Senior Health Clinic Study (N = 1296) with T2D (n = 247). Main outcome measures: Nonachievement of fasting blood glucose (FBG), low-density lipoprotein (LDL-C), and blood pressure (BP) levels set by the national treatment guidelines. Results: Nonachievement rates of FBG, BP and LDL-C were 47%, 85%, and 47%, respectively. Non-usage of T2D medication was negatively (adjusted OR 0.38, 95% CI 0.16-0.88) and central obesity positively (1.88, 1.09-3.24) related to nonachievement of FBG target level; alcohol use was positively (3.71, 1.04-13.16) and decreased selfrated health negatively (0.34, 0.12-0.97) related to the nonachievement of BP target level. Nonachievement of LDL-C target level was positively related to poor financial status (3.50, 1.19-10.28) and non-use of lipid-lowering medication (7.70, 4.07-14.56). Conclusions: Nonachievement rates of the national treatment goals were high among older T2D patients, and nonachievement was related to use of medication, obesity, alcohol use, poor health, and poor financial status. We emphasize the importance of customized target setting by risk factor levels and active treatment.",2024
An entity-weights-based convolutional neural network for large-sale complex knowledge embedding,"Knowledge graph (KG) has increasingly been seen as a significant resource in financial applications (e.g., risk control, auditing and anti-fraud). However, there are few prior studies that focus on multi-relational circles, extracting additional information under the completed KG and selecting similarity measures for knowledge representation. In this paper, we introduce multi-relational circles and propose a novel embedding model, which considers entity weights calculated by PageRank algorithm to improve TransE method. In order to extract additional information, we use entity weights to convert embeddings into an on-map mining problem, and propose a model called CNNe based on entity weights and a convolutional neural network with three hidden layers, which converts vectors of entities, entity weights and relationships into matrices to perform link prediction in the same way as image processing. With the help of ten different similarity measures, it is demonstrated that the choice of distance measure greatly effect the results of the translation embedding models. Moreover, we propose two embedding methods, sMFE and tMFE, to enhance the results using matrix factorization. The complete incidence matrix is first applied to knowledge embedding, which contains the most comprehensive topological properties of the graph. Experimental results on standard benchmark datasets demonstrate that the proposed models are effective. In particular, CNNe achieves a mean rank of 166 less than the baseline method and an improvement of 2.1% on the proportion of correct entities ranked in the top ten on YAGO3-10 dataset. (C) 2022 Elsevier Ltd. All rights reserved.",2022
The exploration of internet finance by using neural network,"In order to find out the risks of Internet finance as much as possible, and to ensure the rapid and healthy development of Internet finance, random forest (RF), a common classification algorithm in machine learning, was applied to analyze the risk factors of Internet finance. Additionally, the results of traditional statistical methods were compared with those of RF and back propagation (BP) neural network methods and their performance was evaluated. Finally, some suggestions were given for these risk factors, especially for the problems with high risk. The results showed that the RF algorithm model had the best classification effect and could accurately analyze the risks of Internet finance in terms of market, law, credit, personal information, and professional knowledge. It was found that credit and personal information risk were the most important factors in the future development of Internet finance when BP neural network was used to evaluate these risks. To a certain extent, they would also hinder the use and development of Internet finance. At the same time, it proved that BP neural network had a good prediction effect. To sum up, using the RF algorithm and BP neural network method in machine learning to explore the problems of Internet finance is of great significance for risk prediction for other financial institutions. (C) 2019 Elsevier B.V. All rights reserved.",2020
Estimating the slip resistant quality of winter footwear using Artificial Intelligence,"Slips and falls on ice are among the common causes of emergency department visits and hospitalizations during the winter season. These injuries are costly and can place a financial burden on healthcare systems and municipalities. Using slip resistant winter footwear is a key factor in reducing the risk of slips and eventually falls. In this study, we developed an Artificial Intelligence model that classifies high and low slip resistant footwear based on images of their outsoles. Our model was trained on a unique dataset which consisted of images of 266 winter footwear outsoles. This dataset included footwear outsoles made from rubber (n = 89), Arctic Grip (n = 101), and Green Diamond material (n = 76). The slip resistance of all footwear samples was tested and rated with a human-centered protocol called the Maximum Achievable Angle test. We applied a transfer learning technique to develop a 2D convolutional neural network to classify the outsoles as having high and low slip resistance. The best classification model used the Xception pre-trained model and obtained an accuracy and F1-score of 0.85 and 0.89, respectively. The AUC-ROC (Area Under the Curve for Receiver Operating Characteristic) was also 0.91. Our results suggest that the proposed model properly identified high and low slip resistant winter footwear outsoles. Our findings also confirmed that the footwear's outsole tread pattern and material directly impact the footwear's slip resistance quality. The proposed model will help footwear manufacturers to improve their workflow and increase product quality which can ultimately decrease the events of slips and falls.",2025
A Fuzzy Comprehensive Evaluation Method of Regional Economic Development Quality Based on a Convolutional Neural Network,"This paper presents an in-depth research analysis on the evaluation of the development quality of regional economy through an improved convolutional neural network algorithm, and uses it to design a fuzzy comprehensive evaluation model for the practical process. Based on the measured indices of different variables, a spatial econometric model is constructed and provincial panel data are selected to empirically analyze the impact and spatial spillover effects of financial agglomeration and technological innovation on regional economic quality development from both static and dynamic aspects and to examine the spatial correlation of the factors. A new serial data flow model is adopted, which optimizes the control of data flow in convolutional computation, reduces the percentage of clock cycles used to read memory data, and increases the computational efficiency. At the same time, with dynamic data caching, a convolutional computation can be completed in one clock cycle, reducing the memory capacity required for caching intermediate data. The effectiveness of the evaluation system constructed in this paper is further tested. Most of the indicators have a significant positive or negative impact on the quality level of economic development, and the direction of the impact is consistent with the positive and negative attributes of the indicators in this study, which verifies the validity of the evaluation indicator system constructed in this paper. In summary of the study, effective suggestions are made in terms of human capital investment, reasonable allocation of fiscal expenditure, enhancing regional greening development and improving risk prevention measures.",2023
Default prediction of online credit loans based on mobile application usage behaviors,"Credit scoring is widely used by financial institutions for default prediction, however, a significant portion of online credit loan customers have inadequate or unverifiable credit histories, making it difficult for financial institutions to make effective credit decisions. Since the widespread use of smartphones and the popularity of mobile applications, it is worth investigating whether mobile application usage behaviors (App behaviors) of customers can effectively predict online loan defaults. This paper proposes a combined algorithm of CNN and LightGBM, and establishes credit scoring models with App behaviors to evaluate the default risk of online credit loans based on logistic regression, LightGBM, CNN and the combined algorithm, respectively. The experimental results suggest that App behaviors have an obvious effect on the default prediction of customers applying for online credit loans, and the combined model outperforms the other models in terms of the area under the curve (AUC). Furthermore, integrated credit scoring models are developed by combining App behaviors with traditional scoring features. A comparison of the integrated models and the traditional scoring model indicates that the integrated models have achieved a significant improvement in classification performance and App behaviors can be a powerful complement to the traditional credit scoring model.",2022
"Upstream, Downstream or Competitor? Detecting Company Relations for Commercial Activities","Due to intricate network in industry business and high cost of supervision, financial institutions usually focus on supervising core enterprises in a supply chain instead of all corporations, which indirectly lower the strength and efficiency of financial institutions as a role of capital supervisor and credit-risk transformer. Furthermore, banks require these corporations to provide correct information by themselves, which lacks of the objectivity of the source information and increases the supervision cost for these banks. Thus, we summarize a company relation detection task in hope to exposing more information about companies to investors and banks by learning a system from public available datasets. We regard this task as an classification problem, and our system can predict relations between any two companies by learning on both structured and unstructured data. To the best of our knowledge, it's the first time to implement deep learning technique to this task. A F1 score 0.769 is achieved from our system.",2019
Associations of decision making abilities with blood pressure values in older adults,"Objectives: Decision making, key to successful aging, has implications for financial success, physical health, and well being. While poor decision making has been linked with increased risk of mortality, age-related cognitive decline, and dementia, less is known regarding its associations with chronic disease indicators. We investigated the associations of decision making with blood pressure (BP) values [i.e., SBP, mean arterial pressure (MAP), and pulse pressure (PP), separately] in a community-based cohort study of aging. Methods: Participants were 908 nondemented older adults (age similar to 81 years; 75% women) from the Rush Memory and Aging Project. Decision making was measured using questions designed to simulate materials used in financial and healthcare settings in the real world and yielded a total score and domain-specific health and financial decision making scores. Two seated and one standing BP measurement were taken with all three contributing to average SBP, MAP that is, [SBP + (2 x DBP)]/3, and PP, that is, SBP - DBP. Participants were queried about hypertension status and antihypertension medications were visually inspected and coded. Participants also underwent medical history and cognitive assessments. Results: In separate multivariable linear regression models, total decision making scores were inversely associated with SBP, MAP, and PP after adjusting for age, sex, education, antihypertension medication use, diabetes, and cumulative cardiovascular disease burden (Pvalues = 0.03). Decision making remained associated with these BP values after additional adjustment for global cognition. Conclusion: Poorer decision making is associated with higher BP values in nondemented older adults.",2020
A study on the financial approach of risk assessment using chemical accident records in chemical process industries,"Usually, risk assessment is a combination of risk analysis and risk appraisal to evaluate the consequences and frequencies of hazardous events. The acceptability of the exposed risk is also judged in the process. In this regard, the financial risk matrix could be a useful tool based on the frequency and expected loss of damage. Thus, it is adopted in this study where a financial approach has been taken in risk assessment; the proposed methodology uses frequencies from chemical accident records and value at risk (VaR). The methodology consists of mainly five steps. It starts with hazard identification, and is followed by adjustment of history-based accident frequencies by using severity ratios. Then, accident probability and expected damage loss are estimated. The results obtained in the previous two steps are combined to compute VaR for the target process; this value is mapped with financial risk matrix to re-evaluate accident frequency. As an illustrative case, Texas BP refinery accident in 2005 is studied according to the proposed methodology. The results indicate that the financial risk increased from a low level to a medium high level after the occurrence of the tragic accident. As similar accidents frequently occurred for the same process, the risk of the process should have been increased. This proposed method can reflect this dynamic change in risks with the help of accident records and their impacts. (C) 2011 Curtin University of Technology and John Wiley & Sons, Ltd.",2011
Quantifying credit portfolio sensitivity toasset correlations with interpretablegenerative neural networks,"We propose a novel approach for quantifying the sensitivity of credit portfolio value-at-risk to asset correlations with the use of synthetic financial correlation matrixesgenerated with deep learning models. In previous work, generative adversarial net-works (GANs) were employed to demonstrate the generation of plausible correlationmatrixes that capture the essential characteristics observed in empirical correlationmatrixes estimated on asset returns. Instead of GANs, we employ variational autoen-coders (VAEs) to achieve a more interpretable latent space representation and toobtain a generator of plausible correlation matrixes by sampling the VAE's latentspace. Through our analysis, we reveal that the VAE's latent space can be a use-ful tool to capture the crucial factors impacting portfolio diversification, particularlyin relation to the sensitivity of credit portfolios to changes in asset correlations. AVAE trained on the historical time series of correlation matrixes is used to generatesynthetic correlation matrixes that satisfy a set of expected financial properties. Our analysis provides clear indications that the capacity for realistic data augmentationprovided by VAEs, combined with the ability to obtain model interpretability, canprove useful for risk management, enhancing the resilience and accuracy of modelswhen backtesting, as past data may exhibit biases and might not contain the essentialhigh-stress events required for evaluating diverse risk scenarios.",2024
Review on Pest Detection and Classification in Agricultural Environments Using Image-Based Deep Learning Models and Its Challenges,"Agronomic pests cause agriculture to incur financial losses because they diminish production, which lowers revenue. Pest control, essential to lowering these losses, involves identifying and eliminating this risk. Since it enables management to take place, identification is the fundamental component of control. Utilizing the pest's traits, visual identification is done. These characteristics differ between animals and are intrinsic. Since identification is so difficult, specialists in the field handle most of the work, which concentrates the information. Researchers have developed various techniques for predicting crop diseases using images of infected leaves. While progress has been made in identifying plant diseases using different models and methods, new advancements and discussions still offer room for improvement. Technology can significantly improve global crop production, and large datasets can be used to train models and approaches that uncover new and improved methods for detecting plant diseases and addressing low-yield issues. The effectiveness of machine learning and deep learning for identifying and categorizing pests has been confirmed by prior research. This paper thoroughly examines and critically evaluates the many strategies and methodologies used to classify and detect pests or insects using deep learning. The paper examines the benefits and drawbacks of various methodologies and considers potential problems with insect detection via image processing. The paper concludes by providing an analysis and outlook on the future direction of pest detection and classification using deep learning on plants like peanuts.",2023
Cardiovascular and renal risk assessment as a guide for treatment in primary hypertension,"BP levels per se may be an unreliable indicator of risk in the individual patient. In fact, the global cardiovascular profile, including the presence and degree of target organ damage, is a better predictor of future events and, therefore, should be used to choose both treatment and BP goals. However, the prevalence of target organ damage and therefore the percentage of patients who are at risk very much depends on the diagnostic techniques used. However, as a result of the high prevalence of hypertension and its financial impact on public health systems, limiting unnecessary and extensive diagnostic tests also should be a priority. The routine search for microalbuminuria may lead to the detection of a significantly greater percentage of patients who are at high risk while contributing the optimization of the cost-effectiveness of diagnostic workup in hypertensive patients.",2004
Improving financial distress prediction using textual sentiment of annual reports,"An accurate prediction of financial distress is beneficial to investors and allows banks and other financial institutions to build an early warning system to avoid risk contagion. This study investigated financial distress prediction using textual sentiment extracted from listed firms' annual reports in the Chinese market. The sentiments reflected by the firms' management discussions and analysis (MD&A) sections and audit reports were extracted separately through the application of deep learning algorithms. We found that the sentiment score extracted from MD&A sections was more optimistic compared with that extracted from audit reports. Moreover, the experimental results demonstrated that the modeling performance was significantly improved with the incorporation of textual sentiment scores, and the inclusion of sentiment from audit reports lead to a more significant incremental improvement than that from the MD&A sections. However, when both sentiment scores were included in the modeling input, the improvement in predictive accuracy was insignificant compared to the model using audit report scores only. Our study highlights the predictive power of textual information in annual reports, and shows that the textual sentiment of annual reports should be applied in distress modeling. The results provide implications for the utilization of soft information in credit risk modeling in the context of Chinese market, and such application can be further explored in other areas of operational research studies.",2023
Fast Direct Calibration of Interest Rate Derivatives Pricing Models,"To price complex derivative instruments and to manage the associated financial risk, investment banks typically model the underlying asset price dynamics using parametric stochastic models. Model parameters are calibrated by fitting cross sections of option prices on the relevant risk factors. It is fundamental for a calibration method to be accurate and fast and, to this end, Deep Learning techniques have attracted increasing attention in recent years. In this paper, the aim is to propose a Neural Network based calibration of a pricing model, where learning is directly performed on market data by using a non-trivial loss function, which includes the financial model adopted. In particular, the model chosen is the two-additive factor Gaussian Interest Rates model in a multi-curve framework calibrated on at-the-money European swaptions. The main advantage lies in the independence from an external calibrator and in the calibration time, reduced from several seconds to milliseconds, achieved by offloading the computational-intensive tasks to an offline training process, while the online evaluation can be performed in a considerably shorter time. Finally, the efficiency of the proposed approach is tested in both a single-currency and a multi-currency framework.",2020
Research on credit risk evaluation based on bp neural network,"As we all know, our current financial credit system is not so perfect, commercial banks are facing huge credit risks everyday. In this paper, we are supposed to construct a model to evaluate the credit risk of commercial bank based on BP neutral network. We also proceed research on possibility of its application to the credit risk analysis. Finally, with a case study, we prove that the scientific credit decisions can be made by commercial banks via the model.",2007
Comparative Text Analytics via Topic Modeling in Banking,"In this paper, we compare and evaluate multiple topic modeling approaches and their effectiveness in analyzing a large set of SEC filings by US public banks. More specifically, we apply four major topic modeling methods to a corpus of 8-K and 10-K filings, from the years 2005-2016, of 578 bank holding companies. These methods include Principal Component Analysis, Non-negative Matrix Factorization, Latent Dirichlet Allocation and KATE, a novel k-competitive autoencoder for text documents. Separately for 8-K and 10-K, the usefulness and effectiveness of these methods is evaluated by comparing their performances on two classification tasks: (i) predicting which section each document corresponds to, where we consider each section within an 8-K or 10-K filing as an individual document, and (ii) detecting text from a bank's year of failure, a task for which we use bank failure data from the 2008 financial crisis. In addition, we qualitatively compare the topics discovered by the different methods. We conclude that topic modeling can be an effective tool in financial decision making and risk management.",2017
What Went Wrong? Identifying Risk Factors for Popular Negative Consequences in AI,"The technologies that we have come to know as artificial intelligence (AI), such as machine learning, deep learning, computer vision, and natural language processing, are becoming general-purpose tools that significantly impact organizational and societal economic and social structures. However, that impact has not been entirely positive. We have already seen many projects where undesirable or negative consequences of AI systems have harmed their respective organizations in social, financial, and legal spheres. In this study, we examine common intended objectives and risk factors that lead to negative consequences in AI. Using a qualitative approach, we propose a unifying theoretical framework for negative consequences in AI projects. We analyzed 840 quotes from key informants about 30 unique AI projects using multiple news articles for each project. We identified intended objectives for implementing AI systems that lead to negative consequences through various linking risk factors.",2024
"Deep learning in the stock market-a systematic survey of practice, backtesting, and applications","The widespread usage of machine learning in different mainstream contexts has made deep learning the technique of choice in various domains, including finance. This systematic survey explores various scenarios employing deep learning in financial markets, especially the stock market. A key requirement for our methodology is its focus on research papers involving backtesting. That is, we consider whether the experimentation mode is sufficient for market practitioners to consider the work in a real-world use case. Works meeting this requirement are distributed across seven distinct specializations. Most studies focus on trade strategy, price prediction, and portfolio management, with a limited number considering market simulation, stock selection, hedging strategy, and risk management. We also recognize that domain-specific metrics such as returns and volatility appear most important for accurately representing model performance across specializations. Our study demonstrates that, although there have been some improvements in reproducibility, substantial work remains to be done regarding model explainability. Accordingly, we suggest several future directions, such as improving trust by creating reproducible, explainable, and accountable models and emphasizing prediction of longer-term horizons-potentially via the utilization of supplementary data-which continues to represent a significant unresolved challenge.",2023
Research on green supply chain finance risk identification based on two-stage deep learning,"As a resonance product between financial services and the upgrading of the green industry, green supply chain finance has garnered extensive attention in the process of ecological civilization construction. Effectively promoting the green transformation of small and medium-sized enterprises and achieving the dual carbon goals necessitate the avoidance of corporate green risks. However, the complex interdependence and information asymmetry among green supply chain finance enterprises result in data characteristics such as multi-source small samples and high-dimensional imbalance. To address these issues, this paper proposes a risk assessment model based on two-stage deep learning. In the first stage, we employ Generative Adversarial Network (GAN) to generate minority class default samples, and utilize Stacked Auto-Encoder (SAE) to extract data features with closed-form parameter calculation capability. In the second stage, the obtained features are input into a Deep Neural Network (DNN), and parameter learning and model optimization are conducted through joint training. Finally, to model low-order feature interactions, we integrate the Support Vector Machine (SVM) algorithm. The paper is grounded in the green innovation production of enterprises, collecting financial data of 176 upstream and downstream enterprises and corresponding core enterprise green indicators from 2013 to 2022. Experimental results demonstrate that GAN oversampling technique not only enhances the model's AUC metric but also significantly improves the F1 score. Compared with traditional deep learning methods, the proposed two-stage deep integration model effectively reduces training loss and exhibits superiority in identifying green supply chain finance risks.",2024
A Deep Learning-Based Ensemble Framework to Predict IPOs Performance for Sustainable Economic Development,"Addressing resource scarcity and climate change necessitates a transition to sustainable consumption and circular economy models, fostering environmental, social, and economic resilience. This study introduces a deep learning-based ensemble framework to optimize initial public offering (IPO) performance prediction while extending its application to circular economy processes, such as resource recovery and waste reduction. The framework incorporates advanced techniques, including hyperparameter optimization, dynamic metric adaptation (DMA), and the synthetic minority oversampling technique (SMOTE), to address challenges such as class imbalance, risk-adjusted metric enhancement, and robust forecasting. Experimental results demonstrate high predictive performance, achieving an accuracy of 76%, precision of 83%, recall of 75%, and an AUC of 0.9038. Among ensemble methods, Bagging achieved the highest AUC (0.90), outperforming XGBoost (0.88) and random forest (0.75). Cross-validation confirmed the framework's reliability with a median AUC of 0.85 across ten folds. When applied to circular economy scenarios, the model effectively predicted sustainability metrics, achieving R-2 values of 0.76 for both resource recovery and waste reduction with a low mean absolute error (MAE = 0.11). These results highlight the potential to align financial forecasting with environmental sustainability objectives. This study underscores the transformative potential of deep learning in addressing financial and sustainability challenges, demonstrating how AI-driven models can integrate economic and environmental goals. By enabling robust IPO predictions and enhancing circular economy outcomes, the proposed framework aligns with Industry 5.0's vision for human-centric, data-driven, and sustainable industrial innovation, contributing to resilient economic growth and long-term environmental stewardship.",2025
Self-Measured Blood Pressure Monitoring at Home: A Joint Policy Statement From the American Heart Association and American Medical Association,"The diagnosis and management of hypertension, a common cardiovascular risk factor among the general population, have been based primarily on the measurement of blood pressure (BP) in the office. BP may differ considerably when measured in the office and when measured outside of the office setting, and higher out-of-office BP is associated with increased cardiovascular risk independent of office BP. Self-measured BP monitoring, the measurement of BP by an individual outside of the office at home, is a validated approach for out-of-office BP measurement. Several national and international hypertension guidelines endorse self-measured BP monitoring. Indications include the diagnosis of white-coat hypertension and masked hypertension and the identification of white-coat effect and masked uncontrolled hypertension. Other indications include confirming the diagnosis of resistant hypertension and detecting morning hypertension. Validated self-measured BP monitoring devices that use the oscillometric method are preferred, and a standardized BP measurement and monitoring protocol should be followed. Evidence from meta-analyses of randomized trials indicates that self-measured BP monitoring is associated with a reduction in BP and improved BP control, and the benefits of self-measured BP monitoring are greatest when done along with cointerventions. The addition of self-measured BP monitoring to office BP monitoring is cost-effective compared with office BP monitoring alone or usual care among individuals with high office BP. The use of self-measured BP monitoring is commonly reported by both individuals and providers. Therefore, self-measured BP monitoring has high potential for improving the diagnosis and management of hypertension in the United States. Randomized controlled trials examining the impact of self-measured BP monitoring on cardiovascular outcomes are needed. To adequately address barriers to the implementation of self-measured BP monitoring, financial investment is needed in the following areas: improving education and training of individuals and providers, building health information technology capacity, incorporating self-measured BP readings into clinical performance measures, supporting cointerventions, and enhancing reimbursement.",2020
Delinquent Events Prediction in Temporal Networked-Guarantee Loans,"Under debt obligation promises, small- and medium-sized enterprises (SMEs) can guarantee each other to enhance their financial security to get loans from commercial banks. When the economy rises, the banks may reduce the threshold to some extent, which may introduce default risk during the economy down period, especially when many SMEs bind together and form complex networks. The risk may diffuse across the guarantee network and may result in a financial crisis. Macroprudential oversight of the guarantee network to eliminate any potential systematics financial risk is the central task of the regulatory commission and the commercial banks. Based on our observation, the delinquent probability of an SME depends not only on self-financial status but also highly related to its temporal behaviors and structural position in networks. The classic approach for loan assessment criteria face challenges in extracting temporal and structural patterns from dynamic networks. To address these issues, we propose a temporal delinquent event prediction (TDEP) framework that preserves temporal network structures and credit behavior sequences in an end-to-end model. In particular, we first employ a graph attention layer to learn the representation of nodes in temporal guarantee networks. We then design a recursive and self-attention mechanism to integrate both credit behavior and network structure information. The learned attentional weights are leveraged to uncover high-risk guarantee patterns that effectively accelerate the risk assessment process. Afterward, we conduct extensive experiments in a real-world guaranteed-loan data set to evaluate its performance. The results show the effectiveness of our proposed approach compared with the state-of-the-art baselines. Finally, we integrate the proposed model in a real-world loan risk management system. We present the implementation details of each subcomponent of the system and report out the performance after online deployment.",2023
"Imbalanced credit risk evaluation based on multiple sampling, multiple kernel fuzzy self-organizing map and local accuracy ensemble","Credit risk evaluation model is generally regarded as a valid method for business risk management. Although the most of literatures about credit risk evaluation always use class-balanced data as sample sets, the study on class-imbalanced datasets is more suitable for actual situation. This paper proposes a new ensemble model to evaluate class-imbalanced credit risk, which integrates multiple sampling, multiple kernel fuzzy self-organizing map and local accuracy ensemble. To preprocess imbalanced sample sets of credit risk evaluation, multiple sampling approaches (synthetic minority over-sampling technique, under sampling and hybrid sampling) are improved and integrated to acquire balanced datasets. To construct more suitable base classifiers, multiple kernel functions (Gaussian, Polynomial and Sigmoid) respectively are used to improve fuzzy self-organizing map. Then, the balanced sample sets are respectively processed by the improved base classifiers to acquire different prediction results. The local accuracy ensemble method is employed to dynamically synthesize these prediction results to obtain final result. The new ensemble model can further avoid over-fitting and information loss, be more suitable to handle the dataset including different financial indicators, and acquire the stable and satisfactory prediction result for imbalanced credit risk evaluation In the empirical research, this paper adopts the financial data from Chinese listed companies, and makes the comparative analysis with the relative models step by step. The results can prove that the new ensemble model presented by this article has better performance than other methods in terms of evaluating the imbalanced credit risk. (C) 2020 Elsevier B.V. All rights reserved.",2020
News Sentiment and the Risk of a Stock Price Crash Risk: Based on Financial Dictionary Combined BERT-DCA,"This study combines a financial knowledge dictionary and pretraining method based on BERT (Bidirectional Encoder Representation from Transformers) to construct a deep learning model for identifying stock news sentiments. The study then calculates the sentiment metrics of all stocks and analyzes the impact of news sentiment on the risk of a stock price crash and its heterogeneity. The results show that stocks with more positive sentiment metrics have a higher risk of crash in the following year. We also investigate the information intermediation and investor sentiment channels by which news sentiment affects the risk of a crash. The results show that more net insider sales, lower information transparency, and less analyst coverage amplify the impact of news sentiment on future crash risk, which is consistent with the information intermediation channel. Additionally, more retail investor positions, more active investor sentiment, and divergence between analysts' opinions and news amplify the impact of news sentiment on the risk of a future stock price crash, which is consistent with the investor sentiment channel.",2022
Modeling of extended osprey optimization algorithm with Bayesian neural network: An application on Fintech to predict financial crisis,"Accurately predicting and anticipating financial crises becomes of paramount importance in the rapidly evolving landscape of financial technology (Fintech). There is an increasing reliance on predictive modeling and advanced analytics techniques to predict possible crises and alleviate the effects of Fintech innovations reshaping traditional financial paradigms. Financial experts and academics are focusing more on financial risk prevention and control tools based on state-of-the-art technology such as machine learning (ML), big data, and neural networks (NN). Researchers aim to prioritize and identify the most informative variables for accurate prediction models by leveraging the abilities of deep learning and feature selection (FS) techniques. This combination of techniques allows the extraction of relationships and nuanced patterns from complex financial datasets, empowering predictive models to discern subtle signals indicative of potential crises. This study developed an extended osprey optimization algorithm with a Bayesian NN to predict financial crisis (EOOABNNPFC) technique. The EOOABNN-PFC technique uses metaheuristics and the Bayesian model to predict the presence of a financial crisis. In preprocessing, the EOOABNN-PFC technique uses a minmax scalar to scale the input data into a valid format. Besides, the EOOABNN-PFC technique applies the EOOA-based feature subset selection approach to elect the optimal feature subset, and the prediction of the financial crisis is performed using the BNN classifier. Lastly, the optimal parameter selection of the BNN model is carried out using a multi -verse optimizer (MVO). The simulation process identified that the EOOABNN-PFC technique reaches superior accuracy outcomes of 95.00% and 95.87% compared with other existing approaches under the German Credit and Australian Credit datasets.",2024
Topological applications of multilayer perceptrons and support vector machines in financial decision support systems,"The heart of this study is particularly on risk assessment of financial decision support systems (FDSSs), to advance the model performance and improve classification accuracy. To conquer the downsides of the classical models, statistical intelligence (SI) technologies, for example, multilayer perceptrons (MLPs) and support vector machines (SVMs), have been deliberated in FDSS applications. Recently, the prestigiousness of SI approaches has been confronted by the latest prediction learners. Therefore, to ensure the competitive performance of SI mechanisms, the current investigation scrutinizes the topological applications of MLPs and SVMs over eight different databases with equivalent combinations in credit scoring and bankruptcy predictions example sets. The experimental results reveal that MLP5-5 and MLP4-4, that is, the sigmoid activation function with five and four hidden layers, are the feasible topologies for the MLP algorithm, and on all databases in all performance criterions, SVM trained with the linear kernel function (SVM-1) achieves better prediction results. From the Baseline family, random forest learner brings significant improvements in financial decisions. Lastly, FDSSs are found to be correlated with the nature of databases and the performance criterions of the trained algorithms. The results of this study, however, have practical and managerial implications to make a range of financial and nonfinancial strategies. With these contributions, therefore, our study not only supplements earlier evidence but also enhances the predictive performance of SI algorithms for financial decision support applications.",2019
Machine learning-based farm risk management: A systematic mapping review,"Farms face various risks such as uncertainties in the natural growth process, obtaining adequate financing, volatile input and output prices, unpredictable changes in farm-related policy and regulations, and farmers' personal health problems. Accordingly, farmers have to make decisions to be prepared for such situations under risk or mitigate their impacts to maintain essential functions. Increasingly, a data-driven perspective is warranted where machine learning (ML) has become an essential tool for automatic extraction of useful information to support decision-making in farm management as well as risk management. ML's role in farm risk management (FRM) has recently increased with advances in technology and digitalization. This paper provides a literature review in the form of a systematic mapping study to identify the publications, trends, active research communities, and detailed reviews on the use of ML methods for FRM. Accordingly, nine research/mapping questions are designed to extract the required information. In total, we retrieved 1819 papers, of which 746 papers were selected based on the defined exclusion criteria for a detailed review. We categorized the studies based on the addressed risk types (e.g., production risk), assessments that addressed risk components (e.g., resilience), used ML types (e.g., supervised learning) and algorithms ranging from regression modeling to deep learning, addressed ML tasks (e.g., classification), data types (e.g., images), and farm types (e.g., crop-based farm). The results reveal that there is a significant increase in employing ML methods including deep learning and convolutional neural networks for FRM in recent years. The production risk and impact/damage assessment are the most frequently addressed risk type and assessment that addressed risk components in ML-FRM, respectively. In addition, research gaps and open problems are identified and accordingly insights and recommendations from risk management and machine learning perspectives are provided for future studies including the need for ML methods for different risk types (e.g., financial risk), assessments addressing different risk components (e.g., resilience assessment), and developing more advanced ML methods (e.g., reinforcement learning) for FRM.",2022
Digitalization as a double-edged sword: A deep learning analysis of risk management in Chinese banks,"Digitalization presents both opportunities and formidable challenges for risk management in commercial banks. This study addresses the critical question of how digitalization influences banks' risk-taking behaviors. Applying an InstructGPT-inspired deep learning model, we developed a multidimensional bank digitalization index to analyze its effects on risk-taking, using data from 149 Chinese commercial banks from 2011 to 2020. The empirical results show that (1) digitalization significantly curtails risk-taking on the balance sheet, while concurrently escalating off-balance sheet risk exposure; (2) digitalization diminishes on-balance sheet risk by lessening distortions in competition due to government guarantees, manifested as a competition effect of onbalance sheet guarantee; (3) digitalization increases the upper limit of expected returns on bank financial products, thereby elevating off-balance sheet risk-taking, evident as an off-balance sheet price competition effect; (4) bank digitalization has a more obvious boosting effect on off-balance sheet risk-taking of banks with a longer average maturiy of wealth management products. This paper enriches the measurement of the digitalization of banks and provides a reference for banks to deepen digital applications and strengthen risk management, which has important practical significance.",2024
Integration of CNN Models and Machine Learning Methods in Credit Score Classification: 2D Image Transformation and Feature Extraction,"The problem of accurately classifying credit scores is critical for financial institutions to assess individual creditworthiness and effectively manage credit risk. Traditional methods often face limitations when processing large datasets, resulting in lower accuracy and longer processing time. To address this issue, this paper proposes a novel approach to credit score classification by integrating convolutional neural networks (CNN) with machine learning methods. First, a 1D dataset of sequential text data is transformed into 2D greyscale images to use 2D CNN models for feature extraction and classification. Six CNN architectures-DenseNet201, GoogLeNet, MobileNetV2, ResNet18, ShuffleNet, and SqueezeNet-are implemented, and the features in the last layer (1000 features) of each CNN are classified using the softmax method. To further improve the performance, the two best CNN models were selected, and a new fully connected layer (NewFC) was added. A class-based feature set [3 x 31,695] representing three credit score types (good, poor, and standard) was extracted from each model and merged into a feature set [6 x 31,695]. This combined feature set was then reclassified using KNN, LDA, Naive Bayes, and SVM algorithms. The performance of both CNN and machine learning methods was evaluated using accuracy, precision, sensitivity, specificity, and F-score metrics. To optimize classification performance and reduce computational cost, the RelieF algorithm was used to select the best 5 out of 6 features. Compared to using all 6 features, significant improvements in accuracy and efficiency were observed, demonstrating the effectiveness of the proposed method in credit score classification.",2025
Anomaly Detection Aided Budget Online Classification for Imbalanced Data Streams,"Learning from imbalanced data streams differs fromthe traditional learning paradigm due to the issues of imbalanced classes. It has significant implications in a myriad of real-world applications, ranging from financial risk, network security, to medical diagnosis. Moreover, outliers usually appear in data streams. The issue of class imbalance or anomaly itself could negatively affect the performance of the underlying learning algorithms, and their combination makes the learning problemharder. In this work, we propose an anomaly detection aided budget online weighted learning method (BOW-LM) to identify positive and negative instances from imbalanced data streams. BOW-LMis based on the widely used Feedforward Networks with Random Weights. An agile lightweight anomaly detector is designed based on the nonlinear mapping of the network. To reduce computational complexity and to response promptly, BOW-LM employs amatrix correction technique to update the learning model by only O(L-2) operations for each data chunk with L hidden layer nodes. Empirical studies on both synthetic and real-world datasets demonstrate the effectiveness of BOW-LM.",2021
Machine learning and financial big data control using IoT,"Machine learning algorithms have been widely used in risk prediction management systems for financial data. Early warning and control of financial risks are important areas of corporate investment decision-making, which can effectively reduce investment risks and ensure companies' stable development. With the development of the Internet of Things, enterprises' financial information is obtained through various intelligent devices in the enterprise financial system. Big data provides high-quality services for the economy and society in the high-tech era of information. However, the amount of financial data is large, complex and variable, so the analysis of financial data has huge difficulties, and with the in-depth application of machine learning algorithms, its shortcomings are gradually exposed. To this end, this paper collects the financial data of a listed group from 2005 to 2020, and conducts data preprocessing and Feature selection, including removing missing values, Outlier and unrelated items. Next, these data are divided into a training set and a testing set, where the training set data is used for model training and the testing set data is used to evaluate the performance of the model. Three methods are used to build and compare data control models, which are based on machine learning algorithm, based on deep learning network and the model based on artificial intelligence and Big data technology proposed in this paper. In terms of risk event prediction comparison, this paper selects two indicators to measure the performance of the model: accuracy and Mean squared error (MSE). Accuracy reflects the predictive ability of the model, which is the proportion of all correctly predicted samples to the total sample size. Mean squared error is used to evaluate the accuracy and error of the model, that is, the square of the Average absolute deviation between the predicted value and the true value. In this paper, the prediction results of the three methods are compared with the actual values, and their accuracy and Mean squared error are obtained and compared. The experimental results show that the model based on artificial intelligence and Big data technology proposed in this paper has higher accuracy and smaller Mean squared error than the other two models, and can achieve 90% accuracy in risk event prediction, which proves that it has higher ability in controlling financial data risk.",2024
A Risk-Optimized Framework for Data-Driven IPO Underperformance Prediction in Complex Financial Systems,"Accurate predictions of Initial Public Offerings (IPOs) aftermarket performance are essential for making informed investment decisions in the financial sector. This paper attempts to predict IPO short-term underperformance during a month post-listing. The current research landscape lacks modern models that address the needs of small and imbalanced datasets relevant to emerging markets, as well as the risk preferences of investors. To fill this gap, we present a practical framework utilizing tree-based ensemble learning, including Bagging Classifier (BC), Random Forest (RF), AdaBoost (Ada), Gradient Boosting (GB), XGBoost (XG), Stacking Classifier (SC), and Extra Trees (ET), with Decision Tree (DT) as a base estimator. The framework leverages data-driven methodologies to optimize decision-making in complex financial systems, integrating ANOVA F-value for feature selection, Randomized Search for hyperparameter optimization, and SMOTE for class balance. The framework's effectiveness is assessed using a hand-collected dataset that includes features from both pre-IPO prospectus and firm-specific financial data. We thoroughly evaluate the results using single-split evaluation and 10-fold cross-validation analysis. For the single-split validation, ET achieves the highest accuracy of 86%, while for the 10-fold validation, BC achieves the highest accuracy of 70%. Additionally, we compare the results of the proposed framework with deep-learning models such as MLP, TabNet, and ANN to assess their effectiveness in handling IPO underperformance predictions. These results demonstrate the framework's capability to enable robust data-driven decision-making processes in complex and dynamic financial environments, even with limited and imbalanced datasets. The framework also proposes a dynamic methodology named Investor Preference Prediction Framework (IPPF) to match tree-based ensemble models to investors' risk preferences when predicting IPO underperformance. It concludes that different models may be suitable for various risk profiles. For the dataset at hand, ET and Ada are more appropriate for risk-averse investors, while BC is suitable for risk-tolerant investors. The results underscore the framework's importance in improving IPO underperformance predictions, which can better inform investment strategies and decision-making processes.",2025
The Protection of Data Sharing for Privacy in Financial Vision,"The primary motivation is to address difficulties in data interpretation or a reduction in model accuracy. Although differential privacy can provide data privacy guarantees, it also creates problems. Thus, we need to consider the noise setting for differential privacy is currently inconclusive. This paper's main contribution is finding a balance between privacy and accuracy. The training data of deep learning models may contain private or sensitive corporate information. These may be dangerous to attacks, leading to privacy data leakage for data sharing. Many strategies are for privacy protection, and differential privacy is the most widely applied one. Google proposed a federated learning technology to solve the problem of data silos in 2016. The technology can share information without exchanging original data and has made significant progress in the medical field. However, there is still the risk of data leakage in federated learning; thus, many models are now used with differential privacy mechanisms to minimize the risk. The data in the financial field are similar to medical data, which contains a substantial amount of personal data. The leakage may cause uncontrollable consequences, making data exchange and sharing difficult. Let us suppose that differential privacy applies to the financial field. Financial institutions can provide customers with higher value and personalized services and automate credit scoring and risk management. Unfortunately, the economic area rarely applies differential privacy and attains no consensus on parameter settings. This study compares data security with non-private and differential privacy financial visual models. The paper finds a balance between privacy protection with model accuracy. The results show that when the privacy loss parameter epsilon is between 12.62 and 5.41, the privacy models can protect training data, and the accuracy does not decrease too much.",2022
Implementation Strategies to Improve Blood Pressure Control in the United States: A Scientific Statement From the American Heart Association and American Medical Association,"Hypertension is one of the most important risk factors that contribute to incident cardiovascular events. A multitude of US and international hypertension guidelines, scientific statements, and policy statements have recommended evidence-based approaches for hypertension management and improved blood pressure (BP) control. These recommendations are based largely on high-quality observational and randomized controlled trial data. However, recent published data demonstrate troubling temporal trends with declining BP control in the United States after decades of steady improvements. Therefore, there is a widening disconnect between what hypertension experts recommend and actual BP control in practice. This scientific statement provides information on the implementation strategies to optimize hypertension management and to improve BP control among adults in the United States. Key approaches include antiracism efforts, accurate BP measurement and increased use of self-measured BP monitoring, team-based care, implementation of policies and programs to facilitate lifestyle change, standardized treatment protocols using team-based care, improvement of medication acceptance and adherence, continuous quality improvement, financial strategies, and large-scale dissemination and implementation. Closing the gap between scientific evidence, expert recommendations, and achieving BP control, particularly among disproportionately affected populations, is urgently needed to improve cardiovascular health.",2023
XVA analysis from the balance sheet,"XVAs denote various counterparty risk related valuation adjustments that are applied to financial derivatives since the 2007-2009 crisis. We root a cost-of-capital XVA strategy in a balance sheet perspective which is key to identifying the economic meaning of the XVA terms. Our approach is first detailed in a static setup that is solved explicitly. It is then plugged into the dynamic and trade incremental context of a real derivative banking portfolio. The corresponding cost-of-capital XVA strategy ensures for bank shareholders a submartingale equity process corresponding to a target hurdle rate on their capital at risk, consistently between and throughout deals. Set on a forward/backward SDE formulation, this strategy can be solved efficiently using GPU computing combined with deep learning regression methods in a whole bank balance sheet context. A numerical case study emphasizes the workability and added value of the ensuing pathwise XVA computations.",2021
Default risk prediction and feature extraction using a penalized deep neural network,"Online peer-to-peer lending platforms provide loans directly from lenders to borrowers without passing through traditional financial institutions. For lenders on these platforms to avoid loss, it is crucial that they accurately assess default risk so that they can make appropriate decisions. In this study, we develop a penalized deep learning model to predict default risk based on survival data. As opposed to simply predicting whether default will occur, we focus on predicting the probability of default over time. Moreover, by adding an additional one-to-one layer in the neural network, we achieve feature selection and estimation simultaneously by incorporating an L-1-penalty into the objective function. The minibatch gradient descent algorithm makes it possible to handle massive data. An analysis of a real-world loan data and simulations demonstrate the model's competitive practical performance, which suggests favorable potential applications in peer-to-peer lending platforms.",2022
StockNet-GRU based stock index prediction,"Predicting financial trends of stock indexes is important for investors to reduce risk on investment and efficient decision making if the prediction is made accurately. Researchers, in recent times have applied deep learning approaches in this field which have essentially beaten conventional machine learning approaches. To overcome the issue of overfitting we presented a new data augmentation approach in our GRU based StockNet model consisting of two modules. Injection module to prohibit overfitting and Investigation module for stock index forecasting. The proposed approach has been validated on Indian stock market (CNX-Nifty). Proposed StockNet-c model produces 65.59%, 27.30% and 14.89 % less test loss in terms of RMSE, MAE and MAPE respectively, in comparison to TargetNet model where overfitting prohibition injection module is missing.",2022
ReDCrypt: Real-Time Privacy-Preserving Deep Learning Inference in Clouds Using FPGAs,"Artificial Intelligence (AI) is increasingly incorporated into the cloud business in order to improve the functionality (e.g., accuracy) of the service. The adoption of AI as a cloud service raises serious privacy concerns in applications where the risk of data leakage is not acceptable. Examples of such applications include scenarios where clients hold potentially sensitive private information such as medical records, financial data, and/or location. This article proposes ReDCrypt, the first reconfigurable hardware-accelerated framework that empowers privacy-preserving inference of deep learning models in cloud servers. ReDCrypt is well-suited for streaming (a.k.a., real-time AI) settings where clients need to dynamically analyze their data as it is collected over time without having to queue the samples to meet a certain batch size. Unlike prior work, ReDCrypt neither requires to change how AI models are trained nor relies on two non-colluding servers to perform. The privacy-preserving computation in ReDCrypt is executed using Yao's Garbled Circuit (GC) protocol We break down the deep learning inference task into two phases: (i) privacy-insensitive (local) computation, and (ii) privacy-sensitive (interactive) computation. We devise a high-throughput and power-efficient implementation of GC protocol on FPGA for the privacy-sensitive phase. ReDCrypt's accompanying API provides support for seamless integration of ReDCrypt into any deep learning framework. Proof-of-concept evaluations for different DL applications demonstrate up to 57-fold higher throughput per core compared to the best prior solution with no drop in the accuracy.",2018
Optimizing Financial Engineering Time Indicator Using Bionics Computation Algorithm and Neural Network Deep Learning,"The present work aims to optimize the time index of financial engineering to improve the efficiency of financial decision-making. A Back Propagation Neural Network (BPNN) model is designed and optimized by the Ant Colony Algorithm (ACA) based on the bionic algorithm and Deep Learning (DL). After introducing the basic knowledge of neural networks and bionic algorithms, the advantages and disadvantages of the algorithms are integrated for maximal effects. Besides, ACA optimizes the weights and thresholds in the neural network in complex problems to reduce the relative error, enhance the stability and accuracy, and improve the classification speed of the BPNN model. The experimental results indicate that the classification accuracy of the ACA model is 91.3%, and the area under the receiver operating characteristic curve is 0.867. Moreover, the running time of BPNN based on ACA is 2.5 s, the error is 0.2, and the required number of iteration steps is 36 times, better than the test results of similar algorithms. These results demonstrate that the improved BPNN based on ACA has higher classification efficiency, better efficiency and smaller errors than the traditional BPNN. In terms of financial engineering decision-making, the time index of decision-making has been significantly improved, which is conducive to reducing the decision-making risk of financial institutions and has a positive effect on improving the overall operational efficiency of enterprises.",2022
A movie box office revenue prediction model based on deep multimodal features,"Demand forecasting a film's opening weekend box office revenue is a difficult and complex task that decision-makers face due to a lack of historical data and various complex factors. We proposed a novel Deep Multimodal Feature Classifier Neural Network model (DMFCNN) for predicting a film's opening weekend box office revenue using deep multimodal visual features extracted from movie posters and movie metadata. DMFCNN is an end-to-end predictive model that fuses two different feature classifiers' predictive power in estimating the movie box office revenue. Initially, a pre-trained residual convolutional neural network (ResNet50) architecture using transfer learning techniques extracts visual, and object representations learned from movie posters. The movie posters' discriminative and financial success-related features are combined with other movie metadata to classify the movie box office revenue. The proposed DMFCNN aided in developing a robust predictive model that jointly learns and defines useful revenue-related poster features and objects semantics, which strongly correlates with movie box office revenue and aesthetic appearance. Although our main task was classification, we also analyzed regressions between our exogenous variables as a regularizer to avoid the risk of overfitting. We evaluated DMFCNN's performance and compared it to various state-of-the-art models on the Internet Movie Database by collecting 49,857 movies metadata and posters from 2006 to 2019. The learned information on movie posters and predicted outcomes outperformed existing models, achieving 59.30% prediction accuracy. The proposed fusion strategy outperformed the existing fusion schemes in precision, Area Under Cover, sensitivity, and specificity by achieving 80%, 81%, 79%, and 78%, respectively.",2023
FluNet: An AI-Enabled Influenza-Like Warning System,"Influenza is an acute viral respiratory disease that is currently causing severe financial and resource strains worldwide. With the COVID-19 pandemic exceeding 153 million cases worldwide, there is a need for a low-cost and contactless surveillance system to detect symptomatic individuals. The objective of this study was to develop FluNet, a novel, proof-of-concept, low-cost and contactless device for the detection of high-risk individuals. The system conducts face detection in the LWIR with a precision rating of 0.98, a recall of 0.91, an F-score of 0.96, and a mean intersection over union of 0.74 while sequentially taking the temperature trend of faces with a thermal accuracy of +/- 1 K. In parallel, determining if someone is coughing by using a custom lightweight deep convolutional neural network with a precision rating of 0.95, a recall of 0.92, an F-score of 0.94 and an AUC of 0.98. We concluded this study by testing the accuracy of the direction of arrival estimation for the cough detection revealing an error of +/- 4.78 degrees. If a subject is symptomatic, a photo is taken with a specified region of interest using a visible light camera. Two datasets have been constructed, one for face detection in the LWIR consisting of 250 images of 20 participants' faces at various rotations and coverings, including face masks. The other for the real-time detection of coughs comprised of 40,482 cough / not cough sounds. These findings could be helpful for future low-cost edge computing applications for influenza-like monitoring.",2021
A Tabular Sarsa-Based Stock Market Agent,"Automated stock trading is now the de-facto way that investors have chosen to obtain high profits in the stock market while keeping risk under control. One of the approaches is to create agents employing Reinforcement Learning (RL) algorithms to learn and decide whether or not to operate in the market in order to achieve maximum profit. Automated financial trading systems can learn how to trade optimally while interacting with the market pretty much like a human investor learns how to trade. In this research, a simple RL agent was implemented using the SARSA algorithm. Next, it was tested against 10 stocks from Brazilian stock market B3 (Bolsa,Brasil,Balcao). Results from experiments showed that the agent was able to provide high profits with less risk when compared to a supervised learning agent that used a LSTM neural network.",2020
Financial Risk Early Warning Model for Listed Companies Using BP Neural Network and Rough Set Theory,"In current financial environment, listed companies are facing increasingly complex markets and ever-changing financial risks. The companies deeply recognize the crucial role of financial risk management in the sustainable development of enterprises. The challenge lies in rapidly changing market conditions, and traditional methods are difficult to predict risks in a timely and accurate manner. Therefore, improving the accuracy and timeliness of financial risk prediction has become an urgent need in the current field to reduce potential losses and maintain the financial health of enterprises. This work aims to enhance the accuracy and timeliness of predicting financial risks for listed companies and reduce potential losses caused by these risks. In the research process, a large volume of data is initially collected, including financial statements, market data, and financial risk event data. Subsequently, the Rough Set Theory (RST) is employed for feature selection to identify financial indicators and market factors highly relevant to financial risk. Finally, a financial risk early warning model on the basis of the Back Propagation Neural Network (BPNN) is built, and then trained and optimized using historical data. Cross-validation analysis is employed to assess the model's performance, and the model is compared with traditional financial risk early warning methods. The findings reveal that the financial risk early warning model based on RST and the BPNN demonstrates high accuracy and reliability in predicting financial risks for listed companies. The model exhibits excellent performance in terms of accuracy, recall, and F1 score, achieving rates of 96%, 95%, and 95.50%, respectively. These research findings are expected to positively impact the financial sector and provide financial decision-makers with more accurate risk early warning and decision support.",2024
Robo-Sukuk pricing for Chinese equities,"Sukuks have assumed increasing importance in the global financial industry, with both institutional and retail investors realizing the benefits of Sukuk, both in terms of their adherence to Islamic principles, as well as being more stable and robust. The growing importance of the Sukuk markets has happened simultaneously with the significant development of China. With the financial crisis and other recent events reducing the trust and confidence of investors in the existing financial system structures, Islamic financial products have received great attention due to their connection to real assets and risk-sharing. While Sukuk financial instruments differ significantly from their conventional bond counterparts, pricing has mostly followed conventional bond pricing methodologies. This represents a significant challenge as the characteristics of Sukuk are not considered, misrepresenting the value and associated performance of the Sukuk. An innovative data-driven methodology for the pricing of Sukuk in the Chinese equity market is presented. It overcomes the challenges with conventional bond pricing methodologies applied to Sukuk pricing. The methodology integrates a deep learning framework for the estimation and forecasting of Sukuk prices, considering factors, such as cashflows, net income, and stock price performance, in addition to textual information. Illustrated on thirty major Chinese corporations listed on the Hong Kong Stock Exchange, the framework provides a more market and value-based approach to pricing Sukuk considering the partnership nature of the Islamic financial product.Copyright (c) 2022, Borsa Istanbul Anonim S , irketi. Production and hosting by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).",2022
Supply Chain Finance Assistance for Small and Medium-Sized Enterprises Using Cognitive Web Services,"When it comes to offering loans to small and medium-sized enterprises, the supply chain finance industries will produce cash flow and commodities (SMEs). The supply management is implemented with cognitive web service. Under the terms of information exchange, a credit risk assessment will be performed for supply chain finance with data analytics. In support vector machine technology, parameters are chosen using a genetic algorithm. To analyze the credit risk of support vector machines, a BP neural network was used to link the evolutionary algorithm with supply chain finance (GASVM-BPNN-SCF). Using a genetic algorithm and a support vector machine has overall classification accuracy equal to the BP neural network method. In addition, the role of the supply chain (SC) in mediating the link between SCF adoption, and the importance of supply chain effectiveness (SCE) is discussed. This research helps marketers and professionals better understand how to use SCF in their enterprises to reduce risk and improve SCF by providing data and connecting with financial institutions.",2023
The Analysis of Credit Risks in Agricultural Supply Chain Finance Assessment Model Based on Genetic Algorithm and Backpropagation Neural Network,"The risk assessment methods of agricultural supply chain finance (SCF) are explored to reduce agricultural SCF's credit risks. First, the genetic algorithm (GA) is utilized to adjust and determine the initial weights and thresholds of the backpropagation neural network (BPNN), which assesses the credit risks. Second, for the problem that many factors affect the credit risks and the difficulty in selecting the characteristics, the principle of assessment indicator selection is proposed; the characteristics of these indicators are selected by principal component analysis (PCA). Finally, the case analysis method is utilized to verify the proposed risk assessment method, and an optimal credit risk assessment method is established. The results show that GA-BPNN can accelerate the convergence speed of the BPNN and improve the disadvantage in easily falling into the local minimum of BPNN. The PCA method simplifies the complexity of assessment indicator selection, and the representative indicators in agricultural SCF credit risk assessment are successfully selected. Through verification, it is found that the GA-BPNN algorithm performs well in credit risk prediction of agricultural SCF, and its prediction accuracy and prediction speed are improved. Therefore, the used GA-BPNN has performed well in the credit risk prediction of agricultural SCF, which applies to financial credit risk assessment to reduce the credit risks in agricultural SCF.",2022
Deep Reinforcement Learning in Agent Based Financial Market Simulation,"Prediction of financial market data with deep learning models has achieved some level of recent success. However, historical financial data suffer from an unknowable state space, limited observations, and the inability to model the impact of your own actions on the market can often be prohibitive when trying to find investment strategies using deep reinforcement learning. One way to overcome these limitations is to augment real market data with agent based artificial market simulation. Artificial market simulations designed to reproduce realistic market features may be used to create unobserved market states, to model the impact of your own investment actions on the market itself, and train models with as much data as necessary. In this study we propose a framework for training deep reinforcement learning models in agent based artificial price-order-book simulations that yield non-trivial policies under diverse conditions with market impact. Our simulations confirm that the proposed deep reinforcement learning model with unique task-specific reward function was able to learn a robust investment strategy with an attractive risk-return profile.",2020
Application of BP Neural Network in Early-Warning Analysis of Investment Financial Risk in Coastal Areas,"Financial risks in coastal areas are not only related to the current state of capital markets, but also to the positive fiscal policy effects implemented in recent years. Foreign speculative capital has not yet had a serious impact on China's monetary and financial markets. In this paper, first, the factors of financial risk in coastal areas are identified, and the corresponding evaluation index system is established with the Delphi method. Then the back-propagation neural network model is used to carry out the early-warning analysis of the major destinations of overseas mining investments. The results show that risk warnings will be moderate in Canada, Russia, and Australia in the coming years, with fewer risk warnings in Brazil, India, and South Africa. South Africa's economy is in a poor state of economic development; Brazil's real lending rate is too high. Chinese enterprises may consider investing in overseas mining in countries where the risk warning is light.",2020
Value at Risk Measurement Method under Deep Learning in Analysing the Excessive Financialization of Enterprises,"This study proposes a novel model that integrates the generative adversarial network (GAN) with the value at risk (VaR) measuring method. The objective is to investigate the efficacy of the VaR method in addressing the issue of excessive financialization in enterprises. Firstly, the related concepts and calculation principles of VaR in the financial field are explained, and the autoregressive conditional heteroscedastic (ARCH) familybased VaR calculation method and the basic structure of GAN under the deep learning are introduced. Then, the GAN algorithm is employed to optimize and train the initialization network, transformation network, and structure network of the GAN algorithm. Finally, the optimized GAN is applied to the VaR measurement of 300 stocks in Shanghai and Shenzhen stock market. GAN demonstrates the ability to handle unbalanced data samples, sample minority data, and fit the overall distribution of minority samples. GAN introduces a groundbreaking method for data processing, and its integration with manual efforts yields significant improvements in practical applications. Moreover, GAN demonstrates a positive impact on data set training, offering reliable potential for advancement and serving as a valuable point of reference. In conclusion, the combination of GAN under deep learning with VaR showcases a dependable practicability in assessing the risks associated with excessive financialization.",2024
Mining User's Opinion Towards the Rising and Falling Trends of the Stock Market: A Hybrid Model,"Mining users' opinions towards the rising and falling trends of the stocks may help the management department estimate the risk and make timely decision. Existing methods ignore the effective fusion of domain information and pretrained language models, hindering mining implicit semantic information. This paper proposes a hybrid method that adopts masked language modeling to obtain a domain-information-enhanced language model. Firstly, it generates an attention-mechanism-oriented masking based on words' importance, word-level polarity and terminology. Then, the masked words and their corresponding knowledge are predicted to acquire domain-aware language representation. Experimental results on two public financial sentiment analysis datasets show the efficacy of the proposed model.",2021
The lending risk predicting of the folk informal financial organization from big data using the deep learning hybrid model,"This article is first to predict and earlier warning folk lending risk used deep learning hybrid model, we find that the LSTM hybrid model has a higher predict accuracy on lending risk fore-casting and earlier warning of the FIFO, with an obviously improvement of the average value of forecasting accuracy. The predict accuracy of LSTM-GRU and LSTM-CNN models on lending risk forecasting of the FIFO is higher than others during COVID-19 pandemic. Therefore, we believe that the LSTM hybrid model, especially the LSTM-GRU model can better predict and early warn lending risk of the FIFO on big data.",2022
Impact of care management processes and integration of care on blood pressure control in diabetes,"Background: Fragmentation within health care systems may negatively impact the quality of chronic disease patient care. We sought to evaluate the relationship between care management processes (CMP), integration of services, and blood pressure (BP) control among diabetic patients. Methods: Retrospective chart reviews were performed for a random sample of adult diabetic hypertensive patients (n = 2,162) from 28 physician organizations in the United States (US). A modified version of the Physician Practice Connection Readiness Survey (PPC-RS) was completed by the chief medical officer at each site. The PPC-RS measured health system organization, delivery system redesign, decision support, clinical information systems, and self-management support, and an integration scale measured structure, functions, and financial risk. Correlations between PPC and integration scores and BP outcomes were assessed using Spearman correlation coefficients. Results: Approximately 39.9% of diabetic patients had controlled BP. Mean total PPC score across sites was 55, with highest mean scores for health system organization (81), followed by design support (60), clinical information systems (57), self-management support (39), and delivery system redesign (39). Mean integration score was 46 (SD 27, range 4-93), and means of subscores were 64 for structure, 33 for financial risk, and 42 for function. Clinical information systems subscore was correlated with uncontrolled BP (r = -0.38, p < 0.05), while association with total PPC score was strong but not significant at p < 0.05 (r = -0.32). Total integration score and the structure subscore were significantly correlated with BP control (r = 0.38, p < 0.05, and r = 0.49, p < 0.01). Conclusions: This study suggests that CMP and service integration may be associated with better outcomes in diabetes, though results were mixed and limited by a small number of participating sites. Primary care implementation of integrated electronic medical records may have a beneficial effect on patient outcomes for diabetes and other chronic diseases.",2013
"Deep learning-based classification, detection, and segmentation of tomato leaf diseases: A state-of-the-art review","The early identification and treatment of tomato leaf diseases are crucial for optimizing plant productivity, efficiency and quality. Misdiagnosis by the farmers poses the risk of inadequate treatments, harming both tomato plants and agroecosystems. Precision of disease diagnosis is essential, necessitating a swift and accurate response to misdiagnosis for early identification. Tropical regions are ideal for tomato plants, but there are inherent concerns, such as weather-related problems. Plant diseases largely cause financial losses in crop production. The slow detection periods of conventional approaches are insufficient for the timely detection of tomato diseases. Deep learning has emerged as a promising avenue for early disease identification. This study comprehensively analyzed techniques for classifying and detecting tomato leaf diseases and evaluating their strengths and weaknesses. The study delves into various diagnostic procedures, including image pre-processing, localization and segmentation. In conclusion, applying deep learning algorithms holds great promise for enhancing the accuracy and efficiency of tomato leaf disease diagnosis by offering faster and more effective results. (c) 2025 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).",2025
Strategic framework for natural disaster risk mitigation using deep learning and cost-benefit analysis,"Given trends in more frequent and severe natural disaster events, developing effective risk mitigation strategies is crucial to reduce negative economic impacts, due to the limited budget for rehabilitation. To address this need, this study aims to develop a strategic framework for natural disaster risk mitigation, highlighting two different strategic implementation processes (SIPs). SIP-1 is intended to improve the predictability of natural disaster-triggered financial losses using deep learning. To demonstrate SIP-1, SIP-1 explores deep neural networks (DNNs) that learn storm and flood insurance loss ratios associated with selected major indicators and then develops an optimal DNN model. SIP-2 underlines the risk mitigation strategy at the project level, by adopting a cost-benefit analysis method that quantifies the cost effectiveness of disaster prevention projects. In SIP-2, a case study of disaster risk reservoir projects in South Korea was adopted. The validated result of SIP-1 confirmed that the predictability of the developed DNN is more accurate and reliable than a traditional parametric model, while SIP-2 revealed that maintenance projects are economically more beneficial in the long term as the loss amount becomes smaller after 8 years, coupled with the investment in the projects. The proposed framework is unique as it provides a combinational approach to mitigating economic damages caused by natural disasters at both financial loss and project levels. This study is its first kind and will help practitioners quantify the loss from natural disasters, while allowing them to evaluate the cost effectiveness of risk reduction projects through a holistic approach.",2022
Fuzzy convolutional deep-learning model to estimate the operational risk capital using multi-source risk events,"Operational Risk (OR) is usually caused by losses due to human errors, inadequate or defective internal processes, system failures or external events that affect an organization. According to the Basel II agreement, OR is defined by seven risk events: internal fraud, external fraud, labor relations, clients, damage to fixed assets, technological failures and failures in the execution & administration of processes. However, due to the large amount of qualitative information, the uncertainty and the low frequency at which these risk events are generated in an organization, their modeling is still a technological challenge. This paper takes up this challenge and presents a fuzzy convolutional deep-learning model to estimate, based on the Basel III recommendations, the ORLoss Component (OR-LC) in an organization. The proposed model integrates qualitative information as linguistic random variables, as well as risk events data from different sources using multi-dimensional fuzzy credibility concepts. The results show the stability of the proposed model with respect to the OR-LC estimation from both structural and dimensional point of views, making it an ideal tool for modeling OR from the perspective of: (a) the regulators (Basel Committee on Banking Supervision) by allowing the integration of experts' criteria into the OR-LC; (b) the insurers by allowing the integration of risk events from different sources; and (c) organizations and financial entities by allowing the a priori evaluation of the OR-LC of new financial products based on technological platforms and electronic channels. (C) 2021 Elsevier B.V. All rights reserved.",2021
Deep graph convolutional reinforcement learning for financial portfolio management-DeepPocket,"Portfolio management aims at maximizing the return on investment while minimizing risk by continuously reallocating the assets forming the portfolio. These assets are not independent but correlated during a short time period. A graph convolutional reinforcement learning framework called DeepPocket is proposed whose objective is to exploit the time-varying interrelations between financial instruments. These interrelations are represented by a graph whose nodes correspond to the financial instruments while the edges correspond to a pair-wise correlation function in between assets. DeepPocket consists of a restricted, stacked autoencoder for feature extraction, a convolutional network to collect underlying local information shared among financial instruments and an actor-critic reinforcement learning agent. The actor-critic structure contains two convolutional networks in which the actor learns and enforces an investment policy which is, in turn, evaluated by the critic in order to determine the best course of action by constantly reallocating the various portfolio assets to optimize the expected return on investment. The agent is initially trained offline with online stochastic batching on historical data. As new data become available, it is trained online with a passive concept drift approach to handle unexpected changes in their distributions. DeepPocket is evaluated against five real-life datasets over three distinct investment periods, including during the Covid-19 crisis, and clearly outperformed market indexes.",2021
MRRFGNN: Multi-relation reconstruction and fusion graph neural network for stock crash prediction,"Stock crash risk often propagates through various interconnected relationships between firms, amplifying its impact across financial markets. Few studies predicted the crash risk of one firm in terms of its relevant firms. A common strategy is to adopt graph neural networks (GNNs) with some predefined firm relations. However, many relations remain undetected or evolve over time. Restricting to several predefined relations inevitably makes noise and thus misleads stock crash predictions. In addition, these relationships are not independent during the process of propagating information and interacting with each other. This study proposes the multi-relation reconstruction and fusion graph neural network (MRRFGNN) to predict stock crash risk by capturing complex relations among listed companies. First, the model employs self-supervised learning and contrastive learning to reconstruct and infer implicit relationships between companies. Second, the model incorporates a relation self-attention mechanism to integrate various types of relationships, enabling a more nuanced understanding of the multiple spillover effects. Empirical evidence from a series of experiments demonstrates the superiority of the proposed method, which achieves the best performance with improvements of at least 2.14% in area under the curve (AUC) and 2.64% in Matthews correlation coefficient (MCC), highlighting its potential for practical application in financial markets.",2025
INTEGRATING REMOTE SENSING FOR EARTHQUAKE RISK ASSESSMENT IN ISTANBUL'S KARTAL DISTRICT,"Developing strategies to mitigate damage from high- risk buildings in earthquake-prone areas is essential. This study focuses on prioritizing buildings based on their risk levels, considering the impracticality of addressing all high- risk structures simultaneously. Traditional methods emphasize individual buildings, overlooking the collective impact. This study extends beyond earthquake effects, considering financial losses due to displacements particularly in energy-dependent contexts. Advancements in remote sensing, particularly SAR technology's phase and amplitude signal characteristics, are crucial. These technologies facilitate shell deformation analysis, classification studies, and post-disaster damage mapping, offering broad spatial coverage and all-weather, day-and-night operation. Our study employs Sentinel 1 SBAS method, Tandem-X Change detection maps, building construction dates, and VS30 data to analyze Istanbul's Kartal District. Utilizing Microsoft's deep learning-based building footprints, seismic VS30 data, TanDEM-X Change Maps, and building age and height information, this research comprehensively assesses earthquake risks. The SBAS technique with Sentinel 1 data is applied for surface displacement analysis, enhancing the understanding of earthquake losses and updating ground deformation data for Istanbul.",2024
Comprehensive review of different artificial intelligence-based methods for credit risk assessment in data science,"Credit risk is the critical problem faced by banking and financial sectors when the borrower fails to complete their commitments to pay back. The factors that could increase credit risk are non-performing assets and frauds which are improved by continuous monitoring of payments and other assessment patterns. In past years, few statistical and manual auditing methods were investigated which were not much suitable for tremendous amount of data. Thus, the growth of Artificial Intelligence (AI) with efficient access to big data is focused. However, the effective Deep Learning (DL) and Machine Learning (ML) techniques are introduced to improve the performance and issues in banking and finance sectors by concentrating the business process and customer interaction. In this review, it mainly focusses on the different learning methods-based research articles available in recent years. This review also considers 93 recent research articles that were available in the last 5 years related to the topic of credit risk with different learning methods to tackle traditional challenges. Thus, these advances can make the banking process as smart and fast while preserving themselves from credit defaulters.",2023
Credit Scoring Model: A Combination of Genetic Programming and Deep Learning,"In recent years, the market of customer lending grows rapidly, that is a reason why credit scoring becomes a core task of financial institutes. Many models based on machine learning have been widely using and providing robust performance. Because most machine learning based models are black-box, it is hard to see the relations between input data and scoring results. Therefore, this paper focuses on improving both the accuracy and the reliability of machine learning based model. Thus, we propose a hybrid idea to combine the power of deep learning network and the comprehensive genetic programming which is extracted rules to build a robust credit model. Our empirical experiment on Australian/German customer credit data sets shows that our model provides the best accuracy, highly reduce credit risk, and reliable IF-THEN rules.",2016
Self-Supervised Prototype Representation Learning for Event-Based Corporate Profiling,"Event-based corporate profiling aims to assess the evolving operational status of the corresponding corporate from its event sequence. Existing studies on corporate profiling have partially addressed the problem via (i) case-by-case empirical analysis by leveraging traditional financial methods, or (ii) the automatic profile inference by reformulating the problem into a supervised learning task. However, both approaches heavily rely on domain knowledge and are labor-intensive. More importantly, the task-specific nature of both approaches prevents the obtained corporate profiles from being applied to diversified downstream applications. To this end, in this paper, we propose a Self-Supervised Prototype Representation Learning (SePaL) framework for dynamic corporate profiling. By exploiting the topological information of an event graph and exploring self-supervised learning techniques, SePaL can obtain unified corporate representations that are robust to event noises and can be easily fine-tuned to benefit various down-stream applications with only a few annotated data. Specifically, we first infer the initial cluster distribution of noise-resistant event prototypes based on latent representations of events. Then, we construct four permutation-invariant self-supervision signals to guide the representation learning of the event prototype. In terms of applications, we exploit the learned time-evolving corporate representations for both stock price spike prediction and corporate default risk evaluation. Experimental results on two real-world corporate event datasets demonstrate the effectiveness of SePaL for these two applications.",2021
Risk Management of Supply Chain Green Finance Based on Sustainable Ecological Environment,"Green supply chain finance is a new financing method that focuses on corporate restructuring and promotes corporate capital flow and the development of environmental protection. This paper used BP neural network technology to study the green financing of the supply chain under the sustainable ecological environment. The method played an important role in the trial. Due to the more uncertain factors faced and the more complex environment, the risks of green supply chain finance are more hidden, diverse, and complex. The BP neural network is relatively mature in both network theory and performance. Its outstanding advantages are its strong nonlinear mapping ability and flexible network structure. The positive effect of BP neural network on green financial risk management is verified by experiments. Green supply chain finance is an innovative model of green finance. This experiment studies the risk management of green finance in supply chain and the evaluation index of green finance risk management through BP neural network method, and shows that the evaluation results are highly scientific. In addition, based on the green supply chain model, the historical data of different regions provide a scientific basis for the sustainable ecological development of the region. This paper provides guidance for the sustainable development of green finance in the supply chain and makes contributions to promoting the development of green economy. In order to control the risks of supply chain financing business, the risks of supply chain financing business are classified and analyzed, and specific project risk levels and points are determined to propose control measures to ensure effective control of the business risks.",2023
DeepClue: Visual Interpretation of Text-Based Deep Stock Prediction,"The recent advance of deep learning has enabled trading algorithms to predict stock price movements more accurately. Unfortunately, there is a significant gap in the real-world deployment of this breakthrough. For example, professional traders in their long-term careers have accumulated numerous trading rules, the myth of which they can understand quite well. On the other hand, deep learning models have been hardly interpretable. This paper presents DeepClue, a system built to bridge text-based deep learning models and end users through visually interpreting the key factors learned in the stock price prediction model. We make three contributions in DeepClue. First, by designing the deep neural network architecture for interpretation and applying an algorithm to extract relevant predictive factors, we provide a useful case on what can be interpreted out of the prediction model for end users. Second, by exploring hierarchies over the extracted factors and displaying these factors in an interactive, hierarchical visualization interface, we shed light on how to effectively communicate the interpreted model to end users. Specially, the interpretation separates the predictables from the unpredictables for stock prediction through the use of intercept model parameters and a risk visualization design. Third, we evaluate the integrated visualization system through two case studies in predicting the stock price with financial news and company-related tweets from social media. Quantitative experiments comparing the proposed neural network architecture with state-of-the-art models and the human baseline are conducted and reported. Feedbacks from an informal user study with domain experts are summarized and discussed in details. The study results demonstrate the effectiveness of DeepClue in helping to complete stock market investment and analysis tasks.",2019
A hybrid model based on iTransformer for risk warning of crude oil price fluctuations,"In order to reduce the unpredictability of crude oil price fluctuations caused by its increasingly prominent financial and geopolitical attributes, and to minimize its negative impact on the world economy, further research on risk warning models for crude oil price fluctuations is urgently needed. To improve the accuracy of early warning, a multi-factor prediction based risk warning method for crude oil price fluctuations is proposed. This method includes three main steps: (1) Risk factor analysis, which systematically identifies the risk factors of crude oil prices from socio-economic, market, production, and environmental aspects, uses Random Forest algorithm to screen key factors, and predicts future trends through LSTM model; (2) Prediction of crude oil prices, which constructs a prediction model for crude oil prices based on the iTransformer algorithm; (3) Fluctuation risk warning, based on historical volatility, constructs a crude oil price fluctuation risk warning mechanism, and analyzes the warning results. This article takes the historical data of WTI crude oil futures closing prices and risk factors as samples, and the model error comparison results confirm that the warning mechanism has significant superiority in accuracy, which can provide scientific and accurate reference basis for government intervention policies.",2025
Stock Recommendation Model with Investor Risk Acceptance,"In this era of high inflation and low interest rates, the public often invests in financial products to increase their passive income and thus increase their savings. Current data show that the public still considers stocks as investment targets. However, because investment is risky and each person's investment personality (risk tolerance) is different, some prefer to take risks to obtain the maximum return, and some are afraid of risks and avoid them to obtain stable returns; nevertheless, the recommendations of current research give little consideration to the risk characteristics of the investment target and the personal characteristics of the investor. However, investment is a trade-off between risk and reward, and the risk acceptance associated with an investment depends on the investor's ability to accept risk. Therefore, in the context of recommending, a consideration of investors' personal characteristics brings recommendations more in line with users' expectations. This study proposes a method to manage investment portfolios based on investors' risk personalities. It is mainly used to classify stocks according to beta indicators (select stocks according to investors' personalities), and financial indicators and an autoencoder are used to score stocks; moreover, technical indicators, covariance matrices, deep reinforcement learning-advantage actor critic (A2C), and proximal policy optimization (PPO) are used for asset allocation with the aim of developing investment portfolios with good performance that are optimally suitable for different types of investors. In the training results, the cumulative return rate obtained by the A2C model is as high as 49.61% for conservative investments, 82.04% for stable investments, and 99.69% for active investments. The cumulative return obtained by the PPO model is as high as 39.92% for conservative investments, 89.89% for stable investments, and 85.61% for active investments.",2024
Improving EMI Risk Model for E-commerce with Customer Embedding Obtained through Heterogeneous Graph,"Machine Learning based credit risk models are often based on handcrafted features based on credit history and financial transactions. In this work, we develop a risk model for Equated Monthly Installment (EMI) based loans offered by one of the biggest e-commerce companies in India using two types of features (a) handcrafted features derived from customer actions and account details (b) customer embedding learned from a heterogeneous graph built using their shopping behavior across various product segments to leverage the purchase and co-purchase patterns of the users. Popular algorithms capable of learning powerful node embedding from the graph structure are transductive in nature, making them difficult to use in large graphs. However, we could exploit the special nature of our graph to generalize our embedding learning method for a large customer population. We show that using our graph based embedding along with handcrafted features improves the risk model's performance trained using just the handcrafted features. We also show that the graph embedding are more powerful than features learnt through autoencoder which can capture the purchase patterns of customers but not the co-purchase patterns among them.",2024
From GARCH to Neural Network for Volatility Forecast,"Volatility, as a measure of uncertainty, plays a crucial role in numerous financial activities such as risk management. The Econometrics and Machine Learning communities have developed two distinct approaches for financial volatility forecasting: the stochastic approach and the neural network (NN) approach. Despite their individual strengths, these methodologies have conventionally evolved in separate research trajectories with little interaction between them. This study endeavors to bridge this gap by establishing an equivalence relationship between models of the GARCH family and their corresponding NN counterparts. With the equivalence relationship established, we introduce an innovative approach, named GARCH-NN, for constructing NN-based volatility models. It obtains the NN counterparts of GARCH models and integrates them as components into an established NN architecture, thereby seamlessly infusing volatility stylized facts (SFs) inherent in the GARCH models into the neural network. We develop the GARCH-LSTM model to showcase the power of the GARCH-NN approach. Experiment results validate that amalgamating the NN counterparts of the GARCH family models into established NN models leads to enhanced outcomes compared to employing the stochastic and NN models in isolation.",2024
A Comprehensive Review on Heart Disease Risk Prediction using Machine Learning and Deep Learning Algorithms,"Cardiovascular diseases claim approximately 17.9 million lives annually, with heart attacks and strokes accounting for over 80% of these deaths. Key risk factors, including hypertension, hyperglycemia, dyslipidemia, and obesity, are identifiable, offering opportunities for timely intervention and reduced mortality. Early detection of heart disease enables individuals to adopt lifestyle changes or seek medical treatment. However, conventional diagnostic methods, such as electrocardiograms-commonly used in clinics and hospitals to detect abnormal heart rhythms-are not effective in identifying actual heart attacks. Additionally, angiography, while more precise, is an invasive method, financial strain on patients, and high chances of incorrect diagnosis, highlighting the need for alternative approaches. The main goal of this study was to assess the accuracy of machine learning techniques, including both individual and combined classifiers, in early detection of heart diseases. Furthermore, the study aims to highlight areas where additional research is necessary. Our investigation covers a decade period from 2014 to 2024, including a thorough review of pertinent literature from international conferences and top journals from the databases like Springer, ScienceDirect, IEEEXplore, Web of Science, PubMed, MDPI, Hindawi and so on. The following keywords were used to search the articles: heart disease risk, heart disease prediction, data mining, data preprocessing, machine learning algorithms, ensemble classifiers, deep learning algorithms, feature selection, hyperparameter optimization techniques. We examine the methodologies used and evaluate their effectiveness in predicting cardiovascular conditions. Our findings reveal notable progress in applying machine learning and deep learning in cardiology. The study concludes by proposing a framework that incorporates current machine learning techniques to enhance heart disease prediction.",2025
Value-at-Risk forecasting: A hybrid ensemble learning GARCH-LSTM based approach,"This study proposes a new hybrid model that combines LSTM and BiLSTM neural networks with GARCH type model forecasts using an ensemble approach to forecast volatility for one-day ahead 95% and 99% Value-at-Risk (VaR) estimates using the Parametric (PAR) and Filtered Historical Simulation (FHS) method. The forecasting abilities of the standard GARCH (GARCH), exponential GARCH (eGARCH), and threshold GARCH (tGARCH) models are combined with the LSTM networks to capture different characteristics of the underlying volatility. We evaluate the model using log returns on Crude Oil during two periods of extreme volatility: the 2007-09 Financial Crisis and the Covid Recession of 2020-21. The performance of hybrid models is compared against several traditional VaR methods like the Historical Simulation, Bootstrap, Age weighted method, and the volatility-based VaR models using the GARCH, LSTM, and BiLSTM model forecasts. The unconditional and conditional coverage tests and a combination of regulator and firm loss functions are used to evaluate the quality of VaR forecasts. We find a significant improvement in the quality and accuracy of the VaR forecasts of the hybrid models over all the other models across all loss functions and coverage tests. The FHS-BiLSTM-HYBRID, a proposed FHS-based hybrid model, combining the BiLSTM model with three GARCH-type models, is the best performing, with the lowest values for both loss functions. The traditional and GARCH-type models do not efficiently model volatility during the crisis periods resulting in poor VaR forecasts. The FHS consistently performs as the best method for generating VaR compared to all other approaches.",2022
A Peak Price Tracking-Based Learning System for Portfolio Selection,"We propose a novel linear learning system based on the peak price tracking (PPT) strategy for portfolio selection (PS). Recently, the topic of tracking control attracts intensive attention and some novel models are proposed based on backstepping methods, such that the system output tracks a desired trajectory. The proposed system has a similar evolution with a transform function that aggressively tracks the increasing power of different assets. As a result, the better performing assets will receive more investment. The proposed PPT objective can be formulated as a fast backpropagation algorithm, which is suitable for large-scale and time-limited applications, such as high-frequency trading. Extensive experiments on several benchmark data sets from diverse real financial markets show that PPT outperforms other state-of-the-art systems in computational time, cumulative wealth, and risk-adjusted metrics. It suggests that PPT is effective and even more robust than some defensive systems in PS.",2018
Prediction Model of International Trade Risk Based on Stochastic Time-Series Neural Network,"With the extreme deterioration of domestic and foreign trade environment, international competition is becoming increasingly fierce. At the same time, many enterprises have loopholes in industrial structure and finance, resulting in many risks in their international trade. Therefore, we must take corresponding measures to effectively manage and avoid risks and realize the healthy and sustainable development of foreign trade enterprises and enterprise economy. This paper designs and proposes a risk prediction model combining ARIMA and BP neural network. The model can get good prediction in different time series and effectively avoid the risk. The model proposed in this paper optimizes the structure of the design model with the support of ARIMA algorithm and BP neural network algorithm and has good accuracy and error control for different time series. The purpose of establishing time series prediction model is to improve the prediction accuracy of the model, and it is also an effective way to enhance the practicability of the prediction model. Applying intersequence analysis method to financial risk prediction can greatly improve efficiency and save cost and has broad application prospects.",2022
Research on Risk Assessment and Prediction of RMB Internationalization Based on the PCA-SA-BPNN Model,"This paper combines principal component analysis, a BP neural network, and a simulated annealing algorithm, to construct a PCA-SA-BPNN risk forecast model to evaluate and predict the RMB internationalization risk status of China. First, we analyze the risk of RMB internationalization and its transmission mechanism from the perspective of the economic characteristics of neighboring countries and trading partner countries. Second, we use the FASP index system construction method for reference to construct a forecast index system for macro- and microrisks brought about by RMB internationalization. Then, the weight of each index is determined through index common degree analysis and principal component analysis, and the risk of RMB internationalization is divided. On this basis, the risks of RMB internationalization in China from 2000 to 2019 are divided into four categories. Based on the BP neural network algorithm optimized by the simulated degradation algorithm, the PCA-SA-BPNN model of RMB internationalization risk forecast is constructed. Finally, the validity of the model is verified by experimental verification, and the risk status of RMB internationalization in 2020 is simulated and predicted. The research results show that the risk status of RMB internationalization in 2020 is basically safe, and the risks of RMB internationalization mainly come from macroeconomic growth risks and systemic risks of the financial system.",2022
Trade-Time Measures of Liquidity,"Dramatic microstructure changes in equity markets have made standard liquidity measures less accurate proxies for trading costs. We develop trade-time liquidity measures that reflect per-dollar price impacts of fixed-dollar volumes. Our measures better capture institutional trading costs and better explain the cross-section of returns than do standard measures, especially in recent years. Despite improvements in measures of market quality, expected trading costs have explanatory power for the cross-section of expected returns: we obtain monthly liquidity premium estimates of 5.3 bp for expected returns and 2.4 bp for risk-adjusted returns. Estimated premiums rise after the financial crisis and remain high thereafter. Received April 15, 2016; editorial decision December 24, 2017 by Editor Andrew Karolyi.",2019
"Time series modelling, NARX neural network and hybrid KPCA-SVR approach to forecast the foreign exchange market in Mauritius","Purpose This study constructs time series model, artificial neural networks (ANNs) and statistical topologies to examine the volatility and forecast foreign exchange rates. The Mauritian forex market has been utilized as a case study, and daily data for nominal spot rate (during a time period of five years spanning from 2014 to 2018) for EUR/MUR, GBP/MUR, CAD/MUR and AUD/MUR have been applied for the predictions. Design/methodology/approach Autoregressive integrated moving average (ARIMA) and generalized autoregressive conditional heteroskedasticity (GARCH) models are used as a basis for time series modelling for the analysis, along with the non-linear autoregressive network with exogenous inputs (NARX) neural network backpropagation algorithm utilizing different training functions, namely, Levenberg-Marquardt (LM), Bayesian regularization and scaled conjugate gradient (SCG) algorithms. The study also features a hybrid kernel principal component analysis (KPCA) using the support vector regression (SVR) algorithm as an additional statistical tool to conduct financial market forecasting modelling. Mean squared error (MSE) and root mean square error (RMSE) are employed as indicators for the performance of the models. Findings The results demonstrated that the GARCH model performed better in terms of volatility clustering and prediction compared to the ARIMA model. On the other hand, the NARX model indicated that LM and Bayesian regularization training algorithms are the most appropriate method of forecasting the different currency exchange rates as the MSE and RMSE seemed to be the lowest error compared to the other training functions. Meanwhile, the results reported that NARX and KPCA-SVR topologies outperformed the linear time series models due to the theory based on the structural risk minimization principle. Finally, the comparison between the NARX model and KPCA-SVR illustrated that the NARX model outperformed the statistical prediction model. Overall, the study deduced that the NARX topology achieves better prediction performance results compared to time series and statistical parameters. Research limitations/implications The foreign exchange market is considered to be instable owing to uncertainties in the economic environment of any country and thus, accurate forecasting of foreign exchange rates is crucial for any foreign exchange activity. The study has an important economic implication as it will help researchers, investors, traders, speculators and financial analysts, users of financial news in banking and financial institutions, money changers, non-banking financial companies and stock exchange institutions in Mauritius to take investment decisions in terms of international portfolios. Moreover, currency rates instability might raise transaction costs and diminish the returns in terms of international trade. Exchange rate volatility raises the need to implement a highly organized risk management measures so as to disclose future trend and movement of the foreign currencies which could act as an essential guidance for foreign exchange participants. By this way, they will be more alert before conducting any forex transactions including hedging, asset pricing or any speculation activity, take corrective actions, thus preventing them from making any potential losses in the future and gain more profit. Originality/value This is one of the first studies applying artificial intelligence (AI) while making use of time series modelling, the NARX neural network backpropagation algorithm and hybrid KPCA-SVR to predict forex using multiple currencies in the foreign exchange market in Mauritius.",2021
On the combination of graph data for assessing thin-file borrowers' creditworthiness,"Thin-file borrowers are customers for whom a creditworthiness assessment is uncertain due to their lack of credit history. To address missing credit information, many researchers have used borrowers' social interactions as an alternative data source. Exploiting social networking data has traditionally been achieved by hand-crafted feature engineering, but lately, graph neural networks have emerged as a promising alternative. Here we introduce an information-processing framework to improve credit scoring models by blending several methods of graph representation learning: feature engineering, graph embeddings, and graph neural networks. In this approach, we aggregate the methods' outputs to be fed to a gradient boosting classifier to produce a final creditworthiness score. We have validated this framework over a unique multi-source dataset that characterizes the relationships, interactions, and credit history for the entire population of a Latin American country, applying it to credit risk models, application, and behavior. It also allows us to study both individuals and companies. Our results show that the methods of graph representation learning should be used as complements; they should not be seen as self-sufficient methods, as it is currently done. We improve the creditworthiness assessment performance in terms of the measures of Area Under the ROC Curve (AUC) and Kolmogorov- Smirnov (KS), outperforming traditional methods of exploiting social interaction data. In the area of corporate lending, where the potential gain is much higher, our results confirm that the evaluation of a thin-file company cannot solely consider the company's own characteristics. The business ecosystem in which these companies interact with their owners, suppliers, customers, and other companies provides novel knowledge that enables financial institutions to enhance their creditworthiness assessment. Our results let us know when and on which population to use graph data and the expected effects on performance. They also show the enormous value of graph data on the credit scoring problem for thin-file borrowers, mainly to help companies with thin or no credit history to enter the financial system.",2023
Application of Support Vector Machines in debt to GDP ratio forecasting,"This paper deals with the application of a novel neural network technique, Support Vector Machine (SVM), in financial time series forecasting. This study applies SVM to predict the debt to GDP ratio index. The objective of this paper is to examine the feasibility of SVM in foreign debt risk forecasting by comparing it with a back-propagation (BP) neural network. We choose Gaussian function as its Kernel function. The experiment shows that SVM outperforms the BP neural network based on the criteria of mean absolute error (MAE), mean absolute percent error (MAPE), mean squared error (MSE) and root mean square error (RMSE). Analysis of the experimental results proved that it is advantageous to apply SVMs to forecast debt to GDP ratio.",2006
The global epidemiology of hypertension,"Hypertension is the leading global cause of cardiovascular disease and premature mortality. In this Review, the authors describe the prevalence, awareness, treatment and control of hypertension worldwide, as well as risk factors for hypertension and the financial burden of this disease. Hypertension is the leading cause of cardiovascular disease and premature death worldwide. Owing to the widespread use of antihypertensive medications, global mean blood pressure (BP) has remained constant or has decreased slightly over the past four decades. By contrast, the prevalence of hypertension has increased, especially in low- and middle-income countries (LMICs). Estimates suggest that 31.1% of adults (1.39 billion) worldwide had hypertension in 2010. The prevalence of hypertension among adults was higher in LMICs (31.5%, 1.04 billion people) than in high-income countries (28.5%, 349 million people). Variations in the levels of risk factors for hypertension, such as high sodium intake, low potassium intake, obesity, alcohol consumption, physical inactivity and unhealthy diet, may explain some of the regional heterogeneity in hypertension prevalence. Despite the increasing prevalence, the proportions of hypertension awareness, treatment and BP control are low, particularly in LMICs, and few comprehensive assessments of the economic impact of hypertension exist. Future studies are warranted to test implementation strategies for hypertension prevention and control, especially in low-income populations, and to accurately assess the prevalence and financial burden of hypertension worldwide.",2020
"RETRACTED: Risk factor analysis combined with deep learning in the risk assessment of overseas investment of enterprises (Retracted article. See vol. 20, 2025)","To evaluate the overseas investment risks of enterprises and expand the application and development of deep learning methods in risk assessment, 15 national clusters are utilized as samples to analyze and discuss the overseas investment risk indicators of enterprises. First, based on the indicator system of overseas investment risks, five major types of investment risks are identified. Second, the Deep Neural Network (DNN) is introduced; a risk evaluation model is constructed for enterprise overseas investment. Finally, the investment attractiveness index in the Fraser risk assessment learning label is adopted as the evaluation results of the model. According to the classification of risks, the model is trained and its performance is tested. The results show that the major source of overseas investment risks includes basic resources, political systems, economic and financial development, and environmental protection. The corresponding risk score is high. North American country clusters and Oceanian country clusters have lower investment risks, while the investment risks in Africa, Latin America, and Asia are affected by multiple factors of the specific cities. This is closely related to the resources and legal systems possessed by the country clusters. This is of great significance for enterprises to conduct risk assessment in overseas investment.",2020
Business investment decision-making based on mathematical model and risk analysis,"Business investments are prone to market risks, so pre-analysis is mandatory. The type of risk, its period, sustainability, and economic impact are the analyzable features for preventing loss and downfall. In recent years, mathematical models have been used for representing business cycles and analyzing the impacting risks. This article introduces a Decisive Risk Analytical Model (DRAM) for identifying spur defects in business investments. The proposed risk analytical model exploits the investments, returns, and influencing factors over the various market periods. The risk model is tuned for identifying the influencing factors across various small and large investment periods. The model is tuned to adapt to different economic periods split into a single financial year. In the process of tuning and training the mathematical analysis model, deep learning is used. The learning paradigm trains the risks and modifying features from expert opinion and previous predictions. Based on these three factors, the risk for the current investment is forecasted. The forecast aids in improving the new investment feasibilities with minimal risks and model modifications. The frequent market status is identified for preventing unnecessary risk-oriented forecasts using the training performed. Therefore, the proposed model is reliable in identifying risks and providing better investment recommendations.",2024
Enterprise Financial Risk Early Warning Using BP Neural Network Under Internet of Things and Rough Set Theory,"In this paper, an enterprise financial risk indicator system is established to warn about the financial risk of enterprises. First, the related knowledge of financial risk and its measurement is introduced. Next, the financial risk indicator system of small- and medium-sized enterprises (SMEs) is established based on back propagation neural network (BPNN). The rough set theory is adopted to simplify the indicator. Finally, the BPNN model is used to predict the financial situation of SMEs. The results show that in the 490th iteration, the performance of the BPNN-based financial risk early warning system for SMEs can reach the optimal and meet the accuracy requirements of initialization. The error of the enterprise financial risk early warning model converges to the target error, so the calculation result is credible. The actual output after training is close to the expected output. By judging the actual output value, it can be known that the financial risk status of SMEs in 2016, 2017 and 2018 is of low alarm. This exploration has a certain preventive effect on the financial risk of enterprises and provides a basis for the rapid development of enterprises.",2022
An Explainable ADASYN-Based Focal Loss Approach for Credit Assessment,"The integration of deep learning techniques with financial technology (fintech) has revolutionized the credit risk analysis, a critical component of financial risk management. A pervasive challenge in credit risk assessment lies in the skewed distribution of data, hindering accurate predictions, particularly for minority class instances. In available literature, various solutions have been proposed to address class imbalance, albeit with limitations. Focal loss is one of the well-known loss functions proposed for handling class imbalance by running the hyperparameter gamma$$ \gamma $$. However, imbalance still remains in terms of number of hard-to-learn observations between the classes. In this paper, we have proposed integration of ADASYN with focal loss to mitigate class imbalance and enhance credit scoring accuracy. ADASYN systematically generates synthetic data based on hard-to-learn examples to counter skewed distributions, while focal loss prioritizes the training of challenging examples, fostering a more balanced model performance. This approach has been rigorously tested using real-world imbalanced datasets and credit assessment data, and the outcomes have been compared against a range of sample technique and loss function combinations. The results clearly show that our suggested strategy is better than other approaches. Although improving the accuracy of credit risk analysis is critical, model interpretability is just as important for enabling financial analysts to make wise choices. In order to solve this, we have measured the global and local contributions of each feature using SHAP (Shapley additive explanation). According to global interpretability, the top 4 parameters influencing credit risk assessment are checking account status, loan purpose, borrower age, credit history, and interest rate/installment rate. Moreover, local interpretability analysis reveals quantitative and direction differences in feature contributions. These revelations not only broaden our knowledge of credit assessment services but also highlight how important a role they could play in attracting new clients and generating income. This paper also highlights how the suggested approach may be scaled to other imbalanced real-world datasets, demonstrating how it can improve model performance in terms of AUC, G-mean, and F-measure.",2025
Enterprise risk assessment model based on graph attention networks,"Enterprise risk assessment not only provides a crucial reference for enterprises' strategic and business decisions, but also forms a fundamental basis for the financing decisions of banks and other financial institutions. Furthermore, as a critical node within the industrial chain, the enterprise's risk may directly affect the stability of the entire industrial chain, highlighting the significance of researching enterprise risk assessment. Existing enterprise risk assessment methods need to be revised to account for the risk transmission between enterprises across different types of relationships. Consequently, it leads to the need for more utilization of industrial chain structure and interaction information between enterprises. To address this problem, an enterprise risk assessment model, which is based on attention mechanism and graph network, is proposed. Firstly, weights of associated enterprises under a particular relationship are focused on. Then, weights of different relationships are introduced. After that, feature aggregation is conducted. Finally, features are put into the classification network to determine the risk category of the target enterprise, and enterprise risk assessment is accomplished. Experiments using dataset in integrated circuit industrial chain are conducted to verify this method, and the result shows that the method can effectively assess enterprise risk.",2025
Early warning of enterprise financial risk based on improved BP neural network model in low-carbon economy,"The concept of low-carbon economic development has led to changes in the business environment and financial environment of enterprises, leading to increased financial risks faced by enterprises. How to help enterprises better warn, prevent and control financial risks from the perspective of low-carbon economy has become a hot issue worth studying. Based on this, this paper is based on the perspective of low carbon economy, on the basis of analyzing the financing risk, investment risk, capital operation risk and growth risk faced by enterprises under the requirements of low carbon economy development. A set of financial risk management framework with clear hierarchy and strict vertical logic has been constructed. Ten financial early-warning indicators are constructed from four aspects. The risk prediction model of the indicator system is established using the research method of BPNN (Back Propagation Neural Network). The model is trained and simulated through the MATLAB neural network toolbox. After 10 indicators passed Bartlett's correlation test, the BPNN financial early warning model was programmed using MATLAB software. The accuracy rate was 84.3%. The neural network training results show that when the layer node is 8, the best correct recognition rate can be obtained. Incorporate low carbon into the financial risk early warning indicator system that meets the requirements of low carbon economic development in the design of enterprise financial risk early warning indicators. This paper is expected to provide reference and reference for low-carbon economy enterprises to deal with financial risks under the new situation.",2023
Adminization: Gatekeeping Consumer Contracts,"Large companies and debt collectors frequently file unmeritorious claims against consumers. Recent high-profile actions brought by the Consumer Financial Protection Bureau against J.P. Morgan, Citibank, and other large debt collectors illustrate the breadth and importance of this phenomenon. Due to the limited financial power of individuals, consumers often do not defend against such baseless claims, which results in the entry of millions of default judgments every year. To combat this problem, policymakers and scholars have explored a variety of court-based solutions that would make it easier for consumers to defend in court, but these prove ineffectual. To solve the problem of unmeritorious claiming, this Article proposes a budget-friendly solution called Adminization. This novel approach uses an administrative agency as a gatekeeper to civil litigation that is tasked with detecting and sanctioning the filing of baseless claims. The agency samples cases, using statistical methods and potentially deep-learning algorithms, and then investigates selected cases using agency auditors. When the auditors find wrongdoing, they are instructed to levy large fines against wrongdoers. Unlike the current system, Adminization subjects every plaintiff to the risk of thorough investigation and large fines, thus undercutting the financial incentive to engage in wrongful behavior. The importance of Adminization lies in its cost-effectiveness, practicality, and political feasibility relative to the court-based approaches that dominate the discussion today.",2018
AI Robo-Advisor with Big Data Analytics for Financial Services,"Robo-Advisors has been growing attraction from the financial industry for offering financial services by using algorithms and acting as like human advisors to support investors making investment decisions. During the investment planning stage, portfolio optimization plays a crucial role, especially for the medium and long-term investors, in determining the allocation weight of assets to achieve the balance between investors expectation return and risk tolerance. The literature on the topic of portfolio optimization has been offering plenty of theoretical and practical guidance for implementing the theory; however, there is a paucity of studies focusing on the applications which are designed for Robo-Advisors. In this research, we proposed a modular system and focused on integrating big data analysis, deep learning method and the Black-Litterman model to generate asset allocation weight. We developed a portfolio optimization module which takes the information from a variety of sources, such as stocks prices, investor profile and the other alternative data, and used them as input to calculate optimal weights of assets in the portfolio. The module we developed could be used as a sub-system for Robo-Advisors, which offers a customized optimal portfolio based on investors preference.",2018
Predicting Hospital Readmission of Diabetics using Deep Forest,"Diabetes can cause a variety of complications, which also leads to a high rate of repeated admission of patients with diabetes, which greatly increases the pain and financial burden of patients. Higher readmission rates also reduce hospital evaluation and operational efficiency. Therefore, it is urgent to screen out high-risk readmission patients in advance and introduce adjuvant treatment to reduce the probability of readmission. In this study, we propose a deep learning model combining wavelet transform and deep forest to hospital readmission of the diabetic. The proposed model has been tested with real clinical records and compared with several prevalent approaches to patient prediction. The experimental results show that the feature representation transformed by wavelet transform may well represent the original features and the deep forest is able to outperform the state-of-the-art approaches to classify diabetics.",2019
Asset pricing via deep graph learning to incorporate heterogeneous predictors,"Tradition financial studies on asset pricing focused on the economic indicators and media information of a stock. Recent financial studies found that the momentum spillovers of relevant firms are salient as well for measuring asset risk. However, previous studies on asset pricing via machine learning only relied on partial of these market information types. In this study, a deep learning framework is proposed to combine these three market information types with different data structures, that is, numerical economic indicators represented as scalars, media represented as textual vectors, and the influences of related firms captured by graphs. More importantly, the unique data characteristics brought by such data fusion are well addressed in the proposed learning framework. Specifically, a matrix-based module is first proposed to fuse numerical economic data and textual media, which specifically considers the interactions of the fused features. Such fused information, along with the firm relevance represented in graphs, is further integrated by a novel self-adaptive graph neural network that can address the dynamic merging of multilinked listed firms. Experiments performed on real market data demonstrate the effectiveness of the proposed approach over state-of-the-art algorithms, including eLSTM, RGCN, and TGC.",2022
Price Trailing for Financial Trading Using Deep Reinforcement Learning,"Machine learning methods have recently seen a growing number of applications in financial trading. Being able to automatically extract patterns from past price data and consistently apply them in the future has been the focus of many quantitative trading applications. However, developing machine learning-based methods for financial trading is not straightforward, requiring carefully designed targets/rewards, hyperparameter fine-tuning, and so on. Furthermore, most of the existing methods are unable to effectively exploit the information available across various financial instruments. In this article, we propose a deep reinforcement learning-based approach, which ensures that consistent rewards are provided to the trading agent, mitigating the noisy nature of profit-and-loss rewards that are usually used. To this end, we employ a novel price trailing-based reward shaping approach, significantly improving the performance of the agent in terms of profit, Sharpe ratio, and maximum drawdown. Furthermore, we carefully designed a data preprocessing method that allows for training the agent on different FOREX currency pairs, providing a way for developing market-wide RL agents and allowing, at the same time, to exploit more powerful recurrent deep learning models without the risk of overfitting. The ability of the proposed methods to improve various performance metrics is demonstrated using a challenging large-scale data set, containing 28 instruments, provided by Speedlab AG.",2021
Application of new deep genetic cascade ensemble of SVM classifiers to predict the Australian credit scoring,"In the recent decades, credit scoring has become a very important analytical resource for researchers and financial institutions around the world. It helps to boost both profitability and risk control since bank credits plays a significant role in the banking industry. In this study, a novel approach based on deep genetic cascade ensemble of different support vector machine (SVM) classifiers (called Deep Genetic Cascade Ensembles of Classifiers (DGCEC)) is applied to the Statlog Australian data. The proposed approach is a hybrid model which merges the benefits of: (a) evolutionary computation, (b) ensemble learning, and (c) deep learning. The proposed approach comprises of a novel 16-layer genetic cascade ensemble of classifiers, having: two types of SVM classifiers, normalization techniques, feature extraction methods, three types of kernel functions, parameter optimizations, and stratified 10-fold cross-validation method. The general architecture of the proposed approach consists of ensemble learning, deep learning, layered learning, supervised training, feature (attributes) selection using genetic algorithm, optimization of parameters for all classifiers by using genetic algorithm, and a new genetic layered training technique (for selection of classifiers). Our developed model achieved the highest prediction accuracy of 97.39%. Hence, our proposed approach can be employed in the banking system to evaluate the bank credits of the applicants and aid the bank managers in making correct decisions. (C) 2019 Elsevier B.V. All rights reserved.",2019
Mitigating long-term financial risk for large customers via a hybrid procurement strategy considering power purchase agreements,"In facing urgent climate issues, large electricity customers committed to the RE100 initiative, aiming to transition entirely to renewable energy sources (RES). However, they encounter significant challenges in managing the unpredictability of RES generation and the volatility of market prices. This study unveils a groundbreaking hybrid procurement model that integrates Power Purchase Agreements (PPAs) with Battery Energy Storage Systems (BESS) to mitigate these financial risks through a novel method. Employing a sophisticated Mixed Integer Linear Programming (MILP) model alongside an innovative deep learning forecast for long-term PPAs planning, we present a unique solution that significantly boosts financial returns and enhances risk mitigation for large electricity customers. Validated with real-world data across three distinct customer profiles, our model demonstrates a notable increase in expected Net Present Value (NPV) by up to 13.58% compared to traditional strategies and improved earnings stability under adverse market conditions. Our proposed study not only charts a path toward more effective long-term RES procurement strategies but also provides large electricity customers with a strategic framework to skillfully navigate the complexities of the electricity market in alignment with their sustainability commitments.",2024
Recognizing the pattern of beta based rough set - Neural network system,"Beta is calculated by linear analysis between the closing prices of stocks and the security index of stock market. However, many studies have showed there are strong relationships between beta and financial information. Since the traditional statistical techniques have many limitations in disposing deficient and high noisy data, the past studies rested on proving the relationships between financial information and systematic risk. Recently, numerous studies have demonstrated that the hybrid system of rough sets and BP neural-networks has many advantages in disposing the problem of pattern recognizing, in which rough sets were used for accelerating or simplifying the process of using neural network by eliminating the redundant data from database. Therefore, this paper used the hybrid system to recognize the clusters of beta with financial information. At last the effectiveness of our approach was verified by testing the hybrid system with the companies which listed on Shenzhen stock market.",2006
Intelligent System to Detect Malicious URLs Using Machine-Learning Algorithms,"Digital technology has made significant advancements in recent years, particularly on the Internet. Since most of our activities are now conducted online, this development is of particular significance. The continuous evolution of cyber threats has led to a heightened risk of cyberattacks, driven by the inventive tactics employed by malicious actors. Among these threats, one of the most perilous is the malicious URL, meticulously crafted to illicitly obtain information from unsuspecting novice end users. Such attacks compromise user systems and incur annual financial losses in the billions of dollars. Consequently, there is a growing imperative to fortify website defenses. The principal objective of this study is to develop a machine-learning model capable of discerning between malicious and legitimate URLs based on carefully selected parameters for each category. This research employs a variety of machine learning techniques, including decision tree (DT), logistic regression (LR), multi-layer perceptron (MLP), and naive Bayes (NB), while exploring different hyperparameter configurations to classify URLs as safe or malicious. Upon analyzing the experimental results, it is evident that the 'tanh' activation function of MLP in conjunction with the 'adam' solver achieves the highest accuracy rate of 80.01%. This underscores the effectiveness of our approach in enhancing cybersecurity measures against malicious URLs.",2024
Evolve Path Tracer: Early Detection of Malicious Addresses in Cryptocurrency,"With the boom of cryptocurrency and its concomitant financial risk concerns, detecting fraudulent behaviors and associated malicious addresses has been drawing significant research effort. Most existing studies, however, rely on the full history features or full-fledged address transaction networks, both of which are unavailable in the problem of early malicious address detection and therefore failing them for the task. To detect fraudulent behaviors of malicious addresses in the early stage, we present Evolve Path Tracer which consists of Evolve Path Encoder LSTM, Evolve Path Graph GCN, and Hierarchical Survival Predictor. Specifically, in addition to the general address features, we propose Asset Transfer Paths and corresponding path graphs to characterize early transaction patterns. Furthermore, since transaction patterns change rapidly in the early stage, we propose Evolve Path Encoder LSTM and Evolve Path Graph GCN to encode asset transfer path and path graph under an evolving structure setting. Hierarchical Survival Predictor then predicts addresses' labels with high scalability and efficiency. We investigate the effectiveness and generalizability of Evolve Path Tracer on three real-world malicious address datasets. Our experimental results demonstrate that Evolve Path Tracer outperforms the state-of-the-art methods. Extensive scalability experiments demonstrate the model's adaptivity under a dynamic prediction setting.",2023
Financial Big Data Management and Control and Artificial Intelligence Analysis Method Based on Data Mining Technology,"Driven by capital and Internet information (IT) technology, the operating scale and capital scale of modern industrial and commercial enterprises and various organizations have increased exponentially. At present, the manual-based financial work model has been unable to adapt to the changing speed of the modern business environment and the business rhythm of enterprises. All kinds of enterprises and organizations, especially large enterprises, urgently need to improve the operational efficiency of financial systems. By enhancing the integrity, timeliness, and synergy of financial information, it improves the comprehensiveness and ability of analyzing complex problems in financial analysis. It can cope with such rapid changes and help improve the financial management capabilities of enterprises. It provides more valuable decision-making guidance for business operations and reduces business risks. In recent years, the vigorous development of artificial intelligence technology has provided a feasible solution to meet the urgent needs of enterprises. Combining data mining, deep learning, image recognition, natural language processing, knowledge graph, human-computer interaction, intelligent decision-making, and other artificial intelligence technologies with IT technology to transform financial processes, it can significantly reduce the processing time of repetitive basic financial processes, reduce the dependence on manual accounting processing, and improve the work efficiency of the financial department. Through the autonomous analysis and decision-making of artificial intelligence, the intelligentization of financial management is realized, and more accurate and effective financial decision-making support is provided for enterprises. This paper studies the company's intelligent financial reengineering process, so as to provide reference and reference for other enterprises to upgrade similar financial systems. The results of the analysis showed that at the level of alpha =0.05, there was a significant difference in the mean between the two populations. When the r value is in the range of -1 and 1, the linear relationship between the x and y variables is more obvious. This paper proposes decision-making suggestions and risk control early warning to the group decision-making body, or evaluates the financial impact of the group's decision-making, and opens the road to financial intelligence.",2022
Portfolio management system in equity market neutral using reinforcement learning,"Portfolio management involves position sizing and resource allocation. Traditional and generic portfolio strategies require forecasting of future stock prices as model inputs, which is not a trivial task since those values are difficult to obtain in the real-world applications. To overcome the above limitations and provide a better solution for portfolio management, we developed a Portfolio Management System (PMS) using reinforcement learning with two neural networks (CNN and RNN). A novel reward function involving Sharpe ratios is also proposed to evaluate the performance of the developed systems. Experimental results indicate that the PMS with the Sharpe ratio reward function exhibits outstanding performance, increasing return by 39.0% and decreasing drawdown by 13.7% on average compared to the reward function of trading return. In addition, the proposed PMS_CNN model is more suitable for the construction of a reinforcement learning portfolio, but has 1.98 times more drawdown risk than the PMS_RNN. Among the conducted datasets, the PMS outperforms the benchmark strategies in TW50 and traditional stocks, but is inferior to a benchmark strategy in the financial dataset. The PMS is profitable, effective, and offers lower investment risk among almost all datasets. The novel reward function involving the Sharpe ratio enhances performance, and well supports resource-allocation for empirical stock trading.",2021
A Novel Class-Imbalance-Oriented Feature Selection Method Based on BPNNs and AdaBoost for Enterprise Credit Risk Prediction in the Supply Chain Context,"The precision of business decisions and early warning of financial crises are linked to the accuracy of supply chain enterprise credit risk prediction. The high-dimensional information and class imbalance of the prediction task increase the difficulty of learning. An increase in prediction performance can be achieved by combining learning algorithms to select class-imbalance-oriented features. With respect to enterprise credit risk prediction, artificial neural networks have demonstrated remarkable capabilities in capturing nonlinear relationships. A feature selection method based on backpropagation neural networks and the AdaBoost algorithm (FS-BPNN-Ada) is suggested. FS-BPNN-Ada obtains differential mean influence values while considering class imbalance and then obtains integrated mean influence values (IMIVs) in accordance with the classifier weights. On the basis of this information, the cumulative contribution rates of the features are calculated, and a robust feature subset oriented toward class imbalance is output. By utilizing credit risk data from Chinese listed enterprises in supply chains, this study reveals that the proposed FS-BPNN-Ada outperforms nine alternative approaches (including the FS-BPNN, Garson, Yoon, Tsaur, Howes, Olden, RF, CHI2 and Fisher methods). FS-BPNN-Ada is a useful method for forecasting corporate credit risk in a supply chain when faced with class imbalance. Furthermore, the paper also provides a summary of the pertinent managerial insights derived from the model test findings.",2025
Optimization model for enterprise financial management utilizing genetic algorithms and fuzzy logic,"This study explores the complexities of enterprise financial management by optimizing financial models with a particular focus on enhancing risk prediction performance. A multi-objective mathematical model is first developed to establish key optimization goals, including cost reduction, improved capital utilization, and increased economic benefits. This model systematically defines decision variables and optimization objectives, providing a comprehensive framework for enterprise financial management. To improve predictive accuracy, the study integrates genetic algorithms with back-propagation (BP) neural networks, leveraging genetic algorithms to optimize the neural network's parameters and structure. Additionally, a hierarchical reinforcement learning model based on fuzzy reasoning (HRL-FR) is proposed to enhance decision-making capabilities. This model employs hierarchical decision-making and policy optimization, incorporating fuzzy reasoning to address uncertainties in complex and dynamic financial environments. Experimental validation using the Compustat dataset confirms the effectiveness of the proposed model. Key financial variables, including the working capital asset ratio and debt-to-equity ratio, are identified as significant influencers of prediction accuracy, reinforcing the model's robustness. The genetic algorithm's search and optimization process identifies parameter combinations that maximize neural network performance, further improving predictive capabilities. Comprehensive evaluations conducted on the Center for Research in Security Prices (CRSP) and Compustat datasets for 2022 confirm the HRL-FR model's superior ability to predict and analyze enterprise financial management information accurately. The model demonstrates higher profitability, enhanced efficiency, and predictive curves that closely align with optimal financial models. These findings highlight the HRL-FR model's potential as a powerful tool for enterprise financial management optimization, offering valuable insights for risk mitigation and strategic decision-making.",2025
A collective portfolio selection approach for investment clubs,"Recently, with the popularity of social investing platforms, participating in an investment club has become a good choice for investors. Following financial experts in the investment club likely generates more profit as they have higher expertise in planning an investment portfolio. In this study, we propose a portfolio selection mechanism that combines collective intelligence extracted from investors' opinions and LSTM stock price predictions to infer a club's investment preference and predict the profitability of the extracted investment targets. Based on a club's risk tolerance and investment preference, the proposed mechanism can create an appropriate stock portfolio for the investors in the club. Utilizing StockTwits and stock historical data, the experimental results verify that the proposed portfolio selection mechanism performs better than market indices and other benchmark approaches in the market.",2024
A novel ensemble classification model based on neural networks and a classifier optimisation technique for imbalanced credit risk evaluation,"Significant research has been performed on credit risk evaluation, with many machine learning and data mining techniques being employed for financial decision-making. The back propagation (BP) neural network has been a popular choice for credit risk evaluation problems, but many studies have found classifier ensembles to be superior to single classifiers. In this paper, a novel ensemble model based on the synthetic minority over-sampling technique (SMOTE) and a classifier optimisation technique is proposed for personal credit risk evaluation. To mitigate the negative effects of imbalanced datasets on the performance of the credit evaluation model, the SMOTE technique is used to rebalance the target training dataset. The particle swarm optimisation (PSO) algorithm is employed to search for the best-connected weights and deviations in the BP neural networks. Based on the optimised BP neural network classifiers, an ensemble model is developed that combines the AdaBoost approach with the base classifiers. To ensure that the proposed model provides accurate and stable performance, we thoroughly explore and discuss the optimal parameters for the ensemble classification model. Finally, the proposed ensemble model is tested on German and Australian real-world imbalanced datasets. The results demonstrate that this model is more effective at processing credit data problems compared to the other classification models examined in this study. (C) 2019 Elsevier B.V. All rights reserved.",2019
Credit Risk and Limits Forecasting in E-Commerce Consumer Lending Service via Multi-view-aware Mixture-of-experts Nets,"Consumer lending service is escalating in E-Commerce platforms due to its capability in enhancing buyers' purchasing power, improving average order value, and increasing revenue of the platforms. Credit risk forecasting and credit limits setting are two fundamental problems in E-Commerce/online consumer lending services. Currently, the majority of institutes rely on two-separate-step methods to resolve. First, build a rating model to evaluate credit risk, and then design heuristic strategies to set credit limits, which requires a large amount of prior knowledge and lacks theoretical justifications. In this paper, we propose an end-to-end multi-view and multi-task learning based approach named MvMoE (Multi-view-aware Mixture-of-Experts network) to solve these two problems simultaneously. First, a multi-view network with a hierarchical attention mechanism is constructed to distill users' heterogeneous financial information into shared hidden representations. Then, we jointly train these two tasks with a view-aware multi-gate mixture-of experts network and a subsequent progressive network to improve their performances. With the real-world dataset contained 5.44 million users, we investigate the effectiveness of MvMoE. Experimental results exhibit that the proposed model is able to improve AP over 5.60% on credit risk forecasting and MAE over 9.52% on credit limits setting compared with conventional methods. Meanwhile, MvMoE has good interpretability, which better underpins the imperative demands in financial industries.",2021
Research of bad debt risk assessment in enterprise based on multi-layer SVM classifier,"With the development of market economy, the problem of bad debt becomes increasingly important in enterprises. In this paper, a bad-debt-risk evaluation model is established based on multi-layer SVM classifier, using a new set of index system which combines financial factors with non-financial factors on the basis of the 5C system evaluation method. The bad debt rating is separated into four classes- normality, attention, doubt and loss through analyzing accounts payable. Then the multi-layer SVM classifier is trained with 180 samples which are stochastically extracted from listed companies, and the four classes are identified by the trained classifier using 65 samples. The test results show that the classifier has an excellent performance on training accuracy and reliability. Finally, BP neural network is also used to assess the same data. The experiment results show that multi-layer SVM classifier is effective in credit risk assessment and achieves better performance than RP neural network.",2007
RETRACTED: Risk assessment of logistics finance enterprises based on BP neural network and fuzzy mathematical model (Retracted Article),"Neural network is used to deal with the nonlinear relationship, usually there is a strong nonlinear relationship between input and output. Through the self-learning of neural network, the weight of data samples is determined after training, and the optimal solution is obtained according to the process steps. In this paper, the a authors analyze the risk assessment of logistics finance enterprises based on BP neural network and fuzzy mathematical model. For logistics companies, it is necessary to determine the ability of logistics companies to engage in logistics finance business, and then to make detailed and accurate grasp of relevant information. The difference between the actual output and the expected output of the training sample is small, so the fitting is completed well, and the parameters of the neural network are further adjusted. The results show that the model has a good ability of learning nonlinear function relations. To sum up, in order to reduce logistics financial risks, we must fully understand the factors that affect logistics financial risks, determine the proportion of risk factors, and then use the fuzzy evaluation method to analyze the financial business risks.",2020
Shallow or deep? Training an autoencoder to detect anomalous flows in a retail payment system ☆,"Our paper applies a deep neural network autoencoder (AE) to detect anomalous payment flows in Canada's retail batch clearing payments system, the Automated Clearing Settlement System (ACSS). We aim to investigate an AE's potential for detecting complex changes in the liquidity outflows between participants, which could provide an early warning indication for exceptionally large outflows for a participant. As the Canadian financial system has neither faced bank runs nor severe liquidity shocks in recent history, we trained our models on normal  data and evaluated them out-of-sample using test data drawn from two constructed scenarios: a sample derived from the largest 1% of observed historical multilateral net outflows and a sample drawn from a simulated bank run. In both cases, the trained AE performed well by producing larger than usual reconstruction errors. Our approach highlights the efficacy of a class of unsupervised machine learning methods as a useful component of a system operator's risk management toolkit.",2021
Using the TSA-LSTM two-stage model to predict cancer incidence and mortality,"Cancer, the second-leading cause of mortality, kills 16% of people worldwide. Unhealthy lifestyles, smoking, alcohol abuse, obesity, and a lack of exercise have been linked to cancer incidence and mortality. However, it is hard. Cancer and lifestyle correlation analysis and cancer incidence and mortality prediction in the next several years are used to guide people's healthy lives and target medical financial resources. Two key research areas of this paper are Data preprocessing and sample expansion design Using experimental analysis and comparison, this study chooses the best cubic spline interpolation technology on the original data from 32 entry points to 420 entry points and converts annual data into monthly data to solve the problem of insufficient correlation analysis and prediction. Factor analysis is possible because data sources indicate changing factors. TSA-LSTM Two-stage attention design a popular tool with advanced visualization functions, Tableau, simplifies this paper's study. Tableau's testing findings indicate it cannot analyze and predict this paper's time series data. LSTM is utilized by the TSA-LSTM optimization model. By commencing with input feature attention, this model attention technique guarantees that the model encoder converges to a subset of input sequence features during the prediction of output sequence features. As a result, the model's natural learning trend and prediction quality are enhanced. The second step, time performance attention, maintains We can choose network features and improve forecasts based on real-time performance. Validating the data source with factor correlation analysis and trend prediction using the TSA-LSTM model Most cancers have overlapping risk factors, and excessive drinking, lack of exercise, and obesity can cause breast, colorectal, and colon cancer. A poor lifestyle directly promotes lung, laryngeal, and oral cancers, according to visual tests. Cancer incidence is expected to climb 18-21% between 2020 and 2025, according to 2021. Long-term projection accuracy is 98.96 percent, and smoking and obesity may be the main cancer causes.",2025
RETRACTED: Artificial Intelligence Enterprise Management Using Deep Learning (Retracted Article),"In this paper, we explore the application status of deep learning (DL) in enterprise management, with China Merchants Bank as an example, and the role of DL in bank enterprise management. We analysed the application status of AI in marketing, risk control, investment, and other fields of CMB and identified five types of problems encountered in the current practical application of AI. We proposed five countermeasures: strengthening the AI organisation system's construction, enhancing the financial data guarantee mechanism, concentrating on customer-oriented, tightly managing the danger of AI technology, and building a full AI talent system. Recent data are used to assess the impact of DL in marketing, risk management, and investment consulting. According to the data, by the end of 2019, the number of clients of CMB's two APP platforms had reached 114 million and 91.2643 million, respectively. In 2019, CMB's personal savings balance climbed by roughly 53% compared to 2016, and its personal loan amount increased by approximately 61%. These findings indicate that the use of AI improves consumer happiness and trust in businesses.",2022
Development and Implementation of a Multilayer Deep Learning-Based Bank Credit Risk Forecasting System,"The complexity of the financial environment and the international community makes the capital flow face various challenges, and it is difficult to obtain accurate credit prediction results in the actual application environment. Considering the complex non-linear characteristics of customer information, the Analytic Hierarchy Process is studied to meet the needs of bank credit risk assessment. On this basis, a depth neural network with different complexities was selected for the three indicators built to classify the features. The composition of the neural network module and the number of neurons were determined by experiment, and Dropout was used to prevent overfitting of the test dataset. Stability and ablation experiments showed that the model can control the error between datasets to 0.021. The ablation experiment showed that the numbers of hidden layers and neurons were the best. Simulation tests showed that the sensitivity and accuracy of this method were 85.25% and 92.55%, respectively, which were superior to other classification methods. The real data of banks in the past four years were tested. The results could accurately classify the risks of enterprises and individual customers, and the results of stress test showed that the model is stable. It is found that traditional credit risk assessment models rely on statistical means and rule decisions, and these methods may not fully reveal the complex non-linear relationship and the internal relationship of financial indicators in high-dimensional data. The combination of deep learning technology and hierarchical analysis can better deal with and explain the complex non-linear problems in bank risk assessment.",2024
A Comprehensive Health Indicator Integrated by the Dynamic Risk Profile from Condition Monitoring Data and the Function of Financial Losses,"Large rotating machinery, such as centrifugal gas compressors and pumps, have been widely applied and acted as crucial components in the oil and gas industries. Breakdowns or deteriorated performance of these rotating machines can bring significant economic loss to the companies. In order to conduct effective maintenance and avoid unplanned downtime, a system-wide health indicator is proposed in this paper. The health indicator not only uses a dynamic risk profile, but also considers financial loss and the fault probability based on condition monitoring data. This methodology is carried out by four steps: fault detection, probability of fault calculation, consequence of fault calculation and dynamic risk assessment. In our methodology, the fault probability is calculated by robust Mahalanobis distance, presenting as a system-wide feature from a sparse autoencoder fault detection model enabled early fault detection. The value of the health indicator is presented in financial loss, which assists in effective operational decision-making in a process system. To evaluate the performance of the proposed indicator, two case studies were carried out-one case tested on multivariate industrial data obtained from a pump, and another one tested on an industrial data set from a compressor. Results prove that the integrated health indicator can detect the faults at their incipient stages, indicate the degradation of the system with dynamically updated process risk at each sampling instant, and suggest an appropriate shutdown time before the system suffers severe damage. In addition, this methodology can be adapted to other machines' health assessments, such as those of turbines and motors. The presented method of processing the industrial data set can benefit relevant readers.",2021
Offshoring Decision Based on a Framework for Risk Identification,"Offshoring has been a growing practice in the last decade. This involves transferring or sharing management control of a business process (BP) to a supplier in a different country. Offshoring implicates information exchange, coordination and trust between the overseas supplier and the company that means to assume risk. In this paper categories and types of risk have been hierarchically classified using a new approach with the aim to propose a multilevel reference model for Supply Chain Risk evaluation. This classification has been used to analysis the offshoring decision taking into account not only operational and financial risks but other aspects as strategic, compliance, reputation and environmental. The proper risk identification can help to take the correct decision whether or not to bet on offshoring or maintain all the processes in the country of origin.",2013
A Comparative Lens on Econometric Standards and Fusion-Based Models,"A clear understanding and subsequent prediction of volatility has become a topic of paramount importance for investors, policy makers and market regulators in financial markets. The said understanding and prediction of volatility enables the investors to take informed decisions and reducing risk exposures. Thus said, this study aims to estimate volatility in the IT enabled services industry, which plays an important role in security markets. The methodology of comparative approach between traditional models and a newly blended model named as fuse model has been applied to assess volatility for effective risk management and guided investment decisions for investors. The methodology collects information on the historical share prices of ITES companies with a special focus on HCL Technologies listed on Indian stock exchanges. This research work delves into the comparative approach between traditional models and fuse models which may be termed as a blended model. The objective of this study approaches towards the concept of best suited model for ITES industry by using four different fuse models namely being: 1. LSTM in conjunction with Fuzzy Logic, 2. Stochastic Process (Markov Decision Process) in conjunction with Fuzzy Logic, 3. Denoising the discrete time series with Discrete Fourier Transform (DFT) followed by Inverse Fourier Transform to obtain the denoised time series which can be treated as an input to LSTM or Time Series Model and finally 4. Ensemble Learning. It is worth mentioning that this type of study is It's a first attempt that this research advocates for a paradigm shift in volatility estimation practices within the Indian ITES sector",2025
"A Hybrid AI Framework for Enhanced Stock Movement Prediction: Integrating ARIMA, RNN, and LightGBM Models","Forecasting stock market movements is a critical yet challenging endeavor due to the inherent nonlinearity, chaotic behavior, and dynamic nature of financial markets. This study proposes the Autoregressive Integrated Moving Average Ensemble Recurrent Light Gradient Boosting Machine (AR-ERLM), an innovative model designed to enhance the precision and reliability of stock movement predictions. The AR-ERLM integrates ARIMA for identifying linear dependencies, RNN for capturing temporal dynamics, and LightGBM for managing large-scale datasets and non-linear relationships. Using datasets from Netflix, Amazon, and Meta platforms, the model incorporates technical indicators and Google Trends data to construct a comprehensive feature space. Experimental results reveal that the AR-ERLM outperforms benchmark models such as GA-XGBoost, Conv-LSTM, and ANN. For the Netflix dataset, the AR-ERLM achieved an RMSE of 2.35, MSE of 5.54, and MAE of 1.58, surpassing other models in minimizing prediction errors. Moreover, the model demonstrates robust adaptability to real-time data and consistently superior performance across multiple metrics. The findings emphasize AR-ERLM's potential to enhance predictive accuracy, mitigating overfitting and reducing computational overhead. These implications are crucial for financial institutions and investors seeking reliable tools for risk assessment and decision-making. The study sets the foundation for integrating advanced AI models into financial forecasting, encouraging future exploration of hybrid optimization techniques to further refine predictive capabilities.",2025
SIDVis: Designing Visual Interactive System for Analyzing Suicide Ideation Detection,"Suicide is a critical global issue that demands a comprehensive examination of factors such as mental illness, substance abuse, financial stress, and trauma. Effectively identifying individuals at risk is vital for intervention and prevention efforts. However, distinguishing suicidal ideation (SID) from non-suicidal language poses challenges. Existing research has addressed this issue, but limited attention has been given to visually interpretable and interactive systems tailored for SID. This study contributes to responsible AI by leveraging deep learning and machine learning techniques to enhance SID detection, enabling proactive interventions and support. In this paper, we introduce SIDVis, an interactive visualization system that improves performance and interpretability at the same time. The rigorous evaluation demonstrates that SIDVis not only outperforms existing methods in terms of accuracy but also provides an explanation for the responsible use of the underlying AI approach, demonstrating its potential to improve SID detection and intervention strategies.",2023
Credit Risk Assessment Modeling Method Based on Fuzzy Integral and SVM,"With the development of financial globalization and financial market volatility, credit risk has become more prominent and serious, and how to establish an effective enterprise credit evaluation system and bank credit risk evaluation model, provide scientific quantitative decision-making basis for bank decision-making, reduce non-performing loans, and improve the quality of credit assets is a common research topic faced by domestic banks. At present, domestic banks have not been effective to establish risk prevention as the core of credit culture and long-term mechanism, the existence of nonperforming loans is still not fully resolved, new risks continue to appear, and there is a lack of a perfect and effective credit risk evaluation system. With the development of the Internet and financial institutions and the fusion, banks and financial institutions drastically increase the recorded data, and this provides a good prerequisite for the application of intelligent algorithms. In view of the shortcomings of BP neural network in the establishment of credit risk assessment model, such as poor promotion ability and long prediction time, and considering that support vector machine (SVM) can deal with some multi-classification problems, this paper introduces SVM method into the field of bank credit risk assessment and establishes an optimization model of credit risk assessment. This paper discusses the structure and algorithm principle of SVM classification method and proposes an integrated SVM based on fuzzy integral to solve this kind of problem. The results show that the algorithm can effectively improve the prediction accuracy, solve the problem of high computation cost, reduce the occupied memory space, improve the operation efficiency, shorten the training time, and provide a more reliable basis for the rapid and effective evaluation of bank credit risk. On the one hand, the research results expand the application of artificial intelligence technology in the field of economic research; the evaluation model can continuously and accurately measure credit risk is obtained, which provides the necessary basis for upgrading and optimizing credit decision-making, so it has high theoretical value and practical value.",2022
Control of modifiable risk factors in ischemic stroke outpatients by pharmacist intervention: an equal allocation stratified randomized study,"Objective: To evaluate the adequacy of management of modifiable risk factors (MRF) in a group of ischemic stroke outpatients and the value of pharmacist intervention in a randomized controlled study in a tertiary referral hospital. Methods: 160 ischemic stroke outpatients from the same catchment area and with the same financial arrangements for healthcare, went through a 6-month equal allocation stratified randomized study. Routine practice was not altered except for a monthly 1-hour pharmacist-intervention education programme. We evaluated the differences in blood pressure (BP), blood glucose and lipid profiles before and after study. The proportion of patients with adequate management of MRF was studied. Results: There were no differences in the demographic characteristics, MRF and medications prescribed throughout the study. Before the study, the proportions of adequate control of BP in the control and intervention groups were 43% vs. 40% (P = 0.64), lipid 27% vs. 13% (P = 0.09) and glucose 36% vs. 21% (P = 0.15) . At the end of the study, the corresponding proportions were for BP 43% vs. 83% (P = 0.00), lipid 27% vs. 40% (P = 0.16) and glucose 46% vs. 35% (P = 0.40). Conclusion: Pharmacist intervention was associated with improved BP control but not with the other MRF. Earlier initiation and longer duration of intervention may improve the outcome further, and whether targeting of high-risk subjects may be particularly rewarding is worthy of investigation.",2008
Improving the Prediction of Asset Returns With Machine Learning by Using a Custom Loss Function,"Not all errors from models predicting asset returns are equal in terms of impact on the efficiency of the algorithm: a small error could trigger poor investment decisions while a significant error has no financial consequences. This economic asymmetry, critical for assessing the performance of algorithms, can usefully be replicated within the machine learning algorithms itself through the loss function to improve its prediction capability. . In this article: (a) we analyze symmetric and asymmetric loss functions for deep learning algorithms. We develop custom loss functions that mimic the asymmetry in economic consequences of prediction errors. (b) We compare the efficiency of these custom loss functions with MSE and the linear- exponential loss LinEx. (c) We present an efficient custom loss function that significantly improves the prediction of asset returns with improved risk-return metrics (like Sharpe ratio twice better), and which we confirm to be robust.",2023
Towards Predicting Length of Stay and Identification of Cohort Risk Factors Using Self-Attention-Based Transformers and Association Mining: COVID-19 as a Phenotype,"Predicting length of stay (LoS) and understanding its underlying factors is essential to minimizing the risk of hospital-acquired conditions, improving financial, operational, and clinical outcomes, and better managing future pandemics. The purpose of this study was to forecast patients' LoS using a deep learning model and to analyze cohorts of risk factors reducing or prolonging LoS. We employed various preprocessing techniques, SMOTE-N to balance data, and a TabTransformer model to forecast LoS. Finally, the Apriori algorithm was applied to analyze cohorts of risk factors influencing hospital LoS. The TabTransformer outperformed the base machine learning models in terms of F1 score (0.92), precision (0.83), recall (0.93), and accuracy (0.73) for the discharged dataset and F1 score (0.84), precision (0.75), recall (0.98), and accuracy (0.77) for the deceased dataset. The association mining algorithm was able to identify significant risk factors/indicators belonging to laboratory, X-ray, and clinical data, such as elevated LDH and D-dimer levels, lymphocyte count, and comorbidities such as hypertension and diabetes. It also reveals what treatments have reduced the symptoms of COVID-19 patients, leading to a reduction in LoS, particularly when no vaccines or medication, such as Paxlovid, were available.",2023
Credit scoring using multi-task Siamese neural network for improving prediction performance and stability,"A credit scoring model serves as a predictive framework for estimating customer credit risk, specifically the probability of default. The model plays a crucial role in determining the approval of financial transactions, credit limits, and interest rates in financial institutions by predicting a customer's credit risk. Numerous studies have been conducted in the credit scoring field using machine learning techniques. Although the stability of a credit score distribution over time is equally important in credit scoring, most studies have focused solely on improving the model's predictive power. Therefore, this study proposes a multitask learning technique based on Siamese neural networks that simultaneously enhances both predictive power and stability in credit scoring models. Specifically, the proposed model uses personal loan execution data to predict customer defaults while ensuring that the score distribution closely aligns with a predefined golden distribution, thereby securing stability. The golden distribution is a hypothetical five-grade scale derived from scores generated by a pretrained deep neural network. Experimental results show that the proposed model outperforms traditional machine learning and stateof-the-art deep learning models in terms of both predictive power and stability. In particular, the proposed model demonstrates robustness by maintaining high predictive power and stability even in an environment where default rates gently decrease over a long period or where default rates change rapidly over a short period, which can lead to high variability in a model's predictive power and stability.",2025
Detecting and adapting to crisis pattern with context based Deep Reinforcement Learning,"Deep reinforcement learning (DRL) has reached super human levels in complex tasks like game solving (Go [1], StarCraft II [2D]), and autonomous driving [3]. However, it remains an open question whether DRL can reach human level in applications to financial problems and in particular in detecting pattern crisis and consequently dis-investing. In this paper, we present an innovative DRL framework consisting in two subnetworks fed respectively with portfolio strategies past performances and standard deviations as well as additional contextual features. The second sub network plays an important role as it captures dependencies with common financial indicators features like risk aversion, economic surprise index and correlations between assets that allows taking into account context based information. We compare different network architectures either using layers of convolutions to reduce network's complexity or LSTM block to capture time dependency and whether previous allocations is important in the modeling. We also use adversarial training to make the final model more robust. Results on test set show this approach substantially over-performs traditional portfolio optimization methods like Markovitz and is able to detect and anticipate crisis like the current Covid one.",2021
Association of Net Worth and Ambulatory Blood Pressure in Early Middle-aged African American Women,"IMPORTANCE Low socioeconomic status (SES) in the form of educational level and income has been linked to greater cardiovascular risk across cohorts; however, associations have been inconsistent for African American individuals. Net worth, a measure of overall assets, may be a more relevant metric, especially for African American women, because it captures longer-term financial stability and economic reserve. OBJECTIVE To examine whether net worth is associated with increased ambulatory blood pressure (ABP), a marker of cardiovascular disease (CVD) risk, independent of educational level and income, in young to middle-aged African American women. DESIGN, SETTING, AND PARTICIPANTS A cross-sectional, community-based study conducted in the southeastern US was performed using 48-hour ambulatory BP monitoring. Participants included 384 African American women aged 30 to 46 years without clinical CVD recruited between December 16, 2016, and March 21, 2019; data analysis was performed from September 2020 to December 2021. EXPOSURES Self-reported net worth (total financial assets minus debts), self-reported educational level, and self-reported income. MAIN OUTCOMES AND MEASURES Mean daytime and nighttime BP levels, assessed via 48-hour ABP monitoring and sustained hypertension (ABP daytime and clinic BP >= 130/80 mm Hg). RESULTS The 384 African American women in this study represented a range of SES backgrounds; mean (SD) age was 38.0 (4.3) years. Excluding 66 women who were not receiving antihypertensive medications, in linear regression models adjusted for age, marital status, educational level, family income, and family size, women reporting a negative net worth (debt) had higher levels of daytime (beta = 6.7; SE = 1.5; P < .001) and nighttime (beta = 6.4; SE = 1.4; P < .001) systolic BP, compared with women reporting a positive net worth. Similar associations were observed with sustained hypertension: women reporting a negative net worth had 150% higher odds (odds ratio, 2.5; 95% CI, 1.3-4.7) of sustained hypertension than those reporting a positive net worth. Associations remained significant after additional adjustments for smoking, body mass index, psychosocial stress due to debt, and depressive symptoms and were similar, although attenuated, when women receiving antihypertensive medications were included and treatment was controlled for in all analyses. CONCLUSIONS AND RELEVANCE In this cross-sectional study, having a negative net worth (ie, debt) was associated with elevated BP in African American women, independent of traditional indicators of SES. This finding suggests that limited assets or a lack of economic reserve may be associated with poor CVD outcomes in this at-risk group.",2022
Evolving Hybrid Neural Fuzzy Network for Realized Volatility Forecasting with Jumps,"Equity assets volatility modeling and forecasting are fundamental in risk management, portfolio construction, financial decision making and derivative pricing. The use of realized volatility models outperforms GARCH and related stochastic volatility models in out-of-sample forecasting. Gains in performance can be achieved by separately considering volatility jump components. This paper suggests an evolving hybrid neural fuzzy network (eHFN) modeling approach for realized volatility forecasting with jumps. The eHFN model is nonlinear, timeraying, and uses neurons based on uninorms and sigmoidal activation functions in a feedforward network topology. The approach simultaneously chooses the number of hidden layer neurons and corresponding neural networks weights. This is of outmost importance in dynamic environments such as in volatility forecasting using data streams. Computational experiments were performed to evaluate and to compare the performance of eHFN with multilayer feedforward neural network, linear regression, and evolving fuzzy models representative of the current state of the art. The experiments use actual data from the main equity market indexes in global markets, namely, S&P 500 and Nasdaq (United States), FTSE (United Kingdom), DAX (Germany), IBEX (Spain) and Ibovespa (Brazil). The results show that the evolving hybrid neural fuzzy network is highly capable to model timevarying realized volatility with jumps.",2014
Risk management in exploration drilling,"In late 1997, BP Amoco realized that a step change in drilling performance, including health, safety, and environment (HSE) performance, was necessary to sustain the future of the Norwegian operation. A review determined which factors contributed to successful exploration drilling projects. A detailed planning process was developed and underpinned by a set of Ten Principles. Identifying, understanding, and managing the HSE and financial risks involved in an operation are vital to achieve world-class levels of performance. A key feature is how risk assessment is integrated seamlessly into the project workflow.",2000
Bank solvency risk and funding cost interactions: Evidence from Korea,"Using proprietary balance sheet data for Korean banks and a simultaneous equation model, we use a unique measure of the cost of new funding to document that increased funding costs lead to larger sol-vency risk (as measured by regulatory capital), which, in turn, leads to larger funding costs. When in-cluding the great financial crisis in the sample, our estimates imply that a 100 basis points (bp) increase in the cost of new funding (regulatory capital) is associated with a 265 (23) bp increase in regulatory capital (cost of new funding). We show these results are robust to alternative measures of solvency risk and that the traditionally used measure of average funding costs (interest expense over interest-bearing liabilities) does not properly capture this two-way negative feedback loop. The strength of this link is weaker during periods of monetary policy tightening, and is not affected by the specific funding business model chosen by banks. Our findings can inform macroprudential stress-tests calibration. (c) 2021 Elsevier B.V. All rights reserved.",2022
A Smart Comparative Analysis for Secure Electronic Websites,"Online banking is an ideal method for conducting financial transactions such as e-commerce, e-banking, and e-payments. The growing popularity of online payment services and payroll systems, however, has opened new pathways for hackers to steal consumers' information and money, a risk which poses significant danger to the users of e-commerce and e-banking websites. This study uses the selection method of the entire e-commerce and e-banking website dataset (Chi-Squared, Gini index, and main learning algorithm). The results of the analysis suggest the identification and comparison of machine learning and deep learning algorithm performance on binary category labels (legal, fraudulent) between similar datasets, and understanding which function plays a vital role in predicting safe e-banking and e-commerce website datasets. The e-commerce and e-banking website dataset was compiled from the UCI machine learning library. We obtained 11,056 entries based on 30 unique website attributes. We used the machine learning algorithms support vector machine (SVM), k-nearest neighbors, random forest (RF), decision tree (DT), and the multilayer perceptron (MLP) deep learning algorithm to analyze the datasets of e-commerce and e-banking websites and found the best algorithms based on accuracy, precision, recall, and F1-measure. MLP had the highest precision at 97%. With this procedure we can now accurately test websites to assist in the early prediction of secure e-banking e-commerce transactions.",2021
"Long-term SARS-CoV-2 neutralizing antibody level prediction using multimodal deep learning: A prospective cohort study on longitudinal data in Wuhan, China","The ongoing epidemic of SARS-CoV-2 is taking a substantial financial and health toll on people worldwide. Assessing the level and duration of SARS-CoV-2 neutralizing antibody (Nab) would provide key information for government to make sound healthcare policies. Assessed at 3-, 6-, 12-, and 18-month postdischarge, we described the temporal change of IgG levels in 450 individuals with moderate to critical COVID-19 infection. Moreover, a data imputation framework combined with a novel deep learning model was implemented to predict the long-term Nab and IgG levels in these patients. Demographic characteristics, inspection reports, and CT scans during hospitalization were used in this model. Interpretability of the model was further validated with Shapely Additive exPlanation (SHAP) and Gradient-weighted Class Activation Mapping (GradCAM). IgG levels peaked at 3 months and remained stable in 12 months postdischarge, followed by a significant decline in 18 months postdischarge. However, the Nab levels declined from 6 months postdischarge. By training on the cohort of 450 patients, our long-term antibody prediction (LTAP) model could predict long-term IgG levels with relatively high area under the receiver operating characteristic curve (AUC), accuracy, precision, recall, and F1-score, which far exceeds the performance achievable by commonly used models. Several prognostic factors including FDP levels, the percentages of T cells, B cells and natural killer cells, older age, sex, underlying diseases, and so forth, served as important indicators for IgG prediction. Based on these top 15 prognostic factors identified in IgG prediction, a simplified LTAP model for Nab level prediction was established and achieved an AUC of 0.828, which was 8.9% higher than MLP and 6.6% higher than LSTM. The close correlation between IgG and Nab levels making it possible to predict long-term Nab levels based on the factors selected by our LTAP model. Furthermore, our model identified that coagulation disorders and excessive immune response, which indicate disease severity, are closely related to the production of IgG and Nab. This universal model can be used as routine discharge tests to identify virus-infected individuals at risk for recurrent infection and determine the optimal timing of vaccination for general populations.",2023
DETECTION AND CHARACTERISATION OF POLLUTANT ASSETS WITH AI AND EO TO PRIORITISE GREEN INVESTMENTS: THE GEOASSET FRAMEWORK,"Detailed and complete data on physical assets are required in order to adequately assess environment-related risk and impact exposure and the diffusion of these risks and impacts through the financial system. Investors need to know where the physical assets (e.g., power plant, factory, farm) are located of companies in their portfolios, and what their polluting characteristics are. This is essential to manage these environment-related risks and to channel investments to more sustainable alternatives. At present, data on physical assets is typically incomplete, inaccurate, or not released in a timely manner. As a result, key stakeholders including asset owners, asset managers, regulators and policymakers are frequently forced to make crucial decisions with incomplete information. Accurate and comprehensive global asset-level databases are a prerequisite for meaningful innovation in green and digital finance. They provide the link between the financial system and the real economy and allows the wealth of EO datasets and insights that we have available to be made actionable for sustainable finance decision making. We created a framework to derive a global database of pollutant plants, such as cement, iron, and steel, which represent about 15% of the global CO2 emissions. Our solution makes use of state-of-the-art deep learning architectures coupled with Earth observation data.",2022
A MODEL BASED ON FACTOR ANALYSIS AND SUPPORT VECTOR MACHINE FOR CREDIT RISK IDENTIFICATION IN SMALL-AND-MEDIUM ENTERPRISES,"Credit Risk Identification in small-and-medium enterrprises(SMEs) is a real problem which is necessary to be solved in Financial sector. Focusing on 32 small-and-medium enterprises which had bank loan, dimension of six indicators used to judge whether enterprises had credit risk was reduced to simplify model by adopting the factor analysis method. Then small sample data was trained and simulated in examples to get the model that could identify whether there was credit risk in enterprises by adopting Support Vector Machine(SVM) method. At last, the Comparison between SVM method and BP neural network method indicated that SVM method had higher reliability in modeling, and this method was used in Credit Risk Identification in SMEs to identify quickly Whether there was credit risk in enterprise, what is more, to lower loan default rate. Meanwhile, it could help SMEs to identify risk quickly, to improve the ability of risk management and to solve the problem of Credit Risk Identification in SMEs creatively.",2009
Association of Economic Policies With Hypertension Management and Control: A Systematic Review,"Importance Economic policies have the potential to impact management and control of hypertension. Objectives To review the evidence on the association between economic policies and hypertension management and control among adults with hypertension in the US. Evidence Review A search was carried out of PubMed/MEDLINE, Cochrane Library, Embase, PsycINFO, CINAHL, EconLit, Sociological Abstracts, and Scopus from January 1, 2000, through November 1, 2023. Included were randomized clinical trials, difference-in-differences, and interrupted time series studies that evaluated the association of economic policies with hypertension management. Economic policies were grouped into 3 categories: insurance coverage expansion such as Medicaid expansion, cost sharing in health care such as increased drug copayments, and financial incentives for quality such as pay-for-performance. Antihypertensive treatment was measured as taking antihypertensive medications or medication adherence among those who have a hypertension diagnosis; and hypertension control, measured as blood pressure (BP) lower than 140/90 mm Hg or a reduction in BP. Evidence was extracted and synthesized through dual review of titles, abstracts, full-text articles, study quality, and policy effects. Findings In total, 31 articles were included. None of the studies examined economic policies outside of the health care system. Of these, 16 (52%) assessed policies for insurance coverage expansion, 8 (26%) evaluated policies related to patient cost sharing for prescription drugs, and 7 (22%) evaluated financial incentive programs for improving health care quality. Of the 16 studies that evaluated coverage expansion policies, all but 1 found that policies such as Medicare Part D and Medicaid expansion were associated with significant improvement in antihypertensive treatment and BP control. Among the 8 studies that examined patient cost sharing, 4 found that measures such as prior authorization and increased copayments were associated with decreased adherence to antihypertensive medication. Finally, all 7 studies evaluating financial incentives aimed at improving quality found that they were associated with improved antihypertensive treatment and BP control. Overall, most studies had a moderate or low risk of bias in their policy evaluation. Conclusions and Relevance The findings of this systematic review suggest that economic policies aimed at expanding insurance coverage or improving health care quality successfully improved medication use and BP control among US adults with hypertension. Future research is needed to investigate the potential effects of non-health care economic policies on hypertension control.",2024
Unravelling the Belgian cascade of hypertension care and its determinants: insights from a cross-sectional analysis,"Background Hypertension is a major risk factor for cardiovascular disease and all-cause mortality worldwide. Despite the widespread availability of effective antihypertensives, blood pressure (BP) control rates remain suboptimal, even in high-income countries such as Belgium. In this study, we used a cascade of care approach to identify where most patients are lost along the continuum of hypertension care in Belgium, and to assess the main risk factors for attrition at various stages of hypertension management.Methods Using cross-sectional data from the 2018 Belgian Health Interview Survey and the Belgian Health Examination Survey, we estimated hypertension prevalence among the Belgian population aged 40-79 years, and the proportion that was (1) screened, (2) diagnosed, (3) linked to care, (4) in treatment, (5) followed up and (6) well-controlled. Cox regression models were estimated to identify individual risk factors for being unlinked to hypertension care, untreated and not followed up appropriately.Results The prevalence of hypertension based on self-reported and measured high BP was 43.3%. While 98% of the hypertensive population had their BP measured in the past 5 years, only 56.7% were diagnosed. Furthermore, 53.4% were linked to care, 49.8% were in treatment and 43.4% received adequate follow-up. Less than a quarter (23.5%) achieved BP control. Among those diagnosed with hypertension, males, those of younger age, without comorbidities, and smokers, were more likely to be unlinked to care. Once in care, younger age, lower BMI, financial hardship, and psychological distress were associated with a higher risk of being untreated. Finally, among those treated for hypertension, females, those of younger age, and without comorbidities were more likely to receive no adequate follow-up.Conclusion Our results show that undiagnosed hypertension is the most significant barrier to BP control in Belgium. Health interventions are thus needed to improve the accurate and timely diagnosis of hypertension. Once diagnosed, the Belgian health system retains patients fairly well along the continuum of hypertension care, yet targeted health interventions to improve hypertension management for high-risk groups remain necessary, especially with regard to improving treatment rates.",2024
Exploration on the financing risks of enterprise supply chain using Back Propagation neural network,"In order to study the risk management of supply chain, promote collaboration among node enterprises, and ensure the normal and good development of supply chain, a risk evaluation model of supply chain based on BP (Back Propagation) neural network (BPNN) was constructed to explore the existing factors affecting the risk evaluation of the supply chain and to build risk evaluation index system of supply chain. The results show that BPNN has unique advantages in solving such highly non-linear problems as evaluation of risks of the supply chain. The proposed method can be regarded as an effective technical means to determine a supply chain risk and provide current enterprises with effective decision support to carry out the risk management of the supply chain. As a result, the proposed model will provide a good reference for enterprises and other financial institutions to expand the financing business of supply chain and facilitate the evaluation of enterprise credit risk. (C) 2019 Elsevier B.V. All rights reserved.",2020
Dynamic Co-Movements among Oil Prices and Financial Assets: A Scientometric Analysis,"In this study, we examined the extant literature on the dynamic association between oil prices and financial assets with special emphasis on the methodologies for measuring the dependence among oil prices, exchange rates, stock prices, energy markets, and assets related to sustainable finance. We performed a scientometric review of the structure and global trends of the dynamic association among oil prices and financial assets, based on research from 1982 to 2022 (September) using techniques such as the analysis of (i) sources, (ii) authors, (iii) documents, and (iv) cluster analysis. A total of 746 bibliographic records from Scopus and Web of Science databases were analyzed to generate the study's research data through scientometric networks. The findings indicate that the most promising areas for further research in this field are represented by co-movement, copula, wavelet, dynamic correlation, and volatility analysis. Furthermore, energy markets and assets related to sustainable finance emerge as crucial trends in investigating dynamic co-movements with oil prices. They also suggest a research gap in analyzing by means of machine learning, deep learning, big data, and artificial intelligence for measuring dynamic co-movements among oil prices and assets in financial and energy markets, especially in emerging countries. Thus, these methodologies can be implemented in further research because these methods could more robustly quantify the association among such variables. The analysis provides researchers and practitioners with a comprehensive understanding of the existing literature and research trends on the dynamic association among oil prices and financial assets. It also promotes further studies in this domain. The identification of these relations presents benefits in risk diversification, hedges, speculation, and inflation targeting.",2022
High-dimensional multi-period portfolio allocation using deep reinforcement learning,"This paper proposes a novel investment strategy based on deep reinforcement learning (DRL) for long-term portfolio allocation in the presence of transaction costs and risk aversion. We design an advanced portfolio policy framework to model the price dynamic patterns using convolutional neural networks (CNN), capture group-wise asset dependence using WaveNet, and solve the optimal asset allocation problem using DRL. These methods are embedded within a multi-period Bellman equation framework. An additional appealing feature of our investment strategy is its ability to optimize dynamically over a large set of potentially correlated risky assets. The performance of this portfolio is tested empirically over different holding periods, risk aversion levels, transaction cost rates, and financial indices. The results demonstrate the effectiveness and superiority of the proposed long-term portfolio allocation strategy compared to several competitors based on machine learning methods and traditional optimization techniques.",2025
Intelligent decision making and risk management in stock index futures markets under the influence of global geopolitical volatility☆,"In the context of escalating global geopolitical turmoil, geopolitical risks have increasingly significant impacts on financial markets, particularly intensifying market volatility in China's stock market, which is dominated by individual investors. These risks present substantial challenges for investors and policymakers. Existing research often treats the stock market as a static entity, lacking integration with quantitative decision-making, and relies on traditional methods that may not capture the complexities of market dynamics. This study aims to innovate trading strategies and risk management methods in the stock index futures market to effectively respond to the unknown risks brought about by geopolitical fluctuations. Firstly, we propose an innovative data-driven market state division strategy. By analyzing market data to quantitatively derive cyclical parameters of market states, we effectively reduce the market risks that may arise from subjective choices inherent in traditional methods. Secondly, we design a real-time trading system that combines the Geopolitical Risk Index with commonly used trend and oscillation indicators in the stock market. This system can identify and adapt to the market's changing trends, achieving precise grasp of market dynamics and flexible application of trading strategies. Additionally, we extend the traditional one-dimensional time trend analysis to a multidimensional data-driven perspective by utilizing Convolutional Neural Networks to automatically identify more diverse market features. To enhance the training effectiveness, generalization ability, and robustness of deep learning models, we introduce image augmentation strategies. By repeatedly emphasizing specific features without increasing training complexity, we enhance the model's ability to learn high-level representations, significantly improving overall performance. Through these innovative methods, this study not only deepens the understanding of the relationship between geopolitical risks and financial market dynamics but also provides more precise and scientific data support for financial market decision-making. It lays a solid foundation for the development of risk management and trading strategies in future high-volatility environments.",2025
Tailored machine learning for evaluating the long-term diabetes risk in older individuals: findings from the Irish Longitudinal Study on Ageing (TILDA),"ObjectivesThe prevalence of diabetes has increased globally, leading to a significant disease burden and financial cost. Early prediction is crucial to control its prevalence.DesignA prospective cohort study.SettingNational representative study on Irish.Participants8504 individuals aged 50 years or older were included.Primary and secondary outcome measuresSurveys were conducted to collect over 40 000 variables related to social, financial, health, mental and family status. Feature selection was performed using logistic regression. Different machine/deep learning algorithms were trained, including distributed random forest, extremely randomised trees, a generalised linear model with regularisation, a gradient boosting machine and a deep neural network. These algorithms were integrated into a stacked ensemble to generate the best model. The model was tested using various metrics, such as the area under the curve (AUC), log loss, mean per classification error, mean square error (MSE) and root MSE (RMSE). The SHapley Additive exPlanations (SHAP) method was used to interpret the established model.ResultsAfter 2 years, 105 baseline features were identified as major contributors to diabetes risk, including sex, low-density lipoprotein cholesterol and cirrhosis. The best model achieved high accuracy, robustness and discrimination in predicting diabetes risk, with an AUC of 0.854, log loss of 0.187, mean per classification error of 0.267, RMSE of 0.229 and MSE of 0.052 in the independent test set. The model was also shown to be well calibrated. The SHAP algorithm provided insights into the decision-making process of the model.ConclusionsThese findings could help physicians in the early identification of high-risk patients and implement targeted interventions to reduce diabetes incidence.",2023
Bias-regularised Neural-Network Metamodelling of Insurance Portfolio Risk,"Deep learning models have attracted considerable attention in metamodelling of financial risks for large insurance portfolios. Those models, however, are generally trained in disregard of the collective nature of the data in the portfolio under study. Consequently, the training procedure often suffers from slow convergence, and the trained model often has poor accuracy. This is particularly evident in the presence of extreme individual contracts. In this paper, we advocate the view that the training of a meta-model for a portfolio should be guided by portfolio-level metrics. In particular, we propose an intuitive loss regulariser that explicitly accounts for the portfolio-level bias. Further, this training regulariser can be easily implemented with the minibatch stochastic gradient descent commonly used in training deep neural networks. Empirical evaluations on both simulated data and a benchmark dataset show that the regulariser yields more stable training, resulting in faster convergence and more reliable portfolio-level risk estimates.",2020
Optimal Therapy in Hypertensive Subjects with Diabetes Mellitus,"Diabetes and its micro- and macrovascular complications represent a worldwide epidemic that will place an enormous financial burden on poorer countries in the years to come. In patients with diabetes and hypertension, the main determinant of the cardiovascular and renal benefits of antihypertensive drugs is the blood pressure (BP) level achieved under treatment. Quite recently, the paradigm of a BP target < 130/80 mm Hg in these patients has been questioned by a number of trials, including data from the Action to Control Cardiovascular Risk in Diabetes (ACCORD) blood pressure-lowering arm and from the diabetic cohort of International Verapamil SR-Trandolapril Study (INVEST). At the same time, even if the key role of BP control is unquestionable, a growing number of published trials suggest that different antihypertensive combinations may offer specific cardio-, vasculo-, and renoprotective advantages that go beyond BP reduction per se. The present review focuses on the most recent and important literature that explored the optimal antihypertensive therapy in patients with type 2 diabetes and concomitant hypertension, and it discusses in detail the various areas of uncertainty, including the specific renoprotective effects of renin-angiotensin system blocking agents and the long-term effects of angiotensin-converting enzyme/angiotensin receptor blocker combinations on the progression of diabetic nephropathy.",2011
Credit Risk Prediction Using Machine Learning and Deep Learning: A Study on Credit Card Customers,"The increasing population and emerging business opportunities have led to a rise in consumer spending. Consequently, global credit card companies, including banks and financial institutions, face the challenge of managing the associated credit risks. It is crucial for these institutions to accurately classify credit card customers as good or bad to minimize capital loss. This research investigates the approaches for predicting the default status of credit card customer via the application of various machine-learning models, including neural networks, logistic regression, AdaBoost, XGBoost, and LightGBM. Performance metrics such as accuracy, precision, recall, F1 score, ROC, and MCC for all these models are employed to compare the efficiency of the algorithms. The results indicate that XGBoost outperforms other models, achieving an accuracy of 99.4%. The outcomes from this study suggest that effective credit risk analysis would aid in informed lending decisions, and the application of machine-learning and deep-learning algorithms has significantly improved predictive accuracy in this domain.",2024
INVESTIGATION OF ALGORITHMIC TRADING MODELS FOR SHARES OF THE DRUG MANUFACTURING INDUSTRY,"Algorithmic trading models are now widely used in investment decision-making. By grounding these models in scientific knowledge, investors can obtain efficient results in financial markets. During the COVID-19 outbreak, the drug manufacturing industry has received substantial attention from investors. The purpose of our research is to form an investment portfolio using an algorithmic trading model in the drug manufacturing industry. The model covers the entire process of portfolio formation: market analysis, selection of industry, selection of particular stocks, data mining, forecasting and investment decision-making. Three portfolios - maximum return, minimum risk and maximum Sharpe ratio - are constructed and compared across two periods. Portfolios formed using deep learning forecasting outperformed the index in more cases than did portfolios created using the Monte Carlo simulation. Portfolio formation using algorithmic trading models is suitable for individual investors, can be easily automated using the computer application and can not only be applied to one industry but diversified across various sectors.",2023
Comparison of Transfer Learning Model Accuracy for Osteoporosis Classification on Knee Radiograph,"In terms of financial costs and human suffering, osteoporosis poses a serious public health burden. Reduced bone mass, degeneration of the microarchitecture of bone tissue, and an increased risk of fracture are its main skeletal symptoms. Osteoporosis is caused not just by low bone mineral density, but also by other factors such as age, weight, height, and lifestyle. Recent advancement in Artificial Intelligence (AI) has led to successful applications of expert systems that use Deep Learning techniques for osteoporosis diagnosis based on some modalities such as dental radiographs amongst others. This study uses a dataset of knee radiographs (i.e., knee-Xray images) to apply and compare three robust transfer learning model algorithms: GoogLeNet, VGG-16, and ResNet50 to classify osteoporosis. From the statistical analysis and scikit learn python analysis, the accuracy of the GoogLeNet model was 90%, the accuracy of the VGG-16 model was 87% and lastly, the accuracy of the ResNet50 model was 83%.",2022
Can machine learning models save capital for banks? Evidence from a Spanish credit portfolio,"We study the impact of machine learning (ML) models for credit default prediction in the calculation of regu-latory capital by financial institutions. We do so by using a unique and anonymized database from a major Spanish bank. We first compare the statistical performance of five models based on supervised learning like Logistic Lasso, Trees (CART), Random Forest, XGBoost and Deep Learning, with a well-known model like Logit. We measure the statistical performance through different metrics, and for different sample sizes and features available. We find that ML models outperform, even when relatively low amount of data is used. We then translate this statistical performance into economic impact by estimating the savings in capital when using an advanced ML model instead of a simpler one to compute the risk-weighted assets following the Internal Ratings Based (IRB) approach. Our benchmark results show that implementing XGBoost instead of Logistic Lasso could yield savings from 12.4% to 17% in terms of regulatory capital requirements.",2022
Predicting early breast cancer recurrence from histopathological images in the Carolina Breast Cancer Study,"Approaches for rapidly identifying patients at high risk of early breast cancer recurrence are needed. Image-based methods for prescreening hematoxylin and eosin (H&E) stained tumor slides could offer temporal and financial efficiency. We evaluated a data set of 704 1-mm tumor core H&E images (2-4 cores per case), corresponding to 202 participants (101 who recurred; 101 non-recurrent matched on age and follow-up time) from breast cancers diagnosed between 2008-2012 in the Carolina Breast Cancer Study. We leveraged deep learning to extract image information and trained a model to identify recurrence. Cross-validation accuracy for predicting recurrence was 62.4% [95% CI: 55.7, 69.1], similar to grade (65.8% [95% CI: 59.3, 72.3]) and ER status (66.3% [95% CI: 59.8, 72.8]). Interestingly, 70% (19/27) of early-recurrent low-intermediate grade tumors were identified by our image model. Relative to existing markers, image-based analyses provide complementary information for predicting early recurrence.",2023
Forthcoming applications of quantum computing: peeking into the future,"We all have been using classical computers for a long time. Quantum computing uses the phenomena of quantum mechanics like superposition and entanglement. Quantum computations can help achieve for the breakthroughs we have been looking for in science, machine learning, financial planning, medicine, etc., where classical computers' computing power is not enough. It was not long back when quantum computing's applications in our life were all just theoretical. However, to utilise the power of quantum computations for real-life applications, several recent developments have been made. Keeping that in mind, this study aims to explore the existing and upcoming applications of quantum computing. In this study, they start with an introduction of quantum computing fundamentals, following which, they give a brief overview of various applications of quantum computing in several significant areas of computer science, such as cryptography, machine learning, deep learning, and quantum simulations. They also cover various real-life scenarios such as risk analysis, logistics, and satellite communication.",2020
Toward interpretable machine learning: evaluating models of heterogeneous predictions,"AI and machine learning have made significant progress in the past decade, powering many applications in FinTech and beyond. But few machine learning models, especially deep learning models, are interpretable by humans, creating challenges for risk management and model improvements. Here, we propose a simple yet powerful framework to evaluate and interpret any black-box model with binary outcomes and explanatory variables, and heterogeneous relationships between the two. Our new metric, the signal success share (SSS) cross-entropy loss, measures how well the model captures the relationship along any feature or dimension, thereby providing actionable guidance on model improvements. Simulations demonstrate that our metric works for heterogeneous and nonlinear predictions, and distinguishes itself from traditional loss functions in evaluating model interpretability. We apply the methodology to an example of predicting loan defaults with real data. Our framework is more broadly applicable to a wide range of problems in financial and information technology.",2024
Imatinib adherence prediction using machine learning approach in patients with gastrointestinal stromal tumor,"BackgroundNonadherence to imatinib is common in patients with gastrointestinal stromal tumor (GIST), which is associated with poor prognosis and financial burden. The primary aim of this study was to investigate the adherence rate in patients with GIST and subsequently develop a model based on machine learning (ML) and deep learning (DL) techniques to identify the associated factors and predict the risk of imatinib nonadherence.MethodsAll eligible patients completed four sections of questionnaires. After the data set was preprocessed, statistically significance variables were identified and further processed to modeling. Six ML and four DL algorithms were applied for modeling, including eXtreme gradient boosting, light gradient boosting machine (LGBM), categorical boosting, random forest, support vector machine, artificial neural network, multilayer perceptron, NaiveBayes, TabNet, and Wide&Deep. The optimal ML model was used to identify potential factors for predicting adherence.ResultsA total of 397 GIST patients were recruited. Nonadherence was observed in 185 patients (53.4%). LGBM exhibited superior performance, achieving a mean f1_score of 0.65 and standard deviation of 0.12. The predominant indicators for nonadherent prediction of imatinib were cognitive functioning, whether to perform therapeutic drug monitoring (if_TDM), global health status score, social support, and gender.ConclusionsThis study represents the first real-world investigation using ML techniques to predict risk factors associated with imatinib nonadherence in patients with GIST. By highlighting the potential factors and identifying high-risk patients, the multidisciplinary medical team can devise targeted strategies to effectively address the daily challenges of treatment adherence. Machine learning and deep learning algorithms were used to analyze imatinib adherence among 397 patients with gastrointestinal stromal tumor (GIST) in this study. The main indicators for predicting nonadherence to imatinib based on light gradient boosting machine were cognitive functioning, if_if_TDM, global health status score, social support, and gender. These results contribute to providing new opportunities for early identification and intervention of adherence in GIST patients, which will enhance imatinib adherence and improve clinical outcomes for this population.",2025
Railroad Near-Miss Occurrence Detection and Risk Estimation System with Data from Camera Using Deep Learning,"An unsafe railway operation system has both direct and indirect societal consequences. Railway accidents are a major safety and financial issue for the railroad industry. Estimating the risk of railway accidents is critical for safety, as it will support in the development of secure railway operations and reduce the further risks associated with railway systems. For many years, researchers have explored various techniques for obstacles detection and early detection of railroad accidents to aid in railway incident management. With recent advancements in machine learning algorithms and data collection techniques, there are a growing number of research studies to provide suitable solutions for the railway safety system. In this paper, we present a novel approach for detecting near-miss occurrences and estimating the risk of event with data from camera using deep learning models. Our proposed approach detects and localizes foreign objects on the railroad. It also detects the position of rail tracks using a segmentation method to estimate the risk of near-miss occurrence by calculating the distance between the detected objects to the rail track. A proposed approach successfully analyzed input image into a rail track segmentation and detection of foreign objects on rail track. Experimental results demonstrate the effectiveness of the proposed approach and its suitability for a complex real-world railway systems.",2021
Decouple then Combine: A Simple and Effective Framework for Fraud Transaction Detection,"With the popularity of electronic mobile and online payment, the demand for detecting financial fraudulent transactions is increasing. Although numerous efforts are devoted to tackling this problem, there are still two key challenges that are not well resolved, i.e., the class imbalance ratio of test samples are extremely larger than that of training samples and amount of detected fraudulent transactions do not be considered. In this paper, we propose a simple and effective framework composed of majority and minority branches to address the above issues. The input samples of majority and minority branches come from vanilla and re-adjusted distribution, respectively. Parameters of each branch are optimized individually, by which the representation learning for majority and minority samples are decoupled. Besides, an extra loss re-weighted by amount is added in the majority branch to improve the recall amount of detected fraudulent transactions. Theoretical results show that under the proposed framework, minimizing the empirical risk is guaranteed to achieve small generalization risk on more imbalanced data with high probability. Experiments on real-world datasets from Tencent Wechat payments demonstrate that our framework achieves superior performance than competitive methods in terms of both number and money of detected fraudulent transactions.",2023
Negative Review or Complaint? Exploring Interpretability in Financial Complaints,"In the financial service sector, customer service is the most critical tool for long-term business growth. A financial complaint detection (CD) system could aid in the identification of shortcomings in product features and service delivery. This could further ensure faster resolution of customer complaints and thereby help retain existing clients and attract new ones. Prior research has prioritized only complaint identification and prediction of the corresponding severity levels; the first aim is to categorize a textual element as a complaint or a noncompliant. The other attempts to classify complaints into several severity levels based on the degree of risk the complainant is willing to endure. Identifying the reason or source of a complaint in a text is a significant but underexplored area in natural language processing study. We propose an explainable complaint cause identification approach with a dyadic attention mechanism at the sentence and word levels, enabling it to give varying amounts of emphasis to more and less important information. As the first subtask, the model simultaneously trains CD, sentiment detection, and emotion recognition tasks. Afterwards, we identify the complaint's cause and its severity level. To do this, the causal span annotations for complaint tweets are added to an existing financial complaints corpus. The findings suggest that conventional computing techniques can be adapted to solve extremely relevant new problems, generating novel opportunities for research(1).",2024
"Three and a half decades of artificial intelligence in banking, financial services, and insurance: A systematic evolutionary review","The banking, financial services, and insurance (BFSI) sector is one of the earliest and most prominent adopters of artificial intelligence (AI). However, academic research substantially lags behind the adoption of AI in practice. At the beginning of this century, AI research has been centered on the sector's credit risk. In the 2010s decade, expert systems were increasingly replaced by data-driven, algorithmic AI. Big data enjoyed much hype in that decade, which diminished later mostly due to unsuccessful implementations. Much published research on big data actually relates to machine and deep learning but not to big data per se. These terms are often found to be conflated in research and practice. The insurance sector is substantially underrepresented in published AI research, and current research is dominated by banking and investments. Governance frameworks for responsible AI (RAI) are yet to be incorporated into practice by fintech companies as well as incumbent organizations. RAI is a particular issue for decentralized finance (DeFi). The most successful implementations of AI in BFSI practice, as well as dominant academic research areas, are in investments, securities, market making, customer relationships, lending, risk management, and compliance.",2022
Finding the Next Interesting Loan for Investors on a Peer-to-Peer Lending Platform,"With the development of the mobile Internet, a peer-to-peer(P2P) online lending platform has become increasingly popular in the financial market, and it attracts a massive number of users. The task that helps investors find potential loans for improving the funding success rate has become a major challenge for lending platforms. However, the traditional recommendation schemes rarely take into account the challenges, such as the timeliness of loans (i.e., when a loan funding is completed or expired, it will no longer recruit investment), the common cold start problem (continuously releasing new loans is a common phenomenon), and the loans' potential default risk. Considering the above characteristics, we propose a deep learning model based on a sequence of the incremental matrix factorization technology (DeepSeIMF). First, the cold start problem of loans can be effectively solved by designing an incremental matrix factorization model based on the time series. Then, a neural network is used to provide investors with personalized investment recommendation services based on risk assessment. Finally, the model performance is systematically evaluated based on a large-scale real-world dataset. The experimental results demonstrate the effectiveness of our solution.",2021
Measuring Risks of Confirming Warehouse Financing from the Third Party Logistics Perspective,"Confirmation warehouse financing is an important model in supply chain finance. This type of financing has special characteristics due to the existence of the reverse repurchase link, and it increases the risk commitment of the core enterprise at a certain level. Previous research on supply chain financial risk mostly settled in 'all-industry, multi-model', ignoring the special risks of single mode. To supplement the vacancies in the current research, the special risks of supply chain finance should be identified under a single model. On this basis, a measurement index system for confirmation warehouse financing risk is created. The article uses a Back Propagation (BP) neural network to build a Third Party Logistics (3PL) perspective of the risk measurement model for confirmation warehouse financing. The said network is combined with the 24 sets of actual cases from ZY Logistics. MATLAB is used to train the sample data. Results show that the absolute errors-0.042998, -0.011102, 0.020514 and 0.039448-between the training value and the predicted value are smaller than the preset error value. Among the 24 cases, high-risk businesses reached 41.7%, whereas low-risk businesses only accounted for 29.2%. The ZY enterprise confirms that warehouse financial business risk is high, and this situation should be revised. Research shows that the risk measurement indicator system has good risk prediction ability. This study establishes and verifies the rationality of the risk measurement index system and provides a reliable reference for 3PL risk aversion in supply chain finance.",2019
RETRACTED: Effects of cost-benefit analysis under back propagation neural network on financial benefit evaluation of investment projects,"To determine the influence of the weight of the economic effectiveness evaluation criteria of the major investments of listed enterprises, and provide new management ideas for the development of the follow-up enterprises, firstly, the financial benefit evaluation system of investment projects is analyzed and constructed, and the specific evaluation process is analyzed. Then, on this basis, the evaluation index is refined; the basic structure of BP neural network (BPNN) is introduced, and genetic algorithm is used to improve BP neural network. The cost-benefit analysis model is constructed based on the improved BPNN. The listed company A is taken as an example to analyze its development data in recent years, and then the data of 10 listed companies are taken as the research object. Matlab simulation software is used to train and verify the improved BPNN model, analyze and predict the weight value of the financial benefit index of the investment projects of these 10 companies, and then determine the index to improve the financial benefit of the investment projects. Under the analysis of the development data of listed company A in the past 10 years, it is found that the indicators of the listed company's profitability per share, debt risk operation ability, development, and growth ability in the past 10 years are in relatively stable state. The principal component analysis of its 20 secondary sub-indexes is conducted based on the four primary indicators: profitability, debt risk, operational capacity, and development and growth. A total of eight principal components including return on equity (ROE), return on assets (ROA), (total asset turnover) TATO, turnover of account receivable (AR), asset-liability ratio, interest protection multiple, income growth rate, and year-on-year rate of increase for complete assets are extracted. The average error between the final output value, the actual value, and the expected value is 0.0304 and 0.0169, respectively. The weight coefficient of the monetary benefits evaluation indicator of investment items is calculated, and the computed results show that year-on-year rate of increase for complete assets, TOTA, ROA, turnover of total capital, and ROE are important indexes in the financial benefit evaluation of investment projects. It indicates that to improve the financial benefit of investment projects of listed enterprises, it is necessary to enhance the year-over-year growth degree of total properties and ROA.",2020
Effectiveness of self-financing patient-led support groups in the management of hypertension and diabetes in low- and middle-income countries: Systematic review,"ObjectiveThere is insufficient evidence on the role of self-financing patient support groups in the control of blood pressure (BP) and/or diabetes in low- and middle-income countries (LMICs). We conducted a systematic review to investigate the effectiveness of these groups in BP and glycaemic control. MethodsWe searched PubMed, Embase, SCOPUS, Web of Science, Global Health, African Journals Online, CINAHL and African Index Medicus for published peer-reviewed articles from inception up to November 2021. Grey literature was obtained from OpenGrey. Studies on patient support groups for hypertension and/or diabetes with a component of pooling financial resources, conducted in LMICs, were included. Narrative reviews, commentaries, editorials and articles published in languages other than English and French were excluded. Study quality and risk of bias were assessed using the National Institutes of Health Quality assessment tool and the revised Cochrane risk-of-bias tool. Results are reported according to PRISMA guidelines. ResultsOf 724 records screened, three studies met the criteria: two trials conducted in Kenya and a retrospective cohort study conducted in Cambodia. All studies reported improvement in BP control after 12 months follow-up with reductions in systolic BP of 23, 14.8, and 16.9 mmHg, respectively. Two studies reported diabetes parameters. The first reported improvement in HbA1c (reduction from baseline 10.8%, to 10.6% at 6 months) and random blood sugar (baseline 8.9 mmol/L, to 8.5 mmol/L at 6 months) but these changes did not achieve statistical significance. The second reported a reduction in fasting blood glucose (baseline-216 mg/dl, 12 months-159 mg/dl) in diabetic patients on medication. ConclusionSelf-financing patient support groups for diabetes and hypertension are potentially effective in the control of BP and diabetes in LMICs. More studies are needed to add to the scarce evidence base on the role of self-financing patient support groups.",2023
FactorVAE: A Probabilistic Dynamic Factor Model Based on Variational Autoencoder for Predicting Cross-Sectional Stock Returns,"As an asset pricing model in economics and finance, factor model has been widely used in quantitative investment. Towards building more effective factor models, recent years have witnessed the paradigm shift from linear models to more flexible nonlinear data-driven machine learning models. However, due to low signal-to-noise ratio of the financial data, it is quite challenging to learn effective factor models. In this paper, we propose a novel factor model, FactorVAE, as a probabilistic model with inherent randomness for noise modeling. Essentially, our model integrates the dynamic factor model (DFM) with the variational autoencoder (VAE) in machine learning, and we propose a prior-posterior learning method based on VAE, which can effectively guide the learning of model by approximating an optimal posterior factor model with future information. Particularly, considering that risk modeling is important for the noisy stock data, FactorVAE can estimate the variances from the distribution over the latent space of VAE, in addition to predicting returns. The experiments on the real stock market data demonstrate the effectiveness of FactorVAE, which outperforms various baseline methods.",2022
RETRACTED: Risk Assessment of Government Debt Based on Machine Learning Algorithm (Retracted Article),"Government debt risk is an important factor affecting macroeconomic stability and public expectation. The key to its prevention and control lies in early warning and early prevention. This paper builds an effective government debt risk assessment system based on machine learning algorithm. According to forming the performance of local government debt risk and its internal and external influencing factors, this study applies the analytic hierarchy process, entropy method, and BP neural network method to construct the local government risk assessment index system, which includes the primary and secondary indexes including the explicit debt risk, the contingent implicit debt risk, and the financial and economic operation risk. Using this system, this study carries on the government debt risk comprehensive weight assignment, the fiscal revenue forecast, the default probability calculation, the safety scale forecast, and finally the government debt risk assessment of the validity analysis. The system can provide signal guidance and policy reference for finance to cope with risks in advance, arrange the priority order of debt repayment, optimize the structure of fiscal revenue and expenditure, etc.",2021
Detection of Banking Financial Frauds Using Hyper-Parameter Tuning of DL in Cloud Computing Environment,"When income, assets, sales, and profits are inflated while expenditures, debts, and losses are artificially lowered, the outcome is a set of fraudulent financial statements (FFS). Manual auditing and inspections are time-consuming, inefficient, and expensive options for spotting these false statements. Auditors will find great assistance from the use of intelligent methods in the analysis of several financial declarations. Now more than ever, victims of financial fraud are at risk since more and more individuals are using the Internet to conduct their financial transactions. And the frauds are getting more complex, evading the protections that banks have put in place. In this paper, we offer a new-fangled method for detecting fraud using NLP models: an ensemble model comprising Feedforward neural networks (FNNs) and Long Short-Term Memories (LSTMs). The Spotted Hyena Optimizer is a unique metaheuristic optimization technique used to choose weights and biases for LSTM (SHO). The proposed method takes inspiration from the law of gravity and is meant to mimic the group dynamics of spotted hyenas. Mathematical models and discussions of the three fundamental phases of SHO - searching for prey, encircling prey, and at-tacking prey - are presented. We build a model of the user's spending habits and look for suspicious outliers to identify fraud. We do this by using the ensemble mechanism, which helps us predict and make the most of previous trades. Based on our analysis of real-world data, we can confidently say that our model provides superior performance compared to state-of-the-art approaches in a variety of settings, with respect to both precision and.",2025
An enhanced interval-valued decomposition integration model for stock price prediction based on comprehensive feature extraction and optimized deep learning,"For the purpose of managing financial risk and making investment decisions, interval stock price forecasting is essential. Currently, decomposition integration frameworks are widely used in point-valued stock price forecasting studies, mainly focusing on mining internal information. However, point forecasts are difficult to adequately capture price uncertainty and may suffer from loss of volatile information. Therefore, this paper proposes an enhanced interval-valued decomposition integration model for stock price prediction based on comprehensive feature extraction and optimized deep learning. Firstly, the interval variational modal decomposition with feedback mechanism (FIVMD) is proposed to extract internal features and can decompose interval values into interval trend and residual. FIVMD not only solves the interval decomposition challenge, but also helps to improve the internal feature extraction capability. Secondly, while considering the influencing factors more comprehensively, appropriate feature selection and compression techniques can effectively achieve external feature extraction, obtain the best influencing factors, and improve the modeling capability of highdimensional data. Finally, the final prediction results are obtained by modeling the interval trend and residuals separately through the optimization algorithm and deep learning model to improve the prediction accuracy. The results of the empirical analysis reveal that the proposed interval decomposition integrated model has the smallest of the three evaluation metrics, where the values of interval mean average percentage errors (IMAPE) are 1.8188%, 1.1244%, 1.9001%, and 2.1542% respectively. This shows that the model is significantly more accurate and stable than the other comparative models, and it is a successful model for predicting intervalvalued stock prices.",2024
Volatility forecasting with hybrid neural networks methods for Risk Parity investment strategies,"We present a hybrid method for computing volatility forecasts that can be used to implement a risk-controlled strategy for a multi-asset portfolio consisting of both US and international equities. Recent years have been characterized by extremely low yields, with 2022 marked by rising interest rates and an increasing inflation rate. These factors produced new challenges for both private and institutional investors, including the need for robust forecast methods for financial assets' volatilities. Addressing such task, our research focuses on a hybrid solution that combines classical statistical models with specific classes of Recurrent Neural Networks (RNNs). In particular, we first use the Generalized Autoregressive Conditional Heteroscedasticity (GARCH) approach within the preprocessing phase to capture volatility clustering, striking an efficient balance between computational effort and accuracy, to then apply RNN architectures, namely GRU, LSTM, and a mixed model with both units, as to maximize performances of volatility forecasts later used as input factors for risk-controlled investment strategies. In terms of portfolio allocation, we focus on a simplified version of the Risk Parity method that was first proposed by the Research division of S&P Global. This version ignores the contribution of cross-correlations among assets, nevertheless providing encouraging results. Indeed, we show the effectiveness of the chosen approach by providing forward-looking risk parity portfolio strategies that outperform standard risk/return portfolio structures.",2023
Cross-modality Labeling Enables Noninvasive Capillary Quantification as a Sensitive Biomarker for Assessing Cardiovascular Risk,"Purpose: We aim to use fundus fluorescein angiography (FFA) to label the capillaries on color fundus (CF) photographs and train a deep learning model to quantify retinal capillaries noninvasively from CF and apply it to cardiovascular disease (CVD) risk assessment. Design: Cross-sectional and longitudinal study. Participants: A total of 90732 pairs of CF-FFA images from 3893 participants for segmentation model development, and 49229 participants in the UK Biobank for association analysis. Methods: We matched the vessels extracted from FFA and CF, and used vessels from FFA as labels to train a deep learning model (RMHAS-FA) to segment retinal capillaries using CF. We tested the model's accuracy on a manually labeled internal test set (FundusCapi). For external validation, we tested the segmentation model on 7 vessel segmentation datasets, and investigated the clinical value of the segmented vessels in predicting CVD events in the UK Biobank. Main Outcome Measures: Area under the receiver operating characteristic curve (AUC), accuracy, sensitivity, and specificity for segmentation. Hazard ratio (HR; 95% confidence interval [CI]) for Cox regression analysis. Results: On the FundusCapi dataset, the segmentation performance was AUC = 0.95, accuracy = 0.94, sensitivity = 0.90, and specificity = 0.93. Smaller vessel skeleton density had a stronger correlation with CVD risk factors and incidence (P < 0.01). Reduced density of small vessel skeletons was strongly associated with an increased risk of CVD incidence and mortality for women (HR [95% CI] = 0.91 [0.84-0.98] and 0.68 [0.54-0.86], respectively). Conclusions: Using paired CF-FFA images, we automated the laborious manual labeling process and enabled noninvasive capillary quantification from CF, supporting its potential as a sensitive screening method for identifying individuals at high risk of future CVD events. Financial Disclosure(s): Proprietary or commercial disclosure may be found in the Footnotes and Disclosures at the end of this article. Ophthalmology Science 2024;4:100441 (c) 2024 Published by Elsevier Inc. on behalf of the American Academy of Ophthalmology. This is an open access article under the CC BY-NC-ND license (http:// creativecommons.org/licenses/by-nc-nd/4.0/).",2024
Neural networks for estimating Macro Asset Pricing model in football clubs,"The recent crisis caused by COVID-19 directly affected consumption habits and the stability sof financial markets. In particular, the football industry has been hit hard by this pandemic and therefore has more volatile stock prices. Given this new scenario, further research is needed to accurately estimate the value of the shares of football clubs. In this paper, we estimate an asset pricing model in football clubs with different compositions of risk nature using non-linear techniques of artificial neural networks. Usually, asset pricing models have been estimated with linear methods such as ordinary least squares. Our results show a precision higher than 90% for all the estimated models, which far exceeds those shown by linear methods in the previous literature. We find that the residual represents about 40% of the variance of the price-dividend ratio. Long-term risks follow in importance, and above all, the habit component and its behaviour in the face of changes. The importance of the residual component exists due to a low correlation between the asset price and consumer behaviour, but to a much lesser extent than that shown in previous studies. The estimation carried out with artificial neural networks, both the Deep Learning methods and especially the Quantum Neural Network, opens up new possibilities to estimate more efficiently the pricing of financial assets in the football industry.",2023
Early warning research on enterprise carbon emission reduction credit risk based on deep learning model under unbalanced data,"To enhance the precision of predicting enterprise credit risk related to carbon emission reduction, this study focuses on publicly traded companies. It introduces a risk early warning model grounded in MLP deep learning. Primarily, this research employs the FA-TOPSIS fusion model to comprehensively assess the credit risk associated with carbon emission reduction in enterprises. Subsequently, it employs K-means clustering to compute enterprise similarities, which forms the basis for supervised learning in the MLP model to assign credit risk grade labels. Furthermore, the study tackles the challenge of imbalanced enterprise grade distribution using the ADASYN over-sampling algorithm. Ultimately, the effectiveness of the model proposed herein is confirmed through a series of multi-model comparison experiments. The results show that: First, carbon emission reduction indicators exhibit differing degrees of influence on enterprises at various credit risk levels. Notably, the most influential indicator is carbon emission intensity, while the development capacity indicator exerts the least influence. Second, the adoption of the XGBoost algorithm for screening carbon emission reduction indicators significantly enhances the prediction accuracy of the early warning model by 4.27%. Third, compared to other models, the MLP model achieves an impressive prediction accuracy of 99.48%, representing an average improvement of 15.24%. These results underscore the model's feasibility and its potential to provide technical support for financial institutions and government entities in conducting credit ratings for enterprise carbon emission reduction.",2023
JEL: Applying End-to-End Neural Entity Linking in JPMorgan Chase,"Knowledge Graphs have emerged as a compelling abstraction for capturing key relationship among the entities of interest to enterprises and for integrating data from heterogeneous sources. JPMorgan Chase (JPMC) is leading this trend by leveraging knowledge graphs across the organization for multiple mission critical applications such as risk assessment, fraud detection, investment advice, etc. A core problem in leveraging a knowledge graph is to link mentions (e.g., company names) that are encountered in textual sources to entities in the knowledge graph. Although several techniques exist for entity linking, they are tuned for entities that exist in Wikipedia, and fail to generalize for the entities that are of interest to an enterprise. In this paper, we propose a novel end-to-end neural entity linking model (JEL) that uses minimal context information and a margin loss to generate entity embeddings, and a Wide & Deep Learning model to match character and semantic information respectively. We show that JEL achieves the state-of-the-art performance to link mentions of company names in financial news with entities in our knowledge graph. We report on our efforts to deploy this model in the company-wide system to generate alerts in response to financial news. The methodology used for JEL is directly applicable and usable by other enterprises who need entity linking solutions for data that are unique to their respective situations.",2021
Green Credit Risk Assessment under the Background of Water Ecological Civilization City Construction-Based on BP Neural Network Model,"The construction of water ecological civilized cities requires a large amount of capital, but at the same time, the project itself has certain risks. Commercial banks are not only the main providers of credit funds, but also the main bearers of project risks. Strengthening the credit risk management of water ecological civilized urban construction projects and enhancing the financial support of commercial banks for water ecological civilized urban construction projects have become the key to further promoting the construction of water ecological civilized cities. At present, the credit risk assessment of commercial banks in China is based on traditional methods, and it is difficult to achieve the desired effect. This paper applies the AHP method to construct the credit risk index system of water conservancy projects, and establishes a credit risk assessment model through BP neural network technology. Finally, it combines 39 listed companies. The data is empirically analyzed for the model to verify the accuracy of the predictions.",2020
A Deep Learning Method for Landing Pitch Prediction based on Flight Data,"With the development of the aviation industry, aircraft has increasingly become one of the most preferred long-distance transportation tools, and aviation safety incidents have attracted extensive attention. The key to dealing with aviation safety incidents is to accurately predict anomalies and potential hazards in advance and instruct pilots to perform corrective operations. As one of the safety incidents, tail strike may cause damage to the aircraft fuselage which may bring financial losses, or even threaten lives. However, there are few studies on tail strike in depth at present. In order to fill this gap, this paper mainly focuses on the tail strike risk, which is defined as the incident that the maximum pitch angle of the aircraft one second after and before touchdown exceeds a certain threshold. Specifically, we employ the LSTM model to make predictions of the maximum pitch angle with 22 parameters from QAR data. Extensive experiments based on a large-scale data show that the prediction model in this paper achieves the lowest MSE, MAE and the highest fitting coefficient R2-score, as compared to 9 traditional machine learning algorithms, which validates the effectiveness of our model in finding high risk flights.",2020
Stock Market Index Prediction: A framework based on transfer learning and knowledge graph enrichment through uncertainty using natural language and fuzzy logic,"The main characteristic of stock market dynamics is uncertainty. While most studies reduce this uncertainty to risk and use objective probabilities to represent it, natural language and fuzzy logic offer tools to go beyond objective probabilities and better represent the uncertainty between the main risk factors (SCRF or super causal risk factor) and the different stock market indices. In this article, an existing knowledge graph (KG) on a complex and uncertain causal process of the financial market dynamics is consider as the main input. We combine expert knowledge, natural language and fuzzy logic to go beyond objectives probabilities and propose a solution based on three pillars: i) The enrichment of each fact in a KG using fuzzy systems theory to introduce uncertainty, then formulation of an input sequence and an output sequence for training a Seq2Seq algorithm as an inference engine. ii) The generation of features that summarize the interaction between each SCRF and each stock index contained in a KG fact. The input sequence is the assumption at time t regarding the behavior of the stock index at time t+1, based on the current interaction between each SCRF and each stock index. The realisation of stock index at time t+1 is represented by the output sequence. (iii) Finally, transfer learning is used to share knowledge (parameter learning) between all stock indexes, increase the training sample, and preserve the stability of input distribution between training, validation, and test samples. Fine-tuning is then employed to improve the predictive power on the specific stock or target index. For instance, when targeting the most significant US index (S&P500), we achieved an accuracy rate of 76%, an F1-score of 74%, and a Matthew Correlation of 0.49, surpassing consistently industry benchmarks over a twelve-year test period. Furthermore, we maintained high and stable metrics compared to two other benchmarks during three sub-periods with high volatility and difficulty in prediction.",2024
Swiss Hypertension and Risk Factor Program (SHARP):: Cardiovascular risk factors management in patients with type 2 diabetes in Switzerland,"The prevalence of hypertension in type 2 diabetics is high, though there is no published data for Switzerland. This prospective cohort survey determined the frequency of type 2 diabetes mellitus associated with hypertension from medical practitioners in Switzerland, and collected data on the diagnostic and therapeutic work-up for cardiovascular risk patients. The Swiss Hypertension And Risk Factor Program ( SHARP) is a two-part survey: The first part, I-SHARP, was a survey among 1040 Swiss physicians to assess what are the target blood pressure ( BP) values and preferred treatment for their patients. The second part, SHARP, collected data from 20,956 patients treated on any of 5 consecutive days from 188 participating physicians. In I-SHARP, target BP <= 135/85 mmHg, as recommended by the Swiss Society of Hypertension, was the goal for 25% of physicians for hypertensives, and for 60% for hypertensive diabetics; values >140/90 mmHg were targeted by 19% for hypertensives, respectively 9% for hypertensive diabetics. In SHARP, 30% of the 20,956 patients enrolled were hypertensive ( as defined by the doctors) and 10% were diabetic ( 67% of whom were also hypertensive). Six per cent of known hypertensive patients and 4% of known hypertensive diabetics did not receive any antihypertensive treatment. Diabetes was not treated pharmacologically in 20% of diabetics. Proteinuria was not screened for in 45% of known hypertensives and in 29% of known hypertensive diabetics. In Switzerland, most physicians set target BP levels higher than recommended in published guidelines. In this country with easy access to medical care, high medical density and few financial constraints, appropriate detection and treatment for cardiovascular risk factors remain highly problematic.",2005
The EU Taxonomy and the Syndicated Loan Market,"The European Union (EU) Taxonomy on Sustainable Activities is one of the most far-reaching financial market regulations to combat climate change. Using international data from the syndicated loan market, we demonstrate that firms with larger EU Taxonomy-eligible revenue shares paid lower interest rates in the years before the formal introduction of the Taxonomy. Business revenue is Taxonomy-eligible if it originates from transitional activities that substantially contribute to climate change mitigation. A one-standard-deviation increase in firm revenue from transitional activities is associated with 5 basis points (bp) lower loan spreads (5% relative to the standard deviation). Effects are more pronounced for firms in countries with greater climate risk exposure and more stringent environmental policies, and when lending institutions have green preferences. The effects of transitional revenue do not simply reflect a borrower's ESG ratings or broad exposure to climate risks and opportunities. Overall, our results indicate that financial markets already priced in some of the intended effects of the Taxonomy.",2025
A Dynamic Default Prediction Framework for Networked-guarantee Loans,"Commercial banks normally require Small and Medium Enterprises (SMEs) to provide their warranties when applying for a loan. If the borrower defaults, the guarantor is obligated to repay its loan. Such a guarantee system is designed to reduce delinquent risks, but may introduce a new dimension risk if more and more SMEs involve and subsequently form complex temporal networks. Monitoring the financial status of SMEs in these networks, and preventing or reducing systematic loan risk, is an area of great concern for both the regulatory commission and the banks. To allow possible actions to be taken in advance, this paper studies the problem of predicting repayment delinquency in the networked-guarantee loans. We propose a dynamic default prediction framework (DDPF), which preserves temporal network structures and loan behavior sequences in an end-to-end model. In particular, we design a gated recursive and attention mechanism to integrate both the loan behavior and network information. Then, we uncover risky warrant patterns by the learned weights, which effectively accelerate risk evaluation process. Finally, we conduct extensive experiments in a real-world loan risk control system to evaluate its performance, the results demonstrate the effectiveness of our proposed approach compared with state-of-the-art baselines.",2019
IMM: An Imitative Reinforcement Learning Approach with Predictive Representation Learning for Automatic Market Making,"Market making (MM) via Reinforcement Learning (RL) has attracted significant attention in financial trading. Most existing RL-based MM methods focus on optimizing single-price level strategies which fail at frequent order cancellations and loss of queue priority. By comparison, strategies involving multiple price levels align better with actual trading scenarios. However, given the complexity that multi-price level RL strategies involve a comprehensive trading action space, the challenge of effectively training RL persists. Inspired by the effective workflow of professional human market makers, we propose Imitative Market Maker (IMM), a novel RL framework leveraging knowledge from both suboptimal signal-based experts and direct policy interactions. Our framework starts with introducing effective state and action formulations that well encode information about multiprice level orders. Furthermore, IMM integrates a representation learning unit capable of capturing both short- and long-term market trends to mitigate adverse selection risk. Subsequently, IMM designs an expert strategy based on predictive signals, and trains the agent through the integration of RL and imitation learning techniques to achieve efficient learning. Extensive experimental results on four real-world market datasets demonstrate the superiority of IMM against current RL-based market making strategies.",2024
Intelligent option portfolio model with perspective of shadow price and risk-free profit,"Since Markowitz proposed modern portfolio theory, portfolio optimization has been being a classic topic in financial engineering. Although it is generally accepted that options help to improve the market, there is still an improvement for the portrayal of their unique properties in portfolio problems. In this paper, an intelligent option portfolio model is developed that allows selling options contracts to earn option fees and considers the high leverage of options in the market. Deep learning methods are used to predict the forward price of the underlying asset, making the model smarter. It can find an optimal option portfolio that maximizes the final wealth among the call and put options with multiple strike prices. We use the duality theory to analyze the marginal contribution of initial assets, risk tolerance limit, and portfolio leverage limit for the final wealth. The leverage limit of the option portfolio has a significant impact on the return. To satisfy the investors with different risk preferences, we also give the conditions for the option portfolio to gain a risk-free return and replace the Conditional Value-at-Risk. Numerical experiments demonstrate that the intelligent option portfolio model obtains a satisfactory out-of-sample return, which is significantly positively correlated with the volatility of the underlying asset and negatively correlated with the forecast error of the forward price. The risk- free option model is effective in achieving the goal of no drawdown and gaining satisfactory returns. Investors can adjust the balance point between returns and risks according to their risk preference.",2023
Risks and Benefits of Future Travel with Hyperloop: A Multi-Analytical Approach,"Despite significant government investment in Hyperloop transportation across various countries, research on its potential advantages and drawbacks from the tourist's perspective remains scarce. Guided by prospect theory, this study examines the perceptions and behaviors of frequent (n = 386) and occasional (n = 214) travelers regarding Hyperloop technology, using multiple analytical methods such as partial least squares structural equation modeling (PLS-SEM), multi-group analysis (MGA), fuzzy-set Qualitative Comparative Analysis (fsQCA), and artificial neural networks (ANN). The study explores how four perceived benefits (economic, environmental, socio-cultural, and time-saving) and four perceived risks (functional, physical, psychological, and financial concerns) influence travelers' intentions to use Hyperloop for tourism. The PLS-SEM and MGA analyses indicate that frequent travelers prioritize time-saving, while economic, environmental, socio-cultural benefits, and functional risks influence occasional travelers' decisions. Additionally, fsQCA findings identify distinct benefit-risk combinations affecting travel decisions, and deep learning models highlight critical factors predicting Hyperloop adoption. This study provides theoretical insights and practical strategies for integrating Hyperloop into tourism planning and management.",2025
A comprehensive review of artificial intelligence and network based approaches to drug repurposing in Covid-19,"Conventional drug discovery and development is tedious and time-taking process; because of which it has failed to keep the required pace to mitigate threats and cater demands of viral and re-occurring diseases, such as Covid19. The main reasons of this delay in traditional drug development are: high attrition rates, extensive time requirements, and huge financial investment with significant risk. The effective solution to de novo drug discovery is drug repurposing. Previous studies have shown that the network-based approaches and analysis are versatile platform for repurposing as the network biology is used to model the interactions between variety of biological concepts. Herein, we provide a comprehensive background of machine learning and deep learning in drug repurposing while specifically focusing on the applications of network-based approach to drug repurposing in Covid-19, data sources, and tools used. Furthermore, use of network proximity, network diffusion, and AI on network-based drug repurposing for Covid-19 is well-explained. Finally, limitations of network-based approaches in general and specific to network are stated along with future recommendations for better network-based models.",2022
Stock market movement forecast: A Systematic review,"Achieving accurate stock market models can provide investors with tools for making better data-based decisions. These models can help traders to reduce investment risk and select the most profitable stocks. Furthermore, creating advanced models enable the usage of non-traditional data like historical stock prices and news. There are several review articles about financial problems, including stock market analysis and forecast, currency exchange forecast, optimal portfolio selection, among others. However, the recent advances in machine learning techniques, like Deep Learning, Text Mining Techniques, and Ensemble Techniques, raises the need to perform an updated review. This study aims to fill this gap by providing an updated systematic review of the forecasting techniques used in the stock market, including their classification, characterization and comparison. The review is focused on studies on stock market movement prediction from 2014 to 2018, obtained from the scientific databases Scopus and Web of Science. Besides, it analyzes surveys and other reviews of recent studies published in the same time frame and the same databases. (C) 2020 Elsevier Ltd. All rights reserved.",2020
Machine Learning Analysis of Mortgage Credit Risk,"In 2008, the US experienced the worst financial crisis since the Great Depression of the 1930s. The 2008 recession was fueled by poorly underwritten mortgages in which a high percentage of less-credit-worthy borrowers defaulted on their mortgage payments. Although the market has recovered from that collapse, we must avoid the pitfalls of another market meltdown. Greed and overzealous assumptions fueled that crisis and it is imperative that bank underwriters properly assess risks with the assistance of the latest technologies. In this paper, machine learning techniques are utilized to predict the approval or denial of mortgage applicants using predicted risks due to external factors. The mortgage decision is determined by a two-tier machine learning model that examines micro and macro risk exposures. In addition a comparative analysis on approved and declined credit decisions was performed using logistic regression, random forest, adaboost, and deep learning. Throughout this paper multiple models are tested with different machine learning algorithms, but time is the key driver for the final candidate model decision. The results of this study are fascinating and we believe that this technology will offer a unique perspective and add value to banking risk models to reduce mortgage default percentages.",2020
B-LSTM-NB BASED COMPOSITE SEQUENCE LEARNING MODEL FOR DETECTING FRAUDULENT FINANCIAL ACTIVITIES,"Deep Learning (DL) in finance is widely regarded as one of the pillars of financial services sectors since it performs crucial functions such as transaction processing and computation, risk assessment, and even behavior prediction. As a subset of data science, DL can learn and develop from their experience, which does not require constant human interference and programming, implying that the technology will improve quickly. By loading an Ensemble Model (EM), a Deep Sequential Learning (DSL)model, and additional upper-layer EM classifier in the correct order, a new Contained-In-Between (C-I-B) composite structured DSL model is recommended in this article. In cases like Fraud Detection System (FDS), where the data flow comprises vectors with complex interconnected characteristics, DL models with this structure have proven to be highly efficient. Finally, by utilizing optimized transaction eigenvectors, a NB classifier is trained. This strategy is more effective than most standard approaches in identifying transaction fraud. The proposed model is evaluated for its accuracy, Recall and F-score, and the results show that the model has better performance against its counterparts.",2022
Innovative laboratory techniques shaping cancer diagnosis and treatment in developing countries,"Cancer is a major global health challenge, with approximately 19.3 million new cases and 10 million deaths estimated by 2020. Laboratory advancements in cancer detection have transformed diagnostic capabilities, particularly through the use of biomarkers that play crucial roles in risk assessment, therapy selection, and disease monitoring. Tumor histology, single-cell technology, flow cytometry, molecular imaging, liquid biopsy, immunoassays, and molecular diagnostics have emerged as pivotal tools for cancer detection. The integration of artificial intelligence, particularly deep learning and convolutional neural networks, has enhanced the diagnostic accuracy and data analysis capabilities. However, developing countries face significant challenges including financial constraints, inadequate healthcare infrastructure, and limited access to advanced diagnostic technologies. The impact of COVID-19 has further complicated cancer management in resource-limited settings. Future research should focus on precision medicine and early cancer diagnosis through sophisticated laboratory techniques to improve prognosis and health outcomes. This review examines the evolving landscape of cancer detection, focusing on laboratory research breakthroughs and limitations in developing countries, while providing recommendations for advancing tumor diagnostics in resource-constrained environments.",2025
Every Corporation Owns Its Structure: Corporate Credit Rating via Graph Neural Networks,"Credit rating is an analysis of the credit risks associated with a corporation, which reflects the level of the riskiness and reliability in investing, and plays a vital role in financial risk. There have emerged many studies that implement machine learning and deep learning techniques which are based on vector space to deal with corporate credit rating. Recently, considering the relations among enterprises such as loan guarantee network, some graph-based models are applied in this field with the advent of graph neural networks. But these existing models build networks between corporations without taking the internal feature interactions into account. In this paper, to overcome such problems, we propose a novel model, Corporate Credit Rating via Graph Neural Networks, CCR-GNN for brevity. We firstly construct individual graphs for each corporation based on self-outer product and then use GNN to model the feature interaction explicitly, which includes both local and global information. Extensive experiments conducted on the Chinese public-listed corporate rating dataset, prove that CCR-GNN outperforms the state-of-the-art methods consistently.",2022
Market-Clearing Price Forecasting Using Keras in Turkish Day-Ahead Electricity Market,"The market-clearing price determined in the electricity market is of great importance for the market players trading in electricity. The market-clearing price constitutes the core of the buying and selling transactions in the electricity market. Knowing what the price of the product, service or commodity to be bought and / or sold would be, provides a great competitive advantage to the relevant party over the person or organization carrying out the relevant commercial activity. It is important to successfully predict the market-clearing price in the market in order to set strategy and game plan and implement risk management. For this purpose, in this study, a model using only publicly available input data on Keras, a deep learning library, is used to predict hourly market-clearing price in Turkish Day-Ahead Electricity Market. Despite the high economic and financial uncertainty and price fluctuations in 2021, the proposed model showed a high performance with a MAPE value of 2.5% and it is clear that the model is successful and applicable in real market conditions.",2022
Evaluating Employee Health Risks Due to Hypertension and Obesity: Self-Testing Workplace Health Stations,"Background: We evaluated employee health risks due to hypertension, pre-hypertension, overweight, and obesity through the use of self-testing workplace health stations that measure blood pressure (BP) and weight. Methods: We analyzed BP and weight data from the first IS months after the installation of health stations in the offices of a financial services company with approximately 20000 employees in 13 US workplace locations. Results: Data showed that 21.7% of the employees voluntarily used a health station at least once to measure BP or weight during the first 18 months. Health station usage ranged from a high of 51.8% to a low of 5.3% at the 13 workplace locations. Among health station users, 52.5% used a health station more than once. Health station users used the health stations an average of 4.2 times (median, 2 times). Among health station users, 95.6% measured BP, 92.2% measured weight, and 87.8% measured both BP and weight. Initial BP results were: hypertension 26.7%, prehypertension 40.3%, and normal BP 32.9%. The initial body mass index (BMI) results were: obese 38%, overweight 34.7%, normal weight 25.3%, and underweight 2%. Employees with hypertension on the initial reading used the health stations more frequently than employees with pre-hypertension or normal BP. Employees with an obese BMI result on the initial reading used the health stations more frequently than employees with an overweight or normal BM I result. Many employees reduced their health risks due to hypertension, pre-hypertension, overweight, or obesity, although the health risks of many other employees were unchanged or increased. Conclusions: Self-testing workplace health stations that measure BP and weight provide employees with information about their health risks due to hypertension, pre-hypertension, overweight, and obesity. Self-testing workplace health stations can also be used to identify at-risk employees who may benefit from health and wellness programs.",2009
Smart Robotic Strategies and Advice for Stock Trading Using Deep Transformer Reinforcement Learning,"The many success stories of reinforcement learning (RL) and deep learning (DL) techniques have raised interest in their use for detecting patterns and generating constant profits from financial markets. In this paper, we combine deep reinforcement learning (DRL) with a transformer network to develop a decision transformer architecture for online trading. We use data from the Saudi Stock Exchange (Tadawul), one of the largest liquid stock exchanges globally. Specifically, we use the indices of four firms: Saudi Telecom Company, Al-Rajihi Banking and Investment, Saudi Electricity Company, and Saudi Basic Industries Corporation. To ensure the robustness and risk management of the proposed model, we consider seven reward functions: the Sortino ratio, cumulative returns, annual volatility, omega, the Calmar ratio, max drawdown, and normal reward without any risk adjustments. Our proposed DRL-based model provided the highest average increase in the net worth of Saudi Telecom Company, Saudi Electricity Company, Saudi Basic Industries Corporation, and Al-Rajihi Banking and Investment at 21.54%, 18.54%, 17%, and 19.36%, respectively. The Sortino ratio, cumulative returns, and annual volatility were found to be the best-performing reward functions. This work makes significant contributions to trading regarding long-term investment and profit goals.",2022
Intelligent Evaluation and Early Warning of Liquidity Risk of Commercial Banks Based on RNN,"With the downward pressure of China's economy and the impact of the epidemic, the accumulated market risk has increased the liquidity pressure of the banking industry, and the mismatch between deposit maturity and loan maturity is the main cause for the increase of liquidity risk. The twenty-first century is the era of rapid and in-depth development of data management technology. The explosive growth of massive financial data makes the information data related to the liquidity risk of commercial banks present the characteristics of complexity, diversity, and heterogeneity. The traditional risk early warning model cannot deal with the influence between a large number of influencing factors and the nonlinear factors of commercial bank liquidity risk. Based on this transformation, the circular neural network model is introduced into the field of liquidity risk early warning of commercial banks from the perspective of the mismatch risk of financing maturity of commercial banks, and the driving factors and risk warning signs of liquidity risk of commercial banks are further analyzed from the institutional level, policy level, industry level, and micro commercial bank level. This paper uses network crawler technology, text analysis, and grounded analysis technology to intelligently identify the liquidity risk of commercial banks and establishes an early warning index system based on the influencing factors of commercial banks and internal liquidity risk. Also, it constructs an intelligent early warning model of commercial bank liquidity risk based on deep learning and uses the data of commercial banks from 2000 to 2020 for early warning. The results show that the constructed model has high accuracy, which can provide support for banks and relevant government departments to formulate and resolve bank liquidity risk.",2022
Guidelines for the management of hypertension at primary health care level,"Objective. To outline rational and cost-effective comprehensive management of hypertension by health care professionals in a primary care setting. Outcomes. Control of hypertension with a target blood pressure (BP) of systolic 140 - 159 mmHg, diastolic 90 - 94 mmHg with minimal or no drug side-effects. Reduce BP in the elderly and those with severe hypertension gradually. Stricter BP control is required for patients with end-organ damage, coexisting risk factors, diabetes mellitus. Extensive data including many randomised controlled trials showed the benefit of controlling hypertension. This evidence is reported in Opie L. H. and Steyn K., Rationale for the hypertension guidelines for primary care in South Africa, S Afr Med J 1995; 85: 1325-1338. Values. To treat as many of the untreated hypertensive patients as possible, using rational and cost-effective care. Cost-effectiveness and access to therapy are major issues. Benefits, harms and costs. Reduction in stroke, cardiac failure, renal failure and coronary artery disease. The major precautions and contraindications to each antihypertensive drug recommended are listed. The financial costs of the drugs are considered. Recommendations. Correct BP measurement procedure. Identification of blood pressure levels for appropriate management. Evaluation of other cardiovascular risk factors and their influence on when to treat hypertension. Lifestyle modification and patient education for all patients. Drug therapy: first line - low-dose diuretics; second line - reserpine or beta-blockers or AGE inhibitors or calcium channel blockers; third line - hydralazine or prazosin or another second-line drug. Drug treatment and referral of specific cases (pregnancy, diabetes mellitus, severe hypertension). Validation. Developed by the Hypertension Society of Southern Africa Executive Committee and co-opted persons during 1995, with added input from HSSA members at the National Congress. Endorsed by the Medical Association of South Africa. Sponsors. The meetings of the HSSA Executive Committee and co-opted persons were predominantly funded by Pfizer Laboratories and Astra Pharmaceuticals.",1995
Study on early warnings of strategic risk during the process of firms' sustainable innovation based on an optimized genetic BP neural networks model: Evidence from Chinese manufacturing firms,"Strategic risk is an inevitable question of reality, which leads to a significant impact that negatively affects firms' overall development, even threatening their survival. Most of extant studies on early warning models merely take the financial factors into account, whereas strategic risk pertaining to firms involves a diverse group of non-financial factors. In addition, the growing attention attached to the sustainable development of ecological and social environment has raised specific concerns to manufacturing firms, which need especially manage the risks generated from the process of sustainable innovation. However, scholars have paid far less attention to early warning models that comprehensively address the above problems. It is crucial to facilitate manufacturing firms to timely detect strategic risk during the process of sustainable innovation, whereas the existing early warning models are not reliable enough to warn the potential risks. Therefore, this study sets out to introduce the sustainable risk into the early warning indicators system of strategic risk. Then, Chinese manufacturing firms are applied to construct an early warning model which based on the back-propagation (BP) neural network optimized by genetic algorithm (GA). The results provide evidence that the proposed model shows a better fitting effect, higher prediction precision and higher convergence speed when compared with conventional models. In addition, the weights of the early warning model obtained from the training are substituted into the forward propagation formula, which enables to determine the relative importance of risk factors. It is of great significance for the firms to prioritize risk management actions. Furthermore, the new model enables manufacturing firms to warn the strategic risk during the process of sustainable innovation while striking a balance among economic, environmental, and social performances.",2021
Application of genetic algorithm and BP neural network in supply chain finance under information sharing,"The supply chain finance industry will generate the flow of funds and commodities when providing financing services to small and medium-sized enterprises (SMEs). At this time, banks will face multiple risks such as policy, operation, market and credit. The investigation on supply chain finance under information sharing from the aspect of credit risk assessment will be conducted. The genetic algorithm combined with support vector machine and BP neural network is selected to evaluate the credit risk of supply chain finance. In the support vector machine method, the parameter selection method adopts genetic algorithm. In the included data, the gap in growth capacity of SMEs is relatively large. The standard deviations of main business, net profit and total assets are all above 30%, and the standard deviations of current ratio and quick ratio are small, which means that the two are more stable and healthier. In addition, among all the investigated enterprises, the cost gap is large, and the standard deviation of the inventory decline price reserve is small, which means that most enterprises have good inventory quality. After classification, 32 high-quality enterprises, 46 neutral enterprises and 55 risk enterprises are obtained in the total sample. In the test sample, there are 21 high-quality enterprises, 12 neutral enterprises, and 26 risk enterprises. The overall classification accuracy of the support vector machine method optimized by genetic algorithm is relatively lower than that of the BP neural network method. The classification accuracy of the support vector machine method optimized by genetic algorithm is 76.27%, and the classification accuracy of BP neural network method is 89.83%. The supply chain financial risk assessment of SMEs is mainly explored from the perspective of banks. The results can provide theoretical support for reducing the probability of bank's profit damage and increasing the bank's profitability. (C) 2020 Elsevier B.V. All rights reserved.",2021
NOTE: non-parametric oversampling technique for explainable credit scoring,"Credit scoring models are critical for financial institutions to assess borrower risk and maintain profitability. Although machine learning models have improved credit scoring accuracy, imbalanced class distributions remain a major challenge. The widely used Synthetic Minority Oversampling TEchnique (SMOTE) struggles with high-dimensional, non-linear data and may introduce noise through class overlap. Generative Adversarial Networks (GANs) have emerged as an alternative, offering the ability to model complex data distributions. Conditional Wasserstein GANs (cWGANs) have shown promise in handling both numerical and categorical features in credit scoring datasets. However, research on extracting latent features from non-linear data and improving model explainability remains limited. To address these challenges, this paper introduces the Non-parametric Oversampling Technique for Explainable credit scoring (NOTE). The NOTE offers a unified approach that integrates a Non-parametric Stacked Autoencoder (NSA) for capturing non-linear latent features, cWGAN for oversampling the minority class, and a classification process designed to enhance explainability. The experimental results demonstrate that NOTE surpasses state-of-the-art oversampling techniques by improving classification accuracy and model stability, particularly in non-linear and imbalanced credit scoring datasets, while also enhancing the explainability of the results.",2024
A Centralized Credit Scoring Prototype for Microlending Institutions Using Neural Networks,"Microlending involves giving small loans to people in need. Usually, these loans are issued to entrepreneurs or those who need extra cash to either expand or for personal use. Digital lending is becoming a leading source of credit especially to low-income citizens with minimal or no financial footprints in various parts of the world. It has quickly become the default way for lenders to service loan requests from borrowers due to the convenience it brings about as well as the increased number of requests that can be processed compared to the traditional way that required quite an amount of paper work. As the number of lending companies grows, there is the need to standardize the credit scoring process and maintain an updated credit activity log for every user. This ensures that lenders are always aware of any other unsettled debts a borrower might have and provides them with the most recent information to assess the risk they face by lending to a borrower. The proposed solution consists of a credit scoring neural network-based algorithm composed of a single input layer, a single hidden layer and an output layer of one neuron, and a representational state transfer (REST) based web service allows lenders to submit details of loans they have approved and issued to a borrower. The information is used to generate and keep track of the user's credit score and amount of risk lenders face should they consider lending to the user. Agile development methodology was used to develop robust credit scoring prototype and Android mobile application. The final prototype was tested to ensure that the requirements were met and the functionality working as required.",2022
Application of the American College of Cardiology (ACC/AHA) 2017 Guideline for the Management of Hypertension in Adults and Comparison with the 2014 Eighth Joint National Committee Guideline,"Objectives: This study aims to compare the 2017-ACC/AHA hypertension guideline with 2014-JNC-8 guideline in regard to the number of patients who are eligible for treatment and to determine the physicians' adherence and the financial impact of implementing the new guideline. Methods: A cross-sectional observational study was conducted on adult patients who attended the hospital outpatient setting in UAE during January 1, 2018 till February 28, 2018. Adults who are diagnosed with hypertension and those with blood pressure (BP) levels based on two or more readings obtained on two or more different occasions were screened for inclusion into this study and cardiovascular diseases (CVD) risk was calculated. The two guidelines were compared with respect to the number of patients diagnosed with hypertension and eligible for treatment. Results were extrapolated to the UAE population. Financial impact of applying the 2017-ACC/AHA guideline was also evaluated. Results: In comparison with the JNC-8, the 2017-ACC/AHA guideline would increase the proportion of patients diagnosed with hypertension among UAE adults from 40.8% to 76.3% and the number of UAE adults recommended for antihypertensive medications would rise from 2.42 million (32.1%) to 4.71 million (62.5%). Among UAE adults, almost 4.42 million (58.6%) and 0.76 million (10.1%) would have BP above the target according to the 2017-ACC/AHA and JNC-8 guidelines, respectively. The expected increase in the cost of anti-hypertension medications prescribed for the new labeled cases according to 2017-ACC/AHA but not JNC-8 would reach 1.8 billion AED/year. For those who were recommended for antihypertensive medications, who had BP above target, the additional cost would reach 3.5 billion AED/year. Conclusions: The current study reveals marked increase in the proportion of patients diagnosed with hypertension in concordance with the 2017-ACC/AHA guideline. This is also will be associated with almost double the number of UAE adults recommended for antihypertensive medications. The poor compliance with the 2017-ACC/AHA reflects the concern regarding the increase risk of adverse events.",2021
Supply chain research based on complex network theory,"Supply chain is a chain structure formed by the sequential processes of production and distribution, spanning from raw material suppliers to end customers. An efficient and reliable supply chain is of great significance in enhancing enterprise's market competitiveness and promoting sustainable social and economic development. The supply chain includes the interconnected flows of materials, resources, capital, and information across various stages, including procurement, production, warehousing, distribution, customer service, information management, and financial management. By representing the various participants in the supply chain as nodes and their interactions-such as the logistics, capital flow, information flow, and other interactions-as edges, the supply chain can be described and characterized as a complex network. In recent years, using complex network theory and methods to model and analyze supply chains has attracted increasing attention from researchers. This paper systematically reviews the supply chain research based on complex network theory, providing an in-depth analysis of supply chain networks in terms of network construction, structural properties, and management characteristics. First, this paper reviews two kinds of approaches to constructing supply chain network: empirical data-based approach and network model-based approach. In the empirical data-based research, scholars use common supply chain databases or integrate multiple data sources to identify the supply chain participants and clarify their attributes, behaviors, and interactions. Alternatively, the research based on network models employs the Barab & aacute;si-Albert (BA) model, incorporating factors such as node distance, fitness, and edge weights, or uses hypergraph models to construct supply chain networks. Next, this paper summarizes the research on the structural properties of supply chain networks, focusing on their topological structure, key node identification, community detection, and vulnerability analysis. Relevant studies explore the topological structure of supply chain networks, uncovering the connections between nodes, hierarchical structures, and information flow paths between nodes. By analyzing factors such as node centrality, connection strength, and flow paths, the key nodes within the supply chain network are identified. Community detection algorithms are used to investigate the relationships between different structural parts and to analyze the positional structure, cooperative relationships, and interaction modes. Furthermore, quantitative evaluation indicators and management strategies are proposed for the robustness and resilience of supply chain networks. Further research has explored the management characteristics of supply chain networks, including risk propagation and competition game. Relevant studies have employed three main methods-epidemic model, cascading failure model, and agent-based model-to construct risk propagation models, simulate the spread of disruption risks, and analyze the mechanisms, paths, and extent of risk propagation within supply chain networks. These studies provide valuable insights for developing risk prevention and mitigation strategies. In addition, the game theory has been used to investigate the cooperative competition, resource allocation, and strategy selection among enterprises within the supply chain network. This paper reviews the research contents and emerging trends in supply chain studies based on complex network methods. It demonstrates the effectiveness and applicability of complex network theory in supply chain network research, discusses key challenges, such as how to obtain accurate, comprehensive, and timely supply chain network data, proposes standardized data processing methods, and determines the attributes of supply chain network nodes and the strength of their relationships. Furthermore, research on the structure of supply chain network has not yet fully captured the unique characteristics of supply chain networks. Existing models and methods for vulnerability assessment often fail to consider the dynamic and nonlinear characteristics of supply chain networks. Research on risk propagation in supply chains has not sufficiently integrated empirical data, overlooking the diversity of risk sources and the complexity of propagation paths. The asymmetry and incompleteness of information in supply chain networks, as well as multiple sources of uncertainty, make the prediction and analysis of multiparty decision-making behavior more complex. This paper also outlines several key directions for future research. One direction involves using high-order network theory to model interactions among multiple nodes and to describe the dynamics of multi-agent interactions within supply chain networks. Furthermore, integrating long short-term memory (LSTM) methods to process long-term dependence in time-series data can enhance the analysis of network structure evolution and improve the prediction of future states. The application of reinforcement learning algorithms can also adaptively adjust network structures and strategies according to changing conditions and demands, thereby improving the adaptability and response speed of supply chain networks in emergency situations. This paper aims to provide valuable insights for supplying chain research and promoting the development and application of complex network methods in this field.",2024
Leveraging Big Data for SME Credit Risk Assessment: A Novel BP-KMV and GARCH Integration,"This study addresses the critical limitations in existing credit risk assessment models for unlisted technology small and medium enterprises (SMEs), which are crucial drivers of innovation and economic growth yet often hindered by traditional financing models' inadequacies. Recognizing the pivotal role of advanced analytical techniques in navigating these challenges, we propose an optimized early warning system, integrating the BP-KMV model with the GARCH (1,1) model and the Ordinary Least Squares (OLS) method. This innovative approach adapts to the volatility of technology ventures and incorporates alternative data sources, such as intellectual property and R&D expenditures, offering a holistic view of an SME's creditworthiness. Empirical validation on data from 525 listed and 150 unlisted technology SMEs demonstrates the model's superior predictive accuracy and early warning capabilities compared to traditional methodologies. Our findings reveal a nuanced understanding of credit risk in the technology sector, emphasizing the importance of dynamic, data-driven models in aligning financial support with innovative enterprises' growth trajectories. This research contributes to the knowledge economy by highlighting the synergies between technological advancements and financial innovation, paving the way for more informed decision-making by governments and banks to foster a thriving ecosystem for technology-driven SMEs.",2024
"IoT Identity Management Systems: The State-of-the-Art, Challenges and a Novel Architecture","The Internet of Things (IoT) is a technology paradigm that has transformed several domains including manufacturing, agriculture, healthcare, power grids, travel and retail. However, the growth of this interconnected world of IoT devices with their services is not without consequences, including identity-related security challenges. Security threats to identities can be vulnerabilities, misconfigurations, insecure credential storage, credential theft and social engineering. The range of different techniques that attackers use to get access to users, devices and other resources lead to serious consequences from the loss of an individual's identity to the sensitive and financial data of institutions. Thus, implementing a robust and secure identity management system (IDMS) is critical in achieving an overall secure IoT environment. Approaches for strong identity management do exist, however, they carry some deficiencies making them inadequate to address the current identity-related security challenges of IoT. These challenges include failure to provide an all-in-one decentralized IDMS inclusive of profiling (registration of entity's attributes) and identification, authentication, identity-related attack risk analysis, and trust establishment mechanisms. The purpose of this work is to investigate existing IDMS and their limitations and propose a novel architecture featuring decentralization, trust, cross-platform, and identity-related attack risk-aware mechanisms with the help of deep learning, trust, and distributed ledger technologies. The proposed IDMS architecture is also compared with existing solutions using qualitative features like availability, trust establishment, attack risk-aware capability, robustness, and cross-platform functionality.",2024
The Role of IT Governance in the Integration of AI in Accounting and Auditing Operations,"IT governance is a framework that manages the efficient use of information technology within an organization, focusing on strategic alignment, risk management, resource management, performance measurement, compliance, and value delivery. This study investigates the role of IT governance in integrating artificial intelligence (AI) in accounting and auditing operations. Data were collected from 228 participants from Saudi Arabia using a combination of convenience sampling and snowball sampling methods. The collected data were then analyzed using structural equation modeling. Unexpectedly, the results demonstrate that AI, big data analytics, cloud computing, and deep learning technologies significantly enhance accounting and auditing functions' efficiency and decision-making capabilities, leading to improved financial reporting and audit processes. The results highlight that IT governance plays a crucial role in managing the complexities of AI integration, aligning business strategies with AI-enabled technologies, and facilitating these advancements. This research fills a gap in previous research and adds significantly to the academic literature by improving the understanding of integrating AI into accounting and auditing processes. It builds on existing theoretical frameworks by investigating the role of IT governance in promoting AI adoption. The findings provide valuable insights for accounting and auditing experts, IT specialists, and organizational leaders. The study provides practical insights on deploying AI-driven technology in organizations to enhance auditing procedures and financial reporting. In a societal context, it highlights the broader implications of AI on transparency, accountability, and trust in financial reporting. Finally, the study offers practitioners, policymakers, and scholars valuable insights on leveraging AI advancements to optimize accounting and auditing operations. It highlights IT governance as an essential tool for effectively integrating AI technologies in accounting and auditing operations. However, successful implementation encounters significant organizational challenges like organizational support, training, data sovereignty, and regulatory compliance.",2024
Investigation of changes in the cumulative number of magnetic anomalies before and after earthquakes using satellite data,"Iran is always at risk of destructive earthquakes due to its location on the Alpine-Himalayan seismic belt. Many significant earthquakes have occurred there so far, which have caused a lot of financial and human losses. The plateau consists of a composite system of collision-oblique transpressive fold-and-thrust mountain belts with active reverse and strike-slip faulting, range-and-basin terrains, active subduction zones, recent volcanic activity, variable crust thicknesses and rigidity, and relatively stable aseismic blocks of different dimensions with low. topographic relief and nearly flat areas., as a result, attention to earthquakes and research in its various fields is necessary and inevitable in Iran. This study investigated Iran's earthquakes from 2014 to 2021 with a magnitude above 5.5. A total of 30 earthquakes were investigated, of which 21 cases were considered due to solar activities and the simultaneous occurrence of some earthquakes. For this purpose, Swarm Alpha and Swarm Charlie satellite data belonging to the European Space Agency have been used vector magnetic field of all the paths that passed near the place of the earthquake was used between two months before the occurrence and one month after it. First, by performing the first stage of processing for the paths that are close to the earthquake in terms of time, the vivid anomalies caused by the event are identified in the y component of the magnetic field. Then, using these anomalies, a threshold value for the standard deviation is defined for each event so that the anomalies with a higher standard deviation than this threshold value are examined and analyzed. Finally, the occurrence of the studied earthquakes was predicted by fitting the sigmoid function to the cumulative number of anomalies. Because the sigmoid function is not a dynamic function, at the same time, a cubic function has been used to estimate the critical time of the system so that when the sigmoid function cannot fit the data, the cubic function can do this. A first-order curve has also been used to show the proper fit of the data with the sigmoid and cubic functions. And also, C-factor has been used to show the strong compatibility of sigmoid and cubic functions with the cumulative number of anomalies. In the last stage, an analysis has been done under the title of Confutation analysis in such a way that the said algorithm is applied to the areas where the earthquake did not occur, and it is expected that the cumulative number of anomalies drawn, will be closer to the linear state than when the earthquake occurred. Using the existing database, 90% of the occurrence of earthquakes studied in this study, pre-indication abnormalities are observed a few hours to a month before the incidence of earthquakes. Also, a Confutation analysis was performed on three cases of earthquakes to show that the obtained results were not random and the change in the cumulative number of magnetic anomalies could be caused by the earthquake. (c) 2024 COSPAR. Published by Elsevier B.V. All rights are reserved, including those for text and data mining, AI training, and similar technologies.",2025
Investigating barriers & facilitators for the successful implementation of the BP@home initiative in London: Primary care perspectives,"Background The COVID-19 pandemic led to the implementation of a national policy of shielding to safeguard clinically vulnerable patients. To ensure consistent care for high-risk patients with hypertension, NHS England introduced the BP@home initiative to enable patients to self-monitor their blood pressure by providing them with blood pressure monitors. This study aimed to identify barriers and facilitators to the implementation of the initiative based on the experience and perspectives of programme managers and healthcare professionals (HCPs) involved in its implementation in London.Methods and findings We conducted five semi-structured focus groups and one individual interview with a total of 20 healthcare professionals involved at different levels and stages in the BP@home initiative across four of the five London Integrated Care Systems (ICSs). All focus groups and interviews were audio-recorded, transcribed and analysed thematically following the Framework Method. Respondents reported being challenged by the lack of adequate IT, human and financial resources to support the substantial additional workload associated with the programme. These issues resulted in and reinforced the differential engagement capacities of PCNs, practices and patients, thus raising equity concerns among respondents. However respondents also identified several facilitators, including the integration of the eligibility criteria into the electronic health record (EHR), especially when combined with the adoption of practice-specific, pragmatic and opportunistic approaches to the onboarding of patients. Respondents also recommended the provision of blood pressure monitors (BPMs) on prescription, additional funding and training based on needs assessment, the incorporation of BP@home into daily practice and simplification of IT tools, and finally the adoption of a person-centred care approach. Contextualised using the second iteration of the Consolidated Framework for Implementation Research (CFIR), these findings support key evidence-based recommendations to help streamline the implementation of the BP@home initiative in London's primary care setting.Conclusions Programs such as BP@Home are likely to become more common in primary care. To successfully support HCPs' aim to care for their hypertensive patients, their implementation must be accompanied by additional financial, human and training resources, as well as supported task-shifting for capacity building. Future studies should explore the perspectives of HCPs based in other parts of the UK as well as patients' experiences with remote monitoring of blood pressure.",2024
Mean Absolute Directional Loss as a new loss function for machine learning problems in algorithmic investment strategies,"This paper investigates the issue of an adequate loss function in the optimization of machine learning models used in the forecasting of financial time series for the purpose of algorithmic investment strategies (AIS) construction. We propose the Mean Absolute Directional Loss (MADL) function, solving important problems of classical forecast error functions in extracting information from forecasts to create efficient buy/sell signals in algorithmic investment strategies. MADL places appropriate emphasis not only on the quality of the point forecast but also on its impact on the rate of achievement by the investment system based on it. The introduction and detailed description of the theoretical properties of this new MADL loss function are our main contributions to the literature. In the empirical part of the study, based on the data from two different asset classes (cryptocurrencies: Bitcoin and commodities: Crude Oil), we show that our new loss function enables us to select better hyperparameters for the LSTM model and obtain more efficient investment strategies, with regard to risk-adjusted return metrics on the out-of-sample data.",2024
Credit Management Based on Improved BP Neural Network,"Credit management is a key factor in reducing credit risk of companies. The performance of credit departments in good standing guarantees stability and profitability of small and medium-sized loan companies. However, loan companies encounter credit risk more and more seriously. Credit managers cannot do very well on supporting the credit decision because credit risk factors are complicated and diversified. Besides, there are different credit risk factors in different cities in terms of their economic development, consumption levels, and competition in the market etc. Loan companies in Ji'nan City, Shandong Province are regarded as critical and competitive financial organizations that make contribution to the economic development of Ji'nan City and control loan risk. This paper analyses the original customer data from a company of Ji'nan City and then predicts overdue status of customers with improved Back Propagation algorithm (improved BP algorithm) by adding momentum coefficient and learning rate, which makes contribution to reducing credit risk. The overall accuracy rate of training has reached 90% and its testing accuracy rate has reached 80%, which contributes to any credit decision objectively instead of the subjective shortage of credit managers in analysis, judgment, and not accuracy.",2016
Carbon price forecasting based on news text mining considering investor attention,"The carbon market relies on market-oriented financial means to solve the problem of carbon emissions. An effective carbon pricing mechanism can improve market efficiency and better serve the implementation of carbon emission reduction. The limited attention of investors increases the uncertainty of carbon market volatility and is an important exogenous factor affecting the price of carbon assets. This study innovatively mines keywords of investor attention on the carbon market through online news texts and eliminates those that have no causal link to carbon price forecasting in order to reduce noise. The results show that the keyword extraction method based on news text mining is better than that of nontext mining. Meanwhile, a carbon price forecasting model based on a particle-swarm-optimization LSTM model structure is constructed, and the forecasting accuracy is improved. The results show that carbon market investors pay more attention to carbon quota supply and demand, carbon prices, environmental change, and the energy market. The results have important implications for the development of effective carbon market policies and risk management.",2023
The integrated methodology of rough set theory and support vector machine for credit risk assessment,"According to the current situation of the credit risk assessment in commercial banks, a hybrid intelligent system is applied to the study of credit risk assessment in commercial banks, combining rough set approach and support vector machine (SVM). The information table can be reduced, which showed that the number of evaluation criteria such as financial ratios and qualitative variables was reduced with no information loss through rough set approach. And then, the reduced information table is used to develop classification rules and train SVM The rationality of hybrid system is using rules developed by rough sets and SVM The former is for an object that matches any of the rules and the latter is for one that does not match any of them. The effectiveness of the methodology was verified by experiments comparing traditional discriminant analysis model and BP neural networks with our approach.",2006
Coastal urban flood risk management: Challenges and opportunities - A systematic review,"Generational mechanisms and spatio-temporal evolution patterns of coastal urban flood risk involve complex interactions between climate change, sea level rise and human-induced factors, necessitating integrated adaptive flood management strategies to mitigate evolving vulnerabilities. This systematic review offers a thorough assessment of the challenges and strategic opportunities for sustainable adaptation in managing flood risk in coastal urban areas. It integrates emerging innovative technologies and financial solutions to identify promising approaches to implement mitigation strategies and improve coastal urban flood resilience. Enhancing governance and policy frameworks is crucial for the successful implementation of coastal urban flood risk management (CUFRM) plans. An innovative participatory planning framework is developed to promote flood management practices which are socially inclusive and equitable. Funding for green infrastructure and nature-based solutions and the strategic use of public-private partnerships are effective methods for advancing sustainable flood risk management (FRM). The advancements in emerging technologies, such as artificial intelligence (AI), machine learning (ML), deep learning (DL), social media and digital twin technologies, provide dynamic and collaborative platforms for simulating flood scenarios and have potential to significantly improve CUFRM practices. In the end, a cross-country comparison of current practices in Australia, China, the Netherlands, the UK and the USA reveals a diverse range of approaches and valuable insights derived from regional experiences. The review provides a comprehensive analysis for researchers, policymakers and practitioners aiming to improve flood resilience in coastal metropolitan regions by learning from effective UFRM approaches that enhance governance structures, infrastructure resilience and funding mechanisms.",2024
The preventing recurrent vascular events and neurological worsening through intensive organized case-management (PREVENTION) trial protocol [clinicaltrials.gov identifier: NCT00931788],"Background: Survivors of transient ischemic attack (TIA) or stroke are at high risk for recurrent vascular events and aggressive treatment of vascular risk factors can reduce this risk. However, vascular risk factors, especially hypertension and high cholesterol, are not managed optimally even in those patients seen in specialized clinics. This gap between the evidence for secondary prevention of stroke and the clinical reality leads to suboptimal patient outcomes. In this study, we will be testing a pharmacist case manager for delivery of stroke prevention services. We hypothesize this new structure will improve processes of care which in turn should lead to improved outcomes. Methods: We will conduct a prospective, randomized, controlled open-label with blinded ascertainment of outcomes (PROBE) trial. Treatment allocation will be concealed from the study personnel, and all outcomes will be collected in an independent and blinded manner by observers who have not been involved in the patient's clinical care or trial participation and who are masked to baseline measurements. Patients will be randomized to control or a pharmacist case manager treating vascular risk factors to guideline-recommended target levels. Eligible patients will include all adult patients seen at stroke prevention clinics in Edmonton, Alberta after an ischemic stroke or TIA who have uncontrolled hypertension (defined as systolic blood pressure (BP) > 140 mm Hg) or dyslipidemia (fasting LDL-cholesterol > 2.00 mmol/L) and who are not cognitively impaired or institutionalized. The primary outcome will be the proportion of subjects who attain 'optimal BP and lipid control'(defined as systolic BP < 140 mm Hg and fasting LDL cholesterol < 2.0 mmol/L) at six months compared to baseline; 12-month data will also be collected for analyses of sustainability of any effects. A variety of secondary outcomes related to vascular risk and health-related quality of life will also be collected. Conclusions: Nearly one-quarter of those who survive a TIA or minor stroke suffer another vascular event within a year. If our intervention improves the provision of secondary prevention therapies in these patients, the clinical (and financial) implications will be enormous.",2010
Credit rating of family farms based on optimal assignment of credit indicators by BP neural network,"PurposeIn order to solve the problems of difficulty in lending to family farms and the lack of credit products, it is necessary to classify the credit rating of family farms and determine the credit risk level of different family farms, so that agriculture-related financial institutions can implement different credit strategies.Design/methodology/approachA method based on BP neural network model is proposed to measure the weights of credit evaluation indicators of family farms and the linear weighting method and the fuzzy comprehensive evaluation method are used to establish the final credit rating system for family farms.FindingsThe empirical results show that the majority of the 246 family farms in Inner Mongolia have a low CC rating.Originality/valueBy constructing a sound and reasonable credit rating system for family farms, thus providing an objective evaluation of the credit rating of family farms, the credit granting status of agriculture-related financial institutions will be adapted to the reasonable loan demand status of family farm owners, and the quality and level of their credit approval will be continuously enhanced.",2024
DeepVol: volatility forecasting from high-frequency data with dilated causal convolutions,"Volatility forecasts play a central role among equity risk measures. Besides traditional statistical models, modern forecasting techniques based on machine learning can be employed when treating volatility as a univariate, daily time-series. Moreover, econometric studies have shown that increasing the number of daily observations with high-frequency intraday data helps to improve volatility predictions. In this work, we propose DeepVol, a model based on Dilated Causal Convolutions that uses high-frequency data to forecast day-ahead volatility. Our empirical findings demonstrate that dilated convolutional filters are highly effective at extracting relevant information from intraday financial time-series, proving that this architecture can effectively leverage predictive information present in high-frequency data that would otherwise be lost if realised measures were precomputed. Simultaneously, dilated convolutional filters trained with intraday high-frequency data help us avoid the limitations of models that use daily data, such as model misspecification or manually designed handcrafted features, whose devise involves optimising the trade-off between accuracy and computational efficiency and makes models prone to lack of adaptation into changing circumstances. In our analysis, we use two years of intraday data from NASDAQ-100 to evaluate the performance of DeepVol. Our empirical results suggest that the proposed deep learning-based approach effectively learns global features from high-frequency data, resulting in more accurate predictions compared to traditional methodologies and producing more accurate risk measures.",2024
The design and implementation of a deep reinforcement learning and quantum finance theory-inspired portfolio investment management system,"Deep Learning (DL) and Reinforcement Learning (RL) are common machine learning techniques used in automatic trading, notwithstanding, RL is deficient in portfolio investment in terms of funds distribution, potential loss control, profit maximization, and examine undetected environment. This paper proposed an intelligent Quantum Finance-based portfolio investment system (QFPIS), which is a combination of Deep Reinforcement Learning (DRL) with Quantum Finance Theory (QFT) to improve these conditions. There are two major agents embodied in the system: 1) a trading agent based on Deep Deterministic Policy Gradient algorithm to determine investment weighting for different financial products by generating continuous actions; 2) an intelligent agent based on Policy Gradient (PG) algorithm to enact risk control and determine whether to hold current orders by producing discrete actions depend on daily Quantum Price Levels (QPLs). The advantages of incorporating a two agents system design are to devise stable and realistic fund allocation for different products in portfolio. Experiment results had shown robustness, flexibility, and profitability on a series of forex products and the U.S. stocks in the back-testing phase as compared to other RL trading systems.",2024
Analysis and Evaluation of Various Fraud Detection Methods for Electronic Payment Cards Transactions in Big Data,"In today's digital world, the vast volume of data generated, often referred to as big data, presents both challenges and opportunities. One significant challenge is the risk of fraud in electronic cash transactions. This study examines and compares 20 common online fraud detection methods within the context of big data, evaluating them based on 11 criteria: type of learning, speed, accuracy, cost (time), complexity, interpretability, scalability, robustness, flexibility, and temporal and spatial complexity. The evaluation highlights the performance of each method against various types of online cash fraud, including identity theft, card skimming, phishing, malware, money laundering, account takeover, refund fraud, and friendly fraud. Performance scores, derived from real-world data and simulations, indicate the effectiveness of each method in identifying and countering fraud in a big data environment. Our findings show that deep learning methods and artificial neural networks outperform other methods in most fraud scenarios, while general rule-based and inferential methods are less effective. This research provides valuable insights for financial institutions, e-commerce platforms, and other online services to enhance their fraud detection capabilities and protect sensitive customer data in the era of big data.",2024
Detection of Distributed Denial of Service (DDoS) Attacks in IOT Based Monitoring System of Banking Sector Using Machine Learning Models,"Cyberattacks can trigger power outages, military equipment problems, and breaches of confidential information, i.e., medical records could be stolen if they get into the wrong hands. Due to the great monetary worth of the data it holds, the banking industry is particularly at risk. As the number of digital footprints of banks grows, so does the attack surface that hackers can exploit. This paper aims to detect distributed denial-of-service (DDOS) attacks on financial organizations using the Banking Dataset. In this research, we have used multiple classification models for the prediction of DDOS attacks. We have added some complexity to the architecture of generic models to enable them to perform well. We have further applied a support vector machine (SVM), K-Nearest Neighbors (KNN) and random forest algorithms (RF). The SVM shows an accuracy of 99.5%, while KNN and RF scored an accuracy of 97.5% and 98.74%, respectively, for the detection of (DDoS) attacks. Upon comparison, it has been concluded that the SVM is more robust as compared to KNN, RF and existing machine learning (ML) and deep learning (DL) approaches.",2022
Privacy-Constrained Biometric System for Non-Cooperative Users,"With the consolidation of the new data protection regulation paradigm for each individual within the European Union (EU), major biometric technologies are now confronted with many concerns related to user privacy in biometric deployments. When individual biometrics are disclosed, the sensitive information about his/her personal data such as financial or health are at high risk of being misused or compromised. This issue can be escalated considerably over scenarios of non-cooperative users, such as elderly people residing in care homes, with their inability to interact conveniently and securely with the biometric system. The primary goal of this study is to design a novel database to investigate the problem of automatic people recognition under privacy constraints. To do so, the collected data-set contains the subject's hand and foot traits and excludes the face biometrics of individuals in order to protect their privacy. We carried out extensive simulations using different baseline methods, including deep learning. Simulation results show that, with the spatial features extracted from the subject sequence in both individual hand or foot videos, state-of-the-art deep models provide promising recognition performance.",2019
Performance Evaluation of You Only Look Once v4 in Road Anomaly Detection and Visual Simultaneous Localisation and Mapping for Autonomous Vehicles,"The proliferation of autonomous vehicles (AVs) emphasises the pressing need to navigate challenging road networks riddled with anomalies like unapproved speed bumps, potholes, and other hazardous conditions, particularly in low- and middle-income countries. These anomalies not only contribute to driving stress, vehicle damage, and financial implications for users but also elevate the risk of accidents. A significant hurdle for AV deployment is the vehicle's environmental awareness and the capacity to localise effectively without excessive dependence on pre-defined maps in dynamically evolving contexts. Addressing this overarching challenge, this paper introduces a specialised deep learning model, leveraging YOLO v4, which profiles road surfaces by pinpointing defects, demonstrating a mean average precision (mAP@0.5) of 95.34%. Concurrently, a comprehensive solution-RA-SLAM, which is an enhanced Visual Simultaneous Localisation and Mapping (V-SLAM) mechanism for road scene modeling, integrated with the YOLO v4 algorithm-was developed. This approach precisely detects road anomalies, further refining V-SLAM through a keypoint aggregation algorithm. Collectively, these advancements underscore the potential for a holistic integration into AV's intelligent navigation systems, ensuring safer and more efficient traversal across intricate road terrains.",2023
Development and Validation of a Deep Learning Algorithm for Differentiation of Choroidal Nevi from Small Melanoma in Fundus Photographs,"Purpose: To develop and validate a deep learning algorithm capable of differentiating small choroidal melanomas from nevi. Design: Retrospective multicenter cohort study. Participants: A total of 802 images from 688 patients diagnosed with choroidal nevi or melanoma. Methods: Wide field and standard field fundus photographs were collected from patients diagnosed with choroidal nevi or melanoma by ocular oncologists during clinical examinations. A lesion was classified as a nevus if it was followed for at least 5 years without being rediagnosed as melanoma. A neural network optimized for image classification was trained and validated on cohorts of 495 and 168 images and subsequently tested on independent sets of 86 and 53 images. Main Outcome Measures: Area under the curve (AUC) in receiver operating characteristic analysis for differentiating small choroidal melanomas from nevi. Results: The algorithm achieved an AUC of 0.88 in both test cohorts, outperforming ophthalmologists using the Mushroom shape, Orange pigment, Large size, Enlargement, and Subretinal fluid (AUC 0.77) and To Find Small Ocular Melanoma Using Helpful Hints Daily (AUC 0.67) risk factors (DeLong's test, P < 0.001). The algorithm performed equally well for wide field and standard field photos (AUC 0.89 for both when analyzed separately). Using an optimal operating point of 0.63 (on a scale from 0.00 to 1.00) determined from the training and validation datasets, the algorithm achieved 100% sensitivity and 74% specificity in the first test cohort (F-score 0.72), and 80% sensitivity and 81% specificity in the second (F-score 0.71), which consisted of images from external clinics nationwide. It outperformed 12 ophthalmologists in sensitivity (Manne-Whitney U, P = 0.006) but not specificity (P = 0.54). The algorithm showed higher sensitivity than both resident and consultant ophthalmologists (Dunn's test, P = 0.04 and P = 0.006, respectively) but not ocular oncologists (P > 0.99, all P values Bonferroni corrected). Conclusions: This study develops and validates a deep learning algorithm for differentiating small choroidal melanomas from nevi, matching or surpassing the discriminatory performance of experienced human ophthalmologists. Further research will aim to validate its utility in clinical settings. Financial Disclosure(s): Financial DisclosuresProprietary or commercial disclosure may be found in the Footnotes and Disclosures at the end of this article. (c) 2024 by the American Academy of Ophthalmology. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).",2025
Recognizing the pattern of beta coefficient based on rough sets and improved SVM,"Systematic risk (Beta) which is presented by beta is the avoidless risk on the stock market Beta is calculated by linear analysis between the prices of stocks and the security index of stock market However, many studies have showed there are stronger relationships between beta and financial ratios. Therefore, a hybrid intelligent system is applied to recognize the clusters of beta (systematic risk), combining rough set approach and improved SVM. We can get reduced information table with no information loss by rough set approach. And then, this reduced information is used to develop classification rules and train SVM. At the same time, in order to improve the general recognizing ability of SVM, we make use of the particle swarm algorithm to optimize the SVM, and obtain appropriate parameters. The rationale of our hybrid system is using rules developed by rough sets for an object that matches any of the rules and SVM for one that does not match any of them. The effectiveness of our methodology was verified by experiments comparing BP neural networks with our approach.",2007
Integrated production of whey protein concentrate and lactose derivatives: What is the best combination?,"In order to model and analyze the techno-economic feasibility of a whey processing unit for the production of whey protein concentrate (WPC) integrated with processing of lactose, the present study utilized the software SuperPro Designer (R) for modeling of the processes, including risk analysis and study of reduced pollution impacts. Six models were constructed for the production of WPC and processing of lactose, which were (1) WPC 34, (2) WPC 34 and lactose powder, (3) WPC 34 and hydrous ethanol fuel, (4) WPC 80, (5) WPC 80 and lactose powder, and (6) WPC 80 and hydrous ethanol fuel. The economic evaluation was performed by analysis of the Payback Period (PP), Net Present Value (NPV), Breakeven Point (BP) and Internal Rate of Return (IRR). Probability distributions obtained by fitting of historical data for whey prices and the final products were used to perform the risk analysis, submitted to a Monte Carlo simulation using the (R) Risk software. The project showed to be feasible due to the elevated IRR and NPV values, coupled with low BP and PP. When evaluating the individual production of ethanol, it was verified that the production cost of this product was superior to the sale price, making independent production of ethanol from lactose present in the whey uneconomical. Plants with production of lactose powder were more economically attractive and also presented greater reduction of Biochemical Oxygen Demand (BOO) and Chemical Oxygen Demand (COD). The financial indices suggested greater feasibility of WPC 80 compared to WPC 34. (C) 2015 Elsevier Ltd. All rights reserved.",2015
"Decomposing socioeconomic inequality in blood pressure and blood glucose testing: evidence from four districts in Kerala, India","Background Non-Communicable Diseases (NCDs) constitute a significant danger to the nation's public health system, both in terms of morbidity and mortality, as well as the financial burden they inflict. Kerala is undergoing an epidemiologic transition, which has significantly impacted the state's morbidity and mortality figures. For decades, the state has been putting in place myriad programs to reduce the burden of NCDs across population groups. Socioeconomic inequalities in NCD testing have been documented in India, although they are understudied in Kerala. The study aimed to estimate and characterize districtwise socioeconomic inequality in Blood Pressure (BP) and Blood Glucose (BG) testing. Methods A cross-sectional household survey was conducted between July-October 2019 in Kasaragod, Alappuzha, Kollam and Thiruvananthapuram districts of Kerala, India. A total of 6383 participants aged 30 years and above were interviewed using multistage random sampling. Descriptive statistics were derived district-wise. We computed ratios, differences, equiplots, and Erreygers concentration indices for each district to measure socioeconomic inequality in BP and BG testing. Erreygers decomposition techniques were used to estimate the relative contribution of covariates to socioeconomic inequality. Results There was a significant concentration of BP and BG testing favouring wealthier quintiles in Alappuzha, Kollam, and Thiruvananthapuram districts. The inequality in BP and BG testing was highest in Thiruvananthapuram (0.087 and 0.110), followed by Kollam (0.077 and 0.090), Alappuzha (0.083 and 0.073) and Kasaragod (0.026 and 0.056). Decomposition analysis revealed that wealth quintile and education contributed substantially to socioeconomic inequality in BP and BG testing in all four districts. It was also found that family history of NCDs significantly contributed to observed socioeconomic inequality in BP testing (29, 11, 16, and 27% in Kasaragod, Alappuzha, Kollam, and Thiruvananthapuram, respectively). Similarly, in BG testing, family history of NCDs substantially contributed to observed socioeconomic inequality, explaining 16-17% in Kasaragod, Alappuzha, Kollam, and Thiruvananthapuram respectively of the total inequality. Conclusion While the magnitude of socioeconomic inequality in NCD risk factor testing did not appear to be very high in four Kerala districts, although levels were statistically significant in three of them. Greater exploration is needed on how education and caste contribute to these inequalities and their relationship to NCD risk factors such as family history. From such analyses, we may be able to identify entry points to mitigate inequalities in testing access, as well as burden.",2022
Detecting Adversarial Attacks via Subset Scanning of Autoencoder Activations and Reconstruction Error,"Reliably detecting attacks in a given set of inputs is of high practical relevance because of the vulnerability of neural networks to adversarial examples. These altered inputs create a security risk in applications with real-world consequences, such as self-driving cars, robotics and financial services. We propose an unsupervised method for detecting adversarial attacks in inner layers of autoencoder (AE) networks by maximizing a non-parametric measure of anomalous node activations. Previous work in this space has shown AE networks can detect anomalous images by thresholding the reconstruction error produced by the final layer. Furthermore, other detection methods rely on data augmentation or specialized training techniques which must be asserted before training time. In contrast, we use subset scanning methods from the anomalous pattern detection domain to enhance detection power without labeled examples of the noise, retraining or data augmentation methods. In addition to an anomalous score our proposed method also returns the subset of nodes within the AE network that contributed to that score. This will allow future work to pivot from detection to visualisation and explainability. Our scanning approach shows consistently higher detection power than existing detection methods across several adversarial noise models and a wide range of perturbation strengths.",2020
The impact of psychological stress on blood pressure in middle school pupils and the role of other risk factors in its occurrence,"Purpose: Assessing the impact of stress on blood pressure in middle school children and of the socio-economic, familial, genetic, school environment and extracurricular risk factors that may influence this overstress. Methods: I have duplicately measured systolic and diastolic blood pressure at an interval of 5 minutes at least, during the first days after the holiday, during the educational classes for the normal values and during the evaluation of students' knowledge, i.e. before taking tests. Individual study was based on a questionnaire on the identity data, school, grade, address, age and occupation of parents, age and number of brothers, school starting age and schedule. Data on family environment focused on how to prepare homework, sleep duration, bedtimes, wakening-up hour in the morning, differentiated by curricular activity and practicing extracurricular physical activities. School environment targeted the average grade obtained in the semester previous to the investigation, most preferred and most disliked study discipline, activities during the holidays. Data were collected from 203 students from V - VIIIth grades from two schools of Sibiu city. Results: Systolic blood pressure (BP) showed an increase (p = 0.0000) from 100.67 mmHg to 112.48 mmHg during knowledge evaluation period, with a highly significant relation (r = 0.68). Diastolic BP increased from 57.71 mmHg to 64.56 mmHg during overstress, r = 0.62. Systolic BP response to stress was correlated with school starting age (r = 0.57). The waking-up time showed significant variances of basal BP (p = 0.0078) and after stress (p = 0.0227) in the schools pupils from one of the schools. The study of genetic factors represented by the current age of the parents showed that the age group of the father and mother did not cause significant variances of basal systolic BP and diastolic BP and during stress. Economic factors were analyzed based on parental occupation and number of siblings as indicators of the financial situation of the family. Maximum systolic BP values during knowledge evaluation were registered in the students having intellectual fathers (110 +/- 20), followed by those without employment (105 +/- 7) and the unemployed (116 +/- 12). Basal systolic BP increased (r = 0.231) with the average grade, variances (p = 0.033) being within physiological school age limits. Diastolic BP differences in relation to the average grade were preserved (p = 0.035) after stress. Conclusions: Psychological stress produced by evaluating school knowledge causes increased BP in normotensive subjects. Diastolic BP is in line with systolic BP after stress. Hemodynamic answer to stress is higher in the schoolchildren with extreme economic situations, expression of parental occupation.",2014
Duplex real-time PCR combined with melting curve analysis for rapid detection of Atlantic salmon (Salmo salar) and rainbow trout (Oncorhynchus mykiss),"Financial loss and health risk caused by the substitution with Salmo solar and Oncorhynchus mykiss have been widely reported around the world, highlighting the necessity to establish rapid and accurate methods for species identification. The aim of the present study was to develop a novel method for rapid identification of S. solar and O. mykiss based on duplex PCR assay (conventional and fluorescent). Specifically, after sequence alignment, specific primers for S. solar and O. mykiss based on the COI (cytochmme oxidase I) and cyt b (cytochrome b) genes were designed and the specificity was verified against 23 common fish species. Clear and distinguishable bands of the expected sizes of 108 bp, and 207 bp, as well as the melting peaks around 81.6 degrees C and 84.7 degrees C, were observed for S. solar, and O. mykiss, respectively. Moreover, the feasibility of melting curve analysis for detecting the adulteration of different amounts of O. mykiss with S.salar has also be confirmed. Therefore, the novel assay in the present study allows a fast and accurate identification of S. solar and O. mykiss in processed fish products.",2021
Transformer-Based Downside Risk Forecasting: A Data-Driven Approach with Realized Downward Semi-Variance,"Realized downward semi-variance (RDS) has been realized as a key indicator to measure the downside risk of asset prices, and the accurate prediction of RDS can effectively guide traders' investment behavior and avoid the impact of market fluctuations caused by price declines. In this paper, the RDS rolling prediction performance of the traditional econometric model, machine learning model, and deep learning model is discussed in combination with various relevant influencing factors, and the sensitivity analysis is further carried out with the rolling window length, prediction length, and a variety of evaluation methods. In addition, due to the characteristics of RDS, such as aggregation and jumping, this paper further discusses the robustness of the model under the impact of external events, the influence of emotional factors on the prediction accuracy of the model, and the results and analysis of the hybrid model. The empirical results show that (1) when the rolling window is set to 20, the overall prediction effect of the model in this paper is the best. Taking the Transformer model under SSE as an example, compared with the prediction results under the rolling window length of 5, 10, and 30, the RMSE improvement ratio reaches 24.69%, 15.90%, and 43.60%, respectively. (2) The multivariable Transformer model shows a better forecasting effect. Compared with traditional econometric, machine learning, and deep learning models, the average increase percentage of RMSE, MAE, MAPE, SMAPE, MBE, and SD indicators is 52.23%, 20.03%, 62.33%, 60.33%, 37.57%, and 18.70%, respectively. (3) In multi-step prediction scenarios, the DM test statistic of the Transformer model is significantly positive, and the prediction accuracy of the Transformer model remains stable as the number of prediction steps increases. (4) Under the impact of external events of COVID-19, the Transformer model has stability, and the addition of emotional factors can effectively improve the prediction accuracy. In addition, the model's prediction performance and generalization ability can be further improved by stacked prediction models. An in-depth study of RDS forecasting is of great value to capture the characteristics of downside risks, enrich the financial risk measurement system, and better evaluate potential losses.",2025
"Unraveling the Nexus between Sustainable Development, Bank Profitability, and Loan Loss Provisions in Vietnam: A Bayesian Vector Autoregression Perspective","Financial institutions play a crucial role in financing projects and initiatives that promote sustainable develop- ment (SD). However, banks are under increasing pressure to align with the United Nations' SD goals by divesting from high CO2-emitting industries and reallocating capital toward environmentally responsible investments. While this transition supports long-term sustainability, it can lead to short-term profitability challenges, as SD projects often involve higher risks, regulatory uncertainties, and lower immediate returns compared to traditional business activities. As a result, banks may need to adjust their loan loss provisions (LLP) to account for potential credit risks associated with these investments. This study investigates the impact of supporting SD goals on bank profitability (BP) and LLP in Vietnam from 2008 to 2019. To achieve this, we employ a Bayesian Vector Autoregression (BVAR) model, which is particularly useful in analyzing dynamic relationships, addressing heterogeneous variables, and managing small sample sizes. Our findings indicate that investing in SD projects initially reduces bank profitability due to increased costs and uncertainties, prompting banks to raise LLP. However, in the long run, such investments contribute to financial stability, enhance risk management, and strengthen the bank's overall reputation. By inte- grating SD principles into their investment strategies, banks can not only mitigate environmental and social risks but also create long-term value for stakeholders, reinforcing their credibility in an evolving global financial land- scape.",2025
MADESANT: malware detection and severity analysis in industrial environments,"Malware remains a persistent threat to industrial operations, causing disruptions and financial losses. Traditional malware detection approaches struggle with the increasing complexity of false positives and negatives. However, existing Intrusion Detection Systems (IDSs) often lack the capability to assess the severity of detected malware, crucial for effective threat mitigation. This paper presents a novel model, MAlware DEtection and Severity Analysis for eNcrypted Traffic (MADESANT), designed to detect and analyze malware severity in encrypted traffic data. MADESANT combines Deep Learning (DL)-based intrusion detection with Machine Learning (ML)-based severity analysis, specifically customized for the minutiae of IoT systems and assets. Notably, MADESANT introduces a cascading model integrating a Cascading Forward Back Propagation Neural Network (CFBPNN) with the J48 tree to systematically assess risk factors in network traffic. Our assessment, conducted on diverse encrypted datasets including UNSW-NB15, IoT23, and XIIoTID, highlights the remarkable efficacy of MADESANT. Impressively, it achieves a flawless 0% false positive rate in detecting binary attack instances, surpassing benchmarks set by conventional models. Additionally, MADESANT excels in accurately estimate malware severity, providing invaluable insights into the factors contributing to the risk. To further validate its efficiency, we compared MADESANT against prevalent Neural Network models like FeedForward and Recurrent Neural Networks, with MADESANT emerging as the superior choice. The experimentation encompasses both the entire dataset and subsets generated through meticulous risk factor analysis. These results underscore MADESANT's prowess in not only identifying malware but also in evaluating its potential impact, signifying a significant leap forward in industrial cybersecurity.",2024
Improving energy efficiency to control greenhouse gas emissions,"Manufacturing oil products to meet market demand patterns and quality requirements is highly energy intensive. To refine and produce 10 tonnes of products requires an energy consumption equivalent to 1 tonne of hydrocarbon fuel. 90% of this energy requirement is combustion of hydrocarbon fuels on the refinery site. These combustion processes release an average 2.5 tonnes carbon dioxide in producing 10 tonnes of products. Although BP Oil has achieved a one third reduction in energy consumption over the last 25 years, John Browne, BP CEO, has publicly stated that BP is committed to go further in improving energy efficiency and understanding how to control our emissions. Improving the energy efficiency of our operations makes good business sense as not only is it a contribution to our goal of no harm or damage to the natural environment but energy is the largest operating cost of the oil refining process, equivalent to approximately 40% of total operating costs. To deliver continuous improvement BP Manufacturing has established focused programmes to capture these opportunities based on a comprehensive and systematic approach to energy efficiency improvement with two major drivers: people and technology. Early, low cost gains come from focusing on the people issues. The way people do their job, the knowledge they have, the way they use that knowledge and their motivation can all significantly contribute to improved energy efficiency. BP has established site programmes which are based on personnel training, technology transfer, implementing best practices and procedures, establishing energy accountability at sites and appointing energy engineers. We expect this programme to deliver 1 - 3% improvement in energy efficiency. In addition energy technology can deliver low risk energy efficiency improvements. Much energy technology is well proven and readily available. The constraint to implementation is more often the provision of an adequate capital investment justification or funds availability. BP is establishing a culture where leading edge process design techniques, superior equipment technology, advanced control techniques and the full assessment of life cycle costs are all elements of justifying energy efficiency projects. We estimate that there is another 10% improvement in energy utilisation available from existing manufacturing plant through implementation of cost effective, proven technology and a motivated workforce and at least a further 30% from emerging lower energy intensity process technologies. Because of the large heat requirement oil refineries are ideal partners with power generation suppliers. Through our own investment and by smart financial and business arrangements with selected partners in the power sector, Combined Heat and Power systems in BP are increasingly contributing to mitigating global emissions. BP is also looking beyond these 'no risk' opportunities to specific projects addressing some longer term technological challenges which could potentially lead to even greater energy efficiency improvement and therefore contribution to carbon dioxide control.",1999
IMPROVING FORECASTING ACCURACY OF THE S&P500 INTRA-DAY PRICE DIRECTION USING BOTH WAVELET LOW AND HIGH FREQUENCY COEFFICIENTS,"Numerous research works have successfully applied the wavelet analysis for the decomposition and forecasting of financial data. Particularly, using the discrete wavelet transform (DWT) stock price time series were analyzed following a fixed sub-band coding scheme, which provides a low time resolution for low frequencies and a high time resolution for high frequencies. Following the standard approach found in the literature, only low frequency components were considered as main features to predict stock prices. However, this approach lacks of details about the generative process of the original data. In this paper, we rely on DWT high frequency sub-band to extract short interval hidden information for better classification of future Standard and Poors (S&P500) one minute ahead direction using artificial neural network trained with backpropagation algorithm. The simulation results show that our approach that uses both low (approximation) and high (detail) frequency coefficients provides better classification rates than the standard one. In addition, simulation results show that low frequency components are appropriate to detect future downshifts in S&P500, whilst our approach is suitable to predict future upwards. Thus, the standard approach provides valuable information for risk averse investors trading S&P500, and our approach that combines low and high frequency coefficients is strongly useful for aggressive investors seeking short-term profits when trading S&P500.",2014
CATE: Contrastive augmentation and tree-enhanced embedding for credit scoring,"Credit transactions are vital financial activities that yield substantial economic benefits. To further improve lending decisions, stakeholders require accurate and interpretable credit scoring methods. While the majority of previous studies have focused on the relationship between individual features and credit risk, only a few have investigated cross-features. Notably, cross -features can not only represent structured data effectively but also provide richer semantic information than individual features. Nevertheless, most previous methods for learning cross -feature effects from credit data have been implicit and unexplainable. This paper proposes a new credit scoring model based on contrastive augmentation and tree-enhanced embedding mechanisms, termed CATE. The proposed model automatically constructs explainable cross -features by using tree-based models to learn decision rules from the data. Moreover, the importance of each local cross-feature is then derived through an attention mechanism. Finally, the credit score of a user is evaluated using embedding vectors. Experimental results on 4 public datasets demonstrated the interpretability of our proposed method and outperformed 13 state-of-the-art benchmark methods in terms of performance.",2023
"Research on venture capital based on information entropy, BP neural network and CVaR model of digital currency in Yangtze River Delta","In 2008, the financial crisis caused by the SUBPRIME mortgage crisis and the development of information technology showed that people's life was gradually networked and digitized, and the digital currency represented by Bitcoin was generated. This paper discusses the investment opportunities and risks brought by the rise of digital currency and its importance to the development of One Belt and One Road. We propose a currency digital venture capital model based on information entropy, BP neural network and CVaR model. The model is divided into two parts. Part A is the research on the risk index model of digital currency based on the information entropy change of CVaR model. Part B is by BP neural network toolbox and CVaR model changing weights of digital currency risk index model, and analyse the development of digital currency weighted score to get the advantage of the Yangtze river delta region. It is of practical significance to build a venture capital model to predict the future development prospect of digital currency and get an investment model with more beneficial returns for investors to avoid risks. (C) 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0) Peer-review under responsibility of the scientific committee of the International Conference on Identification, Information and Knowledge in the internet of Things, 2020.",2021
Zero End-Digit Preference in Blood Pressure and Implications for Cardiovascular Disease Risk Prediction-A Study in New Zealand,"Background/Objectives: Blood pressure (BP) readings are often rounded to the nearest zero end-digit. Guidelines permit rounding to the closest 2 mmHg. This paper investigated the effect of rounding systolic blood pressure (SBP) values on the prediction of cardiovascular disease (CVD) risk among the New Zealand population. A total of 427,299 individuals received opportunistic cardiovascular disease risk assessments at primary care facilities in New Zealand. Method: A total of 292,122 SBP readings possessed a non-zero terminal digit. These were rounded to the nearest zero end-digit. A survival model estimating a 5-year CVD risk was applied to both datasets, i.e., with and without rounding. Hazard ratios and misclassification rates were analysed to emphasise the notable differences. Financial impact was assessed by examining healthcare expenditures. Results: In total, 32% of SBP values exhibited a terminal digit of zero, and 2.85% and 4.24% of men were misclassified as moderate and high risk, respectively, while approximately 3.21% of women were misclassified into the same risk categories. Likewise, 1.19% and 0.47% of men, as well as 0.62% and 0.20% of women, were misclassified into the low and moderate risk categories, respectively. Conclusions: Precisely measuring SBP is crucial in accurately assessing CVD risk and managing healthcare resources effectively.",2024
GRANDE : a neural model over directed multigraphs with application to anti-money laundering,"The application of graph representation learning techniques to the area of financial risk management (FRM) has attracted significant attention recently. However, directly modeling transaction networks using graph neural models remains challenging: Firstly, transaction networks are directed multigraphs by nature, which could not be properly handled with most of the current off-the-shelf graph neural networks (GNN). Secondly, a crucial problem in FRM scenarios like anti-money laundering (AML) is to identify risky transactions and is most naturally cast into an edge classification problem with rich edgelevel features, which are not fully exploited by the prevailing GNN design that follows node-centric message passing protocols. In this paper, we present a systematic investigation of design aspects of neural models over directed multigraphs and develop a novel GNN protocol that overcomes the above challenges via efficiently incorporating directional information, as well as proposing an enhancement that targets edge-related tasks using a novel message passing scheme over an extension of edge-tonode dual graph. A concrete GNN architecture called GRANDE is derived using the proposed protocol, with several further improvements and generalizations to temporal dynamic graphs. We apply the GRANDE model to both a real-world anti-money laundering task and public datasets. Experimental evaluations show the superiority of the proposed GRANDE architecture over recent state-of-the-art models on dynamic graph modeling and directed graph modeling.",2022
The underlying coherent behavior in intraday dynamic market equilibrium,"PurposeThis paper applies a volume-price probability wave differential equation to propose a conceptual theory and has innovative behavioral interpretations of intraday dynamic market equilibrium price, in which traders' momentum, reversal and interactive behaviors play roles.Design/methodology/approachThe authors select intraday cumulative trading volume distribution over price as revealed preferences. An equilibrium price is a price at which the corresponding cumulative trading volume achieves the maximum value. Based on the existence of the equilibrium in social finance, the authors propose a testable interacting traders' preference hypothesis without imposing the invariance criterion of rational choices. Interactively coherent preferences signify the choices subject to interactive invariance over price.FindingsThe authors find that interactive trading choices generate a constant frequency over price and intraday dynamic market equilibrium in a tug-of-war between momentum and reversal traders. The authors explain the market equilibrium through interactive, momentum and reversal traders. The intelligent interactive trading preferences are coherent and account for local dynamic market equilibrium, holistic dynamic market disequilibrium and the nonlinear and non-monotone V-shaped probability of selling over profit (BH curves).Research limitations/implicationsThe authors will understand investors' behaviors and dynamic markets through more empirical execution in the future, suggesting a unified theory available in social finance.Practical implicationsThe authors can apply the subjects' intelligent behaviors to artificial intelligence (AI), deep learning and financial technology.Social implicationsUnderstanding the behavior of interacting individuals or units will help social risk management beyond the frontiers of the financial market, such as governance in an organization, social violence in a country and COVID-19 pandemics worldwide.Originality/valueIt uncovers subjects' intelligent interactively trading behaviors.",2023
Deep learning based bi-level approach for proactive loan prospecting,"A fundamental component to managing a marketing campaign is identifying prospects and selection of leads. Current lead generation models focus on predicting the intention of a customer to purchase a product, however with financial products, particularly loans, this can be insufficient as there are many factors to consider, such as risk, utility, and financial maturity. Developing a marketing campaign for loan prospecting should consider not only customers who need a loan, but rather clients who need a loan and will also be approved. Otherwise, the marketing effort is deemed ineffective, if the lead cannot be converted into a sale. Although, a low response rate is expected for a marketing campaign for loans, we highlight a better approach in managing resources while maintaining a shortlist of high-quality leads. This manuscript introduces a bi-level approach to handle the complex nature of loan products. Two classifiers are built, one modelling loan intention and the other one modelling loan eligibility. We adopt convex combination to control weights of both problems, which in most cases results in an improved performance for identifying future successful loan applicants when compared to baseline models. Rank-based evaluation measures are also adopted to explore the performance of customer rankings. We find that soft classifiers, such as deep learning techniques, are ideal for ranking customers, achieving a superior performance when compared to other machine learning techniques. In addition, we conclude that an ideal cut-off for K customers is estimated to be between 20 to 25 customers, however our best model can maintain an Average Precision of greater than 0.85 when K approaches 50.",2021
An intelligent federated learning boosted cyberattack detection system for Denial-Of-Wallet attack using advanced heuristic search with multimodal approaches,"In the modern digital era, owing to technological progressions, the diversification and intensity of cyber-attacks have attained an extraordinary level. Unlike network users, intruders use technological developments and implement attacks to cause operational disruptions, data breaches, and financial losses. The Denial-of-Wallet (DoW) attack adapts the standard Denial-of-Service (DoS) attack. The principle of either attack is equivalent: to use the feedback capability to flood requirements to a service, making it unable to utilize it correctly. The DoW attack goal is to use the limitation of the calculating capability dealing with the cloud service, trying to cause direct financial loss. Federated Learning (FL) has been developed as a guaranteed solution for detecting DoW. This model deals with safety concerns, minimizes the data breach risk, and improves scalability. This manuscript presents a Cyberattack Detection Model for Denial-Of-Wallet Using Advanced Metaheuristic Optimization Algorithms in Federated Learning (CDMDoW-AMOAFL) model. The proposed CDMDoW-AMOAFL model aims to detect and mitigate malicious activities in a network. The z-score normalization is initially applied in the data normalization stage to transform input data into a beneficial format. Furthermore, the proposed CDMDoW-AMOAFL method utilizes the Harris hawk optimization (HHO) model for the feature selection process to identify and select the most relevant features from a dataset. For cyberattack detection, the ensemble models, namely the gated recurrent unit (GRU), temporal convolutional network (TCN), and convolutional autoencoder (CAE) models, are employed. Finally, the modified marine predator algorithm (MMPA) optimally adjusts ensemble models' hyperparameter values, resulting in better classification performance. A wide-ranging experimentation was performed to prove the performance of the CDMDoW-AMOAFL method under the DoW attack detection dataset. The performance validation of the CDMDoW-AMOAFL technique illustrated a superior accuracy value of 98.12% over existing models.",2025
Phishing and Fraudulent Email Detection through Transfer Learning using pretrained transformer models,"Phishing is a type of social engineering attack used by malicious users and cyber criminals for stealing sensitive information, installation of unwanted and malicious software, ransomware, and other advanced persistent threats on a victim's computer or mobile device. With the widespread adoption of the Internet, phishing attacks are on the rise and the recent work-from-home paradigm has increased the risk of phishing attacks targeted at large and small organizations alike. The consequences of phishing scams are often severe, ranging from financial loss, identity theft, data loss, and data theft. Though there are many ways of launching phishing attacks, phishing emails are one of the most commonly used techniques employed by cybercriminals. This is primarily because email addresses are easily obtainable and sending bulk emails is quite cheap, enabling attackers to send out a large number of emails hoping a few users will fall prey to the scam. Phishing emails are used for stealing sensitive information and credentials, delivering unwanted and malicious software, and delivering ransomware. This paper proposes a deep learning approach for detecting phishing and fraudulent emails. The proposed approach uses state-of-the-art pretrained transformer models and achieves very high accuracy, recall, and f1 score of 0.99.",2022
Is Equity Crowdfunding the Leapfrog to Companies' Success? Financial Performance in China,"As the fastest-growing crowdfunding model, equity crowdfunding (ECF) brings high returns and uncertainty. In this context, it is crucial to understand these crowdfunding projects' actual performance. Since ECF is currently in the early stage of integration, there are still a lot of risk issues, such as the uncertainty of equity structure, capital supervision, or project management. Therefore, this paper develops a new profitability indicator, return on registered capital, to test its impact on the ECF project's actual return. This paper studies which factors affect the financial performance of ECF projects through the traditional statistical model and a deep neural network (DNN) model. There is evidence that return on registered capital affects the actual return of the project. At the same time, the company's operating time and the number of employees had an unexpected effect on project performance. In addition, the recognition accuracy of the DNN model in this study exceeds 97%, which affirms the applicability of the DNN model in the analysis of ECF success factors. This paper also uses tenfold cross-validation to prove that deep learning has certain advantages in this topic's accuracy and generalization error. This study explores whether company representatives' gender and knowledge level affect project performance. The results will be described in detail in the paper.",2022
Deep neural network for prediction of time-history seismic response of bridges,"The collapse of civil infrastructure due to natural disasters results in financial losses and many casualties. In particular, the recent increase in earthquake activities has highlighted on the importance of assessing the seismic performance and predicting the seismic risk of a structure. However, the nonlinear behavior of a structure and the uncertainty in ground motion complicate the accurate seismic response prediction of a structure. Artificial intelligence can overcome these limitations to reasonably predict the nonlinear behavior of structures. In this study, a deep learning-based algorithm was developed to estimate the time-history seismic response of bridge structures. The proposed deep neural network was trained using structural and ground motion parameters. The performance of the seismic response prediction algorithm showed the similar phase and magnitude to those of the time-history analysis in a single-degree-of-freedom system that exhibits nonlinear behavior as a main structural element. Then, the proposed algorithm was expanded to predict the seismic response and fragility prediction of a bridge system. The proposed deep neural network reasonably predicted the nonlinear seismic behavior of piers and bearings for approximately 93% and 87% of the test dataset, respectively. The results of the study also demonstrated that the proposed algorithm can be utilized to assess the seismic fragility of bridge components and system.",2022
Exchange Rate Transaction of International Trade Goods Based on Fuzzy Granulation and Deep Learning,"The change of international trade goods exchange rate transaction has an impact on economic operations and economic stability. Therefore, an international trade goods exchange rate transaction based on fuzzy granulation and in-depth learning is proposed. Based on fuzzy information granulation and BP neural network, this paper analyzes the interest rate evaluation theory. For the future expectation of currency exchange rate, portfolio equilibrium determines the proportional relationship of each component in the portfolio and analyzes the impact of asset price and exchange rate change according to this relationship. Then, it points out the risk evaluation index system, calculates the risk degree of exchange rate transaction of international trade goods, and then evaluates the risk of exchange rate transaction of international trade goods. It completes the research on exchange rate transactions of international trade goods based on fuzzy granulation and in-depth learning. The experimental results show that excessive exchange rate fluctuation will bring the same proportion fluctuation to the asset price in the financial market, and the coordination between exchange rates and the coordination of exchange rate and asset price can promote the steady growth of national economy.",2021
A BLENDED SOFT-COMPUTING MODEL FOR STOCK- VALUE PREDICTION,"Stock investments play a crucial role in deciding the global economic growth of the country. Investors can optimize profit and avoid risk through accurate stock-value prediction models, which motivates researchers to work on various aspects of correlated features and predictive models for stock-value prediction. The existing stock-value prediction models used data like Twitter, microblogs, price history and Google trends. On the other hand, domain specific dictionary-based deep learning evolved as a competitive model for alternative models in stock value prediction. But, the accuracy of these models depends on the quality of the input, the correlation among the features and the correctness of the sentiment scores generated for the dictionary terms. Financial-news sentiment analysis for stock-value prediction with dictionary-based learning needs attention in improving the quality of the input and dictionary terms' sentiment score generation. The present research aims to develop a blended soft computing model for stock-value prediction (BSCM) with cooperative fusion and dictionary-based deep learning. In the current work, six Indian stocks that cover uptrend, sideways and downtrend characteristics are considered with stock-price histories and news headlines from 8th August 2016 to 31st March 2023, i.e., 2427 days. The number of records in price-history dataset is 14,562 and in the news headlines dataset is 46,213. The performance of the stock-value prediction can be improved by taking advantage of multi-source information and context-aware learning. The present research aims to achieve three objectives: 1. Applying cooperative fusion to combine the news headlines and price history of stocks collected from multiple sources to improve the quality of the input with correlated features. 2. Building a dictionary, FNSentiment, with a novel strategy. 3. Predicting stock values using FNSentiment and News Sentiment Prediction Model (NSPM) integration. In the experimentation, the proposed model outperformed the state-of-the-art models with an accuracy of 91.11%, RMSE of 10.35, MAPE of 0.02 and MAE of 2.74.",2023
Champion-challenger analysis for credit card fraud detection: Hybrid ensemble and deep learning,"Credit card fraud detection is an essential part of screening fraudulent transactions in advance of their authorization by card issuers. Although credit card frauds occur extremely infrequently, they result in huge losses as most fraudulent transactions have large values. An adequate detection of fraud allows investigators to take timely actions that can potentially prevent additional fraud or financial losses. In practice, however, investigators can only check a few alerts per day since the investigation process can be long and tedious. Thus, the primary goal of the fraud detection model is to return accurate alerts with fewer false alarms and missed frauds. Conventional fraud detection is mainly based on the hybrid ensemble of diverse machine learning models. Recently, several studies have compared deep learning and traditional machine learning models including ensemble. However, these studies used evaluation methods without considering that the real-world fraud detection system operated with the constraints: (i) the number of investigators who check the high-risk transactions from the data-driven scoring models are limited and (ii) the two types of misclassification, false alarms and missed frauds, have different costs. In this study, we conducted an in-depth comparison between the hybrid ensemble and deep learning method to determine whether or not to adopt the latter in our partner's system that currently operates with the hybrid ensemble model. To compare the two, we introduced the champion-challenger framework and the development process of the two models. After developing the two models, we evaluated them on large transaction data sets taken from our partner, a major card issuing company in South Korea. We used various practical evaluation metrics appropriate for this domain that has severe class and cost imbalances. Moreover, we deployed these models in a real-world fraud detection system to check the post-launch performance for one month. The challenger outperformed the champion on both in off-line and post-launch tests. (C) 2019 Elsevier Ltd. All rights reserved.",2019
Credit Card Fraud Detection Using Synthetic Minority Oversampling Technique and Deep Learning Technique,"recently, credit card frauds are raised to huge figures due to the reliance on online shopping by users. E-commerce and many other online sites have increased online payment modes which increased the risk of online fraud. There are many techniques have been used by researchers to protect against and detect credit card fraud. Different machine-learning algorithms were used to detect and analyze fraud in online transactions. However, existing solutions suffer from two main issues: class imbalance and insufficient feature extraction methods. Furthermore, extracting relevant features for fraud detection need human-based features engineering which time-consuming and complex problem. The aim of this study is to design and develop an effective credit card fraud detection model. The class imbalance problem has been addressed using a synthetic minority oversampling algorithm. Then, using the sequential deep learning techniques, a credit card detection model was designed and developed to utilize the data generated from SMOTE to improve the feature extraction and representation to solve the problem of insufficient features. The performance of the proposed model has been evaluated by comparing it with the related work in terms of accuracy, detection rate, and f-measure. Results show that the proposed model outperforms the existing state of the arts related models. It achieves a 0.99924 Accuracy, and 0.75976 F-measure. The proposed credit card fraud detection model, which addresses the class imbalance problem using synthetic minority oversampling and utilizes sequential deep learning techniques for improved feature extraction and representation, has shown to outperform existing models in terms of accuracy, detection rate, and f-measure. This could potentially have a significant impact on online markets as it may lead to a decrease in credit card fraud, which would increase consumer trust and confidence in online transactions. Additionally, the proposed model's improved feature extraction and representation may also lead to more efficient and effective fraud detection, potentially reducing costs for businesses and financial institutions.",2024
Machine Learning-Based Phishing Website Detection: A Comparative Analysis and Web Application Development,"Phishing, a cybercrime that uses sociotechnical and technical deception, targets identifiable information and financial credentials and poses a high risk according to the IBM Cost of a Data Breach Report 2022 which shows that on average precisely, the cost per transaction is $4.91 million, phishing attacks are on the rise, challenging the ability of traditional scanning systems to adapt to trends This study examines and it compares the effectiveness of three antiphishing methods: Autoencoder, Extreme Gradient Boost (XGBoost), and Random Forest (RF). Through feature selection and robust machine learning (ML) algorithms, including Random Forest achieving a remarkable 97.03% accuracy, the proposed solution integrates list-based methods with ML models for two-tier security. The wrapper method is employed to extract crucial features, facilitating precise phishing detection. Specific algorithms such as Random Forest and XGBoost are chosen for their proven effectiveness in handling complex data and class imbalances. However, potential limitations include the need for continuous adaptation to new phishing methods and exploring ensemble techniques for enhanced model robustness. Benchmarking against existing methods highlights the superiority of Random Forest in achieving balanced recall and precision. This study contributes to advancing phishing detection systems by leveraging machine learning and proposing strategies for improved performance and accuracy, which are then applied to a web application for countering phishing attacks.",2024
The analysis of influence mechanism for internet financial fraud identification and user behavior based on machine learning approaches,"The study is to explore the risks in the Internet finance and the factors affecting users' behavior under the background of big data. First, the risks of the Internet finance under the background of big data and the existing risk control modes are analyzed. Then, based on BP neural network (BPNN), an Internet financial fraud identification model is constructed, and corresponding touch rules are made. Its prediction performance is quantitatively compared with that of support vector machine and random forest algorithm. Finally, based on the structural equation model, the influence path of perceived security control on the Internet financial behavior is explored. The results show that, the applicants whose unit addresses are on blacklist have the highest touch fraud rate (14.16%). The precision rate (88.14%), accuracy rate (96.37%), recall rate (70.96%), and F-Score value (16.36) of the financial fraud identification model based on BPNN are the highest versus the other two algorithms, and the error detection rate (7.19%) is the lowest. The perceived security, identity authentication, non-repudiation of transactions, privacy protection, and control strength of data integrity positively affect users' trust, which further positively affects the attitude and intention of using the Internet finance, and the intention eventually affects users' behavior. Finally, some suggestions are put forward to improve the supervision of the Internet finance in China. To sum up, the Internet financial fraud identification model based on BPNN demonstrates satisfying performance and is worth of promotion. Additionally, the authentication technology, non-repudiation of transactions, privacy protection, data integrity, and users' sense of trust of the Internet finance have a significant impact on users' behavior.",2022
Retinopathy in Persons without Diabetes The Handan Eye Study,"Purpose: To describe the prevalence and associations of retinopathy in a population-based nondiabetic sample of rural Chinese. Design: Population-based cross-sectional study. Participants: We included 6830 Han Chinese aged >= 30 years from 13 villages of Yongnian County, Handan City, Hebei Province, China. Methods: All participants underwent a standardized interview and extensive examinations including retinal photography, measurement of blood pressure (BP) and fasting plasma glucose (FPG). Diabetes mellitus was defined as either FPG >= 7.0 mmol/l, use of diabetic medication or a physician diagnosis of diabetes. Photographic grading of retinopathy followed the modified Early Treatment Diabetic Retinopathy Study classification system. Logistic regression models were used to assess associations of retinopathy. Main Outcome Measures: Any retinopathy. Results: The prevalence of retinopathy among participants without diabetes was 13.6% (95% confidence interval [CI], 12.6-14.6%). The age and gender standardized prevalence of retinopathy in the Chinese adult population (aged 30+ years) without diabetes was estimated to be 12.1% (95% CI 11.1-12.9%). Independent risk factors associated with retinopathy were age (odds ratio [OR], 1.02; 95% CI 1.01-1.03 per year increase), male gender (male vs. female, OR 1.27; 95% CI 1.08-1.49), higher FPG (OR 1.30; 95% CI 1.11-1.53 per mmol/l increase), higher systolic BP (OR 1.15; 95% CI 1.05-1.27 per 10 mmHg increase) and higher diastolic BP (OR 1.16; 95% CI 1.09-1.22 per 10 mmHg increase). Conclusions: Retinopathy was common among rural Chinese adults without diabetes. Its association with FPG and BP suggests that early microvascular damage is occurring at high normal levels of blood glucose and BP. Financial Disclosure(s): The authors have no proprietary or commercial interest in any of the materials discussed in this article. Ophthalmology 2010; 117: 531-537 (C) 2010 by the American Academy of Ophthalmology.",2010
"RETRACTION: Risk Prediction and Response Strategies in Corporate Financial Management Based on Optimized BP Neural Network (Retraction of Vol 2021, art no 9973377, 2021)",,2023
'What matters is what works': Labour's journey from 'national superannuation' to 'personal accounts',"A key element of Labour's response to the Pensions Commission's recommendations for 'a new pension settlement for the twenty-first century' is a system of 'personal accounts' that will be administered and invested by the private sector. The contrast with 50 years ago, when Britain faced similar pressures, is striking. Then, Labour presented to the British public proposals for a state-run scheme embodying redistribution between higher and lower-paid workers and the accumulation of a very large fund that would be directly invested in stock markets by the state to promote faster growth. Today's scheme embodies neither redistribution nor collective control of the scheme's assets, and investment and risk-taking will be the responsibility of individuals rather than the state. This article explores the differences between Labour's proposals in 1957 and the scheme it proposes today. It considers what these differences tell us about the party's changing conception of social democracy, and highlights the irony that, with consumers' faith in financial markets shattered by the most severe financial crisis since 1929, New Labour's embrace of a private sector solution on the grounds that 'what matters is what works' now seems badly mistaken. British Politics (2010) 5, 41-64. doi:10.1057/bp.2009.27",2010
Volatility forecasting for interbank offered rate using grey extreme learning machine: The case of China,"Interbank Offered rate is the only direct market rate in China's currency market. Volatility forecasting of China Interbank Offered Rate (IBOR) has a very important theoretical and practical significance for financial asset pricing and financial risk measure or management. However, IBOR is a dynamics and non-steady time series whose developmental changes have stronger random fluctuation, so it is difficult to forecast the volatility of IBOR. This paper offers a hybrid algorithm using grey model and extreme learning machine (ELM) to forecast volatility of IBOR. The proposed algorithm is composed of three phases. In the first, grey model is used to deal with the original IBOR time series by accumulated generating operation (AGO) and weaken the stochastic volatility in original series. And then, a forecasting model is founded by using ELM to analyze the new IBOR series. Lastly, the predictive value of the original IBOR series can be obtained by inverse accumulated generating operation (IAGO). The new model is applied to forecasting Interbank Offered Rate of China. Compared with the forecasting results of BP and classical ELM, the new model is more efficient to forecasting short- and middle-term volatility of IBOR. (C) 2015 Elsevier Ltd. All rights reserved.",2016
Demographic and Metabolic Risk Factors Associated with Development of Diabetic Macular Edema among Persons with Diabetes Mellitus,"Purpose: Diabetic macular edema (DME), a leading cause of visual impairment, can occur regardless of diabetic retinopathy (DR) stage. Poor metabolic control is hypothesized to contribute to DME development, although large-scale studies have yet to identify such an association. This study aims to determine whether measurable markers of dysmetabolism are associated with DME development in persons with diabetes. Design: Retrospective cohort study. Participants: Using data from the Sight Outcomes Research Collaborative (SOURCE) repository, patients with diabetes mellitus and no preexisting DME were identified and followed over time to see what factors associated with DME development. Methods: Cox proportional hazard modeling was used to assess the relationship between demographic variables, diabetes type, smoking history, baseline DR status, blood pressure (BP), lipid profile, body mass index (BMI), hemoglobin A1C (HbA1C), and new onset of DME. Main Outcome Measures: Adjusted hazard ratio (HR) of developing DME with 95% confidence intervals (CIs). Results: Of 47 509 eligible patients from 10 SOURCE sites (mean age 63 +/- 12 years, 58% female sex, 48% White race), 3633 (7.6%) developed DME in the study period. The mean +/- standard deviation time to DME was 875 +/- 684 days (w2.4 years) with those with baseline nonproliferative DR (HR 3.67, 95% CI: 3.41-3.95) and proliferative DR (HR 5.19, 95% CI: 4.61-5.85) more likely to develop DME. There was no difference in DME risk between type 1 and type 2 patients; however, Black race was associated with a 40% increase in DME risk (HR 1.40, 95% CI: 1.30-1.51). Every 1 unit increase in HbA1C had a 15% increased risk of DME (HR 1.15, 95% CI: 1.13-1.17), and each 10 mmHg increase in systolic BP was associated with a 6% increased DME risk (HR 1.06, 95% CI: 1.02-1.09). No association was identified between DME development and BMI, triglyceride levels, or high-density lipoprotein levels. Conclusions: These findings suggest that in patients with diabetes modifiable risk factors such as elevated HbA1C and BP confer a higher risk of DME development; however, other modifiable systemic markers of dysmetabolism such as obesity and dyslipidemia did not. Further work is needed to identify the underlying contributions of race in DME. Financial Disclosure(s): Proprietary or commercial disclosure may be found in the Footnotes and Disclosures at the end of this article. (c) 2024 by the American Academy of Ophthalmology. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/ licenses/by-nc-nd/4.0/).",2024
Short term wind speed forecasting using artificial and wavelet neural networks with and without wavelet filtered data based on feature selections technique,"Wind speed forecasting plays a crucial role in enhancing the efficiency, reliability, and profitability of renewable energy systems. Accurate wind speed forecasting optimizes energy production and grid integration in renewable energy systems. It assists in maintenance scheduling, decision-making in energy markets, and supports risk management for financial planning. This paper investigates the difficult balance between model complexity and forecasting accuracy in wind speed forecasting using Artificial Neural Networks (ANNs) and Wavelet Neural Networks (WNNs). Employing a time series approach, the study develops models for 1-h-ahead wind speed forecasting, utilizing recent averaged data and exploiting correlations between consecutive wind speeds for improved short-term predictions. Models training involve the Backpropagation algorithm, with careful input variable selection to minimize errors. This study emphasizes that simpler ANN and WNN models can outperform complex ones and explores the effectiveness of wavelet filtering techniques and demonstrates the benefits of using wavelet filtering to enhance forecasting accuracy. The robustness of the developed models is validated through K-fold cross-validation, confirming the efficacy of the proposed models. Evaluation across two datasets demonstrates the superiority of the proposed models over the persistence model, with enhancements of 7-14% in RMSE. Additionally, the efficacy of wavelet transforms in enhancing forecasting accuracy compared to regular neural network predictions is emphasized, underscoring the effectiveness of wavelet filtering offering a strategic approach for optimizing wind power management in electrical grids.",2024
"Primary Prevention of Cardiovascular Disease at Community Clinics in the State of Sao Paulo, Brazil: Results from the Epidemiological Information Study of Communities","Background: Primary prevention of cardiovascular disease (CVD) remains a major challenge, especially in communities of low-and middle-income countries with poor medical assistance influenced by distinct local, financial, infrastructural, and resource -related factors. Objective: This a community-based study aimed to determine the proportion and prevalence of uncontrolled cardiovascular risk factors (CRF) in Brazilian communities. Methods: The EPICO study was an observational, cross-sectional, and community clinic-based study. Subjects were living in Brazilian communities and were of both sexes and & GE;18 years old, without a history of a stroke or myocardial infarction but presenting at least one of the following cardiovascular risk factors: hypertension, diabetes mellitus and hypercholesterolemia. The study was carried out in Brazil, including 322 basic health units (BHU) in 32 cities. Results: A total of 7,724 subjects with at least one CRF were evaluated, and one clinical visit was performed. Mean age was 59.2 years-old (53.7% were >60 years old). A total of 66.7% were women. Of the total, 96.2% had hypertension, 78.8% had diabetes mellitus type II, 71.1% had dyslipidemia, and 76.6% of patients were overweight/obese. Controlled hypertension (defined by <130/80 mmHg or <140/90 mmHg) was observed in 34.9% and 55.5% patients among respective criteria, the rates of controlled blood glucose in patients taking antidiabetic medications was 29.5%, and among those with documented dyslipidemia who received any lipid-lowering medication, only 13.9% had LDL-c on target. For patients presenting three CRF less than 1.9% had LDL-c < 100 mg/dL once their BP and blood glucose were on target. High education level as associated with blood pressure (BP) target of less than 130 / 80mm Hg. The glucose and LDL-c levels on target were associated with the presence of hypertension and diabetes mellitus. Conclusion: In Brazilian community clinics, regarding most patients in primary prevention, the CRF such as BP, blood glucose, and lipid levels are poorly controlled, with a majority of patients not achieving guidelines/recommendations.",2023
Secured Data Movement using Data Ring Fencing,"The exponential increase in data volume, the growing pervasiveness of digital technologies, and frequent data breaches have given rise to a broad range of privacy concerns. These concerns stem from the fact that data privacy measures have not kept pace with the scale and heterogeneity of sensitive data being produced, leading to unauthorized and unintended access, especially in multi-party scenarios. In the context of enterprises and individuals, data is one of the most important crown jewels to be protected. Current data protection frameworks struggle to regulate data sharing across multiple parties due to the existence of varying data access rules, and privacy and data governance policies across these institutions and individuals. The notion of Ring Fencing has been used in the financial sector to create a virtual barrier that isolates a portion of a company's financial assets to mitigate risk. In this paper, we propose to leverage this concept in order to enhance data security through the integration of a Data Ring Fencing architecture. Our Data Ring Fencing framework offers a multi-layered security paradigm that models privacy-preserving data-sharing agreements across multiple institutions. It achieves this goal by governing data privileges and regulating who can access what and for what purpose, and at what cost. Our data ring fencing framework supports three phases: Evaluate, Enforce, and Execute (referred to as the Three-E architecture). The Three-E architecture leverages deep learning-based models such as BERT + Multiclass LR for query classification and Transfer Learning on a sequence-to-sequence model for text-to-SQL generation. We demonstrate a practical application of the Three-E architecture based on Data Ring Fencing using a multi-institution instance from the healthcare domain. After conducting extensive experimentation on our custom datasets, our BERT + Multiclass LR model gave us the best performance achieving more than 99% accuracy.",2023
Forecasting stock market crisis events using deep and statistical machine learning techniques,"This work contributes to this ongoing debate on the nature and the characteristics of propagation channels of crash events in international stock markets. Specifically, we investigate transmission mechanisms across stock markets along with effects from bond and currency markets. Our approach comprises a solid forecasting mechanism of the probability of a stock market crash event in various time frames. The developed approach combines different machine learning algorithms which are presented with daily stock, bond and currency data from 39 countries that cover a large spectrum of economies. Specifically, we leverage the merits of a series of techniques including Classification Trees, Support Vector Machines, Random Forests, Neural Networks, Extreme Gradient Boosting, and Deep Neural Networks. To the best of our knowledge, this is the first time that Deep Learning and Boosting approaches are considered in the literature as a means of predicting stock market crisis episodes. The independent variables included in our data contain information regarding both the two fundamental linkage channels through which financial contagion can be initiated: returns and volatility. We apply a suite of machine learning algorithms for selecting the most relevant variables out of a large set of proposed ones. Finally, we employ bootstrap sampling for adjusting the imbalanced nature of the available fitting dataset. Our experimental results provide strong evidence that stock market crises tend to exhibit persistence. We also find significant evidence of interdependence and cross-contagion effects among stock, bond and currency markets. Finally, we show that the use of Deep Neural Networks significantly increases the classification accuracy, while offering a robust way to create a global systemic early warning tool that is more efficient and risk-sensitive than the currently established ones. Thus, central banks may use these tools to early adjust their monetary policy, so as to ensure financial stability. (C) 2018 Elsevier Ltd. All rights reserved.",2018
DGHNL: A new deep genetic hierarchical network of learners for prediction of credit scoring,"Credit scoring (CS) is an effective and crucial approach used for risk management in banks and other financial institutions. It provides appropriate guidance on granting loans and reduces risks in the financial area. Hence, companies and banks are trying to use novel automated solutions to deal with CS challenge to protect their own finances and customers. Nowadays, different machine learning (ML) and data mining (DM) algorithms have been used to improve various aspects of CS prediction. In this paper, we introduce a novel methodology, named Deep Genetic Hierarchical Network of Learners (DGHNL). The proposed methodology comprises different types of learners, including Support Vector Machines (SVM), k-Nearest Neighbors (kNN), Probabilistic Neural Networks (PNN), and fuzzy systems. The Statlog German (1000 instances) credit approval dataset available in the UCI machine learning repository is used to test the effectiveness of our model in the CS domain. Our DGHNL model encompasses five kinds of learners, two kinds of data normalization procedures, two extraction of features methods, three kinds of kernel functions, and three kinds of parameter optimizations. Furthermore, the model applies deep learning, ensemble learning, supervised training, layered learning, genetic selection of features (attributes), genetic optimization of learners parameters, and novel genetic layered training (selection of learners) approaches used along with the cross-validation (CV) train-ingtesting method (stratified 10-fold). The novelty of our approach relies on a proper flow and fusion of information (DGHNL structure and its optimization). We show that the proposed DGHNL model with a 29-layer structure is capable to achieve the prediction accuracy of 94.60% (54 errors per 1000 classifications) for the Statlog German credit approval data. It is the best prediction performance for this well-known credit scoring dataset, compared to the existing work in the field. (C) 2019 The Authors. Published by Elsevier Inc.",2020
???????Effects of Mobile-Based Financial Incentive Interventions for Adults at Risk of Developing Hypertension: Feasibility Randomized Controlled Trial,"Background: Hypertension is the leading modifiable risk factor for cardiovascular disease and mortality. Adopting lifestyle modifications, like increasing physical activity (PA), can be an effective strategy in blood pressure (BP) control, but many adults do not meet the PA guidelines. Financial incentive interventions have the power to increase PA levels but are often limited due to cost. Further, mobile health technologies can make these programs more scalable. There is a gap in the literature about the most feasible and effective financial incentive PA framework; thus, pay-per-minute (PPM) and self-funded investment incentive (SFII) frameworks were explored. Objective: The aims were to (1) determine the feasibility (recruitment, engagement, and acceptability) of an 8-week mobile-based PPM and SFII hypertension prevention PA program and (2) explore the effects of PPM and SFII interventions relative to a control on the PA levels, BP, and PA motivation. Methods: In total, 55 adults aged 40-65 years not meeting the Canadian PA guidelines were recruited from Facebook and randomized into the following groups: financial incentive groups, PPM or SFII, receiving up to CAD $20 each (at the time of writing: CAD $1=US $0.74), or a control group without financial incentive. PPM participants received CAD $0.02 for each minute of moderate-to-vigorous PA (MVPA) per week up to the PA guidelines and the SFII received CAD $2.50 for each week they met the PA guidelines. Feasibility outcome measures (recruitment, engagement, and acceptability) were assessed. Secondary outcomes included changes in PA outcomes (MVPA and daily steps) relative to baseline were compared among PPM, SFII, and control groups at 4 and 8 weeks using linear regressions. Changes in BP and relative autonomy index relative to baseline were compared among the groups at follow-up. Results: Participants were randomized to the PPM (n=19), SFII (n=18), or control (n=18) groups. The recruitment, retention rate, and engagement were 77%, 75%, and 65%, respectively. The intervention received overall positive feedback, with 90% of comments praising the intervention structure, financial incentive, and educational materials. Relative to the control at 4 weeks, the PPM and SFII arms increased their MVPA with medium effect (PPM vs control: eta(2)(p)=0.06, mean 117.8, SD 514 minutes; SFII vs control:eta(2)(p)=0.08, mean 145.3, SD 616 minutes). At 8 weeks, PPM maintained a small effect in MVPA relative to the control (eta(2)(p)=0.01, mean 22.8, SD 249 minutes) and SFII displayed a medium effect size (eta(2)(p)mean 113.8, SD 256 minutes). Small effects were observed for PPM and SFII relative to the control for systolic blood pressure (SBP) and diastolic blood pressure (DBP) (PPM:eta(2)(p)=0.12, Delta mean SBP 7.1, SD 23.61 mm Hg;eta(2)(p)=0.04, Delta mean DBP 3.5, SD 6.2 mm Hg; SFII:eta(2)(p)=0.01, Delta mean SBP -0.4, SD 1.4 mm Hg; eta(2)(p)=0.02,.mean DBP -2.3, SD 7.7 mm Hg) and relative autonomy index (PPM:eta(2)(p)=0.01; SFII: eta(2)(p)=0.03). Conclusions: The feasibility metrics and preliminary findings suggest that a future full-scale randomized controlled trial examining the efficacy of PPM and SFII relative to a control is feasible, and studies with longer duration are warranted.",2023
"Relationship Between Psychosocial Stress and Blood Pressure: The National Heart, Lung, and Blood Institute Family Heart Study","Introduction: Various domains of psychosocial stress have been significantly related to blood pressure. However, ambiguity is present in how these relationships are defined in the literature. Objective: To add to the existing literature and examine the relationship between psychosocial stress (financial strain and job strain) and other cofactors on blood pressure. Methods: This secondary analysis is designed to analyze the relationship between levels of job and financial stress and blood pressure outcomes among participants in the National Heart, Lung, and Blood Institute (NHLBI) Family Heart Study 2004-2008. The descriptive, cross-sectional design uses data from a subset of study participants, 350 White and 195 Black (n =545), 338 female (62%), and all aged 18-56 years. Psychosocial stress was measured using the Singh Stress Scale. Resting systolic (SBP) and diastolic (DBP) blood pressure values obtained on a stress reactivity protocol day in the primary study, as well as calculated mean arterial pressure (MAP) were used for this analysis. Multivariate linear regression analyses were used to explore the relationship between psychosocial stress and blood pressure. Results: In this young cohort, self-report of either financial strain or job strain was associated with lower blood pressure levels than those of participants who reported neither stressor. Differential sex and race effects appear to contribute to these results. Blood pressure levels were not significantly associated with self-report of both stressors. Conclusion: Understanding the effects of various forms of stress on blood pressure may inform more precise HTN risk-factor screening and interventions to improve BP management.",2022
An Unmet Need Meets an Untapped Resource: Pharmacist-Led Pathways for Hypertension Management for Emergency Department Patients,"Purpose of ReviewThe purpose of this review is to describe the role of the pharmacist in innovative pathways of care for hypertension (HTN) management for emergency department (ED) patients, particularly in under-resourced communities. Due to intersecting socioeconomic and personal health risk factors, these patients bear a disproportionate share of cardiovascular disease, yet often have limited access to high-quality primary care.Recent FindingsRecent meta-analyses demonstrate a clear advantage associated with pharmacist-physician collaborative models over traditional physician-only care in achieving blood pressure control. However, no prior study has evaluated use of pharmacist-led follow-up for ED patients with uncontrolled blood pressure (BP). Thus, we developed a pharmacist-driven transitional care clinic (TCC) that utilizes a collaborative practice agreement with ED physicians to improve HTN management for ED patients. We have successfully implemented the TCC in a high-volume urban ED and in a pilot study have shown clinically relevant BP reductions with our collaborative model.SummaryThe use of pharmacist-led follow-up for HTN management is highly effective. Novel programs such as our TCC, which extend the reach of such a model to ED patients, are promising, and future studies should focus on implementation through larger, multicenter, randomized trials. However, to be most effective, policy advocacy is needed to expand pharmacist prescriptive authority and develop innovative financial models to incentivize this practice.",2019
LexDeep: Hybrid Lexicon and Deep Learning Sentiment Analysis Using Twitter for Unemployment-Related Discussions During COVID-19,"The COVID-19 pandemic has spread globally, resulting in financial instability in many countries and reductions in the per capita gross domestic product. Sentiment analysis is a cost-effective method for acquiring sentiments based on household income loss, as expressed on social media. However, limited research has been conducted in this domain using the LexDeep approach. This study aimed to explore social trend analytics using LexDeep, which is a hybrid sentiment analysis technique, on Twitter to capture the risk of household income loss during the COVID-19 pandemic. First, tweet data were collected using Twint with relevant keywords before (9 March 2019 to 17 March 2020) and during (18 March 2020 to 21 August 2021) the pandemic. Subsequently, the tweets were annotated using VADER (lexiconbased) and fed into deep learning classifiers, and experiments were conducted using several embeddings, namely simple embedding, Global Vectors, and Word2Vec, to classify the sentiments expressed in the tweets. The performance of each LexDeep model was evaluated and compared with that of a support vector machine (SVM). Finally, the unemployment rates before and during COVID-19 were analysed to gain insights into the differences in unemployment percentages through social media input and analysis. The results demonstrated that all LexDeep models with simple embedding outperformed the SVM. This confirmed the superiority of the proposed LexDeep model over a classical machine learning classifier in performing sentiment analysis tasks for domain-specific sentiments. In terms of the risk of income loss, the unemployment issue is highly politicised on both the regional and global scales; thus, if a country cannot combat this issue, the global economy will also be affected. Future research should develop a utility maximisation algorithm for household welfare evaluation, given the percentage risk of income loss owing to COVID-19.",2023
"A Data-Driven, Farmer-Oriented Agricultural Crop Recommendation Engine (ACRE)","Agriculture has a significant role to play in any emerging economy and provides the source of income and employment for a large portion of the population. A key challenge faced by small and marginal farmers is to determine which crops to grow to maximize their utililty. With a wrong choice of crops, farmers could end up with sub-optimal yields and low, and possibly even loss of revenue. This work seeks to design and develop ACRE (Agricultural Crop Recommendation Engine), a tool that provides a scientific method to choose a crop or a portfolio of crops, to maximize the utility to the farmer. ACRE uses available data such as soil characteristics, weather conditions, and historical yield data, and uses state-of-the-art machine learning/deep learning models to compute an estimated utility to the farmer. The main idea of ACRE is to generate several recommendations of portfolios of crops, with a ranking of portfolios based on the Sharpe ratio, a popular risk metric in financial investments. We use publicly available data from agmarknet portal in India to perform several thought experiments with ACRE. ACRE provides a rigorous, data-driven backend for designing farmer-friendly mobile apps for assisting farmers in choosing crops (This work was supported by the National Bank for Agriculture and Rural Development (NABARD), Government of India, through a research grant).",2022
A Deep Learning-Based Framework for Phishing Website Detection,"Phishing attackers spread phishing links through e-mail, text messages, and social media platforms. They use social engineering skills to trick users into visiting phishing websites and entering crucial personal information. In the end, the stolen personal information is used to defraud the trust of regular websites or financial institutions to obtain illegal benefits. With the development and applications of machine learning technology, many machine learning-based solutions for detecting phishing have been proposed. Some solutions are based on the features extracted by rules, and some of the features need to rely on third-party services, which will cause instability and time-consuming issues in the prediction service. In this paper, we propose a deep learning-based framework for detecting phishing websites. We have implemented the framework as a browser plug-in capable of determining whether there is a phishing risk in real-time when the user visits a web page and gives a warning message. The real-time prediction service combines multiple strategies to improve accuracy, reduce false alarm rates, and reduce calculation time, including whitelist filtering, blacklist interception, and machine learning (ML) prediction. In the ML prediction module, we compared multiple machine learning models using several datasets. From the experimental results, the RNN-GRU model obtained the highest accuracy of 99.18%, demonstrating the feasibility of the proposed solution.",2022
Self-Reported Sexual Behavioral Interests and Polymorphisms in the Dopamine Receptor D4 (DRD4) Exon III VNTR in Heterosexual Young Adults,"Polymorphisms in the dopamine D4 receptor (DRD4) have previously been shown to associate with a variety of human behavioral phenotypes, including ADHD pathology, alcohol and tobacco craving, financial risk-taking in males, and broader personality traits such as novelty seeking. Recent research has linked the presence of a 7-repeat (7R) allele in a 48-bp variable number of tandem repeats (VNTR) along exon III of DRD4 to age at first sexual intercourse, sexual desire, arousal and function, and infidelity and promiscuity. We hypothesized that carriers of longer DRD4 alleles may report interest in a wider variety of sexual behaviors and experiences than noncarriers. Participants completed a 37-item questionnaire measuring sexual interests as well as Cloninger's Temperament and Character Inventory, and were genotyped for the 48-bp VNTR on exon III of DRD4. Based on our final genotyped sample of female (n = 139) and male (n = 115) participants, we found that 7R carriers reported interest in a wider variety of sexual behaviors (r = 0.16) within a young adult heterosexual sample of European descent. To our knowledge, this is the first reported association between DRD4 exon III VNTR genotype and interest in a variety of sexual behaviors. We discuss these findings within the context of DRD4 research and broader trends in human evolutionary history.",2016
Tree-based Machine Learning and Deep Learning in Predicting Investor Intention to Public Private Partnership,"Public private partnership (PPP) is the government initiate in accelerating public infrastructure development growth. However, the scheme exposes private sector to various risks including political risk which in turn affect financial performance and reporting of participating firms. Given that one of the issues facing the government is the lack of participation from the private sector in such arrangements. Thus, the main objective of this study is to observe the machine learning prediction models on private investor intention in participating the PPP program. Tree-based machine learning and deep learning are two different types of promising algorithms, which proven to be useful in widely domain of prediction problems but never been tested on the concerned problem of this study. Based on real data of investors for Indonesian listed firms, this paper presents the ability of the selected machine learning algorithms by means of different assessments point of view. First assessment is on the algorithms' performances in producing accurate prediction. Second assessment is to identify the variance of PPP attributes in each of the prediction model with the machine learning algorithms. The performance results show that all the prediction models with the machine learning algorithms and the PPP attributes were well-fitted at R squared above 80%. The findings contribute a significant knowledge to various fields of scholars to implement a more in-depth analysis on the machine learning methods and investors' prediction.",2023
Prevalence of mental health problems among stranded international students during the COVID-19 pandemic,"Background The novel coronavirus disease (COVID-19) spread fast throughout China and the rest of the world, prompting the World Health Organization to declare a worldwide pandemic on March 11, 2020. Many countries have implemented travel bans, lockdowns, and stay-at-home policies to combat the spread of the COVID-19 pandemic. This study aimed to investigate the risk factors of mental health problems among international students stranded outside of China during the pandemic. Methods A qualitative study was conducted among non-Chinese international students enrolled at Chinese universities who were stranded in their home countries. The participants were recruited using a purposive sampling technique. Following informed consent, in-depth interviews were conducted with the help of a semi-structured guide. Two independent investigators transcribed and coded the interview data. The investigators established themes after going through a detailed discussion. Results Participants reported several mental health risk factors, such as a rise in hopelessness and level of uncertainty, worry, lost interest and focus, lack of support, unemployment and financial hardships, social pressure, behavioral and mood changes, sleep disorder, and increased smoking. These mental health problems will affect the concentration and deep learning, thereby increasing academic stress. In addition, we found that the outbreak of the delta-variant led to a further increase in these mental health risk factors. Conclusions The pandemic scenario, along with international travel restrictions, increased the likelihood of mental health problems among stranded international students. Thus, preventing further rises in mental health disorders and reducing the effects of pandemic-related measures on stranded international students, such as researchers and policymakers can mitigate the pandemic's effects and achieve national or international health and educational goals. Adequate intervention for this group is strongly recommended.",2022
Outcomes of an Asynchronous Care Model for Chronic Conditions in a Diverse Population: 12-Month Retrospective Chart Review Study,"Background: Diabetes and hypertension are some of the most prevalent and costly chronic conditions in the United States. However, outcomescontinue to lag behind targets, creating further risk of long-term complications, morbidity, and mortality for people living with these conditions. Furthermore, racial and ethnic disparities in glycemic and hypertension control persist. Flexible telehealth programs leveraging asynchronous care allow for increased provider access and more convenient follow-up, ultimatelyimprovingcritical healthoutcomesacross demographic groups. Objective: We aim to evaluate the 12-month clinical outcomesof participants in the 9amHealth web-based clinic for diabetes and hypertension. We hypothesized that participation in the 9amHealth program would be associated with significant improvements in glycemic and blood pressure (BP) control across a diverse group of individuals. Methods: We enrolled 95 patients in a completely web-based care clinic for diabetes and hypertension who received nutrition counseling, health coaching, and asynchronous physician consultations for medication prescribing. Patients received standard or cellular-connected glucose meters and BP cuffs in order to share data. Laboratory tests were completed either with at-home phlebotomy draws or a self-administered test kit. Patients' first and last hemoglobin A 1c (HbA1c) and BP results over the 12-month period were compared, and analyses were repeated across race and ethnicity groups. Results: Among all 95 patients, the average HbA1c decreased by -1.0 (from 8.2% to 7.2%; P <.001) over 12 months of program participation. In those with a baseline HbA1c >8%, the average HbA1c decreased by -2.1 (from 10.2% to 8.1%; P <.001), and in those with a baseline HbA1c >9%, the average HbA1c decreased by -2.8 (from 11% to 8.2%; P <.001). Among participants who identified as a race or ethnicity other than White, the HbA1c decreased by -1.2 (from 8.6% to 7.4%, P =.001). Further examination of subgroups confirmed HbA1c lowering within each race or ethnicity group. In the overall population, the average systolic BP decreased by 17.7 mm Hg (P=.006) and the average diastolic BP decreased by 14.3 mm Hg (P=.002). Among participants self-identifying as a race or ethnicity other than White, the results similarly showed a decrease in BP (average reduction in systolic BP of 10mm Hg and in diastolic BP of 9mm Hg). Conclusions:A fully web-based model leveraging all-asynchronous physician review and prescribing, combined with synchronous and asynchronous coaching and nutrition support, was associated with clinically meaningful improvement in HbA1c and BP control over a12-monthperiodamonga diverse group ofindividuals. Further studies should prospectively evaluate the effectiveness of such models among larger populations, assess the longer-term sustainability of these outcomes, and explore financial models to make these types of programs broadly accessible.",2024
Net interest margin decomposition for the Russian banking industry,"This study addresses the estimating interest rate risk in the banking book (IRRBB) faced by Russian banks amid key rate changes. We propose a methodological framework to decompose net interest margin to evaluate contributions of different asset and liability categories and idiosyncratic, price, and weight effects to IRRBB. Using a sample of 315 banks, we employ linear regression models to evaluate interest income for asset and interest expenses for liability categories. Statistical significance is assessed using block bootstrap with 1000 resamples. The main result of this study is the development of a methodology for assessing the contributions of different asset and liability categories to IRRBB. Our findings indicate that banks tend to adopt strategic rather than tactical responses to crises. However, systematically important financial institutions (SIFIs) tactically adjust their liability structures to mitigate unexpected key rate movements. This was particularly evident during the COVID-19 pandemic, when, despite a declining key rate, SIFIs maintained a net positive price contribution of 1.645 bp per quarter.",2025
International carbon market price forecasting using an integration model based on SVR,"Better forecast of carbon emission prices may increase risk control capabilities of emission market stakeholders, and provide decision support for policy makers, financial institutions and enterprises. However, the issue of carbon price forecasting is complicated and several existing prediction models are difficult to achieve satisfactory results. This paper proposes an integration model based on SVR to predict international carbon market price. The model we suggest includes two steps: we respectively establish ARIMA, BP neural network, grey model GM(1,1) and genetic programming to fit the original sequence of the carbon price at the first phase, and get four prediction results. Additionally, SVR is used to integrate these four results and eventually obtain prediction result. For verification and testing, EUA (DEC15) carbon price from December 3, 2012 to April 10, 2015 under the EU ETS was used to examine the forecasting ability of the proposed integration model. The result demonstrates the accuracy of integration model proposed in this paper is superior to the other three basic models.",2015
Assessing the utility of deep neural networks in predicting postoperative surgical complications: a retrospective study,"Background Early detection of postoperative complications, including organ failure, is pivotal in the initiation of targeted treatment strategies aimed at attenuating organ damage. In an era of increasing health-care costs and limited financial resources, identifying surgical patients at a high risk of postoperative complications and providing personalised precision medicine-based treatment strategies provides an obvious pathway for reducing patient morbidity and mortality. We aimed to leverage deep learning to create, through training on structured electronic health-care data, a multilabel deep neural network to predict surgical postoperative complications that would outperform available models in surgical risk prediction. Methods In this retrospective study, we used data on 58 input features, including demographics, laboratory values, and 30-day postoperative complications, from the American College of Surgeons (ACS) National Surgical Quality Improvement Program database, which collects data from 722 hospitals from around 15 countries. We queried the entire adult (>= 18 years) database for patients who had surgery between Jan 1, 2012, and Dec 31, 2018. We then identified all patients who were treated at a large midwestern US academic medical centre, excluded them from the base dataset, and reserved this independent group for final model testing. We then randomly created a training set and a validation set from the remaining cases. We developed three deep neural network models with increasing numbers of input variables and so increasing levels of complexity. Output variables comprised mortality and 18 different postoperative complications. Overall morbidity was defined as any of 16 postoperative complications. Model performance was evaluated on the test set using the area under the receiver operating characteristic curve (AUC) and compared with previous metrics from the ACS-Surgical Risk Calculator (ACS-SRC). We evaluated resistance to changes in the underlying patient population on a subset of the test set, comprising only patients who had emergency surgery. Results were also compared with the Predictive OpTimal Trees in Emergency Surgery Risk (POTTER) calculator. Findings 5 881 881 surgical patients, with 2941 unique Current Procedural Terminology codes, were included in this study, with 4 694 488 in the training set, 1173 622 in the validation set, and 13 771 in the test set. The mean AUCs for the validation set were 0.864 (SD 0.053) for model 1, 0.871(0.055) for model 2, and 0.882 (0.053) for model 3. The mean AUCs for the test set were 0.859 (SD 0.063) for model 1, 0.863 (0.064) for model 2, and 0.874 (0.061) for model 3. The mean AUCs of each model outperformed previously published performance metrics from the ACS-SRC, with a direct correlation between increasing model complexity and performance. Additionally, when tested on a subgroup of patients who had emergency surgery, our models outperformed previously published POTTER metrics. Interpretation We have developed unified prediction models, based on deep neural networks, for predicting surgical postoperative complications. The models were generally superior to previously published surgical risk prediction tools and appeared robust to changes in the underlying patient population. Deep learning could offer superior approaches to surgical risk prediction in clinical practice. Copyright (C) 2021 The Author(s). Published by Elsevier Ltd.",2021
Automatic detection of migrating soaring bird flocks using weather radars by deep learning,"1. The use of weather radars to detect and distinguish between different biological patterns greatly improves our understanding of aeroecology and its consequences for our lives. Importantly, it allows us to quantify passerine bird migration at different scales. Yet, no algorithm to detect soaring bird flocks in weather radar is available, precluding our ability to study this type of migration over large spatial scales. 2. We developed the first automatic algorithm for detecting the migration of flocks of soaring birds, an important bio-flow phenomenon involving many millions of birds that travel across large spatial extents, with implications for risk of collisions. The algorithm was developed with a deep learning network for semantic segmentation using U-Net architecture. We tested several models with different weather radar products and with image sequences for flock movement identification. 3. The best model includes the radial velocity product and a sequence of two previous images. It identifies 93% of soaring bird flocks that were tagged by a human on the radar image, with a false discovery of less than 20%. 4. Large birds such as those detected by the algorithm pose a serious risk for flight safety of civilian and military transportation and therefore the application of this algorithm can substantially reduce bird-strikes, leading to reduced financial losses and threats to human lives. In addition, it can help overcome one of the main challenges in the study of bird migration by automatically and continuously detecting flocks of large birds over wide spatial scales without the need to equip the birds with tracking devices, unravelling the abundance, timing, spatial flyways, seasonal trends and influences of environmental conditions on the migration of bird flocks.",2023
Design of Underground Space Intelligent Disaster Prevention System Based on Multisource Data Deep Learning,"With the rapid development of national economy, the population to big cities gathered themselves together, and especially the first-line cities, lead to city continuously extend outward, city scale is more and more big, the surface space is completely unable to meet the needs of urban development and transportation, the demand such as life, development, and use of underground space has become the important way of solving the urban development diameter. With the vigorous development of underground space, many disaster problems, such as fire and flood, have also appeared in many places, which have brought huge human and financial losses to the society. In order to solve the problem of disaster in underground space, this paper summarizes the main disasters, and urban underground space analysis of the different degrees of the risk of disasters; the emergency toughness of disaster prevention concept, combined with intelligent technology application in urban underground space disaster warning and decision-making, according to the requirement of the underground space of disaster prevention wisdom, put forward to underground space disaster, disaster prevention expert database, such as multisource data fusion. Deep learning is used to realize the linkage of disaster rescue and recovery, and an intelligent disaster prevention system based on deep learning of multisource data is established. The results show that the urban underground space disasters mainly include fire, explosion, earthquake, flood, toxic, and combustible gas. Combining with the overlapping characteristics of different disasters and the inability to define the boundaries, the theory of emergency resilience disaster prevention provides effective suggestions and measures for the decision-making and treatment of underground space fires. The intelligent comprehensive disaster prevention system of urban underground space is established from the three aspects of predisaster prevention, rescue in disaster, and reconstruction after disaster, so as to realize the full coverage of intelligent disaster prevention in the whole life cycle of underground space and provide data support for integrated decision-making of disaster prevention and reduction. The research results have important guiding significance for digitization, informationization, and intelligent construction of sudden disaster decision-making in underground space.",2022
Prediction of unplanned 30-day readmission for ICU patients with heart failure,"Background Intensive Care Unit (ICU) readmissions in patients with heart failure (HF) result in a significant risk of death and financial burden for patients and healthcare systems. Prediction of at-risk patients for readmission allows for targeted interventions that reduce morbidity and mortality. Methods and results We presented a process mining/deep learning approach for the prediction of unplanned 30-day readmission of ICU patients with HF. A patient's health records can be understood as a sequence of observations called event logs; used to discover a process model. Time information was extracted using the DREAM (Decay Replay Mining) algorithm. Demographic information and severity scores upon admission were then combined with the time information and fed to a neural network (NN) model to further enhance the prediction efficiency. Additionally, several machine learning (ML) algorithms were developed to be used as the baseline models for the comparison of the results. Results By using the Medical Information Mart for Intensive Care III (MIMIC-III) dataset of 3411 ICU patients with HF, our proposed model yielded an area under the receiver operating characteristics (AUROC) of 0.930, 95% confidence interval of [0.898-0.960], the precision of 0.886, sensitivity of 0.805, accuracy of 0.841, and F-score of 0.800 which were far better than the results of the best baseline model and the existing literature. Conclusions The proposed approach was capable of modeling the time-related variables and incorporating the medical history of patients from prior hospital visits for prediction. Thus, our approach significantly improved the outcome prediction compared to that of other ML-based models and health calculators.",2022
A Coupled Mathematical Model of the Dissemination Route of Short-Term Fund-Raising Fraud,"To effectively protect citizens' property from the infringement of fund-raising fraud, it is necessary to investigate the dissemination, identification, and causation of fund-raising fraud. In this study, the Susceptible Infected Recovered (SIR) model, Back-Propagation (BP) neural network, Fault tree, and Bayesian network were used to analyze the dissemination, identification, and causation of fund-raising fraud. Firstly, relevant data about fund-raising fraud were collected from residents in the same area via a questionnaire survey. Secondly, the SIR model was used to simulate the dissemination of victims, susceptibles, alerts, and fraud amount; the BP neural network was used to identify the data of financial fraud and change the accuracy of the number analysis of neurons and hidden layers; the fault-tree model and the Bayesian network model were employed to analyze the causation and importance of basic events. Finally, the security measures of fund-raising fraud were simulated by changing the dissemination parameters. The results show that (1) for the spread of the scam, the scale of the victims expands sharply with the increase of the fraud cycle, and the victims of the final fraud cycle account for 12.5% of people in the region; (2) for the source of infection of the scam, the initial recognition rate of fraud by the BP neural network varies from 90.9% to 93.9%; (3) for the victims of the scam, reducing fraud publicity, improving risk awareness, and strengthening fraud supervision can effectively reduce the probability of fraud; and (4) reducing the fraud rate can reduce the number of victims and delay the outbreak time. Improving the alert rate can reduce victims on a large scale. Strengthening supervision can restrict the scale of victims and prolong the duration of fraud.",2022
Methodology for integration of wind resource forecasts based on artificial neural networks,"An adaptation of the portfolio theory (PT) is proposed in this article, denoted as PrevPT, Previsao (in Portuguese) by PT, to integrate the three artificial neural networks, namely multilayer perceptron (MLP) backpropagation, radial basis function (RBF), and self-organizing map (SOM), based forecasting techniques, aiming to analyze the impact of wind speed forecasting errors and achieve more accurate results. In its first use, the PT goal was to maximize a financial return, at any risk, through the diversification of securities or investments that are not positively correlated. Based on the development of PrevPT, which was used until this work only for solar forecasting, the proposed technique is applied in this paper to integrate and improve the results of individual wind forecasts. Four-year wind speed data (January 2007 to December 2010) from two different locations (Algeciras, Spain and Petrolina, Brazil) were used. Our methodology develops a topology that integrates the forecasts obtained by MLP, RBF, and SOM aiming to obtain smaller forecast errors. By diversifying the forecasted asset, when one of the assets has negative prediction errors, another compensates for them and, thus, the total or partial cancellation of the errors occurs. PrevPT obtains a mean absolute percentage error of 1.13% for Spain and 2.35% for Brazil. PrevPT surpassed the results obtained by the three techniques applied individually in the two locations. The main innovations of the methodology are the significant reduction of errors and optimization of resource planning, and the beneficial features compared to other predictor integration techniques.",2022
Landslide risk zoning using support vector machine algorithm,"Landslides are one of the most dangerous phenomena and natural disasters. Landslides cause many human and financial losses in most parts of the world, especially in mountainous areas. Due to the climatic conditions and topography, people in the northern and western regions of Iran live with the risk of landslides. One of the measures that can effectively reduce the possible risks of landslides and their crisis management is to identify potential areas prone to landslides through multi-criteria modeling approach. This research aims to model landslide potential area in the Oshvand watershed using a support vector machine algorithm. For this purpose, evidence maps of seven effective factors in the occurrence of landslides namely slope, slope direction, height, distance from the fault, the density of waterways, rainfall, and geology, were prepared. The maps were generated and weighted using the continuous fuzzification method and logistic functions, resulting values in zero and one range as weights. The weighted maps were then combined using the support vector machine algorithm. For the training and testing of the machine, 81 slippery ground points and 81 non-sliding points were used. Modeling procedure was done using four linear, polynomial, Gaussian, and sigmoid kernels. The efficiency of each model was compared using the area under the receiver operating characteristic curve; the root means square error, and the correlation coefficient . Finally, the landslide potential model that was obtained using Gaussian's kernel was selected as the best one for susceptibility of landslides in the Oshvand watershed.",2023
Cardiometabolic risk factors and MyChart enrollment among adult patients,"Objectives: The purpose of this study was to assess the relationship between MyChart and cardiometabolic risk factors (i.e., body mass index [BMI], blood pressure [BP], and smoking status) among adult patients. We assessed whether activated MyChart account status and number of MyChart logins differed based on cardiometabolic risk factors, above and beyond demographic covariates. Methods: This study was an electronic medical record review of 137,837 adult patients who were seen during June 2014-June 2015 at all ambulatory outpatient facilities in one large, Midwestern healthcare system. We performed multivariable logistic and multiple linear regression analyses. Results: Of patients, 25.8% had an active MyChart account status. Multivariable regression analyses indicated that overweight patients were 5.0% more likely (OR=1.05, CI = [1.01, 1.08]) to have an active account compared to normal weight counterparts, but patients with hypertension were 18.0% less likely (OR=0.82, CI = [0.79, 0.85]) to have an active account compared to those with normal BR Former smokers were 54.0% less likely (OR=0.46, CI = [0.44, 0.48]) to have an activate account compared to patients who never smoked. Multiple linear regression results indicated obesity (b = 2.65) and active smoking (b = 5.10) positively affected the number of MyChart logins, whereas pre-hypertensive BP negatively affected the number of MyChart account logins (b =-1.20). Conclusions: Healthcare organizations and employees should consider these findings when developing strategies for MyChart enrollment and utilization. Future research should compare system implementation, patient care quality, and financial efficiency of MyChart between healthcare organizations of similar structural makeup and geographic locations. (C) 2017 Fellowship of Postgraduate Medicine. Published by Elsevier Ltd. All rights reserved.",2017
Impact of Physiological and Psychological Stress on Glaucoma Development and Progression: A Narrative Review,"Glaucoma is a leading cause of irreversible blindness worldwide. Presently, elevated intraocular pressure (IOP) is the only approved modifiable risk factor. A consensus of the current literature suggests that both physiological and psychological stress may also impact the lifelong course of glaucoma. Specifically, stress is known to influence sympathetic nervous system activity. An increase in sympathetic nervous system activity may elevate a person's blood pressure (BP) and IOP, and both are strongly associated with glaucomatous disease. Anxiety and depression have more conflicting evidence in relation to glaucoma. Socioeconomic and environmental stress may worsen adherence to therapy and disease outcomes due to a lack of financial resources and related access to healthcare. Neighborhood quality and environmental conditions, particularly urban environments, have been associated with glaucoma risk factors, higher glaucoma prevalence, and delayed surgical interventions. Racial differences have also been identified, with Black patients being more stressed and likely to present with increased glaucoma severity and faster disease progression than White patients. Mindfulness, meditation, and other forms of psychological relaxation have been shown to reduce IOP and stress biomarkers and result in improved quality of life (QOL). Larger studies in more diverse populations are needed to clarify risk and identify the best therapeutic approaches to reduce stress as a method to improve clinical outcomes and QOL for glaucoma patients.",2025
Non-pharmacological interventions for primary hypertension: a systematic review and network meta-analysis protocol,"Introduction Primary hypertension (PH) affects over one billion individuals globally, yet less than 30% achieve controlled blood pressure (BP) with medication. Many patients require a combination of multiple medications to reach targets, but adverse effects and financial burdens undermine adherence. Additionally, prehypertension affects 25%-50% of adults, increasing the risk of cardiovascular complications. Early detection and management of prehypertension are crucial for delaying the need for pharmacological interventions. In recent years, clinical guidelines have increasingly emphasised non-pharmacological interventions for PH management. However, the diversity of non-pharmacological therapies and the inconsistencies in efficacy challenge clinical decision-making. This study aims to use network meta-analysis (NMA) to synthesise existing evidence on non-pharmacological interventions for PH, offering updated clinical insights and evidence-based support to optimise treatment strategies. It will also provide recommendations for integrating these interventions into community-based chronic disease management.Methods and analysis To identify potentially relevant randomised controlled trials, a reverse search strategy will be employed to ascertain all non-pharmacological interventions for PH. A well-constructed search strategy will be applied across nine academic databases (Web of Science, Embase, PubMed, PsycINFO, CENTRAL, AMED, CNKI, WF and VIP database) and three clinical trial registries (WHO ICTRP, ClinicalTrials.gov and ChiCTR) for studies conducted between 1 January 2014 and 1 August 2024. Two investigators will independently extract information from eligible articles and document reasons for exclusions. The primary outcomes will encompass changes in systolic and diastolic BP. Pairwise and Bayesian NMA will be conducted using 'meta' and 'GeMTC' package (R 4.4.1). Risk of bias will be assessed using the Risk of Bias 2 tool, and the quality of evidence will be evaluated according to the Grading of Recommendations, Assessment, Development and Evaluation approach.Ethics and dissemination As this review involves secondary analysis of previously published data, ethical approval is not required. The results will be published in peer-reviewed journals.PROSPERO registration number CRD42023451073.",2025
The prevalence of diabetes and metabolic syndrome and associated risk factors in Sudanese individuals with gallstones: a cross sectional survey,"Background: The gallstones are common health problem across the world with huge financial burden on health authorities. Obesity and insulin resistance are associated with risk of gallstones disease (GSD). The aim of this study was to assess the prevalence of metabolic syndrome (MetS) and diabetes and associated risk factors in Sudanese patients with gallstones. Methods: A prospective cross-sectional study, enrolled patients with gallstones attending Ibn Sina Specialized 'leaching Hospital for gastrointestinal and hepatobiliary diseases. A structured questionnaire was applied, anthropometric measures were taken, and blood tested for HbAlc, fasting glucose and lipid profile. Data was analysed using SPSS version 23. Results: A total number of 151 participants were recruited in the study, 71 of them were ultrasound confirmed GSD patients, and the other 80 were controls without GSD over a period of six months. The prevalence of the MetS and diabetes was 30% and 23.9% respectively. Borderline diabetes was 16.9% and overweight and obesity constituted more than half of the sample 59.6%. Using Chi-Square test, a statistically significant association was found between MetS and HDL, TG, LDL level, waist circumference and blood pressure (BP). Absolute predictors and the risk factors for gallstone disease were waist circumference, age, HbAlc and LDL. Conclusions: The prevalence of MetS and diabetes among gallstone patients was 30% and 23.9% respectively. Absolute predictors and the risk factors for gallstone disease were waist circumference, age, HbAlc and LDL.",2020
OptIForest: Optimal Isolation Forest for Anomaly Detection,"Anomaly detection plays an increasingly important role in various fields for critical tasks such as intrusion detection in cybersecurity, financial risk detection, and human health monitoring. A variety of anomaly detection methods have been proposed, and a category based on the isolation forest mechanism stands out due to its simplicity, effectiveness, and efficiency, e.g., iForest is often employed as a state-of-the-art detector for real deployment. While the majority of isolation forests use the binary structure, a framework LSHiForest has demonstrated that the multi-fork isolation tree structure can lead to better detection performance. However, there is no theoretical work answering the fundamentally and practically important question on the optimal tree structure for an isolation forest with respect to the branching factor. In this paper, we establish a theory on isolation efficiency to answer the question and determine the optimal branching factor for an isolation tree. Based on the theoretical underpinning, we design a practical optimal isolation forest OptIForest incorporating clustering based learning to hash which enables more information to be learned from data for better isolation quality. The rationale of our approach relies on a better bias-variance trade-off achieved by bias reduction in OptIForest. Extensive experiments on a series of benchmarking datasets for comparative and ablation studies demonstrate that our approach can efficiently and robustly achieve better detection performance in general than the state-of-the-arts including the deep learning based methods.",2023
The Stock Index Prediction Based on SVR Model with Bat Optimization Algorithm,"Accurate stock market prediction models can provide investors with convenient tools to make better data-based decisions and judgments. Moreover, retail investors and institutional investors could reduce their investment risk by selecting the optimal stock index with the help of these models. Predicting stock index price is one of the most effective tools for risk management and portfolio diversification. The continuous improvement of the accuracy of stock index price forecasts can promote the improvement and maturity of China's capital market supervision and investment. It is also an important guarantee for China to further accelerate structural reforms and manufacturing transformation and upgrading. In response to this problem, this paper introduces the bat algorithm to optimize the three free parameters of the SVR machine learning model, constructs the BA-SVR hybrid model, and forecasts the closing prices of 18 stock indexes in Chinese stock market. The total sample comes from 15 January 2016 (the 10th trading day in 2016) to 31 December 2020. We select the last 20, 60, and 250 days of whole sample data as test sets for short-term, mid-term, and long-term forecast, respectively. The empirical results show that the BA-SVR model outperforms the polynomial kernel SVR model and sigmoid kernel SVR model without optimized initial parameters. In the robustness test part, we use the stationary time series data after the first-order difference of six selected characteristics to re-predict. Compared with the random forest model and ANN model, the prediction performance of the BA-SVR model is still significant. This paper also provides a new perspective on the methods of stock index forecasting and the application of bat algorithms in the financial field.",2021
Advancing the Reliability of Ultra-Low Field MRI Brain Volume Analysis Using CycleGAN,"The increasing prevalence of neurodegenerative diseases poses a significant threat to the well-being of the growing elderly population, with biological age being a major risk factor. This has increased the demand for cost-effective and informative neuroimaging modalities and analysis tools. Specifically, measuring brain volume is of critical importance as abnormal atrophy patterns are strong indicators of disease onset. Ultra-low field (ULF) MRI provides an innovative pathway to more accessible neuroimaging by mitigating various logistical, financial, and safety considerations associated with clinical MRI. However, the image quality of ULF-MRI impacts the reliability of brain volume analysis. Advancements in deep learning (DL) have proven capable of enhancing the image quality and analysis of medical images. Yet, these tools have not been fully realized for ULF-MRI, largely due to data scarcity as the technology is still relatively new. As a result, existing DL techniques for ULF image enhancement are trained with synthetically generated images, leading to potential domain shift issues when applied to real images. Here, we introduce a CycleGAN framework that learns with real ULF and high-field (HF) MRIs to improve the image enhancement process compared to existing methods. We demonstrate that this approach increases the accuracy of brain volume measurements based on improved correlations with paired clinical data and higher test-retest reliability across repeat measurements. Ultimately, our proposal has the potential to enhance clinical and research workflows through the increased accessibility and reliability of ULF-MRI.",2025
Validation study of Yunnan ethnic culture industry stock model under epidemic situation based on chaotic particle swarm optimization neural networks,"The new crown pneumonia epidemic is raging, in the context of global integration, the scope of the impact of this sudden event spread around the world, the stock market has not been spared, the financial risk has increased dramatically compared with the past, the emergence of the epidemic has led to the spread of investor panic, March 2020, the U.S. S&P 500 index appeared in the four plunge, and led to the market trading meltdown, the world's financial markets have had an extremely serious impact. The study of the impact of Xin Guan Pneumonia on the company's stock returns is not only conducive to enriching the theoretical study of public health emergencies, but also conducive to improving the coping strategy, stabilizing the general economic market, and enhancing the public's awareness of risk response. This paper compares the effect of the four intelligent algorithms of chaotic particle swarm algorithm, chaotic bee colony algorithm, chaotic fruit fly algorithm and chaotic ant colony algorithm combined with neural network on the prediction of the stock price trend of Yunnan national culture, and the study shows that the speed of convergence of the chaotic particle swarm optimization neural network and the speed of descent is better than that of the two models of chaotic fruit fly and chaotic bee colony, and the coefficients of decision of the chaotic particle swarm optimization neural network are higher than that of the other three models, and the errors are lower than the other three models. Indexes are lower than the other three models and have high accuracy in stock prediction of Yunnan ethnic culture, this finding emphasizes the potential of PSO-BP model to provide robust stock market prediction, which is important for both investors and policy makers in dealing with volatile market conditions.",2024
Physiological effects of slot play in women,"The purpose of this study is to describe the physiological responses occurring during slot gambling in 23 females with problematic and non-problematic gambling backgrounds in two sites: at a casino using their own money and at a casino laboratory without wagering money. Using the National Opinion Research Center Diagnostic Screen (NODS), 12 women were not-at-risk gamblers and 11 were at-risk, problem, or pathological gamblers. Blood pressure (BP), heart rate (HR), respiratory rate (RR), skin conductance (SC), and skin temperature (ST) were measured for 5 min before gambling (baseline), 10 min while gambling, and 5 min after gambling (recovery). In the casino, SBP (p = .001), DBP (p = .031), HR (p = .030), and RR (p = 004) rose during gambling and fell during recovery; ST rose throughout the study (p = .006). There were no differences between subjects based on NODS score. A total of 12 subjects were also studied in the laboratory. SBP (p = .004), DBP (p = .000); HR (p = .023); RR (p = .000) and SC (p = .002) rose during gambling and fell during recovery; ST rose throughout the study (p = .006). There were no significant differences by location. The observed effects suggest that females find slot play physiologically arousing, with or without financial stakes, because physiological changes were consistent with an arousal response.",2007
Connectionist Model to Help the Evaluation of Medical Equipment Purchasing Proposals,"There is in the developing world a great number of idle medical equipment, due to the absence of experienced professionals to conduct an effective purchasing plan in its several phases, including vendors proposals evaluation. As artificial neural networks are typically applied for pattern recognition and function approximation, it was developed a decision-making computational model, based on artificial neural networks, which entries were grades given to physical risk, cost and strategic importance to a chosen medical equipment. The outputs were also grades attributed by clinical engineers according to the importance of five factors (clinical, financial, quality, safety and technical) during the equipment evaluation. The use of the model's outcome allows any clinical engineer to identify the proposal that best attend the health unit requirements. To validate this model, a national inquiry (32 clinical engineers) was conducted using an electronic chart that permitted to: (a) establish a major professional profile of the inquired engineers; (b) determine which were the most important criteria considered during a medical equipment procurement process and (c) generate 95 examples that were used to train, and to test, diverse types of artificial neural networks. Hence, to represent the knowledge of clinical engineers (for the evaluation process of purchasing proposals) who worked at public hospitals, with three to ten years of experience, the best results were encountered for an ensemble of 100 two-hidden-layers perceptrons trained with the Backpropagation algorithm. The neural networks responses presented average reliability superior than 85% in all cases studied. Therefore, a connectionist computational model can be useful during a decision making process to help hospital managers to choose an appropriate medical equipment.",2007
Android Malware Detection Using ResNet-50 Stacking,"There has been an increase in attacks on mobile devices, such as smartphones and tablets, due to their growing popularity. Mobile malware is one of the most dangerous threats, causing both security breaches and financial losses. Mobile malware is likely to continue to evolve and proliferate to carry out a variety of cybercrimes on mobile devices. Mobile malware specifically targets Android operating system as it has grown in popularity. The rapid proliferation of Android malware apps poses a significant security risk to users, making static and manual analysis of malicious files difficult. Therefore, efficient identification and classification of Androidmalicious files is crucial. Several ConvolutionalNeuralNetwork (CNN) basedmethods have been proposed in this regard; however, there is still room for performance improvement. In this work, we propose a transfer learning and stacking approach to efficiently detect the Android malware files by utilizing two well-known machine learning models, ResNet-50 and Support Vector Machine (SVM). The proposed model is trained on the DREBIN dataset by transforming malicious APK files into grayscale images. Our model yields higher performance measures than state-of-the-art works on the DREBIN dataset, where the reported measures are accuracy, recall, precision, and F1 measures of 97.8%, 95.8%, 95.7%, and 95.7%, respectively.",2023
"A comparison of neural network, statistical methods, and variable choice for life insurers' financial distress prediction","This study examines the effect of the statistical/mathematical model selected and the variable set considered on the ability to identify financially troubled life insurers. Models considered are two artificial neural network methods (back-propagation and learning vector quantization (LVQ)) and two more standard statistical methods (multiple discriminant analysis and logistic regression analysis). The variable sets considered are the insurance regulatory information system (IRIS) variables, the financial analysis solvency tracking (FAST) variables, and Texas early warning information system (EWIS) variables, and a data set consisting of twenty-two variables selected by us in conjunction with the research staff at TDI and a review of the insolvency prediction literature. The results show that the back-propagation (BP) and LVQ outperform the traditional statistical approaches for all four variable sets with a consistent superiority across the two different evaluation criteria (total misclassification cost and resubstitution risk criteria), and that the twenty-two variables and the Texas EWIS variable sets are more efficient than the IRIS and the FAST variable sets for identification of financially troubled life insurers in most comparisons.",2006
A novel multifactor clustering integration paradigm based on two-stage feature engineering and improved bidirectional deep neural networks for exchange rate forecasting,"Accurate exchange rate forecasting is of great importance for foreign exchange investment, hedging foreign exchange risk and international economic transactions. However, it is extremely challenging to make accurate forecasts for exchange rates because of their high volatility, nonlinearity, and non-stationarity. Based on this, this paper proposes a multifactor clustering integration paradigm for exchange rate prediction. From the classical theory of exchange rate determination, a comprehensive library of factors affecting the exchange rate is constructed. A two-stage feature engineering is constructed to capture the stable structure of features. In order to enable features to be learned adequately and to improve algorithmic efficiency and predictive performance, a novel clustering integration paradigm is constructed to improve the stability of the model. The framework builds different predictive sub-models for different data, and then embeds Bayesian optimization algorithms into the bidirectional deep neural networks. Finally, the output results of different sub-models are integrated using nonlinear integration techniques. In addition, the superiority of the proposed model is verified using eight comparative models. The results of the empirical analysis show that the average percentage error of our proposed model is the lowest among all the comparative models (0.412648 %, 0.515348 %, and 0.329892 % on the three datasets, respectively). Compared to the standard LSTM, the average percentage error is at least 88 % lower, proving the effectiveness of the proposed model. It can help investors to make better decisions in the international financial markets.",2023
"Proceedings From a National Heart, Lung, and Blood Institute and the Centers for Disease Control and Prevention Workshop to Control Hypertension","Hypertension treatment and control prevent more cardiovascular events than management of other modifiable risk factors. Although the age-adjusted proportion of US adults with controlled blood pressure (BP) defined as <140/90 mm Hg, improved from 31.8% in 1999-2000 to 48.5% in 2007-2008, it remained stable through 2013-2014 and declined to 43.7% in 2017-2018. To address the rapid decline in hypertension control, the National Heart, Lung, and Blood Institute and the Division for Heart Disease and Stroke Prevention of the Centers for Disease Control and Prevention convened a virtual workshop with multidisciplinary national experts. Also, the group sought to identify opportunities to reverse the adverse trend and further improve hypertension control. The workshop immediately preceded the Surgeon General's Call to Action to Control Hypertension, which recognized a stagnation in progress with hypertension control. The presentations and discussions included potential reasons for the decline and challenges in hypertension control, possible big ideas, and multisector approaches that could reverse the current trend while addressing knowledge gaps and research priorities. The broad set of big ideas was comprised of various activities that may improve hypertension control, including: interventions to engage patients, promotion of self-measured BP monitoring with clinical support, supporting team-based care, implementing telehealth, enhancing community-clinical linkages, advancing precision population health, developing tailored public health messaging, simplifying hypertension treatment, using process and outcomes quality metrics to foster accountability and efficiency, improving access to high-quality health care, addressing social determinants of health, supporting cardiovascular public health and research, and lowering financial barriers to hypertension control.",2022
Efficient and Secure Federated Learning for Financial Applications,"Conventional machine learning (ML) and deep learning approaches require sharing customers' sensitive information with an external credit bureau to generate a prediction model, thereby increasing the risk of privacy leakage. This poses a significant challenge for financial companies. To address this challenge, federated learning has emerged as a promising approach to protect data privacy. However, the high communication costs associated with federated systems, particularly for large neural networks, can be a bottleneck. To mitigate this issue, it is necessary to limit the number and size of communications for practical training of large neural structures. Gradient sparsification is a technique that has gained increasing attention as a method to reduce communication costs, as it updates only significant gradients and accumulates insignificant gradients locally. However, the secure aggregation framework cannot directly employ gradient sparsification. To overcome this limitation, this article proposes two sparsification methods for reducing the communication costs of federated learning. The first method is a time-varying hierarchical sparsification method for model parameter updates, which addresses the challenge of maintaining model accuracy after a high sparsity ratio. This method can significantly reduce the cost of a single communication. The second method is to apply sparsification to the secure aggregation framework. Specifically, the encryption mask matrix is sparsified to reduce communication costs while protecting privacy. Experiments demonstrate that our method can reduce the upload communication costs to approximately 2.9% to 18.9% of the conventional federated learning algorithm under different non-IID experiment settings when the sparsity rate is 0.01.",2023
First-Gen Lens: Assessing Mental Health of First-Generation Students across Their First Year at College Using Mobile Sensing,"The transition from high school to college is a taxing time for young adults. New students arriving on campus navigate a myriad of challenges centered around adapting to new living situations, financial needs, academic pressures and social demands. First-year students need to gain new skills and strategies to cope with these new demands in order to make good decisions, ease their transition to independent living and ultimately succeed. In general, first-generation students are less prepared when they enter college in comparison to non-first-generation students. This presents additional challenges for first-generation students to overcome and be successful during their college years. We study first-year students through the lens of mobile phone sensing across their first year at college, including all academic terms and breaks. We collect longitudinal mobile sensing data for N=180 first-year college students, where 27 of the students are first-generation, representing 15% of the study cohort and representative of the number of first-generation students admitted each year at the study institution, Dartmouth College. We discuss risk factors, behavioral patterns and mental health of first-generation and non-first-generation students. We propose a deep learning model that accurately predicts the mental health of first-generation students by taking into account important distinguishing behavioral factors of first-generation students. Our study, which uses the StudentLife app, offers data-informed insights that could be used to identify struggling students and provide new forms of phone-based interventions with the goal of keeping students on track.",2022
From forecasting to trading: A multimodal-data-driven approach to reversing carbon market losses,"The carbon market is characterized by inherent nonlinearity and high volatility, significantly influenced by several market and factor exposures. These include the energy market, financial market, foreign exchange market, international carbon markets, environmental factors, public attention, and market sentiment. Given the multifaceted determinants of carbon prices, this study has bridged a gap in the existing research by transitioning from traditional historical-data-driven methods to an innovative multimodal-data-driven framework integrating both structured and unstructured data. Combining decomposition techniques with feature filtering, we analyze the dynamic relationships between multiple variables and different frequency components of carbon prices, particularly within the relatively young and understudied Chinese carbon market. Furthermore, we calculate entropy values to distinguish between high-complexity and low-complexity sub-sequences and implement an adaptive forecasting process fusing conventional statistical approaches with prevalent deep learning methods, improving interpretability and forecasting accuracy. The proposed method has a prediction RMSE of only 0.3471 in the carbon market of Hubei, China, and a prediction MAPE of 0.9491 in the newly established national unified carbon market. Building upon the forecasting results, this paper makes a further extension by proposing an interval-constrained trading strategy that encapsulates the predictive uncertainties, providing an effective risk management tool in the volatile carbon market. Enterprises can improve their cumulative return rate by 2 % to 14 % through the improvement of our trading strategies, and the maximum drawdown can be reduced by about 2 %. Notably, our strategy's potential for reversing losses to gains, could offer actionable insights for enterprises' decision-making processes.",2025
"Deepwater Drilling: Law, Policy, and Economics of Firm Organization and Safety","Although the causes of the Deepwater Horizon spill are not yet conclusively identified, significant attention has focused on the safety-related policies and practices-often referred to as the safety culture-of BP and other firms involved in drilling the well. This Article defines and characterizes the economic and policy forces that affect safety culture and identifies reasons why those forces may or may not be adequate or effective from the public's perspective. Two potential justifications for policy intervention are that: (1) not all of the social costs of a spill may be internalized by a firm; and (2) there may be principal-agent problems within the firm, which could be reduced by external monitoring. The Article discusses five policies that could increase safety culture and monitoring: liability, financial responsibility (a requirement that a firm's assets exceed a threshold), government oversight, mandatory private insurance, and risk-based drilling fees. We find that although each policy has a positive effect on safety culture, there are important differences and interactions that must be considered. In particular, the latter three policies provide external monitoring. Furthermore, raising liability caps without mandating insurance or raising financial responsibility requirements could have a small effect on the safety culture of small firms that would declare bankruptcy in the event of a large spill. The Article concludes with policy recommendations for promoting stronger safety culture in offshore drilling; our preferred approach would be to set a liability cap for each well equal to the worst-case social costs of a spill and to require insurance up to the cap.",2011
The Effectiveness of Self-Management of Hypertension in Adults Using Mobile Health: Systematic Review and Meta-Analysis,"Background: Effective treatment of hypertension requires careful self-management. With the ongoing development of mobile technologies and the scarcity of health care resources, mobile health (mHealth)-based self-management has become a useful treatment for hypertension, and its effectiveness has been assessed in many trials. However, there is a paucity of comprehensive summaries of the studies using both qualitative and quantitative methods. Objective: This systematic review aimed to measure the effectiveness of mHealth in improving the self-management of hypertension for adults. The outcome measures were blood pressure (BP), BP control, medication adherence, self-management behavior, and costs. Methods: A systematic search was conducted using 5 electronic databases. The snowballing method was used to scan the reference lists of relevant studies. Only peer-reviewed randomized controlled trials (RCTs) published between January 2010 and September 2019 were included. Data extraction and quality assessment were performed by 3 researchers independently, adhering to the validation guideline and checklist. Both a meta-analysis and a narrative synthesis were carried out. Results: A total of 24 studies with 8933 participants were included. Of these, 23 studies reported the clinical outcome of BP, 12 of these provided systolic blood pressure (SBP) and diastolic blood pressure (DBP) data, and 16 articles focused on change in self-management behavior and medication adherence. All 24 studies were included in the narrative synthesis. According to the meta-analysis, a greater reduction in both SBP and DBP was observed in the mHealth intervention groups compared with control groups, -3.78 mm Hg (P<.001; 95% CI -4.67 to -2.89) and -1.57 mm Hg (P<.001; 95% CI -2.28 to -0.86), respectively. Subgroup analyses showed consistent reductions in SBP and DBP across different frequencies of reminders, interactive patterns, intervention functions, and study duration subgroups. A total of 16 studies reported better medication adherence and behavioral change in the intervention groups, while 8 showed no significant change. Six studies included an economic evaluation, which drew inconsistent conclusions. However, potentially long-term financial benefits were mentioned in all economic evaluations. All studies were assessed to be at high risk of bias. Conclusions: This review found that mHealth self-management interventions were effective in BP control. The outcomes of this review showed improvements in self-management behavior and medication adherence. The most successful mHealth intervention combined the feature of tailored messages, interactive communication, and multifaceted functions. Further research with longer duration and cultural adaptation is necessary. With increasing disease burden from hypertension globally, mHealth offers a potentially effective method for self-management and control of BP. mHealth can be easily integrated into existing health care systems.",2020
Texas City refinery accident: Case study in breakdown of defense-in-depth and violation of the safety-diagnosability principle in design,"In 2005 an explosion rocked the BP Texas City refinery, killing 15 people and injuring 180. The company incurred direct and indirect financial losses on the order of billions of dollars for victims' compensation as well as significant property damage and loss of production. The internal BP accident investigation and the Chemical Safety Board investigation identified a number of factors that contributed to the accident. In this work, we first examine the accident pathogens or lurking adverse conditions at the refinery prior to the accident. We then analyze the sequence of events that led to the explosion, and we highlight some of the provisions for the implementation of defense-in-depth and their failures. Next we identify a fundamental failure mechanism in this accident, namely the absence of observability or ability to diagnose hazardous states in the operation of the refinery, in particular within the raffinate splitter tower and the blowdown drum of the isomerization unit. We propose a general safety-diagnosability principle for supporting accident prevention, which requires that all safety-degrading events or states that defense-in-depth is meant to protect against be diagnosable, and that breaches of safety barriers be unambiguously monitored and reported. The safety-diagnosability principle supports the development of a living or online quantitative risk assessment, which in turn can help re-order risk priorities in real time based on emerging hazards, and re-allocate defensive resources. We argue that the safety-diagnosability principle is an essential ingredient for improving operators' situation awareness. Violation of the safety-diagnosability principle translates into a shrinking of the time window available for operators to understand an unfolding hazardous situation and intervene to abate it. Compliance with this new safety principle provides one way to improve operators' sensemaking and situation awareness and decrease the conditional probability that an accident will occur following an adverse initiating event. We suggest that defense-in-depth be augmented with this principle, without which it can degenerate into an ineffective defense-blind safety strategy. (C) 2013 Elsevier Ltd. All rights reserved.",2014
"Comparing the learning effectiveness of BP, ELM, I-ELM, and SVM for corporate credit ratings","Corporate credit ratings are one of the key problems of the credit risk management, which has attracted much research attention since the credit crisis in 2007. Scorecards are the most widely used approaches for corporate credit ratings nowadays. However, they have heavy dependency on the involvement of users. Al technologies, such as Artificial Neural Networks (ANNs) and Support Vector Machines (SVMs) have demonstrated their remarkable performance on automatic corporate credit ratings. Corporate credit ratings involve various rating models, and their outputs can scale to multiple levels and be used for various applications. Such inherent complexity gives rise to the requirement of higher demands on the effectiveness of learning algorithms regarding the accuracy, overfitness, error distribution, and output distribution. Most research works show that SVMs have better performance than ANNs on accuracy. This paper carries out a comprehensive experimental comparison study over the effectiveness of four learning algorithms, i.e., BP, ELM, I-ELM, and SVM over a data set consisting of real financial data for corporate credit ratings. The results are presented and discussed in the paper. (C) 2013 Elsevier B.V. All rights reserved.",2014
"Internet of Things Applications, Security Challenges, Attacks, Intrusion Detection, and Future Visions: A Systematic Review","Internet of Things (IoT) technology is prospering and entering every part of our lives, be it education, home, vehicles, or healthcare. With the increase in the number of connected devices, several challenges are also coming up with IoT technology: heterogeneity, scalability, quality of service, security requirements, and many more. Security management takes a back seat in IoT because of cost, size, and power. It poses a significant risk as lack of security makes users skeptical towards using IoT devices. This, in turn, makes IoT vulnerable to security attacks, ultimately causing enormous financial and reputational losses. It makes up for an urgent need to assess present security risks and discuss the upcoming challenges to be ready to face the same. The undertaken study is a multi-fold survey of different security issues present in IoT layers: perception layer, network layer, support layer, application layer, with further focus on Distributed Denial of Service (DDoS) attacks. DDoS attacks are significant threats for the cyber world because of their potential to bring down the victims. Different types of DDoS attacks, DDoS attacks in IoT devices, impacts of DDoS attacks, and solutions for mitigation are discussed in detail. The presented review work compares Intrusion Detection and Prevention models for mitigating DDoS attacks and focuses on Intrusion Detection models. Furthermore, the classification of Intrusion Detection Systems, different anomaly detection techniques, different Intrusion Detection System models based on datasets, various machine learning and deep learning techniques for data pre-processing and malware detection has been discussed. In the end, a broader perspective has been envisioned while discussing research challenges, its proposed solutions, and future visions.",2021
Deep learning application detecting SARS-CoV-2 key enzymes inhibitors,"The fast spread of the COVID-19 over the world pressured scientists to find its cures. Especially, with the disastrous results, it engendered from human life losses to long-term impacts on infected people's health and the huge financial losses. In addition to the massive efforts made by researchers and medicals on finding safe, smart, fast, and efficient methods to accurately make an early diagnosis of the COVID-19. Some researchers focused on finding drugs to treat the disease and its symptoms, others worked on creating effective vaccines, while several concentrated on finding inhibitors for the key enzymes of the virus, to reduce its spreading and reproduction inside the human body. These enzymes' inhibitors are usually found in aliments, plants, fungi, or even in some drugs. Since these inhibitors slow and halt the replication of the virus in the human body, they can help fight it at an early stage saving the patient from death risk. Moreover, if the human body's immune system gets rid of the virus at the early stage it can be spared from the disastrous sequels it may leave inside the patient's body. Our research aims to find aliments and plants that are rich in these inhibitors. In this paper, we developed a deep learning application that is trained with various aliments, plants, and drugs to detect if a component contains SARS-CoV-2 key inhibitor(s) intending to help them find more sources containing these inhibitors. The application is trained to identify various sources rich in thirteen coronavirus-2 key inhibitors. The sources are currently just aliments, plants, and seeds and the identification is done by their names.",2023
DEED: DEep Evidential Doctor*,"As Deep Neural Networks (DNN) make their way into safety-critical decision processes, it becomes imperative to have robust and reliable uncertainty estimates for their predictions for both in-distribution and out-of-distribution (OOD) examples. This is particularly important in real-life high-risk settings such as healthcare, where OOD examples (e.g., patients with previously unseen or rare labels, i.e., diagnoses) are frequent, and an incorrect clinical decision might put human life in danger, in addition to having severe ethical and financial costs. While evidential uncertainty estimates for deep learning have been studied for multi-class problems, research in multi-label settings remains untapped. In this paper, we propose a DEep Evidential Doctor (DEED), which is a novel deterministic approach to estimate multi-label targets along with uncertainty. We achieve this by placing evidential priors over the original likelihood functions and directly estimating the parameters of the evidential distribution using a novel loss function. Additionally, we build a redundancy layer (particularly for high uncertainty and OOD examples) to minimize the risk associated with erroneous decisions based on dubious predictions. We achieve this by learning the mapping between the evidential space and a continuous semantic label embedding space via a recurrent decoder. Thereby inferring, even in the case of OOD examples, reasonably close predictions to avoid catastrophic consequences. We demonstrate the effectiveness of DEED on a digit classification task based on a modified multi-label MNIST dataset, and further evaluate it on a diagnosis prediction task from a real-life electronic health record dataset. We highlight that in terms of prediction scores, our approach is on par with the existing state-of-the-art having a clear advantage of generating reliable, memory and time efficient uncertainty estimates with minimal changes to any multi-label DNN classifier. (c) 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).",2023
QUANTITATIVE INVESTMENT DECISIONS BASED ON MACHINE LEARNING AND INVESTOR ATTENTION ANALYSIS,"According to the trading rules and financial data structure of the stock index futures market, and considering the impact of major emergencies, we intend to build a quantitative investment decision-making model based on machine learning. We first adopt the Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN) signal decomposition technology to separate the short-term noise, cycle transformation and long-term trend from the original series, and use the CSI 500 Baidu index series to reflect the investors' attention, which provides data support for establishing a more effective forecasting model. Then, the CEEMDANBP neural network model is designed based on the obtained effective information of low -frequency trend series, investor attention index and CSI 500 stock index futures market transaction data. Finally, an Attention-based Dual Thrust quantitative trading strategy is proposed and optimized. The optimized Attention-based Dual Thrust strategy solves the core problem of breakout interval determination, effectively avoids the risk of subjective selection, and can meet investors' different risk preferences. The quantitative investment decision-making model based on CEEMDAN-BP neural network utilizes the advantages of different algorithms, avoids some defects of a single algorithm, and can make corresponding adjustments according to changes in investors' attention and the occurrence of emergencies. The results show that considering investor attention can not only improve the predictive ability of the model, but also reduce the cognitive bias of the market, effectively control risks and obtain higher returns.",2024
Patients' and Providers' Perspectives on and Needs of Telemonitoring to Support Clinical Management and Self-care of People at High Risk for Preeclampsia: Qualitative Study,"Background: Preeclampsia is one of the leading causes of maternal mortality worldwide, with a global prevalence at 2%-8% of pregnancies. Patients at high risk for preeclampsia (PHRPE) have an increased risk of complications, such as fetal growth restriction, preterm delivery, abnormal clotting, and liver and kidney disease. Telemonitoring for PHRPE may allow for timelier diagnosis and enhanced management, which may improve maternal and perinatal outcomes. Objective: The objective of this study is to determine the perceptions and needs of PHRPE and their health care providers with respect to telemonitoring through semistructured interviews with both groups. This study explored (1) what the needs and challenges of monitoring PHRPE are during pregnancy and in the postpartum period and (2) what features are required in a telemonitoring program to support self-care and clinical management of PHRPE. Methods: This study used a qualitative descriptive approach, and thematic analysis was conducted. PHRPE and health care providers from a high-risk obstetrical clinic in a large academic hospital in Toronto, Canada, were asked to participate in individual semistructured interviews. Two researchers jointly developed a coding framework and separately coded each interview to ensure that the interviews were double-coded. The software program NVivo version 12 was used to help organize the codes. Results: In total, 7 PHRPE and 5 health care providers, which included a nurse practitioner and physicians, participated in the semistructured interviews. Using thematic analysis, perceptions on the benefits, barriers, and desired features were determined. Perceived benefits of telemonitoring for PHRPE included close monitoring of home blood pressure (BP) measurements and appropriate interventions for abnormal BP readings; the development of a tailored telemonitoring system for pregnant patients; and facilitation of self-management. Perceived barriers to telemonitoring for PHRPE included financial and personal barriers, as well as the potential for increased clinician workload. Desired features of a secure platform for PHRPE included the facilitation of self-management for patients and decision making for clinicians, as well as the inclusion of evidence-based action prompts. Conclusions: The perceptions of patients and providers on the use of telemonitoring for PHRPE support the need for a telemonitoring program for the management of PHRPE. Recommendations from this study include the specific features of a telemonitoring program for PHRPE, as well as the use of frameworks and design processes in the design and implementation of a telemonitoring program for PHRPE.",2022
Artificial Intelligence Models to Identify Patients at High Risk for Glaucoma Using Self-reported Health Data in a United States National Cohort,"Purpose: Early glaucoma detection is key to preventing vision loss, but screening often requires specialized eye examination or photography, limiting large-scale implementation. This study sought to develop artificial intelligence models that use self-reported health data from surveys to prescreen patients at high risk for glaucoma who are most in need of glaucoma screening with ophthalmic examination and imaging. Design: Cohort study. Participants: Participants enrolled from May 1, 2018, to July 1, 2022, in the nationwide All of Us Research Program who were >= 18 years of age, had >= 2 eye-related diagnoses in their electronic health record (EHR), and submitted surveys with self-reported health history. Methods: We developed models to predict the risk of glaucoma, as determined by EHR diagnosis codes, using 3 machine learning approaches: (1) penalized logistic regression, (2) XGBoost, and (3) a fully connected neural network. Glaucoma diagnosis was identified based on International Classification of Diseases codes extracted from EHR data. An 80/20 train-test split was implemented, with cross-validation employed for hyperparameter tuning. Input features included self-reported demographics, general health, lifestyle factors, and family and personal medical history. Main Outcome Measures: Models were evaluated using standard classification metrics, including area under the receiver operating characteristic curve (AUROC). Results: Among the 8205 patients, 873 (10.64%) were diagnosed with glaucoma. Across models, AUROC scores for identifying which patients had glaucoma from survey health data ranged from 0.710 to 0.890. XGBoost achieved the highest AUROC of 0.890 (95% confidence interval [CI]: 0.860-0.910). Logistic regression followed with an AUROC of 0.772 (95% CI: 0.753-0.795). Explainability studies revealed that key features included traditionally recognized risk factors for glaucoma, such as age, type 2 diabetes, and a family history of glaucoma. Conclusions: Machine and deep learning models successfully utilized health data from self-reported surveys to predict glaucoma diagnosis without additional data from ophthalmic imaging or eye examination. These models may eventually enable prescreening for glaucoma in a wide variety of low-resource settings, after which high-risk patients can be referred for targeted screening using more specialized ophthalmic examination or imaging. Financial Disclosure(s): The author(s) have no proprietary or commercial interest in any materials discussed in this article. (c) 2024 by the American Academy of Ophthalmology. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).",2025
Mechanisms and Treatment of CKD,"As CKD continues to increase worldwide, along with the demand for related life-saving therapies, the financial burden of CKD will place an increasing drain on health care systems. Experimental studies showed that glomerular capillary hypertension and impaired sieving function with consequent protein overload play a pathogenic role in the progression of CKD. Consistently, human studies show that proteinuria is an independent predictor of progression and that its reduction is renoprotective. At comparable BP control, inhibitors of the renin-angiotensin system (RAS), including angiotensin converting enzyme (ACE) inhibitors and angiotensin II receptor blockers (ARBs), more effectively than non-RAS inhibitor therapy reduce proteinuria, slow progression to ESRD, and even improve the kidney function achieving disease regression in some cases. In participants with diabetes, RAS inhibitors delay the onset of microalbuminuria and its progression to macroalbuminuria, and ACE inhibitors may reduce the excess cardiovascular mortality associated with diabetic renal disease. In addition to RAS inhibitors, however, multimodal approaches including lifestyle modifications and multidrug therapy will be required in most cases to optimize control of the several risk factors for CKD and related cardiovascular morbidity. Whether novel medications may help further improve the cost-effectiveness of renoprotective interventions is a matter of investigation.",2012
"Detection and typing of low-risk human papillomavirus genotypes HPV 6, HPV 11, HPV 42, HPV 43 and HPV 44 by polymerase chain reaction and restriction fragment length polymorphism","A novel PCR-restriction fragment length polymorphism assay (PCR-RFLP) was developed for sensitive detection and reliable differentiation of five low-risk human papillomavirus (lr-HPV) genotypes: HPV 6, HPV 11, HPV 42, HPV 43 and HPV 44, as well as differentiation of prototypic and non-prototypic HPV 6 genomic variants. The assay is based on the amplification of a 320-bp fragment of the HPV E1 gene and subsequent analysis of PCR-products with BsaJI and HinFI. Testing on plasmid standards showed that PCR-RFLP enabled simple and reliable identification and differentiation of five targeted lr-HPV genotypes and could detect reproducibly down to 10 copies of viral genome equivalents per PCR. The PCR-RFLP showed almost complete agreement with previously obtained genotyping results on 42 HPV-DNA negative samples and 223 HPV-DNA positive samples (45 HPV 6,34 HPV 11.35 HPV 42,10 HPV 43, 24 HPV 44 positive samples and 75 samples containing 28 non-targeted HPV genotypes). The novel assay is simple and robust, does not require any sophisticated equipment and can be of great value for epidemiological studies, particularly in settings in which financial resources are limited. (C) 2010 Elsevier B.V. All rights reserved.",2010
Using feature construction to improve the performance of neural networks,"Recent years have seen the growth in popularity of neural networks for business decision support because of their capabilities' for modeling, estimating, and classifying. Compared to other AI methods for problem solving such as expert systems, neural network approaches are especially useful far their ability to learn adaptively from observations. However, neural network learning performed by algorithms such as back-propagation (BP) are known to be slow due to the size of the search space involved and also the iterative manner in which the algorithm works. In this paper, we show that the degree of difficulty in neural network learning is inherent in the given set of training examples. We propose a technique for measuring such learning difficulty, and then develop a feature construction methodology that helps transform the training data so that both. the learning speed and classification accuracy of neural network algorithms are improved, We show the efficacy of the proposed method for financial risk classification, a domain characterized by frequent data noise, lack of functional structure, and high attribute interactions. Moreover, the empirical studies also provide insights into the structural characteristics of neural networks with respect to the input data used as well as possible mechanisms to improve the learning performance.",1998
Transformative reconstruction of missing acoustic well logs using multi-head self-attention BiRNNs,"Acoustic well logs are vital for many industrial projects, such as mining, oil and gas, civil engineering, geothermal energy, water resource exploration, mineral exploration, and carbon capture and storage. However, these important well log data, which reveal acoustic properties of the subsurface properties, due to operational or financial constraints, may not be always available. This hinders well planning, drilling operation risk assessment, reservoir evaluation, and production optimization in these projects. In recent years, deep learning has gained prominence in well log prediction. Recurrent neural networks (RNNs), especially suited for capturing geological-driven trends in well logs, have emerged as a preferred technique. Multihead attention (MHA) is used to evaluate diverse facets of relationships within the data, enhancing contextual understanding and overcoming challenges. To the best of our knowledge, this study, for the first time, has examined three RNN variants, (BiRNN, BiLSTM and BiGRU), combined with MHA mechanism for the objective of reconstructing acoustic well logs using the existing well log data (i.e. Neutron, Gamma, Density). To this aim, three different models, MHA-BiRNN, MHABiLSTM, and MHA-BiGRU were designed, trained, validated and tested on well logging data taken from Shengli Oilfield. It is noteworthy that, to enhance the significance and reliability of the models, the dataset originated from a discerningly selected subset of 100 wells, purposefully chosen from a pool of 463 (making over 500,000 sequences). This deliberate approach ensures the impartiality of the data, enhancing the trustworthiness and robustness of our models. The results showed promising performance of MHA-BiGRU, MHA-BiRNN and MHA-BiLSTM in capturing nonlinear relationships and vertical depth sequence information between logging curves and good prediction accuracy in actual testing wells. Among them, MHA-BiGRU outperformed (R2 = 0.807, Pearson = 0.914). The proposed method provides a fast and effective way for filling missing values, which is valuable for geological research and engineering applications.",2025
"Smart city and cyber-security; technologies used, leading challenges and future recommendations","Today, some cities around the world have tended to use new technologies and become smart city. New technologies improve the quality of citizens' life. However, the use of any technology raises new issues and challenges. In a smart city, the vulnerable action of an individual or organization can put the entire city at risk. Due to the reliance of various components of smart cities on information and communication technology, cyber-security challenges (such as information leakage and malicious cyber-attacks) in this field affect smart cities behavior. Therefore, in order to respond to the enthusiastic acceptance of global smart city technologies, cyber security must develop in same direction. The aim of this paper is survey and discus on explanation of cyber security, smart cities, and survey of available relevant literature on security in that technology. For this purpose, the present study focuses on the four main components of a smart city, i.e. smart grid, Smart building, Smart transportation system, and Smart healthcare. In particular, summary of two deep learning method and cyber-security programs as well as technology correlation in smart cities are discussed. Furthermore, effective functional solutions in maintaining cyber-security and user privacy in smart cities are explained. The next progress trends of smart city with cyber security are described. Solutions need to be devised to address each of the security issues. The research in this study showed that meeting these challenges depends on the hard work of governments, developers of equipment and software and companies providing IT security services. In addition, designing flexible systems with high information protection capabilities is essential to prevent serious security incidents as these incidents can lead to disastrous financial, data, credit and loss of public trust. (C) 2021 The Author. Published by Elsevier Ltd.",2021
Do incentives work? A qualitative study of managers' motivations in hazardous industries,"Incentive schemes are one way that companies seek to align the interests of their employees with corporate goals. Indicators of major accident risk management have been historically excluded from such incentives. However, analyses of the recent BP disasters found that the incentives worked against process safety, and it was recommended that companies move to include indicators to support the safe management of their complex technologies. The extent to which this recommendation has been applied, and its appropriateness in practice has not been the subject of systematic inquiry. Drawing on the literature on human motivation and incentives, this article addresses the present and potential role of incentives to manage major accident risk in hazardous industries. It focuses on the extent to which senior managers are motivated by incentives in their daily decisions. This analysis is based on qualitative interviews, observation, and document analysis in 11 case study companies across the oil and gas, petrochemical, pipeline, and mining sectors. We argue that despite discomfort with the concept that safety decisions might be influenced by money, incentives influence priorities and behaviours because they do not rely for their effect on economic self-interest alone. Instead they tap a number of human motives, among them the need for approval, and the need to be recognised as making a valuable contribution. We conclude that if incentives continue to be used as a motivation strategy for financial and business performance, safety particularly as it relates to major accident prevention must also be incentivised in this way. (C) 2014 Elsevier Ltd. All rights reserved.",2014
Cost of poor adherence to anti-hypertensive therapy in five European countries,"The financial burden for EU health systems associated with cardiovascular disease (CV) has been estimated to be nearly a,not sign110 billion in 2006, corresponding to 10 % of total healthcare expenditure across EU or a mean a,not sign223 annual cost per capita. The main purpose of this study is to estimate the costs related to hypertension and the economic impact of increasing adherence to anti-hypertensive therapy in five European countries (Italy, Germany, France, Spain and England). A probabilistic prevalence-based decision tree model was developed to estimate the direct costs of CV related to hypertension (CV defined as: stroke, heart attack, heart failure) in five European countries. Our model considered adherence to hypertension treatment as a main driver of blood pressure (BP) control (BP < 140/90 mmHg). Relative risk of CV, based on controlled or uncontrolled BP group, was estimated from the Framingham Heart Study and national review data. Prevalence and cost data were estimated from national literature reviews. A national payer (NP) perspective for 10 years was considered. Probabilistic sensitivity analysis was performed in order to evaluate uncertainty around the results (given as 95 % confidence intervals). The model estimated a total of 8.6 million (1.4 in Italy, 3.3 in Germany, 1.2 in Spain, 1.8 in France and 0.9 in England) CV events related to hypertension over the 10-year time horizon. Increasing the adherence rate to anti-hypertensive therapy to 70 % (baseline value is different for each country) would lead to 82,235 fewer CV events (24,058 in Italy, 7,870 in Germany, 18,870 in Spain, 24,855 in France and 6,553 in England). From the NP perspective, the direct cost associated with hypertension was estimated to be a,not sign51.3 billion (8.1 in Italy, 17.1 in Germany, 12.2 in Spain, 8.8 in France and 5.0 in England). Increasing adherence to anti-hypertensive therapy to 70 % would save a total of a,not sign332 million (CI 95 %: a,not sign319-346 million) from the NPs perspective. This study is the first attempt to estimate the economic impact of non-adherence amongst patients with diagnosed hypertension in Europe, using data from five European countries (Italy, France, Germany, Spain and England).",2015
Volatility transmission and volatility impulse response functions in crude oil markets,"Using daily data from July 2005 to February 2011 for WTI, Dubai and Brent futures contracts, we employ a VAR-BEKK model to investigate crude oil markets integration on the second moment. We also quantify the size and persistence of these connections through the analysis of Volatility Impulse Response Functions (VIRF) for two historical shocks, namely the 2008 Financial Crisis and the BP Deepwater Horizon oil spill. We observe that Brent and Dubai crude are highly responsive to market shocks, whereas WTI crude shows the least responsiveness of the three benchmarks, which creates questions about its predominance as a benchmark crude oil. Furthermore, we fit the density of the VIRF at different forecast horizons. These fitted distributions are asymmetric, showing that the probability of observing a large impact of a shock is lower while the probability of a relatively smaller impact is much higher. Finally, we simulate the VIRF for a given probability of a random shock. The VIRF shows that only a large shock (derived from a smaller probability) will result in an increase in expected conditional volatilities. These results provide useful insights into the volatility transmission mechanism in crude oil markets and their associated risk estimation, and may have significant implications for various market participants and regulators. (C) 2012 Elsevier B.V. All rights reserved.",2012
Deterring and Compensating Oil-Spill Catastrophes: The Need for Strict and Two-Tier Liability,"The BP Deepwater Horizon oil spill highlighted the glaring weaknesses in the current liability and regulatory regime for oil spills and for environmental catastrophes more broadly. This Article proposes a new liability structure for deep-sea oil drilling and for catastrophic risks generally. It delineates a two-tier system of liability. The first tier would impose strict liability up to the firm's financial resources, including insurance coverage. The second tier would be an annual tax equal to the expected costs in the coming year beyond this damages amount. Before beginning a risky operation, the proposed liability scheme would identify a single firm the operator of an oil well as responsible for generating the risk. That firm would be expected to contract with other participants in order to be reimbursed in the event of an accident. The proposed liability scheme would also require the responsible firm to demonstrate substantial ability to pay in the first tier before being permitted to engage in the risky activity. This structure provides for efficient deterrence for environmental catastrophes since the responsible party is expecting to bear the risks that it is imposing. The two-tier system also addresses the challenges posed by the fat-tailed distributions of catastrophic environmental risks and provides for more assured and adequate compensation of potential losses than do current liability and regulatory arrangements.",2011
Life course pathways from parental education to age-related decrements in kidney function among Black and white American adults,"Objective: Using cross-sectional data on Black and white adults, this analysis examined whether age-related decrements in kidney function across adulthood were associated with parental education, and whether the association was differentially influenced by race. Further, this study assessed racial differences in life course pathways from parental education to age-related decrements in kidney function, through current SES and healthrelated risk factors. Method: Data from the main survey and the Biomarker Project of the Midlife in the United States (MIDUS) Wave 2 and Refresher samples were combined, resulting in 1861 adults (54.5% female; age 25-84, Mage = 53.37) who self-identified as non-Hispanic Black (n = 326) and non-Hispanic white (n = 1535). Estimated glomerular filtration rate (eGFR) was based on serum creatinine, calculated using the CKD-EPI formula. Adults SES was based on education, income, and financial strains. Health-related risk factors included obesity, elevated blood pressure (BP), and insulin resistance. Hypotheses were tested by utilizing multiple linear regression and regression-based moderated mediation analysis. Results: Lower parental education was associated with steeper age-related decrements in eGFR (B = 0.38, SE = 0.15, p = .013, 95%CI = 0.08, 0.68), due to higher eGFR among younger participants and lower eGFR among older participants. In addition, age-related decrements in kidney function were steeper among Black relative to white adults (B = 0.41, SE = 0.13, p < .01, 95%CI = 0.16, 0.66), driven by higher proportion of younger Black adults that met criterion for renal hyperfiltration. Furthermore, parental education and race were associated with age-related decrements in kidney function in an additive rather than interactive way. There were some racial differences in the life course pathways from parental education to age-related differences in eGFR, glucoregulation, and hypertension. Among Black adults, lower parental education was associated with elevated eGFR among younger participants through insulin resistance. Among white adults, lower parental education was linked to higher eGFR among younger adults and lower eGFR among older adults, and the association was mediated by current SES, elevated BP, and insulin resistance. Discussion: Early life SES can have a long-lasting influence on the preclinical renal senescence that is associated with the normal biology of aging for both Black and white adults.",2021
DeepPricing: pricing convertible bonds based on financial time-series generative adversarial networks,"Convertible bonds are an important segment of the corporate bond market, however, as hybrid instruments, convertible bonds are difficult to value because they depend on variables related to the underlying stock, the fixed-income part, and the interaction between these components. Besides, embedded options, such as conversion, call, and put provisions are often restricted to certain periods, may vary over time, and are subject to additional path-dependent features of the state variables. Moreover, the most challenging problem in convertible bond valuation is the underlying stock return process modeling as it retains various complex statistical properties. In this paper, we propose DeepPricing, a novel data-driven convertible bonds pricing model, which is inspired by the recent success of generative adversarial networks (GAN), to address the above challenges. The method introduces a new financial time-series generative adversarial networks (FinGAN), which is able to reproduce risk-neutral stock return process that retains the unique statistical properties such as the fat-tailed distributions, the long-range dependence, and the asymmetry structure etc., and then transit to its risk-neutral distribution. Thus it is more flexible and accurate to capture the dynamics of the underlying stock return process and keep the rich set of real-world convertible bond specifications compared with previous model-driven models. The experiments on the Chinese convertible bond market demonstrate the effectiveness of DeepPricing model. Compared with the convertible bond market prices, our model has a better convertible bonds pricing performance than both model-driven models, i.e. Black-Scholes, the constant elasticity of variance, GARCH, and the state-of-the-art GAN-based models, i.e. FinGAN-MLP, FinGAN-LSTM. Moreover, our model has a better fitting capacity for higher-volatility convertible bonds and the overall convertible bond market implied volatility smirk, especially for equity-liked convertible bonds, convertible bonds trading in the bull market, and out-of-the-money convertible bonds. Furthermore, the Long-Short and Long-Only investment strategies based on our model earn a significant annualized return with 41.16% and 31.06%, respectively, for the equally-weighted portfolio during the sample period.",2022
Solving the optimal stopping problem with reinforcement learning: an application in financial option exercise,"The optimal stopping problem is a category of decision problems with a specific constrained configuration. It is relevant to various real-world applications such as finance and management. To solve the optimal stopping problem, state-of-the-art algorithms in dynamic programming, such as the least-squares Monte Carlo (LSMC), are employed. This type of algorithm relies on path simulations using only the last price of the underlying asset as a state representation. In addition, the LSMC is designed for the valuation of options where risk-neutral probabilities can be employed to explain uncertainty. However, the general optimal stopping problem goals may not fit the requirements of the LSMC showing auto-correlated prices. We employ a data-driven method that uses Monte Carlo simulation to train and test artificial neural networks (ANN) to solve the optimal stopping problem. Using ANN to solve decision problems is not entirely new. We propose a different architecture that uses convolutional neural networks (CNN) to deal with the dimensionality problem that arises when we transform the whole history of prices into a Markovian state. We present experiments that indicate that our proposed architecture improves results over the previous implementations under specific simulated time series function sets. Lastly, we employ our proposed method to compare the optimal exercise of the financial options problem with the LSMC algorithm. Our experiments show that our method can capture more accurate exercise opportunities when compared to the LSMC. We have an outstandingly higher (above 974% improvement) expected payoff from these exercise policies under the many Monte Carlo simulations that used the real-world return database on the out-of-sample (test) data.",2022
Comprehensive Review on the Use of Artificial Intelligence in Ophthalmology and Future Research Directions,"Background: Having several applications in medicine, and in ophthalmology in particular, artificial intelligence (AI) tools have been used to detect visual function deficits, thus playing a key role in diagnosing eye diseases and in predicting the evolution of these common and disabling diseases. AI tools, i.e., artificial neural networks (ANNs), are progressively involved in detecting and customized control of ophthalmic diseases. The studies that refer to the efficiency of AI in medicine and especially in ophthalmology were analyzed in this review. Materials and Methods: We conducted a comprehensive review in order to collect all accounts published between 2015 and 2022 that refer to these applications of AI in medicine and especially in ophthalmology. Neural networks have a major role in establishing the demand to initiate preliminary anti-glaucoma therapy to stop the advance of the disease. Results: Different surveys in the literature review show the remarkable benefit of these AI tools in ophthalmology in evaluating the visual field, optic nerve, and retinal nerve fiber layer, thus ensuring a higher precision in detecting advances in glaucoma and retinal shifts in diabetes. We thus identified 1762 applications of artificial intelligence in ophthalmology: review articles and research articles (301 pub med, 144 scopus, 445 web of science, 872 science direct). Of these, we analyzed 70 articles and review papers (diabetic retinopathy (N = 24), glaucoma (N = 24), DMLV (N = 15), other pathologies (N = 7)) after applying the inclusion and exclusion criteria. Conclusion: In medicine, AI tools are used in surgery, radiology, gynecology, oncology, etc., in making a diagnosis, predicting the evolution of a disease, and assessing the prognosis in patients with oncological pathologies. In ophthalmology, AI potentially increases the patient's access to screening/clinical diagnosis and decreases healthcare costs, mainly when there is a high risk of disease or communities face financial shortages. AI/DL (deep learning) algorithms using both OCT and FO images will change image analysis techniques and methodologies. Optimizing these (combined) technologies will accelerate progress in this area.",2023
Machine learning and deep learning models for preoperative detection of lymph node metastasis in colorectal cancer: a systematic review and meta-analysis,"Objective To evaluate the diagnostic performance of Machine Learning (ML) and Deep Learning (DL) models for predicting preoperative Lymph Node Metastasis (LNM) in Colorectal Cancer (CRC) patients. Methods A systematic review and meta-analysis were conducted following PRISMA-DTA and AMSTAR-2 guidelines. We searched PubMed, Web of Science, Embase, and Cochrane Library databases until February 16, 2024. Study quality and risk of bias were assessed using the QUADAS-2 tool. Data were analyzed using STATA v18, applying random-effects models to all analyses. Results Twelve studies involving 8321 patients were included, with most published in 2021-2024 (9/12). The pooled AUC of ML models for predicting LNM in CRC patients was 0.87 (95% CI: 0.82-0.91, I-2:86.17) with a sensitivity of 78% (95% CI: 69-87%) and a specificity of 77% (95% CI: 64%-90%). In addition, when assessing the AUC reported by radiologists, both junior and senior radiologists had similar performance, significantly lower than the ML models. (P < 0.001). Subgroup analysis revealed higher AUCs in prospective studies (0.95, 95% CI: 0.87-1) compared to retrospective studies (0.85, 95% CI: 0.81-0.89) (P = 0.03). Studies without external validation exhibited significantly higher AUCs than those with external validation (P < 0.01). While there was no significant difference in AUC and sensitivity between the T1-T2 and T2-T4 stages, specificity was significantly higher in the T2-T4 stages than the low stages of T1 and T2 (95%, 95% CI: 92-98% vs. 61%, 95% CI: 44-78%; P < 0.01). Conclusion ML models demonstrate strong potential for preoperative LNM staging and treatment planning in CRC, potentially reducing the need for additional surgeries and related health and financial burdens. Further prospective multicenter studies, with standardized reporting of algorithms, modality parameters, and LNM staging, are needed to validate these findings.",2025
A recent review on optimisation methods applied to credit scoring models,"Purpose - This paper aims to present a literature review of the most recent optimisation methods applied to Credit Scoring Models (CSMs). Design/methodology/approach - The research methodology employed technical procedures based on bibliographic and exploratory analyses. A traditional investigation was carried out using the Scopus, ScienceDirect and Web of Science databases. The papers selection and classification took place in three steps considering only studies in English language and published in electronic journals (from 2008 to 2022). The investigation led up to the selection of 46 publications (10 presenting literature reviews and 36 proposing CSMs).Findings - The findings showed that CSMs are usually formulated using Financial Analysis, Machine Learning, Statistical Techniques, Operational Research and Data Mining Algorithms. The main databases used by the researchers were banks and the University of California, Irvine. The analyses identified 48 methods used by CSMs, the main ones being: Logistic Regression (13%), Naive Bayes (10%) and Artificial Neural Networks (7%). The authors conclude that advances in credit score studies will require new hybrid approaches capable of integrating Big Data and Deep Learning algorithms into CSMs. These algorithms should have practical issues considered consider practical issues for improving the level of adaptation and performance demanded for the CSMs.Practical implications - The results of this study might provide considerable practical implications for the application of CSMs. As it was aimed to demonstrate the application of optimisation methods, it is highly considerable that legal and ethical issues should be better adapted to CSMs. It is also suggested improvement of studies focused on micro and small companies for sales in instalment plans and commercial credit through the improvement or new CSMs. Originality/value - The economic reality surrounding credit granting has made risk management a complex decision-making issue increasingly supported by CSMs. Therefore, this paper satisfies an important gap in the literature to present an analysis of recent advances in optimisation methods applied to CSMs. The main contribution of this paper consists of presenting the evolution of the state of the art and future trends in studies aimed at proposing better CSMs.",2023
Predictors of Impaired Left Ventricular Global Longitudinal Strain in Patients with Essential Hypertension and Preserved Ejection Fraction,"Background: Early identification of hypertensive patients at risk of heart failure (HF) helps guide treatment intensification and predict prognosis. Global longitudinal strain (GLS) derived from two-dimensional speckle-tracking echocardiography (STE) uncovers subclinical left ventricular (LV) systolic dysfunction (SLVSD) in patients with hypertension (HT) and preserved LV ejection fraction (PLVEF). STE is unavailable and/or underutilized in our locality for financial and technical reasons. Objectives: We aim to identify clinical and echocardiographic parameters associated with and/or predictive of impaired GLS in hypertensive patients with PLVEF. Method: In this single-clinic, cross-sectional, observational study, 100 hypertensive patients with PLVEF were examined using conventional and 2D STE. Results: The average GLS was found to be mildly reduced (-18.4 +/- 2.2%) in the study group. Lower GLS (than -19%) was more common among patients with poorly controlled HT (Odds Ratio (OR)=9), being on multiple anti-hypertensive agents (OR=5), positive Sokolow-Lyon electrocardiographic criteria (OR=4.3), and obesity (OR=2). Conventional echocardiographic parameters predicting impaired GLS included: mitral annular plane systolic excursion (MAPSE) (p=0.001), inter-ventricular septal thickness (IVSd) (p=0.003), LV mass (p=0.003), and LV remodelling (p=0.02). The aortic acceleration-to-ejection time ratio (AT/ET) had a good correlation with GLS (p=0.034). The novel product (IVSd x AT/ET) >= 2.7 mm was found to be the best predictor of GLS worse than -19% (AU ROC=0.8, 95% CI [0.68-0.93]; p=0.001). Conclusion: In hypertensive patients with PLVEF, GLS was found to correlate well with blood pressure (BP) control, body size, measures of LV mass, and MAPSE. These parameters predict at least 50% of the variance in GLS and could help practitioners with limited access to STE in risk-stratifying hypertensive patients.",2022
Multi-Path Attention Inverse Discrimination Network for Offline Signature Verification,"Signature verification, which is a method to distinguish the authenticity of signature images, is a biometric verification technique that can effectively reduce the risk of forged signatures in financial, legal, and other business envir-onments. However, compared with ordinary images, signature images have the following characteristics: First, the strokes are slim, i.e., there is less effective information. Second, the signature changes slightly with the time, place, and mood of the signer, i.e., it has high intraclass differences. These challenges lead to the low accuracy of the existing methods based on convolutional neural net-works (CNN). This study proposes an end-to-end multi-path attention inverse dis-crimination network that focuses on the signature stroke parts to extract features by reversing the foreground and background of signature images, which effectively solves the problem of little effective information. To solve the problem of high intraclass variability of signature images, we add multi-path attention modules between discriminative streams and inverse streams to enhance the discriminative features of signature images. Moreover, a multi-path discrimination loss function is proposed, which does not require the feature representation of the samples with the same class label to be infinitely close, as long as the gap between inter-class distance and the intra-class distance is bigger than the set classification threshold, which radically resolves the problem of high intra-class difference of signature images. In addition, this loss can also spur the network to explore the detailed infor-mation on the stroke parts, such as the crossing, thickness, and connection of strokes. We respectively tested on CEDAR, BHSig-Bengali, BHSig-Hindi, and GPDS Synthetic datasets with accuracies of 100%, 96.24%, 93.86%, and 83.72%, which are more accurate than existing signature verification methods. This is more helpful to the task of signature authentication in justice and finance.",2023
Efficacy in Galleria mellonella Larvae and Application Potential Assessment of a New Bacteriophage BUCT700 Extensively Lyse Stenotrophomonas maltophilia,"In recent years, Stenotrophomonas maltophilia (S. maltophilia) has become an important pathogen of clinically acquired infections accompanied by high pathogenicity and high mortality. Moreover, infections caused by multidrug-resistant S. maltophilia have emerged as a serious challenge in clinical practice. Bacteriophages are considered a promising alternative for the treatment of S. maltophilia infections due to their unique antibacterial mechanism and superior bactericidal ability compared with traditional antibiotic agents. Here, we reported a new phage BUCT700 that has a double-stranded DNA genome of 43,214 bp with 70% GC content. A total of 55 ORFs and no virulence or antimicrobial resistance genes were annotated in the genome of phage BUCT700. Phage BUCT700 has a broad host range (28/43) and can lyse multiple ST types of clinical S. maltophilia (21/33). Furthermore, bacteriophage BUCT700 used the Type IV fimbrial biogenesis protein PilX as an adsorption receptor. In the stability test, phage BUCT700 showed excellent thermal stability (4 to 60 degrees C) and pH tolerance (pH = 4 to 12). Moreover, phage BUCT700 was able to maintain a high titer during long-term storage. The adsorption curve and one-step growth curve showed that phage BUCT700 could rapidly adsorb to the surface of S. maltophilia and produce a significant number of phage virions. In vivo, BUCT700 significantly increased the survival rate of S. maltophilia-infected Galleria mellonella (G. mellonella) larvae from 0% to 100% within 72 h, especially in the prophylactic model. In conclusion, these findings indicate that phage BUCT700 has promising potential for clinical application either as a prophylactic or therapeutic agent.IMPORTANCE The risk of Stenotrophomonas maltophilia infections mediated by the medical devices is exacerbated with an increase in the number of ICU patients during the Corona Virus Disease 2019 (COVID-19) epidemic. Complications caused by S. maltophilia infections could complicate the state of an illness, greatly extending the length of hospitalization and increasing the financial burden. Phage therapy might be a potential and promising alternative for clinical treatment of multidrug-resistant bacterial infections. Here, we investigated the protective effects of phage BUCT700 as prophylactic and therapeutic agents in Galleria mellonella models of infection, respectively. This study demonstrates that phage therapy can provide protection in targeting S. maltophilia-related infection, especially as prophylaxis. The risk of Stenotrophomonas maltophilia infections mediated by the medical devices is exacerbated with an increase in the number of ICU patients during the Corona Virus Disease 2019 (COVID-19) epidemic. Complications caused by S. maltophilia infections could complicate the state of an illness, greatly extending the length of hospitalization and increasing the financial burden.",2023
FORMATION OF PARTNERSHIP STAKEHOLDER RELATIONS AT CONSTRUCTION ENTERPRISES: ORGANIZATIONAL AND ECONOMIC ASPECTS,"The urgency of forming partner stakeholder relations at construction enterprises (BP) in the conditions of slow growth or decrease of the main indicators of the state functioning, negative influence of external and internal factors, unstable socio-economic and political situation in the state is determined. It is proved that in the construction sector there are processes of slowing down the index of construction products with increasing total area of residential and non-residential buildings. Based on the study of theoretical and methodological provisions, formed approaches to the definition of stakeholders: functional; structural; process; an approach based on identifying threats affecting stakeholders; strategic; social; retrospective; complex; resource. Sound approaches allowed to propose the definition of stakeholders of construction companies, which are characterized as individuals and (or) legal entities or groups of persons interacting in the construction sector on the basis of strategic contours and social directions and determined by functional, resultant, structural, process, strategic, complex features. the relationship of which has a certain level of risk and threat, which allows to form a contractual relationship in capital construction, to carry out architectural control, appropriate calculations, provided by the project documentation, material and labor resources. The types of stakeholders of construction companies are identified based on the characteristics of internal and external stakeholders interacting with construction companies, which allowed to form economic and organizational support for the formation and implementation of stakeholder relations and build a quantitative basis for sound management decisions to strengthen their financial condition. A quantitative basis for the creation and development of stakeholder partnerships has been formed.",2021
Predicting soil ecological criteria of 17 metal(loid)s in China based on quantitative ion character-activity relationship - Species sensitivity distribution (QICAR-SSD) coupled model,"Soil pollution caused by metal(loid)s is increasingly serious and poses unexpected risks to terrestrial organisms. Establishing soil quality standards is essential for assessing ecological risks of metal(loid)s and protecting soil ecosystems. However, the limited availability of metal(loid) ecotoxicological data has hampered the development of soil quality standards due to financial and practical constraints on toxicity testing. This study collected 77 normalization equations and 58 cross-species extrapolation equations to calculate the normalized EC10 (the added concentration causing a 10 % inhibition effect) of metal(loid)s under a representative scenario. A set of quantitative ion character-activity relationship (QICAR) models were then constructed using normalized EC10 and nine critical ionic characters (AR, AR/AW, BP, MP, Z/r(2), Z/r, Xm, sigma p, and |Log(K-OH)|). Subsequently, these QICAR models were employed to predict ecotoxicological EC10 of 17 metal(loid)s to 12 soil species and coupled with species sensitivity distribution (SSD) to determine Predicted No Effect Concentration (PNEC). The results demonstrated the coupled QICAR-SSD model could effectively derive terrestrial PNEC for data-poor metal(loid)s, with errors between the predicted PNEC and reported soil standards (excluding soil background levels) from different countries mostly <0.3 orders of magnitude. Finally, soil ecological criteria (SEC) for 17 metal(loid)s were calculated using an added risk approach based on PNEC and national soil background concentration. Overall, the coupled model proposed here can provide a valuable supplement to the development of soil quality standards for numerous metal(loid)s in soil components.",2024
Genome-wide Association Studies of Retinal Vessel Tortuosity Identify Numerous Novel Loci Revealing Genes and Pathways Associated With Ocular and Cardiometabolic Diseases,"Purpose: To identify novel susceptibility loci for retinal vascular tortuosity, to better understand the molecular mechanisms modulating this trait, and reveal causal relationships with diseases and their risk factors. Design: Genome-wide Association Studies (GWAS) of vascular tortuosity of retinal arteries and veins followed by replication meta-analysis and Mendelian randomization (MR). Participants: We analyzed 116 639 fundus images of suitable quality from 63 662 participants from 3 cohorts, namely the UK Biobank (n = 62 751), the Swiss Kidney Project on Genes in Hypertension (n = 397), and Methods: Using a fully automated retina image processing pipeline to annotate vessels and a deep learning algorithm to determine the vessel type, we computed the median arterial, venous and combined vessel tortuosity measured by the distance factor (the length of a vessel segment over its chord length), as well as by 6 alternative measures that integrate over vessel curvature. We then performed the largest GWAS of these traits to date and assessed gene set enrichment using the novel high-precision statistical method PascalX. Main Outcome Measure: We evaluated the genetic association of retinal tortuosity, measured by the distance factor. Results: Higher retinal tortuosity was significantly associated with higher incidence of angina, myocardial infarction, stroke, deep vein thrombosis, and hypertension. We identified 175 significantly associated genetic loci in the UK Biobank; 173 of these were novel and 4 replicated in our second, much smaller, metacohort. We estimated heritability at w25% using linkage disequilibrium score regression. Vessel type specific GWAS revealed 116 loci for arteries and 63 for veins. Genes with significant association signals included COL4A2, ACTN4, LGALS4, LGALS7, LGALS7B, TNS1, MAP4K1, EIF3K, CAPN12, ECH1, and SYNPO2. These tortuosity genes were overexpressed in arteries and heart muscle and linked to pathways related to the structural properties of the vasculature. We demonstrated that retinal tortuosity loci served pleiotropic functions as cardiometabolic disease variants and risk factors. Concordantly, MR revealed causal effects between tortuosity, body mass index, and low-density lipoprotein. Conclusions: Several alleles associated with retinal vessel tortuosity suggest a common genetic architecture of this trait with ocular diseases (glaucoma, myopia), cardiovascular diseases, and metabolic syndrome. Our results shed new light on the genetics of vascular diseases and their pathomechanisms and highlight how GWASs and heritability can be used to improve phenotype extraction from high-dimensional data, such as images. Financial Disclosure(s): The author(s) have no proprietary or commercial interest in any materials discussed in this article. Ophthalmology Science 2023;3:100288 & COPY; 2023 by the American Academy of Ophthalmology. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).",2023
Effect of birthplace on cardiometabolic risk among blacks in the Metabolic Syndrome Outcome Study (MetSO),"Background: Metabolic syndrome poses an increased global burden of disease and causes immense financial burden, warranting heightened public health attention. The present study assessed the prevalence and severity of cardiometabolic risk among foreign-born versus US-born blacks, while exploring potential gender-based effects. Methods: A total of 1035 patients from the Metabolic Syndrome Outcome Study (Trial registration: NCT01946659) provided sociodemographic, medical history, and clinical data. General Linear Model (GLM) was used to assess the effects of birthplace and gender on cardiometabolic parameters, adjusting for age differences in the sample. Results: Of the sample, 61.6 % were foreign-born blacks (FBB) and 38.4 % were US-born blacks (USB). FBB had significantly lower BMI compared with USB (32.76 +/- 0.35 vs. 35.41 +/- 0.44, F = 22.57), but had significantly higher systolic blood pressure (136.70 +/- 0.77 vs. 132.83 +/- 0.98; F = 9.60) and fasting glucose levels than did USB (146.46 +/- 3.37 vs. 135.02 +/- 4.27; F = 4.40). Men had higher diastolic BP (76.67 +/- 0.65 vs. 75.05 +/- 0.45; F = 4.20), glucose (146.53 +/- 4.48 vs. 134.95 +/- 3.07; F = 4.55) and triglyceride levels (148.10 +/- 4.51 vs. 130.60 +/- 3.09; F = 10.25) compared with women, but women had higher LDL-cholesterol (109.24 +/- 1.49 vs. 98.49 +/- 2.18; F = 16.60) and HDL-cholesterol levels (50.71 +/- 0.66 vs. 42.77 +/- 0.97; F = 46.01) than did men. Conclusions: Results showed that birthplace has a significant influence on cardiometabolic profiles of blacks with metabolic syndrome. Patients' gender also had an independent influence on cardiometabolic profile.",2016
"` An analysis from the Quality Outcomes Database, Part 2. Predictive model for return to work after elective surgery for lumbar degenerative disease","OBJECTIVE Current costs associated with spine care are unsustainable. Productivity loss and time away from work for patients who were once gainfully employed contributes greatly to the financial burden experienced by individuals and, more broadly, society. Therefore, it is vital to identify the factors associated with return to work (RTW) after lumbar spine surgery. In this analysis, the authors used data from a national prospective outcomes registry to create a predictive model of patients' ability to RTW after undergoing lumbar spine surgery for degenerative spine disease. METHODS Data from 4694 patients who underwent elective spine surgery for degenerative lumbar disease, who had been employed preoperatively, and who had completed a 3-month follow-up evaluation, were entered into a prospective, multicenter registry. Patient-reported outcomes Oswestry Disability Index (ODI), numeric rating scale (NRS) for back pain (BP) and leg pain (LP), and EQ-5D scores were recorded at baseline and at 3 months postoperatively. The time to RTW was defined as the period between operation and date of returning to work. A multivariable Cox proportional hazards regression model, including an array of preoperative factors, was fitted for RTW. The model performance was measured using the concordance index (c-index). RESULTS Eighty-two percent of patients (n = 3855) returned to work within 3 months postoperatively. The risk-adjusted predictors of a lower likelihood of RTW were being preoperatively employed but not working at the time of presentation, manual labor as an occupation, worker's compensation, liability insurance for disability, higher preoperative ODI score, higher preoperative NRS-BP score, and demographic factors such as female sex, African American race, history of diabetes, and higher American Society of Anesthesiologists score. The likelihood of a RTW within 3 months was higher in patients with higher education level than in those with less than high school level education. The c-index of the model's performance was 0.71. CONCLUSIONS This study presents a novel predictive model for the probability of returning to work after lumbar spine surgery. Spine care providers can use this model to educate patients and encourage them in shared decision-making regarding the RTW outcome. This evidence-based decision support will result in better communication between patients and clinicians and improve postoperative recovery expectations, which will ultimately increase the likelihood of a positive RTW trajectory.",2017
"Quant 4.0: engineering quantitative investment with automated, explainable, and knowledge-driven artificial intelligence","Quantitative investment (abbreviated as quant in this paper) is an interdisciplinary field combining financial engineering, computer science, mathematics, statistics, etc. Quant has become one of the mainstream investment methodologies over the past decades, and has experienced three generations: quant 1.0, trading by mathematical modeling to discover mis-priced assets in markets; quant 2.0, shifting the quant research pipeline from small strategy workshops to large alpha factories; quant 3.0, applying deep learning techniques to discover complex nonlinear pricing rules. Despite its advantage in prediction, deep learning relies on extremely large data volume and labor-intensive tuning of black-box neural network models. To address these limitations, in this paper, we introduce quant 4.0 and provide an engineering perspective for next-generation quant. Quant 4.0 has three key differentiating components. First, automated artificial intelligence (AI) changes the quant pipeline from traditional hand-crafted modeling to state-of-the-art automated modeling and employs the philosophy of algorithm produces algorithm, model builds model, and eventually AI creates AI. Second, explainable AI develops new techniques to better understand and interpret investment decisions made by machine learning black boxes, and explains complicated and hidden risk exposures. Third, knowledge-driven AI supplements data-driven AI such as deep learning and incorporates prior knowledge into modeling to improve investment decisions, in particular for quantitative value investing. Putting all these together, we discuss how to build a system that practices the quant 4.0 concept. We also discuss the application of large language models in quantitative finance. Finally, we propose 10 challenging research problems for quant technology, and discuss potential solutions, research directions, and future trends. (sic)(sic)(sic)(sic)(quant)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic),(sic)(sic)(sic)(sic)(sic),(sic)(sic),(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic). (sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic): (sic)(sic)(sic)(sic)(sic)(sic)(sic)(quant 1.0)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic); (sic)(sic)(sic)(sic)(sic)(sic)(sic)(quant 2.0)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)alpha(sic)(sic); (sic)(sic)(sic)(sic)(sic)(sic)(sic)(quant 3.0)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic). (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic). (sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)quant 4.0(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic). Quant 4.0(sic)3(sic)(sic)(sic)(sic)(sic)(sic)(sic). (sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(AI)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic), AI(sic)(sic)AI(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic). (sic)(sic), (sic)(sic)(sic)AI(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic). (sic)(sic), (sic)(sic)(sic)(sic)AI(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)AI(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic). (sic)(sic), (sic)(sic)(sic)(sic)3(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)quant 4.0(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic). (sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic). (sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)10(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic),(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).",2024
"Prevalence, awareness, treatment, and control of hypertension in rural adults from Liaoning Province, northeast China","Liaoning Province is located in northeast China, which has distinct weather conditions, geographic characteristics and lifestyles compared with other regions of the country; the lifestyle differences are especially pronounced in the rural parts of this region, where there is a dearth of financial and other resources. However, information on the prevalence, awareness, treatment, and control of hypertension in these impoverished areas is very scarce. We therefore performed multistage cluster random sampling of a group of 29,970 adult residents (>= 5 years of residency; >= 35 years of age) of the rural portions of Liaoning Province from 2005 to 2006. The sampling included a survey on blood pressure and associated risk factors. The overall prevalence of hypertension in the community was 36.2%, and 73.0% of hypertensives were unaware of their condition. Among the total group of hypertensives, only 19.8% were taking prescribed medication to lower their BP, and 0.9% had controlled hypertension. Of all subjects, 46.4% did not think that high blood pressure would endanger their lives. As to the reasons given by hypertensives who were aware of their hypertension for not taking antihypertensive medication, 47.4% reported that they lacked knowledge about the mortality of hypertension. The average salt intake in hypertensives was 16.6 +/- 9.9 g/day, and the percentages of smoking (44.3%), drinking (31.7%) and salt intake >6 g/day (86.8%) in hypertensives were high. Logistic regression analysis indicated that the relative risks (95% confidence interval [CI]) of overweight, obesity, smoking, drinking, increased salt intake and family history of hypertension for hypertension were 1.95 (range, 1.82-2.08), 2.92 (2.40-3.55), 1.19 (1.12-1.27), 1.16 (1.08-1.25), 1.26 (1.20-1.33) and 2.85 (2.66-3.05), respectively. A higher education level was found to be a protective factor. In conclusion, the prevalence of hypertension in adults living in the rural parts of Liaoning Province was high, and the rates of awareness, treatment, and control were unacceptably low, which may have been due to unique geographical characteristics, unwholesome lifestyles, greater sodium intake, lower education levels, and genetic risk factors.",2007
Strategies for generating synthetic computed tomography-like imaging from radiographs: A scoping review,"Background: Advancements in tomographic medical imaging have revolutionized diagnostics and treatment monitoring by offering detailed 3D visualization of internal structures. Despite the significant value of computed tomography (CT), challenges such as high radiation dosage and cost barriers limit its accessibility, especially in low- and middle-income countries. Recognizing the potential of radiographic imaging in reconstructing CT images, this scoping review aims to explore the emerging field of synthesizing 3D CT-like images from 2D radiographs by examining the current methodologies. Methods: A scoping review was carried out following PRISMA-SR guidelines. Eligibility criteria for the articles included full-text articles published up to September 9, 2024, studying methodologies for the synthesis of 3D CT images from 2D biplanar or four-projection x-ray images. Eligible articles were sourced from PubMed MEDLINE, Embase, and arXiv. Results: 76 studies were included. The majority (50.8 %, n = 30) were published between 2010 and 2020 (38.2 %, n = 29) and from 2020 onwards (36.8 %, n = 28), with European (40.8 %, n = 31), North American (26.3 %, n = 20), and Asian (32.9 %, n = 25) institutions being primary contributors. Anatomical regions varied, with 17.1 % (n = 13) of studies not using clinical data. Further, studies focused on the chest (25 %, n = 19), spine and vertebrae (17.1 %, n = 13), coronary arteries (10.5 %, n = 8), and cranial structures (10.5 %, n = 8), among other anatomical regions. Convolutional neural networks (CNN) (19.7 %, n = 15), generative adversarial networks (21.1 %, n = 16) and statistical shape models (15.8 %, n = 12) emerged as the most applied methodologies. A limited number of studies included explored the use of conditional diffusion models, iterative reconstruction algorithms, statistical shape models, and digital tomosynthesis. Conclusion: This scoping review summarizes current strategies and challenges in synthetic imaging generation. The development of 3D CT-like imaging from 2D radiographs could reduce radiation risk while simultaneously addressing financial and logistical obstacles that impede global access to CT imaging. Despite initial promising results, the field encounters challenges with varied methodologies and frequent lack of proper validation, requiring further research to define synthetic imaging's clinical role.",2025
TriXY-Homogeneous genetic sexing of highly degraded forensic samples including hair shafts,"Sexing of biological evidence is an important aspect in forensic investigations. A routinely used molecular-genetic approach to this endeavour is the amelogenin sex test, which is integrated in most commercially available polymerase chain reaction (PCR) kits for human identification. However, this assay is not entirely effective in respect to highly degraded DNA samples. This study presents a homogeneous PCR assay for robust sex diagnosis, especially for the analysis of severely fragmented DNA. The introduced triplex for the X and Y chromosome (TriXY) is based on real-time PCR amplification of short intergenic sequences (< 50 bp) on both gonosomes. Subsequent PCR product examination and molecular-genetic sex-assignment rely on high-resolution melting (HRM) curve analysis. TriXY was optimized using commercially available multi-donor human DNA preparations of either male or female origin and successfully evaluated on challenging samples, including 46 ancient DNA specimens from archaeological excavations and a total of 16 DNA samples extracted from different segments of eight hair shafts of male and female donors. Additionally, sensitivity and cross-species amplification were examined to further test the assay's utility in forensic investigations. TriXY's closed-tube format avoids post-PCR sample manipulations and, therefore, distinctly reduces the risk of PCR product carry-over contamination and sample mix-up, while reducing labour and financial expenses at the same time. The method is sensitive down to the DNA content of approximately two diploid cells and has proven highly useful on severely fragmented and low quantity ancient DNA samples. Furthermore, it even allowed for sexing of proximal hair shafts with very good results. In summary, TriXY facilitates highly sensitive, rapid, and costeffective genetic sex-determination. It outperforms existing sexing methods both in terms of sensitivity and minimum required template molecule lengths. Therefore, we feel confident that TriXY will prove to be a reliable addition to the toolbox currently used for sex-typing in forensic genetics and other fields of research. (C) 2016 Elsevier Ireland Ltd. All rights reserved.",2016
AI predictive models and advancements in microdissection testicular sperm extraction for non-obstructive azoospermia: a systematic scoping review,"STUDY QUESTION How accurately can artificial intelligence (AI) models predict sperm retrieval in non-obstructive azoospermia (NOA) patients undergoing micro-testicular sperm extraction (m-TESE) surgery?SUMMARY ANSWER AI predictive models hold significant promise in predicting successful sperm retrieval in NOA patients undergoing m-TESE, although limitations regarding variability of study designs, small sample sizes, and a lack of validation studies restrict the overall generalizability of studies in this area.WHAT IS KNOWN ALREADY Previous studies have explored various predictors of successful sperm retrieval in m-TESE, including clinical and hormonal factors. However, no consistent predictive model has yet been established.STUDY DESIGN, SIZE, DURATION A comprehensive literature search was conducted following PRISMA-ScR guidelines, covering PubMed and Scopus databases from 2013 to 15 May 2024. Relevant English-language studies were identified using Medical Subject Headings (MeSH) terms. We also used PubMed's 'similar articles' and 'cited by' features for thorough bibliographic screening to ensure comprehensive coverage of relevant literature.PARTICIPANTS/MATERIALS, SETTING, METHODS The review included studies on patients with NOA where AI-based models were used for predicting m-TESE outcomes, by incorporating clinical data, hormonal levels, histopathological evaluations, and genetic parameters. Various machine learning and deep learning techniques, including logistic regression, were employed. The Prediction Model Risk of Bias Assessment Tool (PROBAST) evaluated the bias in the studies, and their quality was assessed using the Transparent Reporting of a Multivariable Prediction Model for Individual Prognosis or Diagnosis (TRIPOD) guidelines, ensuring robust reporting standards and methodological rigor.MAIN RESULTS AND THE ROLE OF CHANCE Out of 427 screened articles, 45 met the inclusion criteria, with most using logistic regression and machine learning to predict m-TESE outcomes. AI-based models demonstrated strong potential by integrating clinical, hormonal, and biological factors. However, limitations of the studies included small sample sizes, legal barriers, and challenges in generalizability and validation. While some studies featured larger, multicenter designs, many were constrained by sample size. Most studies had a low risk of bias in participant selection and outcome determination, and two-thirds were rated as low risk for predictor assessment, but the analysis methods varied.LIMITATIONS, REASONS FOR CAUTION The limitations of this review include the heterogeneity of the included research, potential publication bias and reliance on only two databases (PubMed and Scopus), which may limit the scope of the findings. Additionally, the absence of a meta-analysis prevents quantitative assessment of the consistency of models. Despite this, the review offers valuable insights into AI predictive models for m-TESE in NOA.WIDER IMPLICATIONS OF THE FINDINGS The review highlights the potential of advanced AI techniques in predicting successful sperm retrieval for NOA patients undergoing m-TESE. By integrating clinical, hormonal, histopathological, and genetic factors, AI models can enhance decision-making and improve patient outcomes, reducing the number of unsuccessful procedures. However, to further enhance the precision and reliability of AI predictions in reproductive medicine, future studies should address current limitations by incorporating larger sample sizes and conducting prospective validation trials. This continued research and development is crucial for strengthening the applicability of AI models and ensuring broader clinical adoption.STUDY FUNDING/COMPETING INTEREST(S) The authors would like to acknowledge Mashhad University of Medical Sciences, Mashhad, Iran, for financial support (Grant ID: 4020802). The authors declare no competing interests.REGISTRATION NUMBER N/A.",2025
Predicting Estuarine Algal Blooms Utilising Neural Network Modelling-A Preliminary Investigation,"Algal blooms are prevalent within the Berowra Estuary. When algal species are present in high numbers they pose serious problems for commercial and recreational users of the estuary. Management authorities require an understanding of the relationship between the incidence of algal blooms and the environmental conditions required to initiate and promote these populations. An Artificial Neural Network (ANN) is currently being developed to predict the occurrence and risk of algal blooms within the Berowra Estuary. Modelling the algal dynamics for this project is based on a unique data set, for South Eastern Australia, obtained from a deployed probe which monitors Chlorophyll-a (Chl-a), temperature and salinity at 15 minute intervals. Distinguishing features of the present study are that it is being conducted in an estuarine environment with prediction horizons of the order of hours to several weeks. This is in contrast to previous studies which are more commonly set within freshwater environments with the relevant time scales ranging from biweekly to seasonal. Preliminary network development for this project has utilised the back-propagation training algorithm and the sigmoid activation function. A multilayer perceptron architecture containing an input, hidden and output layer was selected. Data pre-processing and division into training, selection and test subsets occurred prior to being incorporated into the network. Prediction outputs have been generated which aim to provide predictions for 1, 3 and 7 days in advance. Preliminary analysis of the data indicates the best predictive results (i.e. lowest selection error) are obtained with models with the lowest number of variables. Specifically, time-lagged Chl-a concentrations provide the best data set from which a prediction is made. This suggests initially that antecedent algal concentrations within the previous week are the most significant variable to be used when predicting future Chl-a levels. However, it is acknowledged that with further refinement of internal network geometries and potential alteration to the data preprocessing techniques this may not be the case. This paper outlines initial model results and compares each individual model on its predictive ability whilst maintaining constant internal model geometries between models. Future improvements to the models developed in this paper are expected. Prediction of Chl-a within the estuarine environment is a suitable application of ANNs. This predictive tool provides opportunities for proactive rather than reactive management regimes with regard to mitigating the effects of estuarine algal blooms. Essential to the implementation and adoption of a proactive strategy is the requirement for a specified degree of certainty in the model outputs, an understanding of problematic algal concentrations and their duration. These requirements are essential to ensure logistics staff and financial support are maintained for an algal bloom early warning system.",2005
"Enterprise generative artificial intelligence technologies, Internet of Things and blockchain-based fintech management, and digital twin industrial metaverse in the cognitive algorithmic economy","Research background: Enterprise generative AI system-based worker behavior tracking and monitoring, socially responsible organizational practices, employee performance management satisfaction, and human resource management procedures, relationships, and outcomes develop on hiring and objective performance assessment algorithms in terms of human resource management activities, functions, processes, practices, policies, and productivity. Deep reinforcement and machine learning techniques, operational and analytical generative AI and cloud capabilities, and real-time anomalous behavior recognition systems further fintech development for credit and lending services, payment analytics processes, and risk assessment, monitoring, and mitigation. Generative AI tools can bolster predictive analytics by collaborative and interconnected sensor and machine data for tailored, seamless, and finetuned product, operational process, and organizational workflow development, efficiency, and innovation, driving agile transformative changes in digital twin industrial metaverse. Purpose of the article: We show that enterprise generative AI-driven schedule prediction tools, job search and algorithmic hiring systems, and synthetic training data can improve team selection, job performance and firing decisions, hiring decision processes, and workforce productivity in terms of prediction and decision-making by use of algorithmic management, system performance, and production process tracking tools. Blockchain-based fintech operations can shape cloud-based financial and digital banking services, quote-to-cash process automation, cash-settled crypto futures, digital loan decisioning, asset tokenization simulated transactions, transaction switching and routing operations, tailored peer-to-peer lending, and proactive credit line management. Collaborative unstructured enterprise data processing, infrastructure, and governance can develop on AI decision and behavior automation technology, retrieval augmented generation and development management systems, and real-time data descriptive and predictive analytics, driving productivity surges and competitive advantage in digital twin industrial metaverse. Methods: Reference and review management tools, together with evidence synthesis screening software, harnessed were Abstrackr, AMSTAR, ASReview Lab, CASP, Catchii, Citation- chaser, DistillerSR, JBI SUMARI, Litstream, PICO Portal, and Rayyan. Findings & value added: The current state of the art is improved for theory on organizational issues and for policy making as deep learning-based generative AI tools and workplace monitoring systems can augment performance and productivity, gauge employee effectiveness, build resilient, satisfied, and engaged workforce, assess human capital, skill, and career development, drive employee and productivity expectations in relation to flexibility and stability, and shape turnover, retention, and loyalty. Cloud and account servicing technologies can be deployed in generative AI fintechs for embedded cryptocurrency trading, transaction moni toring and processing, digital asset transfers, payment screening, corporate and retail banking operations, and fraud prevention. Generative AI technologies can reshape jobs and reimagine meaningful work, involving creativity and innovation and adaptable and resilient sustained performance, providing valuable constructive feedback, optimizing workplace flexibility and psychological safety, and measuring and supporting autonomy and flexibility-based efficien- cy, performance, and productivity, while configuring demanding, engaging, and rewarding experiences by cloud and edge computing devices in digital twin industrial metaverse.",2024
Prediction of cryptocurrency's price using ensemble machine learning algorithms,"Purpose - Cryptocurrency markets are gaining popularity, with over 23,000 cryptocurrencies in 2023 and a total market valuation of 870.81 billion USD in 2023. With its increasing popularity, cryptocurrencies are also susceptible to volatility. Predicting the price with the least fallacy or more accuracy has become the need of the hour as it significantly influences investment decisions. Design/methodology/approach - This study aims to create a dynamic forecasting model using the ensemble method and test the forecasting accuracy of top 15 cryptocurrencies' prices. Statistical and econometric model prediction accuracy is examined after hyper tuning the parameters. Drawing inferences from the statistical model, an ensemble model using machine learning (ML) algorithms is developed using gradient-boosted regressor (GBR), random forest regressor (RFR), support vector regression (SVR) and multi-layer perceptron (MLP). Validation curves are utilized to optimize model parameters and boost prediction accuracy. Findings - It is found that when the price movement exhibits autocorrelation, the autoregressive integrated moving average (ARIMA) model and the ensemble model performed better. ARIMA, simple linear regression (SLR), random forest (RF), decision tree (DT), gradient boosting (GB) and multi-model regression (MLR) ensemble models performed well with coins, showing that trends, seasonality and historical price patterns are prominent. Furthermore, the MLR approach produces more accurate predictions for coins with higher volatility and irregular price patterns. Research limitations/implications - Although the dataset includes crisis period data, anomalies or outliers are yet to be explicitly excluded from the analysis. The models employed in this study still demonstrate high accuracy in predicting cryptocurrency prices despite these outliers, suggesting that the models are robust enough to handle unexpected fluctuations or extreme events in the market. However, the lack of specific analysis on the impact of outliers on model performance is a limitation of the study, as it needs to fully explore the resilience of the forecasting models under adverse market conditions. Practical implications - The present study contributes to the body of literature on ensemble methods in forecasting crypto price in general, potentially influencing future studies on price forecasting. The study motivates the researchers on empirical testing of our framework on various asset classes. As a result, on the prediction ability of ensemble model, the study will significantly influence the decision-making process of traders and investors. The research benefits the traders and investors to effectively develop a model to forecast cryptocurrency price. The findings highlight the potential of ensemble model in predicting high volatile cryptocurrencies and other financial assets. Investors can design the investment strategies and asset allocation decisions by understanding the relationship between market trends and consumer behavior. Investors can enhance portfolio performance and mitigate risk by incorporating these insights into their decision-making processes. Policymakers can use this information to design more effective regulations and policies promoting economic stability and consumer welfare. The study emphasizes the need for using diversified model to understand the market dynamics and improving trading strategies. Originality/value - This research, to the best of our knowledge, is the first to use the above models to develop an ensemble model on the data for which the outliers have not been adjusted, and the model still outperformed the other statistical, econometric, ML and deep learning (DL) models.",2025
GUIDANCE ON IN LINE INSPECTION FIRST RUN SUCCESS,"First run success is a key performance measure used in the BP Global In Line Inspection (ILI) Contract [1]. This drives effectiveness and efficiency in the processes supporting ILI and it is a key commercial performance indicator for ILI Suppliers. Although run success rates are often referred to across the industry there has been little standardisation in the terminology, or the factors that lead to a successful run. Three definitions have been established for run success: Technical; Commercial and Operational. Each has a place although it is Operational run success that drives improvements between operators and suppliers. The introduction of a performance measure for first run success increases the focus on getting things right the first time. The financial cost of ILI run failure has probably been underestimated by the industry; although it is estimated that it could be as high as 30% of total contracted costs for ILI. For some projects the costs associated with a failed run can be far greater than the original project costs (e.g. additional vessel support costs for deployment or recovery during offshore operations). A failed run can also result in a delayed inspection and an associated increased risk as well as potentially compromising compliance with regulatory requirements. The consequences of run failure vary in severity and can be presented in a pyramid similar to the typical representation of safety statistics. A stuck tool requiring intervention or a pipeline failure, as a result of an incorrect inspection report, would be at the top of the pyramid. The lower tiers would capture technical failures and the effectiveness of cleaning. Understanding the consequence of failures can help drive performance improvements across the industry. As part of the BP continuous improvement process, ILI Suppliers and internal stakeholders were brought together for a facilitated workshop to understand the factors affecting first run success rates. The workshop identified a number of common themes which were consistent across all of the Suppliers addressing; both operational issues and tool performance. A Guidance Note was then developed with the ILI Suppliers to drive improvements in first run success rates. This was shared with the Pipeline Operators Forum (POE) in October 2011 and has been further developed as a POF Guidance Document. A separate guidance note has been developed to address recommended practices for collecting and verifying field data. Successful ILI requires good communication between all parties. As the industry starts to inspect more difficult and challenging lines it will be important to improve ILI run success rates. Across the industry we probably know how to do it, but doing it consistently is the challenge. The development of industry Guidance Notes represent a small step towards achieving this objective. As ILI operations improve the focus will increasingly turn to the reliability of tools. There is much that can be learnt from other industry sectors, such as the motor or aviation industry, on improving reliability of components and systems. This will require an increased use of preventative maintenance practices. There is also a need to create a common basis for reporting reliability of inspection tools and for this to be taken into account when operators make their selection of ILI tools. The Global ILI Contract has brought an increased focus to the performance of the overall inspection process which is driving improvements in first run success rates. It has facilitated the development of guidelines on best practice and is starting to set standards for reliability. The high level of cooperation between suppliers and operators to drive improvements in this area is a measure of the importance of first run success rates to all parts of our industry. Achieving ILI first run success requires both the operator and ILI supplier to work together. Whilst each has a key part to play effective communication from an early stage is essential.",2013
Reinfection of farm dogs following praziquantel treatment in an endemic region of cystic echinococcosis in southeastern Iran,"Cystic Echinococcosis (CE) as a prevalent tapeworm infection of human and herbivorous animals worldwide, is caused by accidental ingestion of Echinococcus granulosus eggs excreted from infected dogs. CE is endemic in the Middle East and North Africa, and is considered as an important parasitic zoonosis in Iran. It is transmitted between dogs as the primary definitive host and different livestock species as the intermediate hosts. One of the most important measures for CE control is dog deworming with praziquantel. Due to the frequent reinfection of dogs, intensive deworming campaigns are critical for breaking CE transmission. Dog reinfection rate could be used as an indicator of the intensity of local CE transmission in endemic areas. However, our knowledge on the extent of reinfection in the endemic regions is poor. The purpose of the present study was to determine E. granulosus reinfection rate after praziquantel administration in a population of owned dogs in Kerman, Iran. A cohort of 150 owned dogs was recruited, with stool samples collected before praziquantel administration as a single oral dose of 5 mg/kg. The re-samplings of the owned dogs were performed at 2, 5 and 12 months following initial praziquantel administration. Stool samples were examined microscopically using Willis flotation method. Genomic DNA was extracted, and E. granulosus sensu lato-specific primers were used to PCR-amplify a 133-bp fragment of a repeat unit of the parasite genome. Survival analysis was performed using Kaplan-Meier method to calculate cumulative survival rates, which is used here to capture reinfection dynamics, and monthly incidence of infection, capturing also the spatial distribution of disease risk. Results of survival analysis showed 8, 12 and 17% total reinfection rates in 2, 5 and 12 months following initial praziquantel administration, respectively, indicating that 92, 88 and 83% of the dogs had no detectable infection in that same time periods. The monthly incidence of reinfection in total owned dog population was estimated at 1.5% (95% CI 1.0-2.1). The results showed that the prevalence of echinococcosis in owned dogs, using copro-PCR assay was 42.6%. However, using conventional microscopy, 8% of fecal samples were positive for taeniid eggs. Our results suggest that regular treatment of the dog population with praziquantel every 60 days is ideal, however the frequency of dog dosing faces major logistics and cost challenges, threatening the sustainability of control programs. Understanding the nature and extent of dog reinfection in the endemic areas is essential for successful implementation of control programs and understanding patterns of CE transmission. Cystic echinococcosis (CE), caused by the small tapeworm of dogs, Echinococcus granulosus, is considered as a prevalent zoonotic infection of human and livestock worldwide. Dogs play a crucial role in the parasite life cycle, serving as definitive hosts for the tapeworm and contributing to the transmission of the disease to humans and other livestock.Praziquantel (PZQ) dosing of dogs is proposed as one of the main elements of CE control programs. Frequent PZQ dosing is required because of reinfection of farm dogs following feeding offal to them and this presents major logistic and financial problems. The frequency of PZQ dosing is dependent on the rate of dog reinfection in each endemic region. We explored the significance of farm dogs reinfection in an endemic area in southeastern Iran, to provide better understanding of CE transmission and developing effective control programs.We monitored a cohort of 150 dogs previously treated for cystic echinococcosis by praziquantel. We showed that the prevalence of echinococcosis in the farm dogs, using PCR assay was 42.6% before praziquantel administration. To our surprise, a significant proportion of these dogs, approximately 17%, experienced reinfection with E. granulosus, 12 months following initial praziquantel administration. This finding was both alarming and informative. Our study emphasized the importance of responsible dog ownership behavior and proper disposal of livestock offal in endemic areas.",2024
"Research on multimorbidity in primary care. Selected abstracts from the EGPRN meeting in Tampere, Finland, 9-12 May 2019 All abstracts of the conference can be found at the EGPRN website: www.egprn.org/page/conference-abstracts","Current primary care in Finland is based on the Primary Health Care Act (1972), which addressed numerous new tasks to all municipalities. All of them had to find a new health centre organization, which provides a wide range of health services, including prevention and public health promotion. Multiple tasks require multiprofessional staff, and thus, the Finnish health centre personnel consisted not only of GPs but of public health nurses, midwives, physiotherapists, psychologists, social workers, dentists, etc. During the next decade, there have been some changes but the idea of multiprofessional structure has remained. According to the QUALICOPC study (2012) Finnish GPs are still co-located with several other healthcare professionals compared to most of the European countries; even compared to other Nordic countries which otherwise have many similarities in their primary healthcare. During the last 10 or 15 years, healthcare providers and researchers have recognized a new challenge: our current systems do not meet the needs of patients with multiple health and social problems-and the proportion of these patients is increasing all the time as the population is getting older. One could suppose that preconditions of handling multimorbidity would be excellent in multiprofessional surroundings like ours, but actually, a person with multiple problems is a challenge there, too. Multiprofessional organization in primary care does not guarantee proper care of patients with multiple diseases, if we do not acknowledge the challenge and revise our systems. We have to develop new ways of collaboration and new models of integrated care. The problematic part is secondary care, which is organized with logic of one medical speciality per visit. In Tampere University Hospital district, we have created a care pathway model, which defines the roles of primary healthcare and secondary care. Nationwide, we have recently started to prepare national guidelines for the care of patients with multimorbidity. What we need more in the future is more research on new practices and models. Background: Most patients with antihypertensive medication do not achieve their blood pressure (BP) target. Several barriers to successful hypertension treatment are well identified but we need novel ways of addressing them. Research question: Can using a checklist improve the quality of care in the initiation of new antihypertensive medication? Methods: This non-blinded, cluster-randomized, controlled study was conducted in eight primary care study centres in central Finland, randomized to function as either intervention (n = 4) or control sites (n = 4). We included patients aged 30-75 years who were prescribed antihypertensive medication for the first time. Initiation of medication in the intervention group was carried out with a nine-item checklist, filled in together by the treating physician and the patient. The treating physician managed hypertension treatment in the control group without a study-specific protocol. Results: In total, 119 patients were included in the study, of which 118 were included in the analysis (n = 59 in the control group, n = 59 in the intervention group). When initiating medication, an adequate BP target was set for 19% of the patients in the control group and for 68% in the intervention group. Shortly after the appointment, only 14% of the patients in the control group were able to remember the adequate BP target, compared with 32% in the intervention group. The use of the checklist was also related to more regular agreement on the next follow-up appointment (64% in the control group vs 95% in the intervention group). Conclusion: Even highly motivated new hypertensive patients in Finnish primary care have significant gaps in their treatment-related skills. The use of a checklist for initiation of antihypertensive medication was related to substantial improvement in these skills. Based on our findings, the use of a checklist might be a practical tool for clinicians initiating new antihypertensive medications. Background: Immediate feedback is underused in the French medical education curriculum, specifically with video-recorded consultation. Research question: The objective of this study was to evaluate the feasibility and the interest in this teaching method as a training and assessment tool in the learning process of general practitioner (GP) trainees. Methods: During the period November 2017 to October 2018, trainees in ambulatory training courses collected quantitative data about recording consultations with a video camera: numbers of recordings, feedback, patients' participation refusals, and information about the learning process and competencies. The trainees' level of satisfaction was measured by means of a questionnaire at the end of their traineeship. Results: Sixty-seven trainees were recruited and 44 of them 65.7% actively participated in the study; 607 video recordings and 243 feedback with trainers were performed. Few patients (18.5%) refused the video-recording. Most trainees considered video recording with immediate feedback to be a relevant learning tool. It made it possible for the participants to observe their difficulties and their achievements. 'Relation, communication, patient-centred care' was the most built competency, non-verbal communication, in particular. Time was the main limiting factor of this teaching method. Most trainees were in favour of its generalization in their university course. Conclusion: Video recording with immediate feedback in real-time consultation needs to be adapted to training areas and depends on time and logistics. This teaching method seems to be useful in the development of communication skills. It could lift the barriers of the trainer's physical presence near GP trainees during immediate feedback in real-time consultation. It could help trainees to build their competencies while enhancing the place of immediate feedback in the general practice curriculum. It could also constitute an additional tool for the certification of GP trainees. Background: Perinatal depression has been associated with psychiatric morbidity in mothers and their offspring. This study assessed the prevalence of perinatal depressive symptoms in a large population of women and investigated associations of these symptoms with demographic and clinical factors. Research question: Which factors (including sociodemographic, medical, lifestyle, and laboratory test) are associated with perinatal depression? Methods: All members of Maccabi Health Services who completed the Edinburgh Postnatal Depression Scale (EPDS) during 2015-2016 were included in the study. Odds ratios (ORs) were calculated for associations of sociodemographic, medical, lifestyle, and laboratory test factors with perinatal depressive symptoms, according to a score >10 on the EPDS. Results: Of 27 912 women who filled the EPDS, 2029 (7.3%) were classified as having peripartum depression. In a logistic regression analysis, the use of antidepressant medications, particularly for a period greater than three months, Arab background, current or past smoking, a diagnosis of chronic diabetes and age under 25 years were all associated with increased ORs for perinatal depression; while Orthodox Jewish affiliation, residence in the periphery and higher haemoglobin level were associated with lower ORs. Incidences of depression were 17.4% in women with a history of antidepressant medication, 16% among women with diabetes, and 11.8% among current smokers. Conclusion: Several demographic, medical, and lifetime factors were found to be substantially more prevalent among women with symptoms of perinatal depression than those without. Encouraging women to complete the EPDS during and following pregnancy may help identify women in need of support. Background: Regulating the quality and effectiveness of the work of general practitioners is essential for a sound healthcare system. In the Republic of Macedonia this is regulated by the Health Insurance Fund through a system of penalties/sanctions. Research question: The goal of this study is to evaluate the types and effectiveness of the sanctions used on primary care practitioners. Methods: This is a quantitative research study for which we used an anonymous survey with 18 questions. This survey was distributed to 443 randomly selected general practitioners from different parts of Macedonia and 438 of them responded. For the quantitative data, we used the Pearson's chi-squared test, correlation and descriptive statistics. Part of the survey is qualitative, consisting of comments and opinions of the general practitioners. Results: From the participants, 336 were female and 102 were male. The doctors' gender was not associated with sanctioning. Most general practitioners were in the age categories of 30-39 and 40-49 years. The participants' age had a significant influence on sanctioning-older doctors were sanctioned more frequently. Out of 438 participants, 33.3% were specialists in family medicine and 66.7% general practitioners. Specialists in family medicine were sanctioned significantly more frequently than general practitioners. Doctors that worked in the hospital or 19 km from the nearest hospital were significantly more frequently sanctioned. The three most common reasons for sanctions were financial consumption of prescriptions and referrals above the agreed amount, higher rate of sick leaves and/or justification of sick leaves and unrealized preventative goals or education. 'Financial sanction by scale' was the most common type of sanction: 49.8% of participants. Doctors who followed the guidelines, but who were exposed to violence were sanctioned significantly more frequently. Conclusion: We can observe that age, speciality, the distance of the workplace from the nearest hospital and violence influence sanctioning. Background: Biases are major barriers to external validity of studies, reducing evidence. Among these biases, the definition and the reality of the Hawthorne effect (HE) (or observation bias) remains controversial. According to McCambridge in a review from 2013, the Hawthorne effect is a behaviour change occurring when the subject is being observed during a scientific study. This effect would be multifactorial, and he suggests the term 'effects of research participation.' However, the reviewed studies were conflicting and evidence is sparse. Research question: We updated McCambridge's review to actualize the definition of the HE. Methods: McCambridge's most recent article dated back to January 3, 2012. We focused on the articles published between January 1, 2012 and August 10, 2018 searching Medline. We used the sole keyword 'Hawthorne Effect.' The search was filtered based on the dates, the availability of an abstract and the languages English and French. We included articles defining or evaluating the HE. Articles citing the effect without defining it or irrelevant to the topic were excluded. Two independent readers searched and analysed the articles. Discrepancies were solved by consensus. Results: Out of 106 articles, 42 articles were included. All the articles acknowledged an observation bias, considered as significant or not, depending on the population (education, literacy), the methods and the variable of interest. It was a psychological change, limited in time. The HE was defined as a change of behaviour related to direct or indirect observation of the subjects or the investigators, to their previous selection and commitment in the study (written agreement) and to social desirability. Despite observations, articles were conflicting. Some do confirm the existence of the HE, others deny it. Meta-analysis is ongoing. Conclusion: No formal consensus regarding the definition of the effect has been reached so far. However, the authors agree on its implication as an experimental artefact. Background: Polypharmacy and multimorbidity are on the rise. Consequently, general practitioners (GPs) treat an increasing number of multimorbid patients with polypharmacy. To limit negative health outcomes, GPs should search for inappropriate medication intake in such patients. However, systematic medication reviews are time-consuming. Recent eHealth tools, such as the 'systematic tool to reduce inappropriate prescribing' (STRIP) assistant, provide an opportunity for GPs to get support when conducting such medication reviews. Research question: Can the STRIP assistant as electronic decision support help GPs to optimize medication appropriateness in older, multimorbid patients with polypharmacy? Methods: This cluster randomized controlled trial is conducted in 40 Swiss GP practices, each recruiting 8-10 patients aged >= 65 years, with >= 3 chronic conditions and >= 5 chronic medications (320 patients in total). We compare the effectiveness of using the STRIP assistant for optimizing medication appropriateness to usual care. The STRIP assistant is based on the STOPP/START criteria (version 2) and, for this trial, it is implemented in the Swiss eHealth setting where some GPs already share routine medical data from their electronic medical records in a research database (FIRE). Patients are followed-up for 12 months and the change in medication appropriateness is the primary outcome. Secondary outcomes are the numbers of falls and fractures, quality of life, health economic parameters, patients' willingness to deprescribe as well as implementation barriers and enablers for GPs when using the STRIP assistant. Results: Patient recruitment started in December 2018. This presentation focuses on the study protocol and the challenges faced when testing this new software in Swiss primary care. Conclusion: Finding out whether the STRIP assistant is an effective tool and beneficial for older and multimorbid patients, who are usually excluded from trials, will have an impact on the coordination of chronic care for multimorbid patients in Swiss primary care in this new eHealth environment. Background: Workplace violence (WPV) towards healthcare staff is becoming a common problem in different healthcare settings worldwide. Moreover, the prevalence is 16 times higher than in other professions. How often it happened towards young doctors working as general practitioners (GPs) at the beginning of their careers has been rarely studied. Research question: To investigate the frequency and forms of WPV, experienced by the young Croatian GPs from their patients, and violence reporting pattern to the competent institutions. Methods: The cross-sectional study was carried out on 74 GP residents, during their postgraduate study in family medicine in May 2018. A specially designed anonymous questionnaire, developed by Association of Family Physicians of South Eastern Europe, was used to investigate the prevalence and forms of WPV, the narrative description of the traumatic event itself and the process of reporting it. Results: The response rate was 91.9%, female 87%, the median of years working as a GP was 3.5 years. Most of the residents were working in an urban practice (63%), others in the rural and the suburban once (27%, 10%). All GP residents experienced patients' and caregivers' violent behaviour directed towards them. High-intensity violence (e.g. physical violence, sexual harassment) was experienced by 44%, middle intensity (e.g. intimidation, visual sexual harassment) by 84% while all residents experienced verbal violence. Only 13.2% residents reported WPV to the competent institutions. Most of GP residents reported the appearance of the new form of violence: the one over the internet. Conclusion: The high prevalence of all types of violence towards young Croatian doctors is worrisome, as is the fact that violent acts are seldom reported to the competent institutions. Those alarming facts could become a threat to GPs career choosing. Background: About 50% of patients adhere to chronic therapy in France. Improving adherence should improve their care. Identifying the patient's difficulties in taking medication is complex for the physician, because there is no gold standard for measuring adherence to medications. How can the general practitioner in his/her practice identify patient compliance? Research question: Analyse studies that develop or validate scales used to estimate adherence in primary care. Methods: A systematic review of the literature from PubMed, the Cochrane Library and PsycINFO databases. The search terms used were the MeSH terms (or adapted to the database's vocabulary): questionnaire, compliance and primary care. All articles were retained whatever the language of writing. Selection criteria were: assessment of the development, validation or reliability of one or more compliance scales; taking place in primary care. One reviewer screened titles, which included the term adherence then abstracts and full text. Only articles evaluating the development, validity or reliability of a primary care adherence rating scale were included in analysis. Results: In total 1022 articles were selected and 18 articles were included. Seventeen adherence scales were identified in primary care, most of which targeted a single pathology, especially hypertension. The most cited scale is the MMAS Morisky medication adherence scale. Three scales were developed for patients with multiple chronic diseases. One scale was developed for patients older than 65 years-the Strathclyde compliance risk assessment tool (SCRAT)-and two scales were developed for adult patients whatever their age-the instrument developed by Sidorkiewicz et al., and the DAMS, diagnostic adherence to medication scale. Conclusion: Two scales have been developed and validated in primary care to assess patient adherence with multiple chronic diseases: the DAMS and the instrument developed by Sidorkiewicz et al. A simple, reliable, reproducible primary care scale would assess the impact of actions developed to improve adherence: motivational interviewing, patient therapeutic education, and the ASALeE protocol. Background: Multimorbidity prevalence increases with age while declining quality of life (QoL) is one of its major consequences. Research question: The study aims to: (1) Assess the relationship between increasing number of diseases and QoL. (2) Identify the most frequently occurring patterns of diseases and how they relate to QoL. (3) Observe how these associations differ across different European countries and regions. Methods: Cross-sectional data analysis performed on wave six of the population-based survey of health, ageing and retirement in Europe (SHARE) (n = 68 231). Data were collected in 2015 among population 50+ years old in 17 European countries and Israel. Multimorbidity is defined as the co-occurrence of two or more chronic conditions. Conditions were self-declared and identified through an open-end questionnaire containing 17 prelisted conditions plus conditions added by participants. Control, autonomy, self-realization and pleasure questionnaire (CASP-12v) was used to evaluate QoL. Association between increasing number of diseases and QoL was assessed with linear regression. Factor analysis is being conducted to identify patterns of diseases to evaluate their impact on QoL further. Multilevel analysis will take into account differences between countries and regions. Confounding was searched with directed acyclic graph (DAG) method and included age, sex, education, socio-economic status, behavioural habits, social support and healthcare parameters. Results: Participants (49.09%) had two or more diseases. Maximum number of diseases per person was 13, mean number was 1.9. Unadjusted preliminary analysis showed that on average QoL decreases by -1.27 (95%CI: -1.29, -1.24) with each added new condition across Europe. The decline appears to be the steepest in Spain, -1.61 (95%CI: -1.71, -1.51), and the least so in Israel, -0.67 (95%CI: -0.82, -0.52). Conclusion: Ongoing analysis will identify disease patterns, which may have the highest impact on QoL, as well as to elucidate the role of confounders in the relationship between increasing number of diseases and disease patterns with QoL. Background: The burden and preventive potential of disease is typically estimated for each non-communicable disease (NCD) separately but NCDs often co-occur, which hampers reliable quantification of their overall burden and joint preventive potential in the population. Research questions: What is the lifetime risk of developing any NCD? Which multimorbidity clusters of NCDs cause the greatest burden? To what extent do three key shared risk factors, namely smoking, hypertension and being overweight, influence this risk, life-expectancy and NCD-multimorbidity? Methods: Between 1990 and 2012 we followed NCD-free participants aged >= 45 years at baseline from the Dutch prospective Rotterdam study for incidents of stroke, heart disease, diabetes, chronic respiratory disease, cancer, and neurodegenerative disease. We quantified (co-)occurrence and remaining lifetime risk of NCDs in a competing risk framework, and studied the effects of smoking, hypertension, and being overweight on lifetime risk and life expectancy. Results: During follow-up of 9061 participants, 814 participants were diagnosed with stroke, 1571 with heart disease, 625 with diabetes, 1004 with chronic respiratory disease, 1538 with cancer, and 1065 with neurodegenerative disease. Among those, 1563 participants (33.7%) were diagnosed with multiple diseases. The lifetime risk of any NCD from the age of 45 onwards was 94.0% (95%CI: 92.9-95.1) for men and 92.8% (95%CI: 91.8-93.8) for women. Absence of shared risk factors was associated with a 9.0-year delay (95%CI: 6.3-11.6) in the age at onset of any NCD. Furthermore, overall life expectancy for participants without risk factors was 6.0 years (95%CI: 5.7-7.9) longer than those with these risk factors. Participants without these risk factors spent 21.6% of their remaining lifetime with NCDs, compared to 31.8% for those with risk factors. Conclusion: Nine out of 10 individuals aged 45 years and older will develop at least one NCD during their remaining lifetime. A third was diagnosed with multiple NCDs during follow-up. Absence of three common shared risk factors related to compression of morbidity of NCDs. Background: This study examined if using electronic reminders increases the rate of diagnosis recordings in the patient chart system following visits to a general practitioner (GP). The impact of electronic reminders was studied in the primary care of a Finnish city. Research question: How effective is the reminder of the information system in improving the diagnostic level of primary care? Which is better and how: financial incentives or reminders? Methods: This was an observational retrospective study based on a before-and-after design and was carried out by installing an electronic reminder in the computerized patient chart system to improve the recording of diagnoses during GP visits. The quality of the recorded diagnoses was observed before and after the intervention. The effect of this intervention on the recording of diagnoses was also studied. Results: Before intervention, the level of recording diagnoses was about 40% in the primary care units. After four years, the recording rate had risen to 90% (p < 0.001). The rate of change in the recording of diagnoses was highest during the first year of intervention. In the present study, most of the visits concerned mild respiratory infections, elevated blood pressure, low back pain and type II diabetes. Conclusion: An electronic reminder improved the recording of diagnoses during the visits to GPs. The present intervention produced data, which reflects the distribution of diagnoses in real clinical life in primary care and thus provides valid data about the public. Background: Child abuse is widespread, occurs in all cultures and communities and remains undiscovered in 90% of the cases. In total, 80% of reported child abuse concerns emotional ill-treatment. In the Netherlands, at least 3% (118 000) of children are victims of child abuse resulting in 50 deaths each year. Only 1-3% of abuse cases are reported by general practitioners (GPs) to the Child Protective Services agency (CPS). To explain this low reporting rate, we examined GPs' experiences with child abuse. Research question: How does the suspicion of child abuse arise in GPs' diagnostic reasoning? How do they act upon their suspicion and what kind of barriers do they experience in their management? Methods: In total 26 GPs (16 female) participated in four focus groups. We used purposive sampling to include GPs with different levels of experience in rural and urban areas spread over the Netherlands. We used NVivo for thematic content analysis. Results: Suspected child abuse arose based on common triggers and a gut feeling that 'something is wrong here'. GPs acted upon their suspicion by gathering more data by history taking and physical examination. They often found it challenging to decide whether a child was abused because parents, despite their good intentions, may lack parenting skills and differ in their norms and values. GPs reported clear signs of sexual abuse and physical violence to CPS. However, in less clear-cut cases they followed-up and built a supporting network around the family. Most GPs highly valued the patient-doctor relationship while recognizing the risk of pushing boundaries. Conclusion: A low child abuse reporting rate by GPs to CPS does not mean a low detection rate. GPs use patients' trust in their doctor to improve a child's situation by involving other professionals. Background: The number of people suffering from multiple chronic conditions, multimorbidity, is rising. For society, multimorbidity is known to increase healthcare expenses through more frequent contacts, especially with the primary sector. For the individual, an increasing number of medical conditions are associated with lower quality of life (QoL). However, there is no statistically validated condition-specific patient-reported outcome measure (PROM) for the assessment of QoL among patients with multimorbidity. A validated PROM is essential in order to measure effect in intervention studies for this patient group. Research question: (1) To identify items covering QoL among patients with multimorbidity in a Danish context. (2) To develop and validate a PROM for assessment of QoL among patients with multimorbidity. (3) To utilize the final PROM in a large group of patients with multimorbidity to measure their QoL when living with different combinations and severity of multimorbidity. Methods: Phase 1: qualitative individual and focus group interviews with patients with multimorbidity to identify relevant QoL items. Phase 2: validation of the items through a draft questionnaire sent by email to around 200-400 patients with multimorbidity. Phase 3: psychometric validation of the draft questionnaire securing items with the highest possible measurement quality. Phase 4: assessment of QoL among approximately 2000 patients with multimorbidity from the Danish Lolland-Falster study. Results: There are no results yet. Currently, the interview guide is under development. Conclusion: Despite the rising number of patients with multimorbidity and the known inverse relationship between a patient's number of medical conditions and their quality of life, there is no statistically validated condition-specific PROM for assessment of QoL among this group. Our aim is that this project's developed and validated PROM will be used in future intervention studies as a valid measure of QoL among patients with multimorbidity. Background: Through a systematic review of the literature and qualitative research across Europe, the European General Practitioners Research Network (EGPRN) has designed and validated a comprehensive definition of multimorbidity. It is a concept considering all the biopsychosocial conditions of a patient. This concept encompasses more than 50 variables and is consequently difficult to use in primary care. Consideration of adverse outcomes (such as death or acute hospitalization) could help to distinguish which variables could be risk factors of decompensation within the definition of multimorbidity. Research question: Which criteria in the EGPRN concept of multimorbidity could detect outpatients at risk of death or acute hospitalization (i.e. decompensation) in a primary care cohort at 24-months of follow-up? Methods: Primary care outpatients (131) answering to EGPRN's multimorbidity definition were included by GPs, during two periods of inclusion in 2014 and 2015. At 24 months follow-up, the status 'decompensation' or 'nothing to report' was collected. A logistic regression following a Cox model was performed to achieve the survival analysis and to identify potential risk factors. Results: At 24 months follow-up, 120 patients were analysed. Three different clusters were identified. Forty-four patients, representing 36.6% of the population, had either died or been hospitalized more than seven consecutive days. Two variables were significantly associated with decompensation: Number of GPs encounters per year (HR: 1.06; 95%CI: 1.03-1.10, p <0.001), and total number of diseases (HR: 1.12; 95%CI: 1.03-1.33; P = 0.039). Conclusion: To prevent death or acute hospitalization in multimorbid outpatients, GPs may be alert to those with high rates of GP encounters or a high number of illnesses. These results are consistent with others in medical literature. Background: A study of casual versus causal comorbidity in family medicine in three practice populations from the Netherlands, Malta and Serbia. Research question: (1) What is the observed comorbidity of the 20 most common episodes of care in three countries? (2) How much of the observed comorbidity is likely to be casual versus causal? Methods: Participating family doctors (FDs) in the Netherlands, Malta and Serbia recorded details of all patient contacts in an episode of care structure using electronic medical records based on the International Classification of Primary Care, collecting data on all elements of the doctor-patient encounter, including the diagnostic labels (episode of care labels, EoCs). Comorbidity was measured using the odds ratio of both conditions being incident or rest-prevalent in the same patient in one-year data frames, as against not. Results: Comorbidity in family practice expressed as odds ratios between the 41 most prevalent (joint top 20) episode titles in the three populations. Specific associations were explored in different age groups to observe the changes in odds ratios with increasing age as a surrogate for a temporal or biological gradient. Conclusion: After applying accepted criteria for testing the causality of associations, it is reasonable to conclude that most of the observed primary care comorbidity is casual. It would be incorrect to assume causal relationships between co-occurring diseases in family medicine, even if such a relationship might be plausible or consistent with current conceptualizations of the causation of disease. Most observed comorbidity in primary care is the result of increasing illness diversity. Background: The concept of therapeutic alliance emerged in the beginning of the twentieth century and came from psychoanalysis. This notion was then extended to the somatic field and aims to replace the paternalistic model in the doctor-patient relationship. The EGPRN TATA group selected the WAI SR as the most reliable and reproducible scale to assess therapeutic alliance. To use it within Europe, it was necessary to translate it into most European languages. The following study aimed to assess the linguistic homogeneity of five of these translations. Research question: Are the translations of the WAI SR homogeneous between Spain, Poland, Slovenia, France and Italy? Methods: Forward-backward translations were achieved in five participating countries (Spain, Poland, France, Slovenia and Italy). Using a Delphi procedure, a global homogeneity check was then performed by comparing the five backward translations during a physical meeting involving GP teachers/researchers from many European countries; ; ",2019
