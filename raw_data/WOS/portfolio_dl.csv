Article Title,Abstract,Publication Year
Harnessing a Hybrid CNN-LSTM Model for Portfolio Performance: A Case Study on Stock Selection and Optimization,"Portfolio theory underpins portfolio management, a much-researched yet uncharted field. This research suggests a collective framework combined with the essence of deep learning for stock selection through prediction and optimal portfolio formation through the mean-variance (MV) model. The CNN-LSTM model, proposed in Stage I blends the benefits of the convolutional neural network (CNN) and the long-short-term memory network (LSTM). The model combines feature extraction and sequential learning about temporal data fluctuations. The experiment considers thirteen input features, combining fundamental market data and technical indicators to capture the nuances of the wildly fluctuating stock market data. The input data sample of 21 stocks was collected from the National Stock Exchange (NSE) of India from January 2005 to December 2021, spanning two significant market crashes. Thus, the sample makes it possible to catch subtle market shifts for model execution. The shortlisted stocks with high potential returns are advanced to Stage II for optimal stock allocation using the MV model. The proposed hybrid CNN-LSTM outperformed the single models, i.e., CNN and LSTM, per the six-performance metrics and advocated by the 10-fold cross-validation technique. Furthermore, the statistical significance of the model is established using non-parametric tests followed by post hoc analysis. In addition, this method is validated by comparing the proposed model to four baseline strategies and relevant pieces of research, which it considerably outperforms in terms of cumulative return per year, Sharpe ratio, and average return to risk with and without transaction cost. These findings highlight the effectiveness of the hybrid CNN-LSTM approach in stock selection and portfolio optimization.",2023
Portfolio Optimization-Based Stock Prediction Using Long-Short Term Memory Network in Quantitative Trading,"In quantitative trading, stock prediction plays an important role in developing an effective trading strategy to achieve a substantial return. Prediction outcomes also are the prerequisites for active portfolio construction and optimization. However, the stock prediction is a challenging task because of the diversified factors involved such as uncertainty and instability. Most of the previous research focuses on analyzing financial historical data based on statistical techniques, which is known as a type of time series analysis with limited achievements. Recently, deep learning techniques, specifically recurrent neural network (RNN), has been designed to work with sequence prediction. In this paper, a long short-term memory (LSTM) network, which is a special kind of RNN, is proposed to predict stock movement based on historical data. In order to construct an efficient portfolio, multiple portfolio optimization techniques, including equal-weighted modeling (EQ), simulation modeling Monte Carlo simulation (MCS), and optimization modeling mean variant optimization (MVO), are used to improve the portfolio performance. The results showed that our proposed LSTM prediction model works efficiently by obtaining high accuracy from stock prediction. The constructed portfolios based on the LSTM prediction model outperformed other constructed portfolios-based prediction models such as linear regression and support vector machine. In addition, optimization techniques showed a significant improvement in the return and Sharpe ratio of the constructed portfolios. Furthermore, our constructed portfolios beat the benchmark Standard and Poor 500 (S&P 500) index in both active returns and Sharpe ratios.",2020
Financial Portfolio Construction for Quantitative Trading Using Deep Learning Technique,"Stock portfolio construction is a difficult task which involves the simultaneous consideration of dynamic financial data as well as investment criteria (e.g.: investors required return, risk tolerance, goals, and time frame). The objective of this research is to present a two phase deep learning module to csonstruct a financial stocks portfolio that can be used repeatedly to select the most promising stocks and adjust stocks allocations (namely quantitative trading system). A deep belief network is used to discover the complex regularities among the stocks while a long short-term memory network is used for time series financial data prediction. The proposed deep learning architecture has been tested on the american stock market and has outperformed other known machine learning techniques (support vector machine and random forests) in several prediction accuracy metrices. Furthermore, the results showed that our architecture as a portfolio construction model outperforms three benchmark models with several financial profitability and risk-adjusted metrics.",2021
Applications of Markov Decision Process Model and Deep Learning in Quantitative Portfolio Management during the COVID-19 Pandemic,"Whether for institutional investors or individual investors, there is an urgent need to explore autonomous models that can adapt to the non-stationary, low-signal-to-noise markets. This research aims to explore the two unique challenges in quantitative portfolio management: (1) the difficulty of representation and (2) the complexity of environments. In this research, we suggest a Markov decision process model-based deep reinforcement learning model including deep learning methods to perform strategy optimization, called SwanTrader. To achieve better decisions of the portfolio-management process from two different perspectives, i.e., the temporal patterns analysis and robustness information capture based on market observations, we suggest an optimal deep learning network in our model that incorporates a stacked sparse denoising autoencoder (SSDAE) and a long-short-term-memory-based autoencoder (LSTM-AE). The findings in times of COVID-19 show that the suggested model using two deep learning models gives better results with an alluring performance profile in comparison with four standard machine learning models and two state-of-the-art reinforcement learning models in terms of Sharpe ratio, Calmar ratio, and beta and alpha values. Furthermore, we analyzed which deep learning models and reward functions were most effective in optimizing the agent's management decisions. The results of our suggested model for investors can assist in reducing the risk of investment loss as well as help them to make sound decisions.",2022
Portfolio optimization and return prediction by integrating modified deep belief network and recurrent neural network,"The victory of portfolio construction is mostly based on the future stock market performance. Recently, the developed machine learning techniques bring more significance of involving the prediction theory for selecting the portfolio. Implementing the return prediction of conventional time series methods in portfolio generation can enhance the efficiency of real portfolio optimization method. But, expert systems and deep structured learning methods has gives awesome performance when comparing other time series methods, in this work integrates return prediction in portfolio formation with hybridized deep learning method named Deep Belief-Recurrent Neural Network (DBRNN). The forecasting of the portfolio is performed by the optimal training (weight optimization) of RNN with DBN, by the hybrid meta-heuristic algorithm termed Harris Hawks-Deer Hunting Optimization (HH-DHO). The newly developed optimization algorithm does not fall into the local optimum owing to the integrated method of exploration in the DHOA and HHO. The combination of standard algorithms is confirmed that it is better for solving the test problems and is it is very competitive and realistic over other conventional algorithms. Thus, it reveals that the implemented HH-DHO can highly balance the exploration and exploitation phases. With the predicted information by the integrated deep learning model, the best companies that high returns are optimally selected by the same hybrid HH-DHO. It can be enlarge the prediction performance of the designed approaches. On observing the analysis, the acquired results reveal that the suggested method is superior to existing ways and benchmarks in terms of returns and risks. (C) 2022 Elsevier B.V. All rights reserved.",2022
Enhancing Portfolio Optimization: A Two-Stage Approach with Deep Learning and Portfolio Optimization,"The portfolio selection problem has been a central focus in financial research. A complete portfolio selection process includes two stages: stock pre-selection and portfolio optimization. However, most existing studies focus on portfolio optimization, often overlooking stock pre-selection. To address this problem, this paper presents a novel two-stage approach that integrates deep learning with portfolio optimization. In the first stage, we develop a stock trend prediction model for stock pre-selection called the AGC-CNN model, which leverages a convolutional neural network (CNN), self-attention mechanism, Graph Convolutional Network (GCN), and k-reciprocal nearest neighbors (k-reciprocal NN). Specifically, we utilize a CNN to capture individual stock information and a GCN to capture relationships among stocks. Moreover, we incorporate the self-attention mechanism into the GCN to extract deeper data features and employ k-reciprocal NN to enhance the accuracy and robustness of the graph structure in the GCN. In the second stage, we employ the Global Minimum Variance (GMV) model for portfolio optimization, culminating in the AGC-CNN+GMV two-stage approach. We empirically validate the proposed two-stage approach using real-world data through numerical studies, achieving a roughly 35% increase in Cumulative Returns compared to portfolio optimization models without stock pre-selection, demonstrating its robust performance in the Average Return, Sharp Ratio, Turnover-adjusted Sharp Ratio, and Sortino Ratio.",2024
An integrative extraction approach for index-tracking portfolio construction and forecasting under a deep learning framework,"This paper proposed a fusion model of the deep long- and short-term memory network named as deep LSTM and the stochastic dominance named as SD filter method to construct an index-tracking portfolio. We present a practical model that provides investors for portfolio construction using the deep LSTM model on extracting stock features and integrating the dimension deduction ability of the SD approach to the fusion model. Three main conclusions are drawn. First, deep learning in a supervised framework can work in portfolio management with our tuned model. Second, our deep LSTM model with an SD selection filter has enhanced the feature extraction ability to construct an index-tracking portfolio. Third, the linear activator, rectified linear unit, cooperated with SD methods can better reduce the estimation errors than the nonlinear activator in our deep LSTM model. These findings can implement on the portfolio construction in the neural network field. Additionally, entropy suggests to evaluate the learning effect of forecasting. The SD methods also are indicated for prosecuting in other neural network models to extract features of time series data, like transformer-based models.",2024
Deep learning applications in investment portfolio management: a systematic literature review,"PurposeMachine learning (ML), and deep learning in particular, is gaining traction across a myriad of real-life applications. Portfolio management is no exception. This paper provides a systematic literature review of deep learning applications for portfolio management. The findings are likely to be valuable for industry practitioners and researchers alike, experimenting with novel portfolio management approaches and furthering investment management practice.Design/methodology/approachThis review follows the guidance and methodology of Linnenluecke et al. (2020), Massaro et al. (2016) and Fisch and Block (2018) to first identify relevant literature based on an appropriately developed search phrase, filter the resultant set of publications and present descriptive and analytical findings of the research itself and its metadata.FindingsThe authors find a strong dominance of reinforcement learning algorithms applied to the field, given their through-time portfolio management capabilities. Other well-known deep learning models, such as convolutional neural network (CNN) and recurrent neural network (RNN) and its derivatives, have shown to be well-suited for time-series forecasting. Most recently, the number of papers published in the field has been increasing, potentially driven by computational advances, hardware accessibility and data availability. The review shows several promising applications and identifies future research opportunities, including better balance on the risk-reward spectrum, novel ways to reduce data dimensionality and pre-process the inputs, stronger focus on direct weights generation, novel deep learning architectures and consistent data choices.Originality/valueSeveral systematic reviews have been conducted with a broader focus of ML applications in finance. However, to the best of the authors' knowledge, this is the first review to focus on deep learning architectures and their applications in the investment portfolio management problem. The review also presents a novel universal taxonomy of models used.",2025
"Forecasting Stock Market Indices Using the Recurrent Neural Network Based Hybrid Models: CNN-LSTM, GRU-CNN, and Ensemble Models","Various deep learning techniques have recently been developed in many fields due to the rapid advancement of technology and computing power. These techniques have been widely applied in finance for stock market prediction, portfolio optimization, risk management, and trading strategies. Forecasting stock indices with noisy data is a complex and challenging task, but it plays an important role in the appropriate timing of buying or selling stocks, which is one of the most popular and valuable areas in finance. In this work, we propose novel hybrid models for forecasting the one-time-step and multi-time-step close prices of DAX, DOW, and S&P500 indices by utilizing recurrent neural network (RNN)-based models; convolutional neural network-long short-term memory (CNN-LSTM), gated recurrent unit (GRU)-CNN, and ensemble models. We propose the averaging of the high and low prices of stock market indices as a novel feature. The experimental results confirmed that our models outperformed the traditional machine-learning models in 48.1% and 40.7% of the cases in terms of the mean squared error (MSE) and mean absolute error (MAE), respectively, in the case of one-time-step forecasting and 81.5% of the cases in terms of the MSE and MAE in the case of multi-time-step forecasting.",2023
Comparative Analysis Of Deep Learning Approaches Used For Stock Price Prediction,"Stock market analysis is nonlinear, highly volatile and complex. Predicting the stock price is a highly challenging task. The change in stock price is affected by certain factors such as economic situation, political circumstances, sentiments, global pandemic like Covid-19 and global impact of Russo-Ukrainian War. Forecasting the stock market presents a significant difficulty to investors to build a profitable portfolio or to reduce stock risk in the stock market. Artificial Intelligence (AI), Machine Learning (ML) and Deep Learning (DL) have been abundantly used for stock trend and price prediction considering time series data and sentiments. In this paper we consider the stocks of 5 companies (Tata Steel, Tata Motors, Sun Pharmacy, Infosys and HDFC Bank) from National Stock Exchange (NIFTY 50). Convolution Neural Network (CNN), Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM) and Bidirectional Long Short-Term Memory (Bi-LSTM) methods were used for data set of duration 01 January 2014 - 01 February 2024, was evaluated the prediction model using Root Mean Squared Error (RMSE) and Mean Absolute Percentage Error (MAPE). The Bi-LSTM model achieved an RMSE of 6.6 for TATA Steel stock and a MAPE of 0.010 for Sun Pharma stock. The study proves the Bi-LSTM is an effective deep learning algorithm for predicting the future closing price of a stock as compared to CNN, RNN and LSTM.",2024
Futuristic portfolio optimization problem: wavelet based long short-term memory,"PurposeThis paper aims to propose an improved version of portfolio optimization model through the prediction of the future behavior of stock returns using a combined wavelet-based long short-term memory (LSTM).Design/methodology/approachFirst, data are gathered and divided into two parts, namely, past data and real data. In the second stage, the wavelet transform is proposed to decompose the stock closing price time series into a set of coefficients. The derived coefficients are taken as an input to the LSTM model to predict the stock closing price time series and the future data is created. In the third stage, the mean-variance portfolio optimization problem (MVPOP) has iteratively been run using the past, future and real data sets. The epsilon-constraint method is adapted to generate the Pareto front for all three runes of MVPOP.FindingsThe real daily stock closing price time series of six stocks from the FTSE 100 between January 1, 2000, and December 30, 2020, is used to check the applicability and efficacy of the proposed approach. The comparisons of future, past and real Pareto fronts showed that the future Pareto front is closer to the real Pareto front. This demonstrates the efficacy and applicability of proposed approach.Originality/valueMost of the classic Markowitz-based portfolio optimization models used past information to estimate the associated parameters of the stocks. This study revealed that the prediction of the future behavior of stock returns using a combined wavelet-based LSTM improved the performance of the portfolio.",2024
A novel prediction based portfolio optimization model using deep learning,"Portfolio optimization is an important part of portfolio management. It realizes the trade-off between maximizing expected return and minimizing risk. A better portfolio optimization model helps investors achieve higher expected returns under the same risk level. This paper proposes a novel prediction based portfolio optimization model. This model uses autoencoder (AE) for feature extraction and long short term memory (LSTM) network to predict stock return, then predicted and historical returns are utilized to build a portfolio optimization model by advancing worst-case omega model. In order to show the effect of AE, the LSTM network without any feature extraction methods is used as a benchmark in stock prediction. Also, an equally weighted portfolio is considered as a comparison to reveal the advantage of the worst-case omega model. Empirical results show that the proposed model significantly outperforms the equally weighted portfolio, and a high risk-return preference is more suitable to this model. In addition, even after deducting transaction fees, this model still achieves a satisfying return and performs better than the state-of-art prediction based portfolio optimization models. Thus, this paper recommends applying this model in practical investment.",2023
Black-Litterman portfolio optimization based on GARCH-EVT-Copula and LSTM models,"In constructing diversified portfolios, the investors might be interested in incorporating some quantifiable views or opinions. The Black-Litterman model is a useful approach to integrate investors' views into the Markowitz allocation model. In this paper we utilize a deep learning model to estimate the investors's views and use GARCH-EVT-Copula to model the dependence structure between stock market returns in a large portfolio. The findings show that the Black-Litterman model for portfolio optimization based on GARCH-EVT-Copula and LSTM (Long Short Term Memory) models gives better performances as compared with the traditional max-Sharpe and the original Black-Litterman portfolio problems.",2025
Stock Market Price Prediction Using LSTM RNN,"Financial Analysis has become a challenging aspect in today's world of valuable and better investment. This paper introduces the implementation of Recurrent Neural Network (RNN) along with Long Short-Term Memory Cells (LSTM) for Stock Market Prediction used for Portfolio Management considering the Time Series Historical Stock Data of Stocks in the Portfolio. The comparison of the model with the traditional Machine Learning Algorithms-Regression, Support Vector Machine, Random Forest, Feed Forward Neural Network and Backpropagation have been performed. Various metrics and architectures of LSTM RNN model have been considered and are tested and analysed. There is discussion on how the sentiments of the customer would affect the stocks along with the changes in trends.",2019
CVaR Prediction Model of the Investment Portfolio Based on the Convolutional Neural Network Facilitates the Risk Management of the Financial Market,"In summary, firstly, a method for establishing a portfolio model is proposed based on the risk management theory of the financial market. Then, a prediction model for CVaR is established based on the convolutional neural network, and the improved particle swarm algorithm is employed to solve the model. The actual data analysis is implemented to prove the feasibility of CVaR prediction model based on deep learning and particle swarm optimization algorithm in financial market risk management. The test results show that the investment portfolio CVaR prediction model based on the convolutional neural network can obtain the optimal solution in the 18th generation at the fastest after using the improved particle swarm algorithm, which is more effective than the traditional algorithm. The CVaR prediction model of the investment portfolio based on the convolutional neural network facilitates the risk management of the financial market.",2022
Portfolio management based on a reinforcement learning framework,"Portfolio management is crucial for investors. We propose a dynamic portfolio management framework based on reinforcement learning using the proximal policy optimization algorithm. The two-part framework includes a feature extraction network and a full connected network. First, the majority of the previous research on portfolio management based on reinforcement learning has been dedicated to discrete action spaces. We propose a potential solution to the problem of a continuous action space with a constraint (i.e., the sum of the portfolio weights is equal to 1). Second, we explore different feature extraction networks (i.e., convolutional neural network [CNN], long short-term memory [LSTM] network, and convolutional LSTM network) combined with our system, and we conduct extensive experiments on the six kinds of assets, including 16 features. The empirical results show that the CNN performs best in the test set. Last, we discuss the effect of the trading frequency on our trading system and find that the monthly trading frequency has a higher Sharpe ratio in the test set than other trading frequencies.",2024
Portfolio optimization with return prediction using deep learning and machine learning,"Integrating return prediction of traditional time series models in portfolio formation can improve the performance of original portfolio optimization model. Since machine learning and deep learning models have shown overwhelming superiority than time series models, this paper combines return prediction in portfolio formation with two machine learning models, i.e., random forest (RF) and support vector regression (SVR), and three deep learning models, i.e., LSTM neural network, deep multilayer perceptron (DMLP) and convolutional neural network. To be specific, this paper first applies these prediction models for stock preselection before portfolio formation. Then, this paper incorporates their predictive results in advancing mean-variance (MV) and omega portfolio optimization models. In order to present the superiority of these models, portfolio models with autoregressive integrated moving average's return prediction are used as benchmarks. Evaluation is based on historical data of 9 years from 2007 to 2015 of component stocks of China securities 100 index. Experimental results show that MV and omega models with RF return prediction, i.e., RF+MVF and RF+OF, outperform the other models. Further, RF+MVF is superior to RF+OF. Due to the high turnover of these two models, this paper discusses their performance after deducting the transaction fee cased by turnover. Experiments present that RF+MVF still performs the best among MVF models and omega model with SVR prediction (SVR+OF) performs the best among OF models. Moreover, RF+MVF performs better than SVR+OF and high turnover erodes nearly half of their total returns especially for RF+OF and RF+MVF. Therefore, this paper recommends investors to build MVF with RF return prediction for daily trading investment.",2021
A new portfolio approach integrating three-way decision and Encoder-Decoder network,"In the stock market, it can be challenging to predict stock trends and identify stocks with investment potential due to uncertainty and risk. Accurate predictive models and reliable asset preselection methods are essential for portfolio management. This paper proposes an integration of the deep learning model, the three-way decision (3WD) theory, and the Mean-Variance (MV) method for asset preselection and optimal asset allocation. In the initial stage, an attention-based Encoder-Decoder model is used to predict asset returns and calculate volatility. It outperforms other benchmark models regarding relative error, absolute error, and directional accuracy. The subsequent stage involves selecting stocks based on expected returns and volatility characteristics. The 3WD theory is then used to identify the delayed decision set for implementing additional investment strategies to hedge portfolio risk and enhance returns. Finally, the MV model is employed for investment portfolio optimization. The proposed model is validated using a substantial dataset from the A-share market's SSE 50 Index from January 2010 to December 2022. Results indicate that the proposed model outperforms benchmark models in terms of daily average returns, annualized Information ratio, Sortino ratio, and other aspects under certain trading costs. However, further exploration is required to establish a mechanism that limits the quantity of preselected assets to ensure its broad applicability.",2024
Financial portfolio optimization with online deep reinforcement learning and restricted stacked autoencoder-DeepBreath,"The process of continuously reallocating funds into financial assets, aiming to increase the expected return of investment and minimizing the risk, is known as portfolio management. In this paper, a portfolio management framework is developed based on a deep reinforcement learning framework called DeepBreath. The DeepBreath methodology combines a restricted stacked autoencoder and a convolutional neural network (CNN) into an integrated framework. The restricted stacked autoencoder is employed in order to conduct dimensionality reduction and features selection, thus ensuring that only the most informative abstract features are retained. The CNN is used to learn and enforce the investment policy which consists of reallocating the various assets in order to increase the expected return on investment. The framework consists of both offline and online learning strategies: the former is required to train the CNN while the latter handles concept drifts i.e. a change in the data distribution resulting from unforeseen circumstances. These are based on passive concept drift detection and online stochastic batching. Settlement risk may occur as a result of a delay in between the acquisition of an asset and its payment failing to deliver the terms of a contract. In order to tackle this challenging issue, a blockchain is employed. Finally, the performance of the DeepBreath framework is tested with four test sets over three distinct investment periods. The results show that the return of investment achieved by our approach outperforms current expert investment strategies while minimizing the market risk. Crown Copyright (C) 2020 Published by Elsevier Ltd.",2020
Deep Learning for Financial Time Series Forecast Fusion and Optimal Portfolio Rebalancing,"Portfolio selection is complicated by the difficulty of forecasting financial time series and the sensitivity of portfolio optimisers to forecasting errors. To address these issues, a portfolio management model is proposed that makes use of Deep Learning Models for weekly financial time series forecasting of returns. Our model uses a late fusion of an ensemble of forecast models and modifies the standard mean-variance optimiser to account for transaction costs, making it suitable for multi-period trading. Our empirical results show that our portfolio management tool outperforms the equally-weighted portfolio benchmark and the buy-and-hold strategy, using both Long Short-Term Memory and Gated Recurrent Unit forecasts. Although the portfolios are profitable, they are also sub-optimal in terms of their risk to reward ratio. Therefore, greater forecasting accuracy is necessary to construct truly optimal portfolios.",2021
Intelligent portfolio construction via news sentiment analysis,"In this study, we apply deep learning and natural language processing methods to construct the view distribution in the Black-Litterman model. We implement this approach for portfolio allocation and perform statistical analysis to assess portfolio performance. The empirical analysis yields two main results. For the three deep learning models, we use mean square error to compare the model prediction results. The gated recurrent unit (GRU) model outperforms the other two models in the price prediction of seven stock assets. Moreover, it is more effective in capturing future trends and stock prices. The long short-term memory (LSTM) model outperforms the recurrent neural network (RNN) model. Moreover, in the comparison of the portfolio models, the Black-Litterman model, constructed by using Google's Bidirectional Encoder Representations from Transformers (BERT) to measure news sentiment and by using the GRU model to predict stock prices, yields the highest annualized return rate of 46.6%. In addition, it has the highest Sharpe and Sortino ratios of 13.0% and 17.9%, respectively, which means that under a certain degree of risk, the Black-Litterman model still outperforms other constructed portfolios.",2024
A One-Layer Recurrent Neural Network for Real-Time Portfolio Optimization With Probability Criterion,"This paper presents a decision-making model described by a recurrent neural network for dynamic portfolio optimization. The portfolio-optimization problem is first converted into a constrained fractional programming problem. Since the objective function in the programming problem is not convex, the traditional optimization techniques are no longer applicable for solving this problem. Fortunately, the objective function in the fractional programming is pseudoconvex on the feasible region. It leads to a one-layer recurrent neural network modeled by means of a discontinuous dynamic system. To ensure the optimal solutions for portfolio optimization, the convergence of the proposed neural network is analyzed and proved. In fact, the neural network guarantees to get the optimal solutions for portfolio-investment advice if some mild conditions are satisfied. A numerical example with simulation results substantiates the effectiveness and illustrates the characteristics of the proposed neural network.",2013
Convolutional Neural Network Portfolio Management System with Heterogeneous Input,"We implement a cryptocurrency portfolio management system based on a convolutional neural network architecture. We train and test several models, each augmented with data from various sources past market information (price, volume, market capitalization), sentiment information (positive, neutral, negative sentiment scores extracted from online forums), and blockchain technical data (number of blocks and transactions per trading unit, amount paid in fees, block difficulty etc.). We show that augmenting the model with transaction volume history can lead to larger profits and higher Sharpe ratio, and augmenting the model with sentiment information can lead to better risk management.",2020
Markowitz Mean-Variance Portfolio Optimization with Predictive Stock Selection Using Machine Learning,"With the advances in time-series prediction, several recent developments in machine learning have shown that integrating prediction methods into portfolio selection is a great opportunity. In this paper, we propose a novel approach to portfolio formation strategy based on a hybrid machine learning model that combines convolutional neural network (CNN) and bidirectional long short-term memory (BiLSTM) with robust input features obtained from Huber's location for stock prediction and the Markowitz mean-variance (MV) model for optimal portfolio construction. Specifically, this study first applies a prediction method for stock preselection to ensure high-quality stock inputs for portfolio formation. Then, the predicted results are integrated into the MV model. To comprehensively demonstrate the superiority of the proposed model, we used two portfolio models, the MV model and the equal-weight portfolio (1/N) model, with LSTM, BiLSTM, and CNN-BiLSTM, and employed them as benchmarks. Between January 2015 and December 2020, historical data from the Stock Exchange of Thailand 50 Index (SET50) were collected for the study. The experiment shows that integrating preselection of stocks can improve MV performance, and the results of the proposed method show that they outperform comparison models in terms of Sharpe ratio, mean return, and risk.",2022
Mean-variance portfolio optimization with deep learning based-forecasts for cointegrated stocks,"Most mean-variance (MV) models construct a portfolio based on nonstationary stocks. This study presents a new MV model constructed using stationary portfolios composed of cointegrated stocks. The expected return of this new model is predicted by using machine learning models, such as support vector machine, random forest, and attention-based long short-term memory (LSTM) network. The proposed model is evaluated using data on stocks in the CSI 300 and the S&P 500, with 42 features over 8 years from May 4, 2012 to August 4, 2020. The empirical results show that the portfolio constructed based on the stationary portfolios in both the Chinese and the US stock markets delivers significant profits. Further, the attention-based LSTM network can more accurately model the spread return using technical indicators, financial investment information, and lagged returns, and can successfully select pairs of cointegrated stocks for constructing a more profitable MV portfolio, than can conventional machine learning models. Using the attention-based LSTM to predict 20-day return movement results in model accuracy of up to 92.59% for the CSI 300 and 88.52% for the S&P 500, and a corresponding Sharpe ratio of 9.31 and 2.77, respectively.",2022
Portfolio formation with preselection using deep learning from long-term financial data,"Portfolio theory is an important foundation for portfolio management which is a well-studied subject yet not fully conquered territory. This paper proposes a mixed method consisting of long short-term memory networks and mean-variance model for optimal portfolio formation in conjunction with the asset preselection, in which long-term dependences of financial time-series data can be captured. The experiment uses a large volume of sample data from the UK Stock Exchange 100 Index between March 1994 and March 2019. In the first stage, long short-term memory networks are used to forecast the return of assets and select assets with higher potential returns. After comparing the outcomes of the long short-term memory networks against support vector machine, random forest, deep neural networks, and autoregressive integrated moving average model, we discover that long short-term memory networks are appropriate for financial time-series forecasting, to beat the other benchmark models by a very clear margin. In the second stage, based on selected assets with higher returns, the mean-variance model is applied for portfolio optimisation. The validation of this methodology is carried out by comparing the proposed model with the other five baseline strategies, to which the proposed model clearly outperforms others in terms of the cumulative return per year, Sharpe ratio per triennium as well as average return to the risk per month of each triennium. i.e. potential returns and risks. (C) 2019 Elsevier Ltd. All rights reserved.",2020
RETRACTED: LSTM-Based Deep Model for Investment Portfolio Assessment and Analysis (Retracted Article),"In recent years, within the scope of financial quantification, quantitative investment models that support human-oriented algorithms have been proposed. These models attempt to characterize fiat-delayed series through intelligent acquaintance methods to predict data and arrange investment strategies. The standard long short-term memory (LSTM) neural network has the shortcoming of low effectiveness of the fiscal cycle sequence. This work utters throughout the amended LSTM design. The augury result of the neural reticulation was upgraded by coalesce attentional propose to the LSTM class, and a genetic algorithmic program product was formulated. Genetic algorithm (GA) updates the inalienable parameters to a higher generalization aptitude. Using man stock insignitor future data from January 2019 to May 2020, we accomplish a station-of-the-contrivance algorithmic rule. Inferences have shown that the improved LSTM example proposed in this paper outperforms other designs in multiple respect, and it performs effectively in investment portfolio design, which is suitable for future investment.",2022
A Deep Learning Based Expert Framework for Portfolio Prediction and Forecasting,"Stock market forecasting involves predicting fluctuations and trends in the value of financial assets, utilizing statistical and machine learning models to analyze historical market data for insights into future behavior. This practice aids investors, traders, financial institutions, and governments in making informed decisions, managing risks, and assessing economic conditions. Forecasting financial markets is difficult due to the intricate interplay of global economics, politics, and investor sentiment, making it inherently unpredictable. This study introduces a Deep Learning based Expert Framework for Stock Market forecasting (Portfolio prediction) called DLEF-SM. The methodology begins with an improved jellyfish-induced filtering (IJF-F) technique for preprocessing, effectively analyzing raw data and eliminating artifacts. To address imbalanced data and enhance data quality, pre-trained convolutional neural network (CNN) architectures, VGGFace2 and ResNet-50, are used for feature extraction. Additionally, an improved black widow optimization (IBWO) algorithm is designed for feature selection, reducing data dimensionality and preventing under-fitting. For precise stock market predictions, integrate deep reinforcement learning with artificial neural network (DRL-ANN) is proposed. Simulation outcomes reveal that the proposed framework achieves maximum forecasting accuracy, reaching 99.562%, 98.235%, and 98.825% for S&P500-S, S&P500-L, and DAX markets, respectively.",2024
Portfolio Optimization with Prediction-Based Return Using Long Short-Term Memory Neural Networks: Testing on Upward and Downward European Markets,"In recent years, artificial intelligence has helped to improve processes and performance in many different areas: in the field of portfolio optimization, the inputs play a crucial role, and the use of machine learning algorithms can improve the estimation of the inputs to create robust portfolios able to generate returns consistently. This paper combines classical mean-variance optimization and machine learning techniques, concretely long short-term memory neural networks to provide more accurate predicted returns and generate profitable portfolios for 10 holding periods that present different financial contexts. The proposed algorithm is trained and tested with historical EURO STOXX 50 (R) Index data from January 2015 to December 2020, and from January 2021 to June 2022, respectively. Empirical results show that our LSTM neural networks are able to achieve minor predictive errors since the average of the MSE of the 10 holding periods is 0.00047, the average of the MAE is 0.01634, and predict the direction of returns with an average accuracy over the 10 investment periods of 95.8%. Our prediction-based portfolios consistently beat the EURO STOXX 50 (R) Index, achieving superior positive results even during bear markets.",2025
Predicting stock price movement using a DBN-RNN,"This paper proposes a deep learning-based model to predict stock price movements. The proposed model is composed of a deep belief network (DBN) to learn the latent feature representation from stock prices, and a long short-term memory (LSTM) network to exploit long-range relations within the trading history. The prediction target of the model is the stock close price direction on the next day. To predict the trend of one stock, the feature of recent trading information is generated from the raw intra-day data through a pre-trained DBN. Then the extracted features are fed into an LSTM classifier to produce the prediction result for the next day. The proposed model was tested on 36 companies in the Shanghai Stock Exchange (SSE) and the Shenzhen Stock Exchange (SZSE), which were selected based on their weights in Chinese A-shares. The experiments cover a span of 12 years, from 2005 to 2016, and the results show that the proposed model offers notable improvements in predicting performance comparing with other learning models. It is also observed that some companies are more predictable than others, which implies that the proposed model can be used for financial portfolio construction.",2021
A Gated Recurrent Unit Approach to Bitcoin Price Prediction,"In today's era of big data, deep learning and artificial intelligence have formed the backbone for cryptocurrency portfolio optimization. Researchers have investigated various state of the art machine learning models to predict Bitcoin price and volatility. Machine learning models like recurrent neural network (RNN) and long short-term memory (LSTM) have been shown to perform better than traditional time series models in cryptocurrency price prediction. However, very few studies have applied sequence models with robust feature engineering to predict future pricing. In this study, we investigate a framework with a set of advanced machine learning forecasting methods with a fixed set of exogenous and endogenous factors to predict daily Bitcoin prices. We study and compare different approaches using the root mean squared error (RMSE). Experimental results show that the gated recurring unit (GRU) model with recurrent dropout performs better than popular existing models. We also show that simple trading strategies, when implemented with our proposed GRU model and with proper learning, can lead to financial gain.",2020
IntelliPortfolio: Intelligent Portfolio for Enhanced Index Tracking Using Clustering and LSTM,"Enhanced index tracking (EIT) is an active research area in portfolio management that focuses on adding reliable value relative to the index on the basis of mimicking the behavior of the benchmark index. To solve the EIT problem, many approaches have been proposed. However, it still remains a critical challenge to efficiently generate a portfolio with good quality. In this study, we propose a learning-based approach named IntelliPortfolio for the EIT problem. IntelliPortfolio uses PCA and clustering to select stock and estimates the investment weight for each constituent stock using a long short-term memory (LSTM) network. Two advantages of the proposed algorithm are as follows. (1) It considers both the fundamentals and the price information for stocks and can balance the trade-off between the performance and the diversity of the selected stocks. (2) It uses a LSTM model to estimate investment weights, which is more capable to handle long sequences of input and is more robust to predict the future trend of stock market. Experimental results on the five real-world datasets of the international stock market illustrate the significant performance superiority of the proposed approach in comparison with five state-of-the-art algorithms.",2022
Portfolio Learning Based on Deep Learning,"Traditional portfolio theory divides stocks into different categories using indicators such as industry, market value, and liquidity, and then selects representative stocks according to them. In this paper, we propose a novel portfolio learning approach based on deep learning and apply it to China's stock market. Specifically, this method is based on the similarity of deep features extracted from candlestick charts. First, we obtained whole stock information from Tushare, a professional financial data interface. These raw time series data are then plotted into candlestick charts to make an image dataset for studying the stock market. Next, the method extracts high-dimensional features from candlestick charts through an autoencoder. After that, K-means is used to cluster these high-dimensional features. Finally, we choose one stock from each category according to the Sharpe ratio and a low-risk, high-return portfolio is obtained. Extensive experiments are conducted on stocks in the Chinese stock market for evaluation. The results demonstrate that the proposed portfolio outperforms the market's leading funds and the Shanghai Stock Exchange Composite Index (SSE Index) in a number of metrics.",2020
Deep learning in stock portfolio selection and predictions,"Deep learning (DL) has made its way into many disciplines ranging from health care to self-driving cars. In financial markets, we see a rich literature for DL applications. Particularly, investors require robust algorithms that can navigate and make sense of extremely noisy and volatile markets. In this work, we use deep learning to select a portfolio of stocks and use a genetic algorithm to optimize the hyperparameters of DL. The work analyzes the improvement in using genetic-based hyperparameter optimization over grid searches. The Genetic Algorithm brings 40% improvements in prediction when compared to a random-grid search. Novelty-wise, the work couples a genetic-based hyperparameter optimization with multiple Deep RankNet models to predict the behavior of financial assets. Our results show promising portfolio returns 20% better than the general market. In the highly volatile COVID 19 period, the models exceed market returns by more than double. Overall, this paper brings a comprehensive work that integrates hyperparameter optimization, Deep RankNet, LSTM, period size variations, input variable transformation, feature selection, training/evaluation ratio analysis, and multiple portfolio selection strategies.",2024
A Multi-Scale Temporal Feature Aggregation Convolutional Neural Network for Portfolio Management,"Financial portfolio management is the process of periodically reallocating a fund into different financial investment products, with the goal of achieving the maximum profits. While conventional financial machine learning methods try to predict the price trends, reinforcement learning based portfolio management methods makes trading decisions according to the price changes directly. However, existing reinforcement learning based methods are limited in extracting the price change information at single-scale level, which makes their performance still not satisfactory. In this paper, inspired by the Inception network that has achieved great success in computer vision and can extract multi-scale features simultaneously, we propose a novel Ensemble of Identical Independent Inception (EI3) convolutional neural network, with the objective of addressing the limitation of existing reinforcement learning based portfolio management methods. With EI3, multiple assets can be processed independently while sharing the same network parameters. Moreover, price movement information for each product can be extracted at multiple scales via wide network and then aggregated to make trading decision. Based on EI3, we further propose a recurrent reinforcement learning framework to provide a deep machine learning solution for the portfolio management problem. Comprehensive experiments on the cryptocurrency datasets demonstrate the superiority of our method over existing competitors, in both upswing and downswing environments.",2019
A novel recurrent neural network based online portfolio analysis for high frequency trading,"The Markowitz model, a Nobel Prize winning model for portfolio analysis, paves the theoretical foundation in finance for modern investment. However, it remains a challenging problem in the high frequency trading (HFT) era to find a more time efficient solution for portfolio analysis, especially when considering circumstances with the dynamic fluctuation of stock prices and the desire to pursue contradictory objectives for less risk but more return. In this paper, we establish a recurrent neural network model to address this challenging problem in runtime. Rigorous theoretical analysis on the convergence and the optimality of portfolio optimization are presented. Numerical experiments are conducted based on real data from Dow Jones Industrial Average (DJIA) components and the results reveal that the proposed solution is superior to DJIA index in terms of higher investment returns and lower risks.",2023
Enhancing Portfolio Performance through Financial Time-Series Decomposition-Based Variational Encoder-Decoder Data Augmentation,"The objective of portfolio diversification is to reduce risk and potentially enhance returns by spreading investments across different asset classes. Existing portfolio diversification models have traditionally been trained on historical financial time series data. However, several issues arise with historical financial time series data, making it challenging to train models effectively to achieve the portfolio diversification objective: an insufficient amount of training data and the uncertainty deficiency problem, wherein the uncertainty that existed in the past is not visible in the present. Insufficient datasets, characterized by small data size, result in information asymmetry and compromise portfolio performance. This limitation underscores the importance of adopting a pattern-centric data augmentation approach, capable of unveiling hidden patterns and structures within the financial time series data. To address these challenges, this paper introduces the financial time series decomposition-based variational encoder-decoder (FED) method to augment financial time series data, overcoming the limitations of insufficient training data and providing a more realistic and dynamic simulation of the financial market environment. By decomposing the data into distinct components, such as trend, dispersion, and residual, FED leverages pattern-centric data augmentation within the financial time series data. In the environment generated using the FED method, this paper proposes a two-class portfolio diversification, called FED2Port. It integrates stochastic elements into the reward function, enabling a reinforcement learning algorithm to learn from a comprehensive spectrum of financial market uncertainties. The experimental results demonstrate that the proposed model significantly enhances portfolio performance.",2024
Prediction-Based Portfolio Optimization Models Using Deep Neural Networks,"Portfolio optimization is a hot research topic, which has attracted many researchers in recent decades. Better portfolio optimization model can help investors earn more stable profits. This paper uses three deep neural networks (DNNs), i.e., deep multilayer perceptron (DMLP), long short memory (LSTM) neural network and convolutional neural network (CNN) to build prediction-based portfolio optimization models which own the advantages of both deep learning technology and modern portfolio theory. These models first use DNNs to predict each stock's future return. Then, predictive errors of DNNs are applied to measure the risk of each stock. Next, the portfolio optimization models are built by integrating the predictive returns and semi-absolute deviation of predictive errors. These models are compared with three equal weighted portfolios, where their stocks are selected by DMLP, LSTM neural network and CNN respectively. Also, two prediction-based portfolio models built with support vector regression are used as benchmarks. This paper applies component stocks of China securities 100 index in Chinese stock market as experimental data. Experimental results present that the prediction-based portfolio model based on DMLP performs the best among these models under different desired portfolio returns, and high desired portfolio return can further improve the performance of this model. This paper presents the promising performance of DNNs in building prediction-based portfolio models.",2020
Developing a hybrid system for stock selection and portfolio optimization with many-objective optimization based on deep learning and improved NSGA-III,"Portfolio management is a critical aspect of investment strategies, with the goal to balance the low-risk and high-return investments. Despite this, existing portfolios frequently overlook the integration of stock selection outcomes and underutilize data from listed companies, leading to suboptimal portfolio performance. Addressing these shortcomings, this paper introduces a hybrid system involving stock selection and portfolio optimization. In stock selection, the system employs a combination of convolutional neural network and bi-directional recurrent neural network to predict stock trends. This approach enables the identification of stocks likely to appreciate in value, setting the stage for their inclusion in the subsequent optimization process. For portfolio optimization, the study formulates a five-objective optimization problem that incorporates mean, variance, skewness, kurtosis, and distance-to-default as key considerations. To solve the manyobjective constrained optimization problem, an advanced strategy employing a static penalty function and an improved Non-dominated Sorting Genetic Algorithm III (NSGA-III) based on tent chaotic mapping is utilized. The efficacy of the proposed hybrid system is rigorously tested through three sets of ablation experiments alongside two discussions focused on its robustness and computational efficiency. The findings from these investigations reveal that the hybrid system outperforms traditional approaches, reducing risks and improving returns for investors.",2024
Fusion of Sentiment and Asset Price Predictions for Portfolio Optimization,"The fusion of public sentiment data in the form of text with stock price prediction is a topic of increasing interest within the financial community. However, the research literature seldom explores the application of investor sentiment in the Portfolio Selection problem. This paper aims to unpack and develop an enhanced understanding of the sentiment-aware portfolio selection problem. To this end, the study uses a Semantic Attention model to predict sentiment towards an asset. We select the optimal portfolio through a sentiment-aware Long Short Term Memory (LSTM) recurrent neural network for price prediction and a mean-variance strategy. Our sentiment portfolio strategies achieved, on average, a significant increase in revenue above the non-sentiment aware models. However, the results show that our strategy does not outperform traditional portfolio allocation strategies from a stability perspective. We argue that an improved fusion of sentiment prediction with a combination of price prediction and portfolio optimization leads to an enhanced portfolio selection strategy.",2022
Hidden-layer configurations in reinforcement learning models for stock portfolio optimization,"In the rapidly evolving field of artificial intelligence and financial markets, efficient and adaptive portfolio management strategies are becoming increasingly critical. This study explores the impact of hidden-layer configurations in reinforcement learning models for stock portfolio optimization. Using a portfolio of 45 actively traded stocks in the Indonesian stock market, the performance of four reinforcement learning algorithms-Advantage Actor-Critic (A2C), Deep Deterministic Policy Gradient (DDPG), Proximal Policy Optimization (PPO), and Twin Delayed Deep Deterministic Policy Gradient (TD3)-is evaluated with zero, one, and two hidden layers. The results show that A2C and DDPG models perform effectively without hidden layers, with A2C achieving the highest Cumulative Return (CuR) and Annualized Return Rate (ARR) among all configurations. Adding hidden layers to A2C improved risk management, resulting in a lower Maximum Drawdown (MDD) and a higher Annualized Sharpe Ratio (ASR). DDPG exhibited consistently strong performance, with its zero hidden- layer model showing the highest ASR. Conversely, PPO underperformed across all configurations, with negative returns in the zero-layer setup and marginal improvements with added complexity. Introducing additional hidden layers improved TD3 ' s performance, enhancing risk-adjusted returns. These findings suggest that the effectiveness of hidden-layer configurations depends on the specific algorithm used. While A2C and DDPG benefit from increased complexity, simpler architectures may be more suitable for PPO and TD3. This study offers new insights into optimizing reinforcement learning models for stock portfolio management by adjusting hidden-layer structures to balance returns and risk.",2025
A novel finite-time q-power recurrent neural network and its application to uncertain portfolio model,"This paper presents a novel finite-time q-power recurrent neural network (FT-QPNN) for uncertain port-folio model. An uncertain mean-variance-skewness model under concave transaction costs is discussed. This portfolio model is essentially a nonconvex nonlinear optimization problem with a non-positive def-inite Hessian matrix of the Lagrange function. The non-positive definite Hessian matrix leads to the fail-ure of many recurrent neural network methods in solving the problem, and many recurrent neural networks cannot converge to the equilibrium point in finite time. To overcome these difficulties, the FT-QPNN is proposed. Combined with finite-time activation function and local convexification method, the FT-QPNN can solve the optimization problem with non-positive definite Hessian matrix and converge to the equilibrium point in finite time. The global finite-time stability and robustness properties of the FT-QPNN are proved theoretically and verified by numerical experiments. Furthermore, the proposed FT-QPNN is applied to solve the uncertain portfolio model. The application simulation results and comparative experiments with other methods respectively illustrate the feasibility and superiority of the FT-QPNN. (c) 2021 Elsevier B.V. All rights reserved.",2021
Hybrid Crow Search Algorithm-LSTM System for Enhanced Stock Price Forecasting,"Featured Application The proposed hybrid crow search algorithm (CSA) and long short-term memory (LSTM) system can be utilized for stock price forecasting by simultaneously leveraging multiple datasets, such as technical indicators, leading indicators, and various time series data related to stock prices. This system enhances prediction accuracy. This system can help financial institutions, investment firms, and individual traders make more informed trading decisions and optimize portfolio strategies by accurately forecasting future stock prices.Abstract This study presents a hybrid crow search algorithm-long short-term memory (CSLSTM) system for forecasting stock prices. This system allows investors to effectively avoid risks and enhance profits by predicting the closing price the following day. This method utilizes a stacking ensemble of long short-term memory (LSTM) networks, with the crow search algorithm (CSA) optimizing the weights assigned to the predictions from multiple LSTM models. To improve the overall accuracy, this system leverages three distinct datasets: technical analysis indicators; price fluctuation limits; and variation mode decomposition (VMD) subsignal sequences. The predictions for the three reference-data types are more comprehensive than single-model or single-data-type approaches. The prediction accuracies of the recurrent neural network, gate recurrent unit, and the LSTM network for five stocks were compared. The proposed CSLSTM system outperforms the other standalone models. Furthermore, we conducted backtesting to demonstrate that the prediction information from our model could generate profit in the stock market, enabling users to benefit from complex stock-market dynamics. The stock prices in this study are expressed in New Taiwan Dollars (TWD), the official currency of Taiwan.",2024
An Advanced Deep Learning Approach for Nickel Price Prediction Model Evading Outliers Using Enhanced Multikernel LSTM,"Managing Investment Portfolio in commodity trading requires focus on profit making, high earnings and effective investment returns within time bound criteria. The level of risk management is majorly decided by the trader, based on the lot size of purchase during each commodity investment. Based on the previous studies and learning from market trading, it is inferred that commodity pricing is the pivot element for strategic decision making. For the current economic trends and variations, predictions with the conventional neural network models may not provide a long-term sustainable solution. With advanced Gaussian Processes (GP) Long Short Term Memory model, predictions gained attention with higher accuracy levels. To meet advanced market trends and adapt to fluctuations in economic variants, an enhancement over Multiple Kernel - LSTM (MK-LSTM) network model along with drop out regularization with repeated cycles to evade outliers is proposed to predict market price of Nickel commodity. With experimental analysis and results derived, this approach provides better bandwidth of predicted price range as outlier detection is regularized. This study indicates better market price prediction and proposal to achieve higher returns in terms of calculation benefits for trader to respond quickly and effectively to changing market dynamics, evading over fitted and under fitted values from the dataset. This approach proposes to build a model based on Enhanced MK-LSTM with dropout regularization aiming to perform preprocessing, normalization of data, apply multiple kernel layers, evade outliers and aim for noise removal using deep learning approaches thereby enhance performance of price prediction model.",2022
Clustering-based return prediction model for stock pre-selection in portfolio optimization using PSO-CNN plus MVF,"Incorporating return prediction in portfolio optimization can make portfolio optimization more efficient by selecting the stocks expected to perform well in the future. This paper proposes a hybrid method that integrates a convolutional neural network (CNN) with optimized hyperparameters by the particle swarm optimization (PSO) for stock pre-selection and a mean-variance with forecasting (MVF) model for portfolio optimization. In the stock pre-selection step, to reduce the computational complexity of the model, the CNN network is trained on the clustered stocks via the K-means method instead of training on each stock. The proposed model also includes a novel feature selection method that weighs features based on their impact on predicting stock returns for more accurate predictions. The results of implementing this model on 21 stocks from the New York Stock Exchange (NYSE) market demonstrate that the proposed method for training the CNN network on clustered stocks does not signicantly differ in prediction accuracy to conventional methods. Moreover, in the portfolio optimization step, the returns predicted in the stock pre-selection step are used to optimize the weight of stocks in the portfolio. Compared to other benchmark models, the proposed model exhibits superior financial performance. & COPY; 2023 The Author(s). Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).",2023
"Should Deep Learning Models be in High Demand, or Should They Simply be a Very Hot Topic? A Comprehensive Study for Exchange Rate Forecasting","Exchange rate movements can significantly impact not only foreign trade, capital flows, and asset portfolio management, but also real economic activity. Therefore, the forecast of exchange rates has always been of great interest among academics, economic agents, and institutions. However, exchange rate series are essentially dynamic and nonlinear in nature and thus, forecasting exchange rates is a difficult task. On the other hand, deep learning models in solving time series forecasting tasks have been proposed in the last half-decade. But the number of formal comparative study in terms of exchange rate forecasting with deep learning models is quite limited. For this purpose, this study applies ten different models (Random Walk, Autoregressive Moving Average, Threshold Autoregression, Autoregressive Fractionally Integrated Moving Average, Support Vector Regression, Multilayer Perceptron, Recurrent Neural Network, Long Short Term Memory, Gated Recurrent Unit and Autoregressive Moving Average-Long Short Term Memory Hybrid Models) and two forecasting modes (recursive and rolling window) to predict three major exchange rate returnsnamely, the Canadian dollar, Australian dollar and British pound against the US Dollar in monthly terms. To evaluate the forecasting performances of the models, we used Model Confidence Set procedure as an advanced test. According to our results, the proposed hybrid model produced the best out-of-sample forecast performance in all samples, without exception.",2021
Long Short-Term Memory Recurrent Neural Network for Predicting the Return of Rate Underframe the Fama-French 5 Factor,"The multifactor approach helps determine the linear connection between a diversified portfolio's return and risk; however, the efficacy of the model models is still limited in the experiment. Algorithms in machine learning have recently grown in popularity to compensate for some of the shortcomings of theoretical models. This study applied a machine learning technique to compare the performance of the Fama-French 5-factor model (FF5). Two approaches are employed in the Fama-French model: Long Short Term Memory Recurrent Neural Network (LSTM-RNN) and Maximum Likelihood Estimation (MLE). From January 1, 2010, through March 3, 2022, the stock market in Ho Chi Minh City was experimentally researched. The rolling window approach is used in combination with the Root Mean Square Error (RMSE), and the results of the FF5 model with the LSTM-RNN algorithm are more efficient in prediction error than the MLE methodology. This contribution encourages investors and hedge fund managers to use the LSTM-RNN algorithm to boost forecasting efficiency.",2022
Deep Learning for Stock Price Prediction and Portfolio Optimization,"Using deep learning for stock market predictions and portfolio optimizations is a burgeoning field of research. This study focuses on the stock market dynamics in developing countries, which are often considered less stable than their developed counterparts. The study is structured in two stages. In the first stage, the authors introduce a stacked LSTM model for predicting NIFTY stocks and then rank the stocks based on their predicted returns. In the second stage, the high-return stocks are selected to form 30 different portfolios with six different objectives, each comprising the top 7, 8, 9, and 10 NIFTY stocks. These portfolios are then compared based on risk and returns. Experimental results show that portfolios with five stocks offer the best returns and that adding more than nine stocks to the portfolio leads to excessive diversification and complexity. Therefore, the findings suggest that the proposed two-stage portfolio optimization method has the potential to construct a promising investment strategy, offering a balance between historical and future information on assets.",2024
Price prediction in China stock market: an integrated method based on time series clustering and image feature extraction,"Stock time-series data has the characteristics of high dimensionality and nonlinearity, which brings great challenges to stock forecasting. Aiming at the impact of stock correlation and the prediction information contained in stock image features, we propose a long short-term memory model based on clustering and image feature extraction, named Kmeans-CAE-LSTM. Firstly, the Kmeans algorithm is used for stock clustering, where the most correlated stocks are found. Secondly, a convolutional autoencoder (CAE) is applied to extract stock price image features. Finally, the stock technical data and image features are respectively input into the double-layer long-term short-term memory network to predict the stock price of the next trading day. The empirical research results on 11 industries in China's stock market show that the hybrid model has achieved the best prediction effect, which further proves the predictive ability of stock image data and can provide investors with new ideas for stock prediction and asset portfolio.",2024
Deep learning for decision making and the optimization of socially responsible investments and portfolio,"A socially responsible investment portfolio takes into consideration the environmental, social and governance aspects of companies. It has become an emerging topic for both financial investors and researchers recently. Traditional investment and portfolio theories, which are used for the optimization of financial investment portfolios, are inadequate for decision-making and the construction of an optimized socially responsible investment portfolio. In response to this problem, we introduced a Deep Responsible Investment Portfolio (DRIP) model that contains a Multivariate Bidirectional Long Short-Term Memory neural network, to predict stock returns for the construction of a socially responsible investment portfolio. The deep reinforcement learning technique was adapted to retrain neural networks and rebalance the portfolio periodically. Our empirical data revealed that the DRIP framework could achieve competitive financial performance and better social impact compared to traditional portfolio models, sustainable indexes and funds.",2019
MCN portfolio: An efficient portfolio prediction and selection model using multiserial cascaded network with hybrid meta-heuristic optimization algorithm,"Generally, financial investments are necessary for portfolio management. However, the prediction of a portfolio becomes complicated in several processing techniques which may cause certain issues while predicting the portfolio. Moreover, the error analysis needs to be validated with efficient performance measures. To solve the problems of portfolio optimization, a new portfolio prediction framework is developed. Initially, a dataset is collected from the standard database which is accumulated with various companies' portfolios. For forecasting the benefits of companies, a Multi-serial Cascaded Network (MCNet) is employed which constitutes of Autoencoder, 1D Convolutional Neural Network (1DCNN), and Recurrent Neural Network (RNN) is utilized. The prediction output for the different companies is stored using the developed MCNet model for further use. After predicting the benefits, the best company with the highest profit is selected by Integration of Artificial Rabbit and Hummingbird Algorithm (IARHA). The major contribution of our work is to increase the accuracy of prediction and to choose the optimal portfolio. The implementation is conducted in Python platform. The result analysis shows that the developed model achieves 0.89% and 0.56% regarding RMSE and MAE measures. Throughout the analysis, the experimentation of the developed model shows enriched performance.",2024
DELAFO: An Efficient Portfolio Optimization Using Deep Neural Networks,"Portfolio optimization has been broadly investigated during the last decades and had a lot of applications in finance and economics. In this paper, we study the portfolio optimization problem in the Vietnamese stock market by using deep-learning methodologies and one dataset collected from the Ho Chi Minh City Stock Exchange (VN-HOSE) from the beginning of the year 2013 to the middle of the year 2019. We aim to construct an efficient algorithm that can find the portfolio having the highest Sharpe ratio in the next coming weeks. To overcome this challenge, we propose a novel loss function and transform the original problem into a supervised problem. The input data can be determined as a 3D tensor, while the predicted output is the unnormalized weighted proportion for each ticker in the portfolio to maximize the daily return Y of the stock market after a given number of days. We compare different deep learning models, including Residual Networks (ResNet), Long short-term memory (LSTM), Gated Recurrent Unit (GRU), Self-Attention (SA), Additive Attention (AA), and various combinations: SA + LSTM, SA + GRU, AA + LSTM, and AA + GRU. The experimental results show that the AA + GRU outperforms the rest of the methods on the Sharpe ratio and provides promising results for the portfolio optimization problem not only in Vietnam but also in other countries.",2020
The commodity risk premium and neural networks,"The paper uses linear and nonlinear predictive models to study the linkage between a set of 128 macroeconomic and financial predictors and the risk premium of commodity futures contracts. The linear models use shrinkage methods based on either naive averaging or principal components. The nonlinear models use feedforward deep neural networks (DNN) either as stand-alone or in conjunction with a long short-term memory network (LSTM). Out of the four specifications considered, the LSTM-DNN architecture best captures the risk premium, which underscores the need to estimate models that are both nonlinear and recurrent. The superior performance of the LSTM-DNN portfolio persists after accounting for transaction costs or illiquidity and is unrelated to previously-documented commodity risk factors.",2023
Forecasting the elasticity of variance with LSTM recurrent neural networks,"Volatility forecasting is an important tool because it can be used in many different applications across the industry including risk management, derivatives trading and optimal portfolio selection. On the other hand, machine learning tends to be more accurate in making predictions when large volumes of data are involved in the system which the financial services industry tends to encounter. In this paper, we show that a fractional stochastic generalization of the elasticity of variance can contain latent features of the market elasticity of variance by using an artificial recurrent neural network architecture called LSTM (Long Short-Term Memory) to forecast the elasticity of variance. It is shown that the forecast only with the elasticity of variance data has no statistically significant difference from forward filling, but information on the Hurst exponent can improve the power of forecasting the elasticity of variance.",2023
Ensemble time series models for stock price prediction and portfolio optimization with sentiment analysis,"The work introduces a hybrid ensemble model that combines conventional stock market prediction models with sentiment analysis of news articles in order to improve the accuracy of predictions. By utilizing the advantages of Long Short-Term Memory(LSTM), Gated Recurrent Unit(GRU), Bidirectional LSTM (BiLSTM), and Recurrent Neural Network(RNN) models in an ensemble framework, we attain an impressive average prediction accuracy of 91.89% where our model was evaluated on ten stocks and surpassed the performance of current models. This outcome underscores the need to integrate news sentiment with technical indicators to get a thorough comprehension of market dynamics. Moreover, the proposed model-driven portfolio regularly outperforms the Nifty 50 benchmark at different risk tolerance levels (0.3, 0.5, and 0.7), generating a stable positive alpha. This indicates greater returns when adjusted for risk. The model's ability to adapt to the varying needs of investors is demonstrated by the performance it achieved across risk profiles. The proposed model is also compared with the existing models to show the model's efficiency.",2025
Deep Portfolio Optimization Modeling based on Conv-Transformers with Graph Attention Mechanism,"Optimizing portfolios is an important concern for all investors. Nowadays, deep learning has been applied to the study of portfolio investment. Still, the widely used deep learning methods based on asset return prediction do not guarantee to maximize the performance of a portfolio. In this paper, we design a neural network with the overall return-risk ratio of the portfolio as the optimization objective to determine the optimal allocation weights of the portfolio. We design the network architecture based on the Conv-Transformer with graph attention mechanisms(CTG) to better model the temporal dependence of assets and the correlation relationship between assets. The empirical results on the Chinese stock market show that our approach achieves the best results compared to the current SOTA model.",2022
RPS: Portfolio asset selection using graph based representation learning,"Portfolio optimization is one of the essential fields of focus in finance. There has been an increasing demand for novel computational methods in this area to compute portfolios with better returns and lower risks in recent years. We present a novel computational method called Representation Portfolio Selection by redefining the distance matrix of financial assets using Representation Learning and Clustering algorithms for portfolio selection to increase diversification. RPS proposes a heuristic for getting closer to the optimal subset of assets. Using empirical results in this paper, we demonstrate that widely used portfolio optimization algorithms, such as Mean-Variance Optimization, Critical Line Algorithm, and Hierarchical Risk Parity can benefit from our asset subset selection.",2024
Novel volatility forecasting using deep learning-Long Short Term Memory Recurrent Neural Networks,"The volatility is related to financial risk and its prediction accuracy is very important in portfolio optimisation. A large body of literature to-date suggests Support Vector Machines (SVM) as the best of regression algorithms for financial data regression. Recent work however found that new deep learning-Long Short Term Memory Recurrent Neural Networks (LSTM RNNs) outperformed SVM for classification problems. In the present paper we conduct a new unbiased evaluation of these two modelling techniques for regression problems, and we also compare them with a popular regression model - Generalized Autoregressive Conditional Heteroskedasticity (GARCH) model for financial volatility or risk forecasting. Our experiments using financial data show that the LSTM RNNs performed as good as v-SVR for large interval volatility forecasting and both performed much better than GARCH model for two financial indices (S&P 500 and AAPL). The LSTM RNNS deep learning method can learn from big raw data and can be run with many hidden layers and neurons under GPU to achieve a good prediction for long sequence data compared to the support vector regression. The deep learning technique - LSTM RNNs with big data can be used to improve the volatility prediction instead of v-SVR when the v-SVR does not predict well for some financial stocks of a portfolio. This will help investors to win the competition to maximize their profit. (C) 2019 Elsevier Ltd. All rights reserved.",2019
A one-layer recurrent neural network for constrained pseudoconvex optimization and its application for dynamic portfolio optimization,"In this paper, a one-layer recurrent neural network is proposed for solving pseudoconvex optimization problems subject to linear equality and bound constraints. Compared with the existing neural networks for optimization (e.g., the projection neural networks), the proposed neural network is capable of solving more general pseudoconvex optimization problems with equality and bound constraints. Moreover, it is capable of solving constrained fractional programming problems as a special case. The convergence of the state variables of the proposed neural network to achieve solution optimality is guaranteed as long as the designed parameters in the model are larger than the derived lower bounds. Numerical examples with simulation results illustrate the effectiveness and characteristics of the proposed neural network. In addition, an application for dynamic portfolio optimization is discussed. (c) 2011 Elsevier Ltd. All rights reserved.",2012
Multi-Model Generative Adversarial Network Hybrid Prediction Algorithm (MMGAN-HPA) for stock market prices prediction,"Deep learning has achieved greater success in optimizing solutions associated with Artificial Intelligence (AI). In the financial domain, it is widely used for stock market prediction, trade execution strategies and portfolio optimization. Stock market prediction is a very significant use case in this domain. Generative Adversarial Networks (GANs) with advanced AI models have gained significance of late. However, it is used in image-image-translation and other computer vision scenarios. GANs are not used much for stock market prediction due to its difficulty in setting the right set of hyperparameters. In this paper, overcome this problem with reinforcement learning and Bayesian optimization. A deep learning framework based on GAN, named Stock-GAN, is implemented with generator and discriminator. The former is realized with LSTM, a variant of Recurrent Neural Network (RNN), while the latter uses Convolutional Neural Network. An algorithm named Generative Adversarial Network based Hybrid Prediction Algorithm (GAN-HPA) is proposed. An empirical study revealed that Stock-GAN achieves promising performance in stock price prediction when compared with the state of the art model known as Multi-Model based Hybrid Prediction Algorithm (MM-HPA). Afterwards, MM-HPA and GAN-HPA combined to form yet another hybrid model known as MMGAN-HPA for improved performance over MM-HPA and GAN-HPA.(c) 2021 The Authors. Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).",2022
A New Time-Aware LSTM based Framework for Multi-label Classification on Healthcare Data,"Medical prevention is a very important aspect of healthcare informatics research through the prediction of medical events (e.g., disease diagnosis). In this work, we propose a deep learning approach to perform multi-label prediction on acts of medical care and treatments. The proposed approach utilizes a time-aware long short-term memory network and extends it with additional information from a fuzzy clustering of the same portfolio. The former mechanism (time-aware) is used to handle the temporal irregularity between the elements of a medical trajectory whereas the latter mechanism (fuzzy clustering) assists in modeling the heterogeneity among patients and treatments. Using a large portfolio of reimbursed medical records (over 16 million consumed acts of medical care) by a healthcare insurance in France, we show that our approach outperforms traditional and deep learning methods in medical multi-label prediction. Our work has implications for supporting medical prevention and more broadly improving the quality of healthcare services and insurance.",2023
Intelligent Asset Allocation Portfolio Division and Recommendation: Based on Deep Learning and Knowledge Graphs,"With the continuous development of financial markets, intelligent asset allocation has become a topic of great concern in the investment field. However, traditional asset allocation methods often face difficulties in grasping the relationship between diversity, risk and return, which limits its application in complex market environments. To solve this problem, this study introduces deep learning and knowledge graphs and proposes an intelligent asset allocation model. Our model makes full use of the advantages of the Knowledge Graph Embedding Model (KGE), LSTM, and Genetic Algorithm (GA) to build a multi-level and multi-dimensional asset allocation model. KGE helps capture the complex relationships between different assets, LSTM is used to learn key patterns of historical portfolio performance, and GA finds the optimal asset allocation combination by simulating natural selection and genetic mechanisms. Experimental findings indicate that our model has demonstrated substantial improvements across various performance metrics and outperforms conventional approaches.",2024
Threshold-based portfolio: the role of the threshold and its applications,"This paper aims at developing a new method by which to build a data-driven portfolio featuring a target risk-return. We first present a comparative study of recurrent neural network models (RNNs), including a simple RNN, long short-term memory (LSTM), and gated recurrent unit. The models are applied to the investment universe consisted of 10 stocks in theS&P500 The experimental results show that the LSTM-based prediction model outperforms the others in terms of hit ratio of 1-month-ahead forecasts. We then build predictive threshold-based portfolios (TBPs) that are subsets of the universe satisfying given threshold criteria for the LSTM-based return forecasts. The TBPs are rebalanced monthly to restore equal weight to the constituents of the TBPs. We find that the risk and return profile of the realized TBP represents a monotonically increasing frontier on the risk-return plane, where the equally weighted universe portfolio plays a role in the lower bound of TBPs. This shows the availability of TBPs in targeting specific risk-return levels, and the EWP of an universe plays a role in the reference portfolio of the TBPs. In the process, thresholds play dominant roles in characterizing risk, return, and the prediction accuracy of the TBPs. The TBP is more data-driven in designing portfolio return and risk than existing ones, in the sense that it requires no prior knowledge of finance such as financial assumptions, financial mathematics, or expert insights. For practical uses, we present a multiperiod TBP management method and also discuss the application of TBP to mean-variance portfolios to reduce estimation risk.",2020
MA-FDRNN: Multi-Asset Fuzzy Deep Recurrent Neural Network Reinforcement Learning for Portfolio Management,"Reinforcement learning (RL) in the context of portfolio optimisation (PO) aims to generate profits beyond the abilities of human traders. However, there is no definitive framework sufficiently able to generate consistent profits in line with expectations on real-world stock exchanges. Previous research has demonstrated the ability of Deep Deterministic Policy Gradient (DDPG), Proximal Policy Optimisation (PPO), Ensemble of Identical Independent Evaluators (EIIE) and Fuzzy Deep Recurrent Neural Network (FDRNN) methodologies to generate positive results within controlled testing environments. This paper consolidates recent progress by evaluating these RL methodologies applied to five different stock exchanges. The selected methodologies are tested on real-world data within a simulated trading framework to assess their performance under different market conditions. To this end, we extend the FDRNN method to allow it to interact with a multi-asset market. As a result, in contrast to previous methods, our new Multi-Asset FDRNN (MA-FDRNN) can take short positions, which we hypothesised would give it an advantage over DDPG, PPO and EIIE. To assess the performance of the RL methods, we compare their results to a selection of benchmark PO algorithms. The results show the superiority of the MA-FDRNN method within the sideways and bear market, where it can exploit short positions and earn higher returns at lower risk than the other methods. In the bull markets, the benchmark algorithms outperform the RL agents, and in the crashed market, the RL methods and benchmark algorithms demonstrate similar performance. The results indicate that while RL methods do show some promise in achieving the goals of portfolio management, further research is needed to create an RL framework capable of succeeding in real-world market conditions.",2021
"Effective Convergence Trading of Sparse, Mean Reverting Portfolios","This paper introduces an effective convergence trading algorithm for mean reverting portfolios using Long Short Term Memory (LSTM) neural networks. Utilizing known techniques for selection of sparse, mean reverting portfolios from asset dynamics following the VAR(1) model, we introduce a 2-step technique to effectively trade the optimal portfolio. Sequence-to-sequence (Seq2Seq) LSTM architecture is implemented to make longer term prediction of future portfolio values and establish a trading range. In addition, a simple LSTM network is applied to predict very precisely one time step ahead. Combining these two constructions, a sophisticated convergence trading algorithm is implemented which produced Sharpe ratios around 1.0 on optimal portfolios selected from historical S[NONSPACE]&P500\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ S[NONSPACE] \& P500$$\end{document} stocks during 2015-2022\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$2015-2022$$\end{document}. This represents a very significant improvement compared to the previous convergence trading algorithms on the same set of portfolios by around 141%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$141\%$$\end{document} on average.",2024
Intelligent Asset Allocation using Predictions of Deep Frequency Decomposition,"The boom of financial technology and artificial intelligence (AI) has influenced financial industry. Application of AI-based techniques especially deep neural networks in the stock market has drawn particular attention in recent years. Moreover, applying modern technology in finance has created new fields such as computational finance and intelligent asset management. Following this revolution, the present research aims to shed light on deep learning models in stocks analysis and apply theses analyses in portfolio management. To this end, we introduced a novel hybrid deep learning model for stock prediction and incorporated these predictions as investors' views in Black-Litterman asset allocation model. The finding indicates that the Black-Litterman portfolio based on the predictions of the hybrid CEEMD-CNN-LSTM model constructed portfolios with high return, low extreme allocation, and low risk. Furthermore, the Black-Litterman portfolios based on the introduced prediction model outperformed the mean-variance portfolio, equal-weighted portfolio, and the Black-Litterman portfolios based on the predictions of CNN-LSTM and LSTM. This remarkable performance could be attributed to each constituting model used in the hybrid model and portfolio formation strategy.",2021
Portfolio Management Framework for Autonomous Stock Selection and Allocation,"Portfolio management is essential to reduce risks and maximize profits. It can be classified into two processes: stock selection and allocation. Stock selection identifies stocks with high expected profits, whereas stock allocation determines the investment ratios for the selected stocks. Most current stock selection methods employ a ranking approach that predicts a ranked stock list based on the relations between stocks. However, the ranking-based stock selection methods do not consider the stock allocation problem. Furthermore, the methods use either simple graphs or hypergraphs, but not both. The sole use of simple graphs or hypergraphs induces information loss as the collective or pairwise relations, respectively, are disregarded. To overcome these issues, we propose a novel portfolio management framework called ASA that combines ranking models with classification and regression models for autonomous stock selection and allocation. For stock selection, the simple graph- and hypergraph-based ranking models are hybridized for relational modeling to select the most profitable stocks. For stock allocation, the classification and regression models are combined to determine the investment ratio. Furthermore, ASA extracts robust features using hierarchical clustering, feature selection, and dimensionality reduction, following which it captures temporal information using long short-term memory (LSTM), bidirectional LSTM, and the Hawkes attention mechanism. The performance of ASA is compared with that of deep learning-based state-of-the-art methods. The experimental results for stocks included in the Standard & Poor's 500 index demonstrate that ASA achieves a compounded annual growth rate of 58.2%, which is 39.1%P higher than that of the second-best performing method.",2022
Quantifying Uncertainty of Portfolios using Bayesian Neural Networks,"Quantifying the uncertainty of a financial portfolio is important for investors and regulatory agencies. Reporting such uncertainty accurately is challenging due to time-dependent market dynamics, non-linearities in the return and risk properties of a portfolio, and due to the unobserved nature of the market risk. We propose Bayesian Neural Network (BNN) models, namely Recurrent Neural Network (RNN) and Long Short Term Memory (LSTM) models, to estimate the time-varying return distribution of an asset portfolio. The proposed models estimate the density of returns and incorporate parameter uncertainty through Bayesian inference. The uncertainty and any financial risk metric of interest can directly be obtained from the estimated density. Furthermore, through the BNN input-output design, proposed BNNs incorporate potential non-linear effects of each asset in the portfolio on the obtained density estimates. The proposed method is applicable to assess the uncertainty of any portfolio where the portfolio weight optimization is separated from risk assessment. We analyze the risk of a daily, equally weighted portfolio of 29 ETFs and a risk-free asset for a long time span with differing market environments between 09/06/2005 and 10/09/2020. We study the effects of different inference methods on the obtained results. The proposed models improve portfolio risk estimates compared to the benchmark. The performances of the proposed models depend on BNN design and the inference method. RNN models lead to relatively more stable results compared to LSTMs. Furthermore, the results of models with a relatively higher number of parameters depend heavily on the estimation method.",2024
Robust portfolio management: A novel multi-task learning model fusing predicted returns and residual data under the framework of Mean-VaR,"We investigate how to build a robust portfolio by introducing a novel multi-task learning model that fuses predicted returns and residual data to assess the portfolio risk under the decision-making framework of Mean-VaR. A common way to build a portfolio is to predict the return of assets and then allocate weights according to the predicted return and corresponding risk. However, predicting asset returns accurately in financial markets remains a challenge. To improve prediction accuracy and, more importantly, effectively reduce risk in the portfolio, we adopt the multi-task learning anomaly detection (MTLAD). In this model, predicting asset returns using deep learning model (long short-term memory, LSTM) is the main task, and anomaly detection is the auxiliary task. We then combine the predicted returns and residual data to evaluate the risk measure when allocating the asset weights. Furthermore, we perform an extensive numerical investigation based on data in the Chinese financial market. Results obtained show that our robust portfolio management approach has great potential compared with multiple benchmarks.",2024
Indonesia Infrastructure and Consumer Stock Portfolio Prediction using Artificial Neural Network Backpropagation,"Artificial Neural Network (ANN) method is increasingly popular to build predictive model that generated small error prediction. To have a good model, ANN needs large dataset as an input. ANN backpropagation is a gradient decrease method to minimize the output error squared. Stock price movements are suitable with ANN requirement : it is a large data set because stock price is recorded up to every seconds, usually called high frequency data. The implementation of stock price prediction using ANN approach is quite new. The predictive model help investor in building stock portfolio and their decision making process. Buying some stocks in portfolio decrease diversified risk and increases the chance of higher return. In this paper, we show how to generate prediction model using artificial neural network backpropagation of stock price and forming portfolio with predicted price that bring prediction of the portfolio with the smallest error. The data set we use is historical stock price data from ten different company stocks of infrastructure and consumer sector Indonesia Stock Exchage. The results is for lower risk condition, ANN predictive model gives higher expected return than the return from real condition, while for higher risk, the return from the real condition is higher than the ANN predictive model.",2017
Portfolio optimization using deep learning with risk aversion utility function,"This paper explores portfolio optimization with deep learning (DL), which can model non-linear returns that traditional methods cannot capture. While Sharpe loss addresses the risk-return trade-off in DL-based portfolio construction, it has limitations, including interpretability issues with negative PnL and biased gradients under stochastic gradient descent (SGD). We propose a new loss function based on a risk-averse utility function, which provides unbiased gradients and clear interpretation even with negative PnL. Additionally, we use DL outputs as adjustments to baseline weights, achieving improved portfolio performance. Experiments on S&P 500 data show that our method outperforms Sharpe loss-based models across several metrics, including the Sharpe ratio.",2025
Prospective Portfolio Optimization With Asset Preselection Using a Combination of Long and Short Term Memory and Sharpe Ratio Maximization,"This research presents a novel portfolio optimization model that incorporates asset preselection. This model aims to demonstrate how using Long and Short-Term Memory and Sharpe Ratio Maximization can enhance the efficiency of portfolios.The suggested approach consists of three stages, each with practical applications. During the initial phase, the data is gathered. In the second phase, the LSTM network, a commonly employed tool in predicting stock price movements, is utilized to anticipate the time series of stock closing prices. The third stage of the process focuses on stock selection and determining the appropriate weighting for each stock in the portfolio. The proposed approach is tested and carefully validated using the daily closing prices of ten equities from the FTSE 100. The results demonstrate the model's resilience and efficacy, as the portfolios generated using the anticipated and validation data exhibit high similarity. Given the importance of selecting the right stocks for portfolio optimization, this study will combine asset preselection with portfolio weighting. Furthermore, this study utilized a Long Short-Term Memory network to forecast the optimization model's parameters accurately and introduced a novel portfolio optimization model.",2024
A new investment method with AutoEncoder: Applications to crypto currencies,"This paper proposes a novel approach to the portfolio management using an AutoEncoder. In particular, features learned by an AutoEncoder with ReLU are directly exploited to portfolio constructions. Since the AutoEncoder extracts characteristics of data through a non-linear activation function ReLU, its realization is generally difficult due to the non-linear transformation procedure. In the current paper, we solve this problem by taking full advantage of the similarity of ReLU and an option payoff. Especially, this paper shows that the features are successfully replicated by applying so-called dynamic delta hedging strategy. An out of sample simulation with crypto currency dataset shows the effectiveness of our proposed strategy. (C) 2020 Elsevier Ltd. All rights reserved.",2020
Forecasting the high-frequency volatility based on the LSTM-HIT model,"Volatility forecasting from high-frequency data plays a crucial role in many financial fields, such as risk management, option pricing, and portfolio management. Many existing statistical models could better describe and forecast the characteristics of volatility, whereas they do not simultaneously account for the long-term memory of volatility, the nonlinear characteristics of high-frequency data, and technical index information during the modeling phase. The purpose of this paper is to use the prediction advantage of deep learning long short-term memory (LSTM) model to predict the volatility fusing three classes of information, that is, high frequency realized volatility (H), technical indicators (I), and the parameters of generalized autoregression conditional heteroskedasticity(GARCH), heterogeneous autoregressive (HAR), and c, resulting in a novel LSTM-HIT model to forecast realized volatility. We employ the extreme value theory (EVT) of a semiparametric method to estimate the quantile of standardized return and construct the LSTM-HIT-EVT model to forecast the value at risk (VaR). Empirical results show that the LSTM-HIT model provides the most accurate volatility forecast among the various considered models and that the LSTM-HIT-EVT model yields forecasts more accurate than other VaR models.",2024
Deep Learning Algorithm to solve Portfolio Management with Proportional Transaction Cost,"Portfolio selection with proportional transaction cost is a singular stochastic control problem that has been widely discussed. In this paper, we propose a deep learning based numerical scheme to solve transaction cost problems, and compare its effectiveness with a penalty partial differential equation (PDE) method. We further extend it to multi-asset cases which existing numerical methods can not be applied to due to the curse of dimensionality. Deep learning algorithm directly approximates the optimal trading strategies by a feedforward neural network at each discrete time. It is observed that deep learning approach can achieve satisfying performance to characterize optimal buy and sell boundaries and thus value function.",2019
Statistical Evaluation of Deep Learning Models for Stock Return Forecasting,"Artificial intelligence applications, including algorithmic training, portfolio allocation, and stock return forecasting in the financial industry, are rapidly developing research fields. Particularly, the forecasting of stock return has received considerable attention. Selecting the most promising model to forecast stock return has always been the most prominent task in the literature. Several studies have reported the prediction ability of recurrent neural network (RNN) models, whereas only a few studies have rigorously evaluated the prediction performance of temporal convolution networks (TCNs) for stock return forecasting settings. Moreover, although most studies are focused on comparing the performance of deep learning models at a single horizon forecasting, the multi-horizon forecasting applications of stock return have been studied only limitedly. In this study, we aim to evaluate the forecasting performance of state-of-the-art deep learning models at multi-horizon forecasting paths in stock return forecasting tasks. Specifically, we focus on TCNs, RNNs, long short-term memory, and gated recurrent unit models in terms of forecasting performance and direction accuracy. Our evaluation framework based on the model confidence set shows which model(s) is (are) better, with statistical significance, for forecasting stock return at multi-horizon forecasting. The empirical results assert that the TCN model has the best out-of-sample forecasting performance at all forecasting horizons on three financial datasets compared to other models.",2024
Gold price prediction by a CNN-Bi-LSTM model along with automatic parameter tuning,"Banking and stock markets consider gold to be an important component of their economic and financial status. There are various factors that influence the gold price trend and its fluctuations. Accurate and reliable prediction of the gold price is an essential part of financial and portfolio management. Moreover, it could provide insights about potential buy and sell points in order to prevent financial damages and reduce the risk of investment. In this paper, different architectures of deep neural network (DNN) have been proposed based on long short-term memory (LSTM) and convolutional-based neural networks (CNN) as a hybrid model, along with automatic parameter tuning to increase the accuracy, coefficient of determination, of the forecasting results. An illustrative dataset from the closing gold prices for 44 years, from 1978 to 2021, is provided to demonstrate the effectiveness and feasibility of this method. The grid search technique finds the optimal set of DNNs' parameters. Furthermore, to assess the efficiency of DNN models, three statistical indices of RMSE, RMAE, and coefficient of determination (R2), were calculated for the test set. Results indicate that the proposed hybrid model (CNN-Bi-LSTM) outperforms other models in total bias, capturing extreme values and obtaining promising results. In this model, CNN is used to extract features of input dataset. Furthermore, Bi-LSTM uses CNN's outputs to predict the daily closing gold price.",2024
RETRACTED: Application of Multiobjective Particle Swarm Optimization in Rural Credit System (Retracted Article),"In China's rural credit system, the problem of credit constraints is prominent. Due to the imperfect credit market, a large number of rural residents have credit constraints. Rural credit constraint is a serious problem restricting China's rural economic development. Aimed at solving the rural credit constraints, this paper makes an optimization analysis on the rural credit system and loan decision-making. To more reasonably evaluate customers' borrowing ability, the credit risk based on farmers' data on the big data platform is evaluated in this paper. The stacked denoising autoencoder network is improved by adopting the deep learning framework to improve the accuracy of credit evaluation. For improving the loan decision-making ability of rural credit system, a loan optimization strategy based on multiobjective particle swarm optimization algorithm is proposed. The simulation results show that the optimization ability, speed, and stability of the proposed algorithm have achieved good results in dealing with the loan portfolio decision-making problem.",2021
"Stock Price Prediction Using GRU, SimpleRNN and LSTM","In today's era, stock prediction has become one of the dominant real world application. Most of the times, scientists attempted to establish a direct connection between information macroeconomic factors and stock returns; however, with the revelation of nonlinear slants in financial exchange record returns, there has been a significant shift in the scientists' focus toward the nonlinear expectation of stock returns. Even though various articles on nonlinear measurable presenting of stock returns have appeared since then, the huge demand is the nonlinear model which is specified before the estimation is performed. Predicting stock value is a difficult task that necessitates a solid algorithmic structure to calculate returns. Because stock prices are volatile and depend on the market up and down, forecasting stock prices becomes difficult. It has never been easy to invest in a portfolio of assets; the abnormalities of the financial market prevent simple models from accurately predicting future asset values. Machine learning, which is teaching computers to execute activities that would ordinarily need human intelligence, is the current scientific study hot topic. This paper explores gated recurrent units (GRU), simple recurrent neural network (Simple RNN) and long short term memory (LSTM) models for stock price prediction.",2023
Portfolio management via two-stage deep learning with a joint cost,"Portfolio management is a series of processes that maximize returns and minimize risk by allocating assets efficiently. Along with the developments in machine learning technology, it has been studied to apply machine learning methods to prediction-based portfolio management. However, such methods have a few limitations. First, they do not consider the relations between assets for the prediction. In addition, the studies commonly focus on the prediction accuracy, neglecting the construction of portfolios. Furthermore, the methods have usually been evaluated with index data, which hardly represent actual prices to buy or sell an asset. To overcome these problems, Exchange Traded Funds (ETFs) are employed for base assets for the evaluation, and we propose a two-stage deep learning framework, called Grouped-ETFs Model (GEM), with a joint cost function. The GEM is designed to learn the features of inter-asset and groups in each stage. Also, the proposed joint cost can consider relative returns for the training while the relative returns are a crucial factor to construct a portfolio. The results of a rigorous evaluation with global ETF data indicate that the proposed GEM with the joint cost outperforms the equally weighted portfolio and the ordinary deep learning model by 33.7% and 30.1%, respectively. An additional experiment using sector ETFs verifies the generality of the proposed model where the results accord with those of the previous experiment. (C) 2019 Elsevier Ltd. All rights reserved.",2020
Behavior Analysis Using Enhanced Fuzzy Clustering and Deep Learning,"Companies aim to offer customized treatments, intelligent care, and a seamless experience to their customers. Interactions between a company and its customers largely depend on the company's ability to learn, understand, and predict customer behaviors. Customer behavior prediction is a pivotal factor in improving a company's quality of services and thus its growth. Different machine learning techniques have been applied to gather customer data to predict behavioral patterns. Traditional methods are unable to discover hidden patterns in ideal situations and need to be improved to produce more accurate predictions. This work proposes a novel hybrid model comprised of two modules: a novel clustering module on the basis of an optimized fuzzy deep belief network and a customer behavior prediction module on the basis of a deep recurrent neural network. Customers' previous purchasing characteristics and portfolio details were analyzed by applying learning parameters. In this paper, the deep learning techniques were optimized by applying the butterfly optimization method, which minimizes the maximum error classification problem. The performance of the system was evaluated using experimental analysis. The proposed approach was compared to other single and hybrid-model-based approaches and attained the highest performance in the respective metrics.",2022
Ensemble Deep Learning Models for Forecasting Cryptocurrency Time-Series,"Nowadays, cryptocurrency has infiltrated almost all financial transactions; thus, it is generally recognized as an alternative method for paying and exchanging currency. Cryptocurrency trade constitutes a constantly increasing financial market and a promising type of profitable investment; however, it is characterized by high volatility and strong fluctuations of prices over time. Therefore, the development of an intelligent forecasting model is considered essential for portfolio optimization and decision making. The main contribution of this research is the combination of three of the most widely employed ensemble learning strategies: ensemble-averaging, bagging and stacking with advanced deep learning models for forecasting major cryptocurrency hourly prices. The proposed ensemble models were evaluated utilizing state-of-the-art deep learning models as component learners, which were comprised by combinations of long short-term memory (LSTM), Bi-directional LSTM and convolutional layers. The ensemble models were evaluated on prediction of the cryptocurrency price on the following hour (regression) and also on the prediction if the price on the following hour will increase or decrease with respect to the current price (classification). Additionally, the reliability of each forecasting model and the efficiency of its predictions is evaluated by examining for autocorrelation of the errors. Our detailed experimental analysis indicates that ensemble learning and deep learning can be efficiently beneficial to each other, for developing strong, stable, and reliable forecasting models.",2020
Stock Market Prediction Based on Generative Adversarial Network,"Deep learning has recently achieved great success in many areas due to its strong capacity in data process. For instance, it has been widely used in financial areas such as stock market prediction, portfolio optimization, financial information processing and trade execution strategies. Stock market prediction is one of the most popular and valuable area in finance. In this paper, we propose a novel architecture of Generative Adversarial Network (GAN) with the Multi-Layer Perceptron (MLP) as the discriminator and the Long Short-Term Memory (LSTM) as the generator for forecasting the closing price of stocks. The generator is built by LSTM to mine the data distributions of stocks from given data in stock market and generate data in the same distributions, whereas the discriminator designed by MLP aims to discriminate the real stock data and generated data. We choose the daily data on S&P 500 Index and several stocks in a wide range of trading days and try to predict the daily closing price. Experimental results show that our novel GAN can get a promising performance in the closing price prediction on the real data compared with other models in machine learning and deep learning. (C) 2019 The Authors. Published by Elsevier B.V.",2019
Deep Residual Convolutional Long Short-term Memory Network for Option Price Prediction Problem,"In the realm of financial markets, the precise prediction of option prices remains a cornerstone for effective portfolio management, risk mitigation, and ensuring overall market equilibrium. Traditional models, notably the Black-Scholes, often encounter challenges in comprehensively integrating the multifaceted interplay of contemporary market variables. Addressing this lacuna, this study elucidates the capabilities of a novel Deep Residual Convolution Long Short -term Memory (DR-CLSTM) network, meticulously designed to amalgamate the superior feature extraction prowess of Convolutional Neural Networks (CNNs) with the unparalleled temporal sequence discernment of Long Short-term Memory (LSTM) networks, further augmented by deep residual connections. Rigorous evaluations conducted on an expansive dataset, representative of diverse market conditions, showcased the DR-CLSTM's consistent supremacy in prediction accuracy and computational efficacy over both its traditional and deep learning contemporaries. Crucially, the integration of residual pathways accelerated training convergence rates and provided a formidable defense against the often detrimental vanishing gradient phenomenon. Consequently, this research positions the DR-CLSTM network as a pioneering and formidable contender in the arena of option price forecasting, offering substantive implications for quantitative finance scholars and practitioners alike, and hinting at its potential versatility for broader financial instrument applications and varied market scenarios.",2023
Revealing Pairs-trading opportunities with long short-term memory networks,"This work examines a deep learning approach to complement investors' practices for the identification of pairs-trading opportunities among cointegrated stocks. We refer to the reversal effect, consisting in the fact that temporarily market deviations are likely to correct and finally converge again, to generate valuable pairs-trading signals based on the application of Long Short-Term Memory networks (LSTM). Specifically, we propose to use the LSTM to estimate the probability of a stock to exhibit increasing market returns in the near future compared to its peers, and we compare and combine these predictions with trading practices based on sorting stocks according to either price or returns gaps. In so doing, we investigate the ability of our proposed approach to provide valuable signals under different perspectives including variations in the investment horizons, transaction costs and weighting schemes. Our analysis shows that strategies including such predictions can contribute to improve portfolio performances providing predictive signals whose information content goes above and beyond the one embedded in both price and returns gaps. (c) 2021 Elsevier B.V. All rights reserved.",2021
Multi-verse metaheuristic and deep learning approach for portfolio selection with higher moments,"The market has become very volatile these days in the presence of a war-like situation with a lot of political turmoil and the rapid occurrence of natural disasters the world over. It is difficult to predict the economic condition of the country and hence the company's financial position. This paper proposes a novel approach that integrates clustering techniques, deep learning, and a metaheuristic algorithm to enhance the process of asset selection and allocation. First, S&P BSE 500 index companies have been clustered into ten groups by using the Expectation Maximization (EM) clustering technique based on 11 fundamental characteristics of the companies. The Prowess financial database has been used to collect the required data. For diversification of the portfolio across clusters and sectors, the best-performing companies are chosen based on Sharpe Ratio. Advanced analytical tools like machine learning and deep learning have been employed to increase the accuracy and precision of estimating the returns on the stocks of the selected companies. The expected return on stocks of these selected companies has been estimated with the help of Neural Basis Expansion Analysis for Interpretable Time Series (N-BEATS), a deep learning neural network-based forecasting technique. A portfolio multi-objective optimization model has been formulated by considering entropy and higher moments like skewness and kurtosis in the objective function. A metaheuristic algorithm named multi-verse is used to solve the optimization model, and hence the selection of the assets with their proportion of investment in the portfolio has been suggested under different scenarios.",2024
Learning to trade in financial time series using high-frequency through wavelet transformation and deep reinforcement learning,"Deep learning-based financial approaches have received attention from both investors and researchers. This study demonstrates how to optimize portfolios, asset allocation, and trading systems based on deep reinforcement learning using three frameworks. In the proposed deep learning structure, the input data are first decomposed through wavelet transformation (WT) to remove noise from stock price time-series data. Then, only the mother wavelet (high-frequency) data are used as input. Second, reinforcement learning is performed using the high-frequency data. The reinforcement learning network employs long short-term memory (LSTM). Actions are determined by the LSTM network or randomly. Third, it learns the optimal investment trading system using the actions of a given transaction and appropriate rewards. The structure of the optimal investment trading system obtained by the proposed deep reinforcement learning structure improves trading performance without requiring the construction of a predictive model. To investigate the performance of the proposed structure, we applied the S&P500, DJI, and KOSPI200 indices to the proposed structure (HW_LSTM_RL) and other reinforcement learning structures for comparison. We evaluated the difference in Sharpe ratio for various test periods (one to three years) and for different rewards. Using the decomposed high-frequency data as input, a portfolio of investment transactions was improved for highly volatile markets. In deep reinforcement learning, we found that network composition and appropriate rewards have significant influence on learning transactions in financial time-series data. Thus, the proposed HW_LSTM_RL structure demonstrates the importance of input data composition, learning network settings, and rewards.",2021
Iterative Deep Learning Approach to Active Portfolio Management with Sentiment Factors,"We suggest using deep learning networks to create expert opinions as part of an iterative active portfolio management process. These opinions would be based on posts from the X platform and the fundamentals of stocks listed in the S&P 500 index. Expert views are integral to active portfolio management, as proposed by Black-Litterman. The method we propose addresses the original subjectivity of the opinions by incorporating innovation and accuracy to generate views using analytical techniques. We utilize daily data from 2010 to 2022 for stocks from the S&P 500 and daily posts from Twitter API v2, collected under a research account license spanning the same period. We found that incorporating sentiment factors with machine learning techniques into the view generation process of the Black-Litterman model improves optimal portfolio allocation. Empirically, our results notably outperform the S&P 500 market when considering the annualized alpha.",2024
Deep-Learning Solution to Portfolio Selection with Serially Dependent Returns,"This paper investigates a deep-learning solution to high-dimensional multiperiod portfolio optimization problems with bounding constraints on the control. We propose a deep neural network (DNN) architecture to describe the underlying control process. The DNN consists of K subnetworks, where K is the total number of decision steps. The feedback control function is determined solely by the network parameters. In this way, the multiperiod portfolio optimization problem is linked to a training problem of the DNN, that can be efficiently computed by the standard optimization techniques for network training. We offer a sufficient condition for the algorithm to converge for a general utility function and general asset return dynamics including serially dependent returns. Specifically, under the condition that the global minimum of the DNN training problem is attained, we prove that the algorithm converges with the quadratic utility function when the risky asset returns jointly follow multivariate autoregressive (1) models and/or multivariate generalized autoregressive conditional heteroskedasticity (1,1) models. Numerical examples demonstrate the superior performance of the DNN algorithm in various return dynamics for a high-dimensional portfolio (up to 100 dimensions).",2020
RETRACTED: Analysis of Option Butterfly Portfolio Models Based on Nonparametric Estimation Deep Learning Method (Retracted Article),"The option butterfly portfolio is the commonly option arbitrage strategy. In reality, because the distribution of the option state price density (SPD) function is not normal and unknown, so the nonparametric deep learning methods to estimate option butterfly portfolio returns are proposed. This paper constructs the single-index nonparametric option pricing model which contains multiple influencing factors and presents the nonparametric estimation form for option butterfly portfolio returns. The empirical analysis shows that the SPD function estimated by using single-index nonparametric option model can effectively calculate the option butterfly portfolio returns with the minimum option strike price interval and provide an effective reference tool for risk-averse investors with limited risk preferences.",2023
Optimization of venture portfolio based on LSTM and dynamic programming,"A rational investor always pursues a portfolio with the greatest possible return and the least possible risk. Therefore, a core issue of investment decision analysis is how to make an optimal investment choice in the market with fuzzy information and realize the balance between maximizing the return on assets and minimizing the risk. In order to find optimal investment portfolios of financial assets with high volatility, such as gold and Bitcoin, a mathematical model for formulating investment strategies based on the long short-term memory time series and the dynamic programming model combined with the greedy algorithm has been proposed in this paper. The model provides the optimal daily strategy for the five-year trading period so that it can achieve the maximum expected return every day under the condition of a certain investment amount and a certain risk. In addition, a reasonable risk measure based on historical increases is established while considering the weights brought by different investment preferences. The empirical analysis results show that the optimal total assets and initial capital obtained by the model change in the same proportion, and the model is relatively stable and has strong adaptability to the initial capital. Therefore, the proposed model has practical reference value and research significance for investors and promotes a better combination of computer technology and financial investment decision.",2023
Exploration of Stock Portfolio Investment Construction Using Deep Learning Neural Network,"To study the intelligent and efficient stock portfolio in China's financial market, based on the relevant theories such as deep learning (DL) neural network (NN) and stock portfolio, this study selects 111 stable stocks from the constituent stocks of the China Security Index (CSI) 300 from January 1, 2018, to December 31, 2021, as the research samples. Then, it analyzes these research samples and imports the relevant data of 111 stocks into the DL NN model. The corresponding prediction results of stock prices are obtained. Finally, the stock portfolio model based on DL NN is compared with the data results of the Shanghai Stock Exchange (SSE) 50 Index and CSI 500 Index. The results show that the closing prices of the selected 111 stocks are relatively stable and fluctuate up and down around the horizontal axis, and the positive and negative returns are relatively balanced, roughly between -5% and 5%. There is a phenomenon of fluctuation aggregation to a certain extent. Comparing the prediction results of different models reveals that the prediction results of model c are closest to the actual stock price trend. Comparing the relevant returns of the proposed stock portfolio with other stocks uncovers that the annualized return of the stock portfolio based on the DL NN model is 47.44%. The sharp ratio is 1.52, the maximum pullback is 18.15%, the monthly excess return is 3.11%, and the information ratio is 0.82. Compared with other indexes, the proposed stock portfolio shows the best results. Therefore, the proposal of the stock portfolio based on DL NN provides a theoretical basis for the development of the financial field in the future.",2022
Multi-Factor RFG-LSTM Algorithm for Stock Sequence Predicting,"As has been demonstrated, the long short-term memory (LSTM) algorithm has the special ability to process sequenced data; however, LSTM suffers from high dimensionality, and its structure is too complex, leading to overfitting. In this research, we propose a new method, RFG-LSTM, which uses a rectified forgetting gate (RFG) to restructure the LSTM. The rectified forgetting gate is a function that can limit the boundary of an input sequence, so it can reduce the dimensionality and complexity of a neural network. Through theoretical analysis, we demonstrate that RFG-LSTM is monotonic, just as LSTM is; additionally, the stringency does not change in the new algorithm. Thus, RFG-LSTM also has the ability to process sequenced data. Based on the real trading scenario of China's A stock market, we construct a multi-factor alpha portfolio with RFG-LSTM. The experimental results show that the RFG-LSTM model can objectively learn the characteristics and rules of the A stock market, and this can contribute to a portfolio investment strategy.",2021
Hopfield networks for asset allocation,"We present the first application of modern Hopfield networks to the problem of portfolio optimization. We performed an extensive study based on combinatorial purged cross-validation over several datasets and compared our results to both traditional and deeplearning-based methods for portfolio selection. Compared to state-of-the-art deep-learning methods such as Long-Short Term Memory networks and Transformers, we find that the proposed approach performs on par or better, while providing faster training times and better stability. Our results show that Modern Hopfield Networks represent a promising approach to portfolio optimization, allowing for an efficient, scalable, and robust solution for asset allocation, risk management, and dynamic rebalancing.",2024
A New Method for Portfolio Construction Using a Deep Predictive Model,"A well-designed portfolio plays a key role in achieving investment goal. In this paper, we use Recurrent Neural Networks with Long Short Term Memory (LSTM) Units, to predict potential returns of a collection of investments. Then, we construct diversified portfolios by giving thresholds for the potential returns and examine the return and risk levels of the portfolios. These results show conclusively that it is possible to build a portfolio given a desired degree of return and risk by adjusting the thresholds, which is promising in asset allocations reflected investors' risk preference.",2018
FactorVQVAE: Discrete latent factor model via Vector Quantized Variational Autoencoder,"This study introduces FactorVQVAE, the first integration of the Vector Quantized Variational Autoencoder (VQVAE) into factor modeling, providing a novel framework for predicting cross-sectional stock returns and constructing systematic investment portfolios. The model employs a two-stage architecture to improve the extraction and utilization of latent financial factors. In the first stage, an encoder-decoder-quantizer compresses high-dimensional input data into discrete latent factors through vector quantization, addressing posterior collapse and ensuring distinct representations. In the second stage, an autoregressive Transformer captures sequential dependencies among these latent factors, enabling precise return predictions. Empirical results in the CSI300 and S&P500 markets demonstrate FactorVQVAE's superior performance. The model achieves the best Rank IC and Rank ICIR scores, surpassing the state-of-the-art latent factor models in varying market conditions. In portfolio evaluations, FactorVQVAE consistently excels in both Top-k Drop-n and Long-Short strategies, translating predictive accuracy into robust investment performance. In particular, it delivers the highest risk-adjusted returns, highlighting its ability to balance returns and risks effectively. These findings position FactorVQVAE as a significant advancement in integrating modern deep learning methodologies with financial factor modeling. Its adaptability, robustness, and exceptional performance in portfolio investment establish it as a promising tool for systematic investing and financial analytics.",2025
Dynamic sparse portfolio rebalancing model: A perspective of investors' behavior-related decisions,"By using the elaboration likelihood model (ELM) and prospect theory (PT) to model investors' behavior-related decisions in portfolio optimization, we propose a novel dynamic behavior-based sparse portfolio selection model (BPSM) operating over multiple periods. With the BPSM model, we complement recent research that involves only investors' sentiments by also considering market sentiments to model investors' portfolio rebalancing behavior. Market sentiments are obtained by analyzing the online information through deep learning text analysis algorithms based on the Bi-directional Long Short-Term Memory (Bi-LSTM) model. The stochastic neural networks-based algorithm is designed to solve the BPSM. We demonstrate the effectiveness of the BPSM model on the Shanghai 50 and Hushen 300 data sets. The frame of experiments includes a dynamic portfolio rebalancing model, in which both the investors' sentiments and the market sentiments are modeled to analyze investors' dynamic portfolio rebalancing behavior. The experiment results show that, first, by updating the expected return rate of each period according to investors' sentiments and market sentiments, in all cases, the BPSM model achieves a higher investment return per unit risk (Rpr) than the conventional Mean-variance (MV) model to minimize investment risk. Second, compared with the two baseline models that include only investors' sentiments, the BPSM realizes a portfolio policy that improves investment return per unit risk (Rpr) in 70% of situations. These results reveal that incorporating investors' behavior-related signals into the portfolio selection model is beneficial to investors' investment results, which offers implications for financial stakeholders.",2022
Predictive multi-period multi-objective portfolio optimization based on higher order moments: Deep learning approach,"We propose a Multi-Period Multi-Objective Portfolio Optimization model (MPMOPO). We used deep-learning approach to predict future behavior of stock returns. We consider four objectives, i.e., wealth, variance, skewness, and kurtosis and several constraints such as cardinality, budget, upper and lower limits of purchase, and diversification to address real-world situations. The investor can rebalance the portfolio through daily trade by buying or selling subject to transaction costs. We applied the proposed method in a daily closing price prediction of six stocks from FTSE 100. Goal programming method was used to solve the models. The results of statistical analysis show the applicability and efficacy of the proposed method in comparison with those methods which used historical data to form the portfolio.",2023
A Quantitative Analysis Decision System Based on Deep Learning and NSGA-II for FX Portfolio Prediction,"Forecasting foreign exchange (FX) rate and optimizing FX portfolio with the help of Artificial Intelligence has aroused wide interest among global capital market. As far as we know, this is the first paper which, from the perspective of institutional and individual investors, proposes a complete quantitative analysis decision system based on Deep Learning and NSGA-II to forecast FX rate and select FX portfolio successively. To be specific, we provide a whole procedure from data collection to FX forecasting with Stacked Autoencoders and further to optimal FX portfolio selection with NSGA-II. Furthermore, an empirical analysis has been conducted with 28 FX currency pairs, in which our algorithm has been compared with two other machine learning algorithms. Ultimately, our system provides optimized FX portfolio solutions for investors with diverse preference.",2018
Pairs trading on different portfolios based on machine learning,"This article presents an advanced visualization and analytics approach for financial research. Statistical arbitrage, particularly pairs trading strategy, has gained ground in the financial market and machine learning techniques are applied to the finance field. The cointegration approach and long short-term memory (LSTM) were utilized to achieve stock pairs identification and price prediction purposes, respectively, in this project. This article focused on the US stock market, investigating the performance of pairs trading on different types of portfolios (aggressive and defensive portfolio) and compare the accuracy of price prediction based on LSTM. It can be briefly concluded that LSTM offers higher prediction precision on aggressive stocks and implementing pairs trading on the defensive portfolio would gain higher profitability during a specific period between 2016 and 2017. However, predicting tools like LSTM only offer limited advice on stock movement and should be cautiously utilized. We conclude that analytics and visualization can be effective for financial analysis, forecasting and investment strategy.",2021
Stock Market Analysis using Long Short-Term Model,"recurrent neural networks (RNN) and long short-term memory ( LSTM) cells for stock market forecasting using time series of historical portfolio stock data is demonstrated in this study. In this study, we applied LSTM to predict stock market values using Yahoo Finance data along with Python modules Pandas and Matplotlib to evaluate the performance of the model. Our results show that the LSTM model is able to make accurate predictions of stock market prices and trends using historical data. The results of the correlation study showed a significant relationship between the daily return and the closing price of four randomly chosen companies. Overall, using LSTM, Yahoo Finance, Python Pandas, and Matplotlib modules to predict stock prices and provide useful information to investors was a successful strategy.",2024
Langevin Dynamics Based Algorithm e-THεO POULA for Stochastic Optimization Problems with Discontinuous Stochastic Gradient,"We introduce a new Langevin dynamics based algorithm, called the extended tamed hybrid epsilon-order polygonal unadjusted Langevin algorithm (e-TH epsilon O POULA), to solve optimization problems with discontinuous stochastic gradients, which naturally appear in real-world applications such as quantile estimation, vector quantization, conditional value at risk (CVaR) minimization, and regularized optimization problems involving rectified linear unit (ReLU) neural networks. We demonstrate both theoretically and numerically the applicability of the e-TH epsilon O POULA algorithm. More precisely, under the conditions that the stochastic gradient is locally Lipschitz in average and satisfies a certain convexity at infinity condition, we establish nonasymptotic error bounds for e-TH epsilon O POULA in Wasserstein distances and provide a nonasymptotic estimate for the expected excess risk, which can be controlled to be arbitrarily small. Three key applications in finance and insurance are provided, namely, multiperiod portfolio optimization, transfer learning in multiperiod portfolio optimization, and insurance claim prediction, which involve neural networks with (Leaky)ReLU activation functions. Numerical experiments conducted using real-world data sets illustrate the superior empirical performance of e-TH epsilon O POULA compared with SGLD (stochastic gradient Langevin dynamics), TUSLA (tamed unadjusted stochastic Langevin algorithm), adaptive moment estimation, and Adaptive Moment Estimation with a Strongly Non-Convex Decaying Learning Rate in terms of model accuracy.",2024
Low correlation portfolio formation with preselection using rich relational data,"The integration of return prediction and portfolio optimization has been widely proven effective. Traditional portfolio optimization approaches, however, rely solely on financial time series data, neglecting the inherent correlations among assets. This study introduces a novel low-correlation portfolio construction methodology utilizing rich relational data integrated via meta-paths. The proposed framework enhances return prediction while minimizing portfolio risk. In the first stage, Long Short-Term Memory (LSTM) networks are implemented to capture sequential patterns in the data. A Graph Neural Network (GNN) with a dual attention mechanism is employed in our framework. This network structure effectively summarizes information from relevant assets while selectively updating features. In the second stage, we develop an asset correlation scoring metric derived from the comprehensive relational data. Based on the predicted returns and correlation scores, we introduce two portfolio construction strategies: (1) a low-correlation strategy and (2) a hybrid strategy with high returns and low correlation. We use sample data from the S&P 500 Index between January 2017 and December 2021 to justify our proposed method. Results demonstrate that incorporating rich relational data significantly improves prediction accuracy. Under Markowitz's framework, the correlation of high-quality assets is negatively related to their optimal weights. The correlation scoring metric is demonstrated to facilitate portfolio optimization. Assets exhibiting low correlations contribute to portfolio variance reduction and enhanced risk-adjusted performance. Our Prediction-based Low Correlation Portfolio (P-LCP) enhances returns at lower levels of risk. The Prediction-based Hybrid Portfolio (P-HP) demonstrates exceptional performance in terms of cumulative returns and Sharpe ratios. This work implements a data-driven portfolio construction method that utilizes historical and relational data, highlighting the effectiveness of combining predictive theory with low-correlation portfolio strategies.",2025
Demand Forecast in E-commerce Using a Long Short-Term Memory Neural Network Methodology,"Generating accurate and reliable sales forecasts is crucial in the E-commerce business. The current state-of-the-art techniques are typically univariate methods, which produce forecasts considering only the historical sales data of a single product. However, in a situation where large quantities of related time series are available, conditioning the forecast of an individual time series on past behaviour of similar, related time series can be beneficial. Since the product assortment hierarchy in an E-commerce platform contains large numbers of related products, in which the sales demand patterns can be correlated, our attempt is to incorporate this cross-series information in a unified model. We achieve this by globally training a Long Short-Term Memory network (LSTM) that exploits the non-linear demand relationships available in an E-commerce product assortment hierarchy. Aside from the forecasting framework, we also propose a systematic pre-processing framework to overcome the challenges in the E-commerce business. We also introduce several product grouping strategies to supplement the LSTM learning schemes, in situations where sales patterns in a product portfolio are disparate. We empirically evaluate the proposed forecasting framework on a real-world online marketplace dataset from Walmart.com. Our method achieves competitive results on category level and super-departmental level datasets, outperforming state-of-the-art techniques.",2019
A portfolio construction framework usingLSTM-based stock markets forecasting,"A novel framework that injects future return predictions into portfolio constructionstrategies is proposed in this study. First, a long-short-term-memory (LSTM) model is trained to learn the monthly closing prices of the stocks. Then these predictions are used in the calculation of portfolio weights. Five different portfolio construction strategies are introduced including modifications to smart-beta strategies. The suggested methods are compared to a number of baseline methods, using the stocks of BIST30 Turkey index. Our strategies yield a very high mean annualized return (25%) which is almost 50% higher than the baseline approaches. The mean Sharpe ratio of our strategies is 0.57, whereas the compared methods' are 0.29 and -0.32. Comprehensive analysis of the results demonstrates that utilizing predicted returns in portfolio construction enables a significant improvement on the performance of the portfolios.",2022
Automated Bitcoin Trading dApp Using Price Prediction from a Deep Learning Model,"Distributed ledger technology (DLT) and cryptocurrency have revolutionized the financial landscape and relevant applications, particularly in investment opportunities. Despite its growth, the market's volatility and technical complexities hinder widespread adoption. This study proposes a cryptocurrency trading system powered by advanced machine learning (ML) models to address these challenges. By leveraging random forest (RF), long short-term memory (LSTM), and bi-directional LSTM (Bi-LSTM) models, the cryptocurrency trading system is equipped with strong predictive capacity and is able to optimize trading strategies for Bitcoin. The up-to-date price prediction information obtained by the machine learning model is incorporated by custom oracle contracts and is transmitted to portfolio smart contracts. The integration of smart contracts and on-chain oracles ensures transparency and security, allowing real-time verification of portfolio management. The deployed cryptocurrency trading system performs these actions automatically without human intervention, which greatly reduces barriers to entry for ordinary users and investors. The results demonstrate the feasibility of creating a cryptocurrency trading system, with the LSTM model achieving a return on investment (ROI) of 488.74% for portfolio management during the duration of 9 December 2022 to 23 May 2024. The ROI obtained by the LSTM model is higher than the performance of Bitcoin at 234.68% and that of other benchmarking models with RF and Bi-LSTM over the same timeframe. This approach offers significant cost savings, transparent portfolio management, and a trust-free platform for investors, paving the way for broader cryptocurrency adoption. Future work will focus on enhancing prediction accuracy and achieving greater decentralization.",2025
An LSTM and GRU based trading strategy adapted to the Moroccan market,"Forecasting stock prices is an extremely challenging job considering the high volatility and the number of variables that influence it (political, economical, social, etc.). Predicting the closing price provides useful information and helps the investor make the right decision. The use of deep learning and more precisely of recurrent neural networks (RNNs) in stock market forecasting is an increasingly common practice in the literature. Long Short Term Memory (LSTM) and Gated Recurrent Unit (GRU) architectures are among the most widely used types of RNNs, given their suitability for sequential data. In this paper, we propose a trading strategy designed for the Moroccan stock market, based on two deep learning models: LSTM and GRU to predict the closing price in the short and medium term respectively. Decision rules for buying and selling stocks are implemented based on the forecasting given by the two models, then over four 3-year periods, we simulate transactions using these decision rules with different settings for each stock. The returns obtained will be used to estimate an expected return. We only hold stocks that outperform a benchmark index (expected return > threshold). The random search is then used to choose one of the available parameters and the performance of the portfolio built from the selected stocks will be tested over a further period. The repetition of this process with a variation of portfolio size makes it possible to select the best possible combination of stock each with the optimized parameter for the decision rules. The proposed strategy produces very promising results and outperforms the performance of indices used as benchmarks in the local market. Indeed, the annualized return of our strategy proposed during the test period is 27.13%, while it is 0.43% for Moroccan all share Indice (MASI), 15.24% for the distributor sector indices, and 19.94% for the pharmaceutical industry indices. Noted that brokerage fees are estimated and subtracted for each transaction. which makes the performance found even more realistic.",2021
Enhancing stock market predictions via hybrid external trend and internal components analysis and long short term memory model,"When it comes to financial decision-making, stock market predictability is extremely important since it offers valuable information that may guide investment strategies, risk management, and portfolio allocation overall. Traditional methods often fail to accurately predict stock prices due to their complexity and inability to handle non-linear and non-stationary patterns in market data. To address these issues, this study introduces an innovative model that combines the External Trend and Internal Components Analysis decomposition method (ETICA) with the Long Short-Term Memory (LSTM) model, aiming to enhance stock market predictions for S&P 500, NASDAQ, Dow Jones, SSE and SZSE indices. Through rigorous testing across various training data proportions and epoch settings, our findings reveal that the proposed hybrid model outperforms the single LSTM model, delivering significantly lower Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) values. This enhanced precision reduces prediction errors, underscoring the model's robustness and reliability. The superior performance of the ETICA-LSTM model highlights its potential as a powerful financial forecasting tool, promising to transform investment strategies, optimize risk management, and enhance portfolio performance.",2024
Equity-Market-Neutral Strategy Portfolio Construction Using LSTM-Based Stock Prediction and Selection: An Application to S&P500 Consumer Staples Stocks,"In recent years, a great deal of attention has been devoted to the use of neural networks in portfolio management, particularly in the prediction of stock prices. Building a more profitable portfolio with less risk has always been a challenging task. In this study, we propose a model to build a portfolio according to an equity-market-neutral (EMN) investment strategy. In this portfolio, the selection of stocks comprises two steps: a prediction of the individual returns of stocks using LSTM neural network, followed by a ranking of these stocks according to their predicted returns. The stocks with the best predicted returns and those with the worst predicted returns constitute, respectively, the long side and the short side of the portfolio to be built. The proposed model has two key benefits. First, data from historical quotes and technical and fundamental indicators are used in the LSTM network to provide good predictions. Second, the EMN strategy allows for the funding of long-position stocks by short-sell-position stocks, thus hedging the market risk. The results show that the built portfolios performed better compared to the benchmarks. Nonetheless, performance slowed down during the COVID-19 pandemic.",2023
LSTM-GARCH Hybrid Model for the Prediction of Volatility in Cryptocurrency Portfolios,"In the present work, the volatility of the leading cryptocurrencies is predicted through generalised autoregressive conditional heteroskedasticity (GARCH) models, multilayer perceptron (MLP), long short-term memory (LSTM), and hybrid models of the type LSTM and GARCH, where parameters of the GARCH family are included as features of LSTM models. The study period covered the scenario of the World Health Organization pandemic declaration around March 2020 at hourly frequency. We have found that the different variants of deep neural network models outperform those of the GARCH family in the sense of the hetorerocedastic error, and absolute and squared error (HSE). Under the sharpe ratio, the volatility forecasting of a uniform portfolio at long horizons systematically outperforms the stablecoin Tether, which is considered here as the risk-free asset. Also, including transaction volume helps reduce the value at risk or loss probability for the uniform portfolio. Moreover, in a minimum variance portfolio, it is observed that before the pandemic declaration, a large proportion of the capital was allocated to bitcoin (BTC). In contrast, after March 2020, the portfolio is more diversified with short positions for BTC. Moreover, the MLP models give the best predictive results, although not statistically different in accuracy compared to the LSTM and LSTM-GARCH versions under the Diebold-Mariano test. In sum, MLP models outperform most stylised financial models and are less computationally expensive than more complex neural networks. Therefore, simple learning models are suggested in highly non-linear time series volatility forecasts as it is the cryptocurrency market.",2024
LSTM-Based Quantitative Trading Using Dynamic K-Top and Kelly Criterion,"With the strong capability of modeling time sequence, long short-term memory (LSTM) networks have been widely applied to predicting financial time series. This has attracted tremendous attention in the quantitative trading area. A complete quantitative trading system usually has three tasks, including market timing, stock selection, and portfolio management. In this paper, we present an LSTM-based quantitative trading system and optimize this system from the following two aspects. Firstly, in the process of stock selection, we first introduce the dynamic K-top method in the LSTM-based quantitative trading system to follow the market change. Secondly, concerning portfolio management, we further incorporate the Kelly Criterion to attain an appropriate position ratio. Taking CSI300 constituent stocks as the study example, extensive experiments have been carried out to show the superiority of the proposed method. In comparison with the straight forward LSTM-based trading strategy, the improved LSTM-based trading strategy with the dynamic K-top method and the Kelly Criterion can achieve an increase of 44.97% over ten days in terms of accumulative return. In addition, our novel method can gain a win ratio of 55.95%, a monthly alpha of 0.16, a monthly Sharpe ratio of 2.17, and a monthly Sortino ratio of 2.96 disregarding the transaction costs.",2020
A hybrid approach for portfolio construction: Combing two-stage ensemble forecasting model with portfolio optimization,"Combining the stock prediction with portfolio optimization can improve the performance of the portfolio construction. In this article, we propose a novel portfolio construction approach by utilizing a two-stage ensemble model to forecast stock prices and combining the forecasting results with the portfolio optimization. To be specific, there are two phases in the approach: stock prediction and portfolio optimization. The stock prediction has two stages. In the first stage, three neural networks, that is, multilayer perceptron (MLP), gated recurrent unit (GRU), and long short-term memory (LSTM) are used to integrate the forecasting results of four individual models, that is, LSTM, GRU, deep multilayer perceptron (DMLP), and random forest (RF). In the second stage, the time-varying weight ordinary least square model (OLS) is utilized to combine the first-stage forecasting results to obtain the ultimate forecasting results, and then the stocks having a better potential return on investment are chosen. In the portfolio optimization, a diversified mean-variance with forecasting model named DMVF is proposed, in which an average predictive error term is considered to obtain excess returns, and a 2-norm cost function is introduced to diversify the portfolio. Using the historical data from the Shanghai stock exchange as the study sample, the results of the experiments indicate the DMVF model with two-stage ensemble prediction outperforms benchmarks in terms of return and return-risk characteristics.",2024
Adoption of deep learning Markov model combined with copula function in portfolio risk measurement,"In order to accurately describe the risk dependence structure and correlation between financial variables, carry out scientific financial risk assessment, and provide the basis for accurate financial decision-making, first the basic theory of Copula function is established and the mixed Copula model is constructed. Then the hybrid Copula model is nested in a hidden Markov model (HMM), the risk dependences among banking, insurance, securities and trust industries are analysed, and the Copula-Garch model is constructed for empirical analysis of investment portfolio. Finally, the deep learning Markov model is adopted to predict the financial index. The results show that the mixed Copula model based on HMM is more effective than the single Copula and the mixed Copula models. The empirical structure shows that among the four major financial industries in China, the banking and insurance industries have strong interdependence and high probability of risk contagion. The investment failure rate under 95%, 97.5% and 99% confidence intervals calculated by Copula-Garch model are 4.53%, 2.17% and 1.08%, respectively. Moreover, the errors of deep learning Markov model in stock price prediction of Shanghai Pudong Development Bank (sh600000), Guizhou Moutai (sh600519) and China Ping An Insurance (sh601318) are 2.56%, 2.98% and 3.56% respectively, which indicates that the four major financial industries in China have strong interdependence and risk contagion, so that the macro or systemic risks may arise, and the deep-learning Markov model can be adopted to predict the stock prices.",2022
Service provider portfolio selection for project management using a BP neural network,"Service provider portfolio selection (SPPS) can be a major challenge for organizations to achieve project success. Hence, organizations need to decide on which service provider portfolio (SPP) is appropriate for project management (PM). However, there has been limited research on how to select a SPP in PM. To address this research gap, we establish a novel model for SPPS based on a BP neural network integrated with entropy-AHP from the perspective of the comprehensive economic benefit. This model employs a BP neural network due to its robustness and memory and nonlinear mapping abilities. Furthermore, we implement the proposed model for a construction project to verify the effectiveness. Our results indicate that the model performs well with a prediction accuracy of 97%. Moreover, the model is confirmed to be robust as it still achieves high prediction accuracy when the input data are disturbed randomly.",2022
T2V_TF: An adaptive timing encoding mechanism based Transformer with multi-source heterogeneous information fusion for portfolio management: A case of the Chinese A50 stocks,"The Stock prediction has traditionally been an attractive and challenging topic for investors and researchers. Traditionally, people concern more about predicting stock prices, less effort has been made to recommend stocks for constructing a profitable portfolio. Moreover, in existing methods for stock prediction, most of them construct models based on one or two kinds of features like stock prices, news sentiment, or simple technical indicators, and disregard the importance of multi-source information fusion. In response to this concern, we propose a novel model T2V_TF based on deep learning by combining both Time2Vec and Transformer technologies. To introduce more diverse information into the proposed model, we further conduct an in-depth exploration of the extraction and fusion of multi-source heterogeneous information, which includes the trading data, time-frequency features, Alpha 101 and Alpha 191 technical indicators, and sentiment scores. Moreover, to increase the ranking ability of our model, T2V_TF takes the ranking loss as the loss function instead of the widely used regression loss. Finally, all the technological innovations of this paper are verified on the portfolio constructed based on the A50 stocks from the Chinese stock market. The experimental results demonstrate that our proposed T2V_TF can get better portfolio cumulative return, compared with other models including the multi-layer perceptron, the support vector machine, the gradient boosting decision trees, the long short-term memory model, and the attention-based long short-term memory model, and the Transformer.",2023
Unidirectional and bidirectional LSTM models for edge weight predictions in dynamic cross-market equity networks,"Predicting financial networks has important implications in finance. However, less research attention has been given in this direction. This study aims to predict cross market linkage strengths in financial networks using dynamic edge weight prediction. The study builds edge weight prediction models using deep learning based unidirectional and bidirectional long short-term memory (LSTM and BiLSTM) approaches. The models are built on temporally variant equity cross market networks in Asia. A rolling window approach is used to generate temporally synchronous observations of edge weight structures and subsequent networks. The models are trained with a series of historical network structure information. Tuning of hyperparameters was performed to obtain the optimized models. The models were validated using nested cross validation methods. The applicability of the optimized models was assessed for different scenarios, and promising results were found for edge weight pre-dictions on both unfiltered and filtered structures. The study also shows that the predictive performance of the BiLSTM model is the same across correlated (positively weighted) and anti-correlated (negatively weighted) edges. However, for LSTM the same does not hold true. The results also demonstrate that the proposed models predict edge weights better during normal conditions than in the crisis period. The proposed models are benchmarked against ARIMA and RNN. To our knowledge, this is the first attempt to build network prediction models for cross market equity networks. The findings can have key implications such as managing international portfolio diversifications and controlling systemic risk transmissions.",2022
Modeling for project portfolio benefit prediction via a GA-BP neural network,"Project portfolio benefit (PPB) prediction can effectively help managers monitor the acquisition of PPBs, thereby better achieving their target benefits. However, no valid model is available for PPB prediction. To narrow this research gap, we develop a model based on a backpropagation neural network improved with a genetic algo-rithm (GA-BPNN) to quantitatively forecast PPBs. First, the evaluation criteria for benefits are determined. Second, the input and output variables of the model are determined and calculated. Third, the initial weights and thresholds of the BPNN are improved by the GA. Fourth, based on the above optimization results, the GA-BPNN model is trained and tested. Last, the numerical example is provided to demonstrate the application of the proposed model. The results indicate that the established model is feasible and effective in predicting PPBs, with an average prediction accuracy rate of 98.64 %, which is 18.24 % better than that of the base BPNN. The model proposed in this paper effectively realizes the quantitative prediction of PPBs, enriching the research on project portfolio management (PPM) and providing managers with a tool to effectively predict PPBs.",2022
Algorithmic trading strategy based on the integration of deep learning models and natural language processing,"The most important goal for people trading in stock markets is to earn a profit. This profit can be obtained from price increases or decreases in a two-sided market, where stockholders gain profit from the difference in purchase and sale prices. This research aims to provide an integrated algorithmic trading system to improve the Sharpe ratio performance index for selecting stocks and maximizing returns during market ups and downs. The proposed strategy utilizes word2vector, autoencoder, and long short-term memory-artificial neural network (LSTM-ANN) methods. We assume that as the markets interact with the news, an internal connection is created between economic and political news and forecasting the market's price trend. The trading system is developed based on price and news to extract features that predict negative or positive market reactions. The tests show that the proposed Price and Price&News trading systems are superior to the Buy&Hold strategy in the S&P500 market. This research studies price data and portfolio news consisting of 15 stocks. The Price&News strategy yielded a 23% higher return than the Buy&Hold strategy, accompanied by a 2.6 improvement in the Sharpe ratio. Additionally, it outperformed the Price algorithm with an 8% higher return and a 0.82 improvement in the Sharpe ratio.",2024
Adoption of deep learning Markov model combined with copula function in portfolio risk measurement,"In order to accurately describe the risk dependence structure and correlation between financial variables, a scientific financial risk assessment was carried out, and the basis for accurate financial decision-making was provided; the basic theory of copula function is established first, and the mixed copula model is constructed; then, the hybrid copula model is nested in a hidden Markov model (HMM); the risk dependences among banking, insurance, securities and trust industries are analysed, and the Copula-Garch model is constructed for empirical analysis of investment portfolio; finally, the deep learning Markov model is adopted to predict the financial index. The results show that the mixed copula model based on the HMM is more effective than the single copula model and the mixed copula model. The empirical structure shows that among the four major financial industries in China, banking and insurance industries have strong interdependence and a high probability of risk contagion. The investment failure rate under 95%, 97.5% and 99% confidence intervals calculated by the Copula-Garch model is 4.53%, 2.17% and 1.08%, respectively. Moreover, the errors of the deep learning Markov model in stock price prediction of Shanghai Pudong Development Bank (sh600000), Guizhou Moutai (sh600519) and China Ping An Insurance (sh601318) are 2.56%, 2.98% and 3.56%, respectively, which indicates that the four major financial industries in China have strong interdependence and risk contagion so that the macro or systemic risks may arise, and the deep learning Markov model can be adopted to predict the stock prices.",2021
Comparative Analysis of ARIMA and LSTM Models for Stock Price Prediction,"Stock price prediction is crucial for informed investment decisions, enabling investors to maximize returns and manage risks effectively in the dynamic and complex world of financial markets. It also aids in portfolio management and financial planning by providing insights into future market movements and asset valuations.This study delves into the intriguing realm of stock price prediction using two models, Auto-Regressive Integrated Moving Average (ARIMA) and Long Short-Term Memory (LSTM) networks, leveraging the efficient market hypothesis framework. Analyzing historical market data for Apple, Google, and Tesla, ARIMA and LSTM models are independently developed to forecast closing stock values. The research compares the forecasting accuracy of each model through Root Mean Square Error (RMSE) and Mean Absolute Percentage Error (MAPE) assessment, aiming to provide insights into their distinct strengths. The findings offer nuanced perspectives on the predictive performance of ARIMA and LSTM models in stock price behavior.",2024
A decision support system using signals from social media and news to predict cryptocurrency prices,"We design, implement, and evaluate a decision support system that combines fine-grained signals derived from news and social media with bitcoin prices using a Long Short-Term Memory (LSTM) neural network. Through this artifact, we construct a portfolio to trade bitcoin in three stages. In the first stage, signals and prices are used as inputs for the LSTM model to predict bitcoin prices. In the second stage, we identify the signals that are the most effective predictors of bitcoin prices and then combine these signals to generate predictions that outperform market benchmarks. In the final stage, we assess portfolios based on their financial performance relative to these benchmarks. This design artifact introduces a method to harness the inherent heterogeneity of online news and social media for bitcoin price prediction.",2024
Machine Learning for Sustainable Portfolio Optimization Applied to a Water Market,"This study introduces a novel methodology that integrates the Black-Litterman model with Long Short-Term Memory Neural Networks (BL-LSTM). We use predictions from the LSTM as views in the Black-Litterman model. The resulting portfolio performs better than the traditional mean-variance (MV) and exchange-traded funds (ETFs) used as benchmarks. The proposal empowers investors to make more insightful decisions, drawing from a synthesis of historical data and advanced predictive techniques. This methodology is applied to a water market. Investing in the water market allows investors to actively support sustainable water solutions while potentially benefiting from the sector's growth, contributing to achieving SDG 6. In addition, our modeling allows for companies' environmental, social, and governance (ESG) scores to be considered in the portfolio construction process. In this case, investors' decisions take into account companies' socially responsible behavior in a broad sense, including aspects related to decent work, respect for indigenous communities and diversity, and the absence of corruption, among others. Therefore, this proposal provides investors with a tool for promoting sustainable investment practices.",2024
Nonlinear asset pricing in Chinese stock market: A deep learning approach,"The redesign of asset pricing models failed to integrate the frequent financial phenomenon that stock markets exhibit a non-linear long-and short-term memory structure. The difficulty lies in developing a nonlinear pricing structure capable of depicting the memory influence of the pricing variable. This paper presents a Long-and Short-Term Memory Neural Network Model (LSTM) to capture the non-linear pricing structure among five elements in the Chinese stock market, including market portfolio return, market capitalisation, book-to-market ratio, earnings factor, and investment factor. The long-short-term memory structure implies that the autocorrelation function of the stock return series decays slowly and has a long-term characteristic. The LSTM model surpasses the standard Fama-French five-factor model in terms of out-of-sample goodness-of-fit and long-short strategy performance. The empirical findings indicate that the LSTM nonlinear model properly represents the nonlinear relationships between the five components.",2023
Improving solar forecasting using Deep Learning and Portfolio Theory integration,"Solar energy has been consolidated as one of the main renewable energy sources capable of contributing to supply global energy demand. However, the solar resource has intermittent feature in electricity production, making it difficult to manage the electrical system. Hence, we propose the application of Deep Learning (DL), one of the emerging themes in the field of Artificial Intelligence (AI), as a solar predictor. To attest its capacity, the technique is compared with other consolidated solar forecasting strategies such as Multilayer Perceptron, Radial Base Function and Support Vector Regression. Additionally, integration of AI methods in a new adaptive topology based on the Portfolio Theory (PT) is proposed hereby to improve solar forecasts. PT takes advantage of diversified forecast assets: when one of the assets shows prediction errors, these are offset by another asset. After testing with data from Spain and Brazil, results show that the Mean Absolute Percentage Error (MAPE) for predictions using DL is 6.89% and for the proposed integration (called PrevPT) is 5.36% concerning data from Spain. For the data from Brazil, MAPE for predictions using DL is 6.08% and 4.52% for PrevPT. In both cases, DL and PrevPT results are better than the other techniques being used. (C) 2020 Elsevier Ltd. All rights reserved.",2020
An Approach for a Multi-Period Portfolio Selection Problem by considering Transaction Costs and Prediction on the Stock Market,"This paper addresses a method to solve a multi-period portfolio selection on the stock market. The portfolio problem seeks an investor to trade stocks with a finite budget and a given integer number of stocks to hold in a portfolio. The trade must be performed through a stockbroker that charges its respective transaction cost and has its minimum required trade amount. A mathematical model has been proposed to deal with the constrained problem. The objective function is to find the best risk-return rate; thus, Sharpe Ratio and Treynor Ratio are used as objective functions. The returns are the same for these ratios, but the risks are not Sharpe considering covariance and Treynor systematical risk. The returns are predicted using a Neural Net with Long-Short-Term Memory (LSTM). This neural net is compared with simple forecasting methods through Mean Absolute Percentage Error (MAPE). Computational experiments show the quality prediction performed by LSTM. The heteroskedastic risk is estimated by Generalized Autoregressive Conditional Heteroskedasticity (GARCH), adjusting the variance for every period; this risk measure is used in Sharpe Ratio. The experiment contemplates a weekly portfolio selection with 5 and 10 stocks in 122 weekly periods for each Chilean market ratio. The best portfolio is Sharpe Ratio with ten stocks, performing a 62.28% real return beating the market, represented by the Selective Stock Price Index (IPSA). Even the worst portfolio, Treynor Ratio, overcomes the IPSA cumulative yield with ten stocks.",2023
Portfolio Optimization Model for Gold and Bitcoin Based on Weighted Unidirectional Dual-Layer LSTM Model and SMA-Slope Strategy,"Portfolio optimization is one of the most complex problems in the financial field, and technical analysis is a popular tool to find an optimal solution that maximizes the yields. This paper establishes a portfolio optimization model consisting of a weighted unidirectional dual-layer LSTM model and an SMA-slope strategy. The weighted unidirectional dual-layer LSTM model is developed to predict the daily prices of gold/Bitcoin, which addresses the traditional problem of prediction lag. Based on the predicted prices and comparison of two representative investment strategies, simple moving average (SMA) and Bollinger bands (BB), this paper adopts a new investment strategy, SMA-slope strategy, which introduces the concept of k-slope to measure the daily ups and downs of gold/Bitcoin. As two typical financial products, gold and Bitcoin are opposite in terms of their characteristics, which may represent many existing financial products in investors' portfolios. With a principle of $1000, this paper conducts a five-year simulation of gold and Bitcoin trading from 11 September 2016 to 10 September 2021. To compensate for the SMA and BB that may miss buying and selling points, 4 different parameters' values in the k-slope are obtained through particle swarm optimization simulation. Also, the simulation results imply that the proposed portfolio optimization model contributes to helping investors make investment decisions with high profitability.",2022
Customized Stock Return Prediction with Deep Learning,"In finance, researchers so far use standard loss functions such as mean squared error when training artificial neural networks for return prediction. However, from an investor's perspective, prediction errors are ambiguous: in practice, the investor prefers to see underprediction of portfolio returns rather than overprediction, as the former implies higher realized returns and thus financial benefits. We present a loss function customized to this behavior and test it based on Long Short-Term Memory (LSTM) models, the state-of-the-art tools in time series analysis. Our model learns unique signals, predicts returns more cautiously, and improves profit chances over the standard LSTM and reversal signals. Daily and weekly revised portfolios achieve on average five percentage points higher annualized returns. We show that our loss function is robust to market sentiment and beneficial in nonlinear optimization.",2022
Portfolio Transformer for Attention-Based Asset Allocation,"Traditional approaches to financial asset allocation start with returns forecasting followed by an optimization stage that decides the optimal asset weights. Any errors made during the forecasting step reduce the accuracy of the asset weightings, and hence the profitability of the overall portfolio. The Portfolio Transformer (PT) network, introduced here, circumvents the need to predict asset returns and instead directly optimizes the Sharpe ratio, a risk-adjusted performance metric widely used in practice. The PT is a novel end-to-end portfolio optimization framework, inspired by the numerous successes of attention mechanisms in natural language processing. With its full encoder-decoder architecture, specialized time encoding layers, and gating components, the PT has a high capacity to learn long-term dependencies among portfolio assets and hence can adapt more quickly to changing market conditions such as the COVID-19 pandemic. To demonstrate its robustness, the PT is compared against other algorithms, including the current LSTM-based state of the art, on three different datasets, with results showing that it offers the best risk-adjusted performance.",2023
Research and development project portfolio benefit prediction: an improved backpropagation neural network-based approach,"PurposeEffectively predicting research and development project portfolio benefit (R&D PPB) could assist organizations in monitoring the execution of research and development project portfolio (R&D PP). However, due to the uncertainty and complexity of R&D PPB, current research remains lacking a valid R&D PPB prediction tool. Therefore, an R&D PPB prediction model is proposed via a backpropagation neural network (BPNN).Design/methodology/approachThe R&D PPB prediction model is constructed via a refined immune genetic algorithm coupling backpropagation neural network (RIGA-BPNN). Firstly, considering the characteristics of R&D PP, benefit evaluation criteria are identified. Secondly, the benefit criteria values are derived as input variables to the model via trapezoidal fuzzy numbers, and then the R&D PPB value is determined as the output variable through the CRITIC method. Thirdly, a refined immune genetic algorithm (RIGA) is designed to optimize BPNN by enhancing polyfitness, crossover and mutation probabilities. Lastly, the R&D PPB prediction model is constructed via the RIGA-BPNN, followed by training and testing.FindingsThe accuracy of the R&D PPB prediction model stands at 99.26%. In addition, the comparative experiment results indicate that the proposed model surpasses BPNN and the immune genetic algorithm coupling backpropagation neural network (IGA-BPNN) in both convergence speed and accuracy, showcasing superior performance in R&D PPB prediction. This study enriches the R&D PPB predicting methodology by providing managers with an effective benefits management tool.Research limitations/implicationsThe research implications of this study encompass three aspects. First, this study provides a profound insight into R&D PPB prediction and enriches the research in PP fields. Secondly, during the construction of the R&D PPB prediction model, the utilization of the composite system synergy model for quantifying synergy contributes to a comprehensive understanding of intricate interactions among benefits. Lastly, in this research, a RIGA is proposed for optimizing the BPNN to efficiently predict R&D PPB.Practical implicationsThis study carries threefold implications for the practice of R&D PPM. To begin with, the approach proposed serves as an effective tool for managers to predict R&D PPB. Then, the model excels in efficiency and flexibility. Furthermore, the proposed model could be used to tackle additional challenges in R&D PPM, such as gauging the potential risk level of R&D PP.Social implicationsEffective predicting of R&D PPB enables organizations to allocate their limited resources more strategically, ensuring optimal use of capital, manpower and time. By accurately predicting benefit, an organization can prioritize high-potential initiatives, thereby improving innovation efficiency and reducing the risk of failed investments. This approach not only strengthens market competitiveness but also positions organizations to adapt more effectively to changing market conditions, fostering long-term growth and sustainability in a competitive business environment.Originality/valueIncorporating the characteristics of R&D PP and quantifying the synergy between benefits, this study facilitates a more insightful R&D PPB prediction. Additionally, improvements to the polyfitness, crossover and mutation probabilities of IGA are made, and the aforementioned RIGA is applied to optimize the BPNN. It significantly enhances the prediction accuracy and convergence speed of the neural network, improving the effectiveness of the R&D PPB prediction model.",2024
A Novel Anti-Risk Method for Portfolio Trading Using Deep Reinforcement Learning,"In the past decade, the application of deep reinforcement learning (DRL) in portfolio management has attracted extensive attention. However, most classical RL algorithms do not consider the exogenous and noise of financial time series data, which may lead to treacherous trading decisions. To address this issue, we propose a novel anti-risk portfolio trading method based on deep reinforcement learning (DRL). It consists of a stacked sparse denoising autoencoder (SSDAE) network and an actor-critic based reinforcement learning (RL) agent. SSDAE will carry out off-line training first, while the decoder will used for on-line feature extraction in each state. The SSDAE network is used for the noise resistance training of financial data. The actor-critic algorithm we use is advantage actor-critic (A2C) and consists of two networks: the actor network learns and implements an investment policy, which is then evaluated by the critic network to determine the best action plan by continuously redistributing various portfolio assets, taking Sharp ratio as the optimization function. Through extensive experiments, the results show that our proposed method is effective and superior to the Dow Jones Industrial Average index (DJIA), several variants of our proposed method, and a state-of-the-art (SOTA) method.",2022
Copula Variational LSTM for High-Dimensional Cross-Market Multivariate Dependence Modeling,"We address a challenging problem-modeling high-dimensional, long-range dependencies between nonnormal multivariates, which is important for demanding applications such as cross-market modeling (CMM). With heterogeneous indicators and markets, CMM aims to capture between-market financial couplings and influence over time and within-market interactions between financial variables. We make the first attempt to integrate deep variational sequential learning with copula-based statistical dependence modeling and characterize both temporal dependence degrees and structures between hidden variables representing nonnormal multivariates. Our copula variational learning network weighted partial regular vine copula-based variational long short-term memory (WPVC-VLSTM) integrates variational long short-term memory (LSTM) networks and regular vine copula to model variational sequential dependence degrees and structures. The regular vine copula models nonnormal distributional dependence degrees and structures. VLSTM captures variational long-range dependencies coupling high-dimensional dynamic hidden variables without strong hypotheses and multivariate constraints. WPVC-VLSTM outperforms benchmarks, including linear models, stochastic volatility models, deep neural networks, and variational recurrent networks in terms of both technical significance and portfolio forecasting performance. WPVC-VLSTM shows a step-forward for CMM and deep variational learning.",2024
Take Bitcoin into your portfolio: a novel ensemble portfolio optimization framework for broad commodity assets,"The emergence and growing popularity of Bitcoins have attracted the attention of the financial world. However, few empirical studies have considered the inclusion of the newly emerged commodity asset in the global commodity market. It is of great importance for investors and policymakers to take advantage of this asset and its potential benefits by incorporating it as a part of the broad commodity trading portfolio. In this study, we propose a novel ensemble portfolio optimization (NEPO) framework utilized for broad commodity assets, which integrates a hybrid variational mode decomposition-bidirectional long short-term memory deep learning model for future returns forecast and a reinforcement learning-based model for optimizing the asset weight allocation. Our empirical results indicate that the NEPO framework could effectively improve the prediction accuracy and trend prediction ability across various commodity assets from different sectors. In addition, it could effectively incorporate Bitcoins into the asset pool and achieve better financial performance compared to traditional asset allocation strategies, commodity funds, and indices.",2021
Fuzzy neural network with backpropagation for fuzzy quadratic programming problems and portfolio optimization problems,"The study aspires to adopt back propagation fuzzy neural networks to solve fuzzy quadratic programming problems. The main motivation behind proposing a back propagation neural network is that it can easily adjust and fine-tune the weights of the network from the error rate obtained at the previous layer. The error rate customarily called the loss function is the dissimilarity between the desired and predicted outputs. The chain and power rules of the derivative allow back propagation and successively update the weights of the network to perform efficiently. Thus, the gradient of the loss function is calculated by iterating backward layer by layer but one at a time to reduce the difference between the desired and the predicted outputs. The research flow is such that first of all the quadratic programming problem is formulated in a fuzzy environment. The problem with fuzzy quadratic programming is formulated as a lower, central, and upper model. The formulated models are then solved with backpropagation fuzzy neural networks. The proposed method is then implemented in the capital market to identify the optimal portfolio for potential investors in the Pakistan Stock Exchange. Six leading stocks traded on the stock exchange from Jan 2016 to Oct 2020 were taken into consideration. At all three levels (lower, central, and upper), the results of identifying the best investment portfolio for investors are consistent. The proposed three models identify the investors to invest in ATHL, MCB and ARPL, whereas, the remaining three IGIHL, INIL and POL are not desirable for investment. In all three cases, the convergence is obtained at 475 iterations which is faster than the previously conducted studies. Moreover, another advantage of the proposed technique is that it brings an improvement of 28.77% in the objective function of mean variance optimization MVO model.",2024
Dynamic portfolio rebalancing through reinforcement learning,"Portfolio managements in financial markets involve risk management strategies and opportunistic responses to individual trading behaviours. Optimal portfolios constructed aim to have a minimal risk with highest accompanying investment returns, regardless of market conditions. This paper focuses on providing an alternative view in maximising portfolio returns using Reinforcement Learning (RL) by considering dynamic risks appropriate to market conditions through dynamic portfolio rebalancing. The proposed algorithm is able to improve portfolio management by introducing the dynamic rebalancing of portfolios with vigorous risk through an RL agent. This is done while accounting for market conditions, asset diversifications, risk and returns in the global financial market. Studies have been performed in this paper to explore four types of methods with variations in fully portfolio rebalancing and gradual portfolio rebalancing, which combine with and without the use of the Long Short-Term Memory (LSTM) model to predict stock prices for adjusting the technical indicator centring. Performances of the four methods have been evaluated and compared using three constructed financial portfolios, including one portfolio with global market index assets with different risk levels, and two portfolios with uncorrelated stock assets from different sectors and risk levels. Observed from the experiment results, the proposed RL agent for gradual portfolio rebalancing with the LSTM model on price prediction outperforms the other three methods, as well as returns of individual assets in these three portfolios. The improvements of the returns using the RL agent for gradual rebalancing with prediction model are achieved at about 27.9-93.4% over those of the full rebalancing without prediction model. It has demonstrated the ability to dynamically adjust portfolio compositions according to the market trends, risks and returns of the global indices and stock assets.",2022
"Discovery and Prediction of Stock Index Pattern via Three-Stage Architecture of TICC, TPA-LSTM and Multivariate LSTM-FCNs","In this study, we attempt to discover and predict stock index patterns through analysis of multivariate time series. Our motivation is based on the notion that financial planning guided by pattern discovery and prediction of stock index prices maybe more realistic and effective than traditional approaches, such as Autoregressive Integrated Moving Average (ARIMA) model. A three-stage architecture constructed by combining Toeplitz Inverse Covariance-Based Clustering (TICC), Temporal Pattern Attention and Long- Short-Term Memory (TPA-LSTM) and Multivariate LSTM-FCNs (MLSTM-FCN and MALSTM-FCN) is applied for pattern discovery and prediction of stock index. In the first stage, we use TICC to discover repeated patterns of stock index. Then, in the second stage, TPA-LSTM that considers weak periodic patterns and long short-term information is used to predict multivariate stock indices. Finally, in the third stage, MALSTM-FCN is applied to predict stock index price pattern. The Hangseng Stock Index and eleven industrial sub-indices are used in the experiment. Empirical results show that the three-stage architecture achieves satisfactory and better performance than traditional methods, such as Naive Bayes Classifier (NB), Support Vector Machine Classifier (SVM), Random Forest (RF), etc. Moreover, we construct equal proportion portfolios based on the bullish trading rules to further analyze the feasibility of the proposed three-stage architecture. Seven comprehensive stock indices are used in the experiment. Empirical results show that the portfolio based on the proposed three-stage architecture presents better performance than the market-based portfolio. These findings may provide new direction for the portfolio construction and risk aversion.",2020
Risk Analysis of the Chinese Financial Market with the Application of a Novel Hybrid Volatility Prediction Model,"This paper endeavors to enhance the prediction of volatility in financial markets by developing a novel hybrid model that integrates generalized autoregressive conditional heteroskedasticity (GARCH) models and long short-term memory (LSTM) neural networks. Using high-frequency data, we first estimate realized volatility as a robust measure of volatility. We then feed the outputs of multiple GARCH models into an LSTM network, creating a hybrid model that leverages the strengths of both approaches. The predicted volatility from the hybrid model is used to generate trading strategy signals, which are subsequently used to build an investment strategy. Empirical analysis using the China Securities Index 300 (CSI300) dataset demonstrates that the hybrid model significantly improves value-at-risk (VaR) prediction performance compared to traditional GARCH models. This study's findings have broad implications for risk management in financial markets, suggesting that hybrid models incorporating mathematical models and economic mechanisms can enhance derivative pricing, portfolio risk management, hedging transactions, and systemic risk early-warning systems.",2023
Long Short-Term Memory in Intelligent Buildings,"This paper presents Long Short-Term Memory (LSTM) in iBuilding: Artificial Intelligence in Intelligent Buildings. LSTM networks are widely used in time series data as their learning algorithm does not present exploding and vanishing gradient descent issues as traditional recurrent neural networks with back propagation learning algorithms. This paper proposes the use of LSTM networks to predict the values of the different iBuilding variables, such as environmental conditions, energy consumption or occupancy. Intelligent Buildings are used as an investment portfolio, Technology and Artificial Intelligence plays a critical role to make a successful Return on Investment (ROI). The business case and main driver to use Artificial Intelligence in Intelligent Buildings is to predict the future value of iBuilding variables therefore preventive action can be taken in the present to reduce OPEX costs such as decreasing overnight heating due low predicted low occupancy or preventive maintenance on mechanical and electrical assets such as lifts with fault detection and diagnosis. The predictions of the proposed LSTM in iBuilding has been validated with several public datasets against other predictors. The obtained results demonstrate that LSTM networks are more accurate than the Linear Regression (LR) model, typically used within the embedded predictors found on common spreadsheet software.",2020
Two-stage stock portfolio optimization based on AI-powered price prediction and mean-CVaR models,"With the advancement of prediction methods in the field of artificial intelligence, accurate price predictions can effectively support financial portfolio selection. This paper proposes an intelligent stock portfolio selection method based on a prediction neural network, incorporating signal processing and hyperparameter optimization techniques. The method is divided into two key stages: stock price prediction and portfolio selection. In the first stage, we apply Savitzky-Golay filtering to denoise price data and reveal its patterns, and optimize the hyperparameters of the long short-term memory network using the sparrow search algorithm to achieve high-precision stock price predictions. In the second stage, we use the mean-Conditional Value-at-Risk (meanCVaR) model to select the optimal stock allocation, considering factors such as potential returns, prediction accuracy, and growth rate. Numerical comparisons based on multiple public financial datasets demonstrate that the proposed two-stage method significantly outperforms seven benchmark methods. Specifically, on the Shanghai and Shenzhen 300 (CSI 300) Index dataset, the proposed method achieves a determination coefficient of 0.9980 and an accuracy rate of 97.05%. Additionally, its cumulative returns reach 9.38%, 8.63%, and 7.54% at different confidence levels.",2024
Measurement of Project Portfolio Benefits With a GA-BP Neural Network Group,"To facilitate the project portfolio benefits (PPB) management and realize the maximization of the benefits, a PPB measurement model based on the genetic algorithm (GA)-BP neural network group (GA-BPNNG) is proposed in current research. Unlike traditional benefits management approaches, the proposed model takes full cooperation and information sharing advantages of group learning to measure PPB more accurately, which considers both the financial and nonfinancial benefits and synergy benefits generated from the interrelationships among project portfolio components. To ascertain the priority of the PPB measurement model, the GA-BPNNG model is compared with BPNN and GA-BPNN, two common models in the literature. The mean square error of the GA-BPNNG model reduced by 94% and 83%, respectively, when compared to the BPNN and GA-BPNN models. The results suggest that the PPB measurement model performs more effectively. Therefore, it could be concluded that the proposed model has a better nonlinear fitting effect for PPB measurement. This article can support managers, decision-makers, and management in realizing strategy by providing a practical and scalable tool for PPB measurement.",2023
Artificial Intelligence for Conversational Robo-Advisor,"With the advent of the artificial intelligence (AI) era, the combination of AI with financial technology (FinTech) has become a development trend in the financial industry. However, deep learning (DL) on the application of automated financial management has been rarely investigated. Thus, this research focuses on the applications of FinTech and DL in asset allocation and aims to optimize investment portfolio. The best investment portfolio in index-based funds based on Taiwan's index-type security investment trust funds are the main investment targets. Time series models for DL, that is, long short-term memory, predict the increase of each investment target and find the best investment portfolio in combination with the relevant asset allocation theory. In this research, we use the Markowitz mean-variance and Black-Litterman models as our asset allocation models for robo-advisor. Results show that the Black-Litterman model has a better accumulated return performance than the Morkowitz model and outperforms other strategies. The Human-Computer Interaction (HCI) dialogue service adopts artificial intelligence markup language (AIML) and a generative model. The main contribution of this paper is that we have developed an integrated knowledge-based and generative-based models for AI conversational robo-advisor.",2018
Deep time series forecasting for enhanced index tracking,"We consider the problem of enhanced index tracking whose objective is to construct a portfolio that maximizes the excess return and minimizes the tracking error between the returns of the tracking portfolio and a benchmark index. This problem is of considerable importance in the field of asset management as beating the market is known to be a notoriously difficult problem. We first identify the shortcomings inherent in the existing approaches to the problem, and then propose a general methodology to enhanced index tracking portfolio construction that moderates the degree of the shortcomings. Then, we present explicit construction schemes that utilize the latest advancements of the deep learning technology, and in particular, of long short-term memory networks that are designed to be efficacious for time series forecasting. Our proposed enhanced index tracking portfolios are empirically compared and contrasted with those of previously known proficient enhanced index tracking schemes over the benchmark of S&P 500. It is presented that our proposed portfolios outperform all other portfolios considered in this paper, and in particular, can beat the benchmark index substantially for a variety of cardinality constraint values tested.",2021
Deep Learning in Finance: A Survey of Applications and Techniques,"Machine learning (ML) has transformed the financial industry by enabling advanced applications such as credit scoring, fraud detection, and market forecasting. At the core of this transformation is deep learning (DL), a subset of ML that is robust in processing and analyzing complex and large datasets. This paper provides a comprehensive overview of key deep learning models, including Convolutional Neural Networks (CNNs), Long Short-Term Memory networks (LSTMs), Deep Belief Networks (DBNs), Transformers, Generative Adversarial Networks (GANs), and Deep Reinforcement Learning (Deep RL). Beyond summarizing their mathematical foundations and learning processes, this study offers new insights into how these models are applied in real-world financial contexts, highlighting their specific advantages and limitations in tasks such as algorithmic trading, risk management, and portfolio optimization. It also examines recent advances and emerging trends in the financial industry alongside critical challenges such as data quality, model interpretability, and computational complexity. These insights can guide future research directions toward developing more efficient, robust, and explainable financial models that address the evolving needs of the financial sector.",2024
Convergence Technology Opportunity Discovery for Firms Based on Technology Portfolio Using the Stacked Denoising AutoEncoder (SDAE),"Technology convergence, as a key driving force of innovation, has brought a burgeoning of research attention. Although numerous studies on technology convergence have been carried out, there were limitations in consideration of a firm's capability in technology convergence. This article proposes a framework for Convergence Technology Opportunity Discovery (CTOD) based on firms' technical convergence competence manifested in their patent portfolios, market competition, and technological growth potential. The present research, by employing a stacked denoising autoencoder, a deep neural network-based collaborative filtering method, provides reliable latent preference toward convergence technology for individual firms. Our CTOD framework is applied to three information technology and biotechnology firms to elaborately demonstrate its validity. Ultimately, the proposed framework is expected to provide practical assistance to organizations seeking technology convergence opportunities in various fields.",2024
"Long-term financial predictions based on Feynman-Dirac path integrals, deep Bayesian networks and temporal generative adversarial networks","This paper presents a new deep learning framework, QuantumPath, for long-term stock price prediction, which is of great significance in portfolio management and risk mitigation, especially when the market becomes volatile due to unpredictable circumstances such as a pandemic. Our approach is based on stochastic equations, the Feynman-Dirac path integral, deep Bayesian networks, and temporal generative adversarial neural networks (t-GAN). The expected financial trajectory is evaluated with a Feynman-Dirac path integral. The latter involves summing all possible financial trajectories that could have been taken by the financial instrument. These trajectories are generated with a t-GAN. A probability is attributed to each point of each path. The probability is a function of the Lagrangian, which is derived from a stochastic equation describing the temporal evolution of the stock. The drift and the volatility at each point, which are required in order to evaluate the Lagrangian, are predicted with a deep Bayesian neural network. Given that the evolution of a stock's price is isomorphic to a time series, our temporal GAN consists of long short-term memory (LSTM) neural networks, which introduce a memory mechanism, and temporal convolutional neural networks (TCN), which ensure causality. Stock prices are predicted over periods of twenty and thirty days for nine stocks, eight of which are included in the S&P 500 index. Our experimental results clearly demonstrate the efficiency of our approach.",2022
An Enriched Time-Series Forecasting Framework for Long-Short Portfolio Strategy,"Stock return forecasting typically requires a large number of factors and these factors usually exhibit nonlinear relations with each other. Conventional methods of stock return forecasting mainly fall into two categories: Technical Analysis and Fundamental Analysis. Technical Analysis focuses on time-series data, while Fundamental Analysis explores low-frequency fundamental variables. Although there are substantial works on either time-series analysis or fundamental analysis, few studies have enriched the time-series forecasting with fundamental variables, as the features are characterized by different frequencies, scales and types. In this paper, we propose a Long Short-Term Memory and Deep Neural Network (LSTM-DNN) hybrid model to integrate the fundamental information into time-series forecasting tasks. We demonstrate how investors can benefit from the superior performance of LSTM-DNN by constructing a long-short portfolio that takes long positions in stocks with the highest forecasting returns and short positions in stocks that are expected to decline. Extensive experimental results on real data show that our novel framework could improve the profitability of long-short portfolio strategies compared to the state-of-the-art approaches. We also find evidence indicating that the outperformance of LSTM-DNN model comes from its enhanced ability to extract information from the nonlinear relations among various features, rather than bearing more market risks. Besides the novel framework, we propose a cross-section normalization method, which benefits the framework by providing enriched cross-section signals.",2020
High return and low risk: Shaping composite financial investment decision in the new energy stock market,"As an emerging market, the new energy stock market is characterized by high volatility and instability, and investors seeking to make investment decisions face significant challenges. To enable investors to diversify risk and obtain more consistent high returns, we have built a composite financial investment decision system that combines portfolio selection, trend forecasting, and quantitative trading. The system takes a sequential, rolling Sharpe ratio calculation and dynamically selects portfolios to reduce risk from market changes and achieve optimal portfolio diversification. Then, the variational mode decomposition (VMD)-bidirectional gated recurrent unit (BiGRU) model is introduced to predict the trend of the portfolio and quantify the trades of the portfolios. Experimental results show that the system can obtain an average annual return of up to 758,508 CNY with a principal capital of 30,000 CNY. Compared with observing the investment ratio of the portfolio statically, selecting the portfolio by calculating the Sharpe ratio continuously and rolling can improve the portfolio return and diversify the risk. In terms of trend forecasting, VMD-BiGRU is shown to greatly improve forecasting performance compared to single gated recurrent unit (GRU) or long short-term memory (LSTM) models. Compared with human-driven trading, quantitative trading has been shown to have the advantage of short holding times, low risk, and high returns by capturing trading opportunities promptly based on the results obtained from predictive models.",2023
Forecasting stock prices changes using long-short term memory neural network with symbolic genetic programming,"This study introduces an augmented Long-Short Term Memory (LSTM) neural network architecture, integrating Symbolic Genetic Programming (SGP), with the objective of forecasting cross-sectional price returns across a comprehensive dataset comprising 4500 listed stocks in the Chinese market over the period from 2014 to 2022. Using the S&P Alpha Pool Dataset for China as basic input, this architecture incorporates data augmentation and feature extraction techniques. The result of this study demonstrates significant improvements in Rank Information coefficient (Rank IC) and IC information ratio (ICIR) by 1128% and 5360% respectively when it is applied to fundamental indicators. For technical indicators, the hybrid model achieves a 206% increase in Rank IC and an impressive surge of 2752% in ICIR. Furthermore, the proposed hybrid SGP-LSTM model outperforms major Chinese stock indexes, generating average annualized excess returns of 31.00%, 24.48%, and 16.38% compared to the CSI 300 index, CSI 500 index, and the average portfolio, respectively. These findings highlight the effectiveness of SGP-LSTM model in improving the accuracy of cross-sectional stock return predictions and provide valuable insights for fund managers, traders, and financial analysts.",2024
Stock-Index Tracking Optimization Using Auto-Encoders,"Deep learning algorithms' powerful capabilities for extracting useful latent information give them the potential to outperform traditional financial models in solving problems of the stock market which is a complex system. In this paper, we explore the use of advanced deep learning algorithms for stock-index tracking. We partially replicate the CSI 300 Index by optimizing with respect to the difference between the returns of the tracking portfolio and the target index. We extract the complex non-linear relationship between index constituents and select a subset of constituents to construct a dynamic tracking portfolio by six well-known auto-encoders (single-hidden-layer undercomplete, sparse, contractive, stacked, denoising, and variational auto-encoders) that have been widely used in contexts other than stock-index tracking. Empirical results show that the auto-encoder-based strategies perform better than conventional ones when the tracking portfolio is constructed with a small number of stocks. Furthermore, strategies based on auto-encoders capable of learning high-capacity encodings of the input, such as sparse and denoising auto-encoders, have even better tracking performance. Our findings offer evidence that deep learning algorithms with explicitly designed hierarchical architectures are suitable for index tracking problems.",2020
Deep Reinforcement Learning Agent for S&P 500 Stock Selection,"This study investigated the performance of a trading agent based on a convolutional neural network model in portfolio management. The results showed that with real-world data the agent could produce relevant trading results, while the agent's behavior corresponded to that of a high-risk taker. The data used were wide in comparison with earlier reported research and was based on the full set of the S&P 500 stock data for twenty-one years supplemented with selected financial ratios. The results presented are new in terms of the size of the data set used and with regards to the model used. The results provide direction and offer insight into how deep learning methods may be used in constructing automatic trading systems.",2020
Public Mood-Driven Asset Allocation: the Importance of Financial Sentiment in Portfolio Management,"The study of the impact of investor sentiment on stock returns has gained increasing momentum in the past few years. It has been widely accepted that public mood is correlated with financial markets. However, only a few studies discussed how the public mood would affect one of the fundamental problems of computational finance: portfolio management. In this study, we use public financial sentiment and historical prices collected from the New York Stock Exchange (NYSE) to train multiple machine learning models for automatic wealth allocation across a set of assets. Unlike previous studies which set as target variable the asset prices in the portfolio, the variable to predict here is represented by the best asset allocation strategy ex post. Experiments performed on five portfolios show that long short-term memory networks are superior to multi-layer perceptron and random forests producing, in the period under analysis, an average increase in the revenue across the portfolios ranging between 5% (without financial mood) and 19% (with financial mood) compared to the equal-weighted portfolio. Results show that our all-in-one and end-to-end approach for automatic portfolio selection outperforms the equal-weighted portfolio. Moreover, when using long short-term memory networks, the employment of sentiment data in addition to lagged data leads to greater returns for all the five portfolios under evaluation. Finally, we find that among the employed machine learning algorithms, long short-term memory networks are better suited for learning the impact of public mood on financial time series.",2018
A comprehensive review on multiple hybrid deep learning approaches for stock prediction,"Numerous recent studies have attempted to create efficient mechanical trading systems through the use of machine learning approaches for stock price estimation and portfolio management. Using the ability to foresee the future trends of the stock performance, the return of investment can be maximized for short-term trading. This paper will review various Artificial Intelligence (AI) and Machine Learning (ML) strategies for stock price forecasting. The aim of this review is to discuss various techniques for stock price prediction that incorporate ARIMA, LSTM, Hybrid LSTM, CNN, and Hybrid CNN. Additionally, it will also discuss the limitations and accuracy of the various models, including the ARIMA model, the LSTM model, the MI-LSTM model, the Bi-LSTM model, the LSTM-DRNN model, the CNN model, the GC-CNN model, the CNN-LSTM model, the CNN-TLSTM model, and the CNN-BiLSTM model, in terms of percentage of accuracy or error calculation in terms of standard accuracy measures like RMSE, MAPE, MAE. The models can be used to forecast either the accurate stock rate, induced by the low MSE, RMSE and MAE of LSTM models, or the general trend and deflection range of the stock the following day, induced by the ability to dynamically capture swift changes in the system of CNN models. These characteristics consequently illustrate the advantages of the hybrid model at efficiently and accurately forecasting stock attributes.",2022
Volatility Spillovers and Contagion During Major Crises: An Early Warning Approach Based on a Deep Learning Model,"This paper contributes to the ongoing debate on the nature and characteristics of the volatility transmission channels of major crash events in international stock markets between 03 July 1997 and 09 March 2021. Using dynamic conditional correlations (DCC) for conditional correlations and volatility clustering, GARCH-BEKK for the direction of transmission of disturbances, and the Diebold-Yilmaz spillover index for the level of volatility contagion, the paper finds that the climbs in external shock transmissions have long-lasting impacts in domestic markets due to the contagion effect during crisis periods. The findings also reveal that the heavier magnitude of financial stress is transmitted between Asian countries via the Hong Kong stock market. Additionally, the degree of volatility spillovers between advanced and emerging equity markets is smaller compared to the pure spillovers between advanced markets or emerging markets, offering a window of opportunity for international market participants in terms of portfolio diversification and risk management applications. Furthermore, the study introduces a novel early warning system created by integrating DCC correlations with a state-of-the-art deep learning model to predict the global financial crisis and COVID-19 crisis. The experimental analysis of long short-term memory network finds evidence of contagion risk by verifying bursts in volatility spillovers and generating signals with high accuracy before the 12-month crisis period. This provides supplementary information that contributes to the decision-making process of practitioners, as well as offering indicative evidence that facilitates the assessment of market vulnerability for policymakers.",2024
Can intangible assets predict future performance? A deep learning approach,"Purpose The aim of this study is to evaluate of the predictive ability of goodwill and other intangible assets on forecasting corporate profitability. Subsequently, this study compares the efficiency of deep learning model to that of other machine learning models such as random forest (RF) and support vector machine (SVM) as well as traditional statistical methods such as the linear regression model. Design/methodology/approach Studies confirm that goodwill and intangibles are valuable assets that give companies a competitive advantage to increase profitability and shareholders' returns. Thus, by using as sample Greek-listed financial data, this study investigates whether or not the inclusion of goodwill and intangible assets as input variables in this modified deep learning models contribute to the corporate profitability prediction accuracy. Subsequently, this study compares the modified long-short-term model with other machine learning models such as SVMs and RF as well as the traditional panel regression model. Findings The findings of this paper confirm that goodwill and intangible assets clearly improve the performance of a deep learning corporate profitability prediction model. Furthermore, this study provides evidence that the modified long short-term memory model outperforms other machine learning models such as SVMs and RF , as well as traditional statistical panel regression model, in predicting corporate profitability. Research limitations/implications Limitation of this study includes the relatively small amount of data available. Furthermore, the aim is to challenge the authors' modified long short-term memory by using listed corporate data of Greece, a code-law country that suffered severely during the recent fiscal crisis. However, this study proposes that future research may apply deep learning corporate profitability models on a bigger pool of data such as STOXX Europe 600 companies. Practical implications Subsequently, the authors believe that their paper is of interest to different professional groups, such as financial analysts and banks, which the authors' paper can support in their corporate profitability evaluation procedure. Furthermore, as well as shareholders are concerned, this paper could be of benefit in forecasting management's potential to create future returns. Finally, management may incorporate this model in the evaluation process of potential acquisitions of other companies. Originality/value The contributions of this work can be summarized in the following aspects. This study provides evidence that by including goodwill and other intangible assets in the authors' input portfolio, prediction errors represented by root mean squared error are reduced. A modified long short-term memory model is proposed to predict the numerical value of the profitability (or the profitability ratio) in contrast to other studies which deal with trend predictions, i.e. the binomial output result of positive or negative earnings. Finally, posing an extra challenge to the authors' deep learning model, the authors' used financial statements according to International Financial Reporting Standard data of listed companies in Greece, a code-law country that suffered during the recent fiscal debt crisis, heavily influenced by tax legislation and characterized by its lower investors' protection compared to common-law countries.",2022
Index tracking through deep latent representation learning,"We consider the problem of index tracking whose goal is to construct a portfolio that minimizes the tracking error between the returns of a benchmark index and the tracking portfolio. This problem carries significant importance in financial economics as the tracking portfolio represents a parsimonious index that facilitates a practical means to trade the benchmark index. For this reason, extensive studies from various optimization and machine learning-based approaches have ensued. In this paper, we solve this problem through the latest developments from deep learning. Specifically, we associate a deep latent representation of asset returns, obtained through a stacked autoencoder, with the benchmark index's return to identify the assets for inclusion in the tracking portfolio. Empirical results indicate that to improve the performance of previously proposed deep learning-based index tracking, the deep latent representation needs to be learned in a strictly hierarchical manner and the relationship between the returns of the index and the assets should be quantified by statistical measures. Various deep learning-based strategies have been tested for the stock market indices of the S&P 500, FTSE 100 and HSI, and it is shown that our proposed methodology generates the best index tracking performance.",2020
Advertisement System Based on Facial Expression Recognition and Convolutional Neural Network,"Advertisements play a crucial role in the mass spreading and success of a product, a service or an entire business. For gaining effectiveness, they should be judged thoroughly by means of direct and indirect rating, portfolio tests, transactions and interactions. Instead of those, human emotions can be a powerful source of reliable feedback. This information is valuable for company to not only re-evaluate the efficiency of their ads but also make them more interactive to customers. To build a good facial expression recognition program, deep learning is applied in the form of Convolutional Neural Network, increasing the accuracy of classifying 7 basic emotions to 90% on CK+ dataset. Moreover, we have designed 2 systems, one for storing and updating the commercials and one for extracting emotion data and attracting customers.",2019
An asymmetric PROMETHEE II for cryptocurrency portfolio allocation based on return prediction,"Portfolio allocation, portfolio selection, and portfolio optimization are recognized as three crucial problems in the financial field. Using different criteria in addition to return and risk in the portfolio allocation problem based on the multi-criteria decision-making (MCDM) methods makes it more practical in the real world. The emergence of new and volatile assets such as cryptocurrencies has recently increased the need to use portfolio allocation models. In order to reduce inequalities and alleviate poverty as one of the sustainable development goals, cryptocurrency portfolio construction leads to sustainable income and wealth. This paper proposes a cryptocurrency portfolio allocation model based on the asymmetric Preference Ranking Organization Method for Enrichment Evaluation (PROMETHEE II) method using eight criteria and nine cryptocurrencies. To reduce the uncertainty of the problem, the return prediction obtained from the Auto-Regressive Integrated Moving Average (ARIMA), the Long Short-Term Memory (LSTM), and the Random Forest Regression (RFR) models as return-related criteria and has been used from the SlideVaR, along with the Value at Risk (VaR) and the Conditional Value at Risk (C-VaR) as risk-related criteria to consider investor insight from the market situation. It is also proposed that an asymmetric preference function be proposed to consider gain and loss asymmetry as a behavioral phenomenon in the model. The out-of-sample performance of the proposed model in the last three months of 2021 confirms the superiority of the proposed model in terms of average return (= 0.017) and standard deviation (= 0.036) among other proposed models.(c) 2022 Elsevier B.V. All rights reserved.",2022
Recurrent neural network for dynamic portfolio selection,"In this paper, the dynamic portfolio selection problem is considered. The Elman network is first designed to simulate the dynamic security behavior. Then, the dynamic covariance matrix is estimated by the cross-covariance matrices. Finally, the dynamic portfolio selection model is formulated. In addition, a numerical example is used to demonstrate the proposed method and compare with the vector autoregression (VAR) model. On the basis of the numerical example, we can conclude that the proposed method outperform to the VAR model and provide the accurate dynamic portfolio selection. (c) 2005 Elsevier Inc. All rights reserved.",2006
A Novel DenseNet-based Deep Reinforcement Framework for Portfolio Management,"The objective of portfolio management is to realize portfolio optimization, i.e., maximizing the cumulative return of the portfolio over continuous trading periods. Using Artificial Intelligence algorithms, e.g., Deep Reinforcement Learning (DRL), to realize portfolio optimization is an emerging research trend. Jiang et al.'s Ensemble of Identical Independent Evaluators (EIIE) framework achieves at least a four-fold improvement in the indicator of final portfolio value. Their framework has high flexibility to allow us to replace components to achieve continuous improvement. In EIIE, the DRL agent uses neural networks to extract data features from historical data of assets and evaluate each asset's potential growth. This paper introduces a novel network architecture called Dense Based EIIE (DBE), which is embedded in an DRL framework based on Convolutional Neural Network (CNN) and Densely Convoluted Neural Network (DenseNet) module. Compared to Jiang et al.'s strategy, our improved framework uses DenseNet to achieve the EIIE framework, further increasing profitability. In all three experiments carried out, our strategy outperforms Jiang et al.'s strategy and nine traditional strategies. Our strategy achieves at least a 17% improvement in cumulative return compared to other strategies. Furthermore, it achieves at least twice as much in Sharpe Ratio as other strategies.",2022
Enhancing performance of shipboard photovoltaic grid-connected inverter through CRNN-LM-BP control optimized by particle swarm optimization of LCL parameters,"The global renewable energy portfolio is experiencing a growing proportion of shipboard photovoltaic (PV) energy. Grid-connected system has become the development trend of photovoltaic power generation technology in marine applications because of its high energy utilization efficiency. However, in the grid-connected process, harmonic pollution is easily caused by time-varying marine environment disturbance, which affects the quality of grid-connected power. The current recurrent neural network Levenberg-Marquardt backpropagation (CRNN-LMBP) method, a control methodology, is introduced in this paper to ensure the robustness, stability, and consistency of the system. In addition, the inductance-capacitance-inductance (LCL) filter is optimized using particle swarm optimization (PSO) to minimize the presence of high frequency harmonics. The system that has been developed possesses the ability to improve the accuracy of steady-state control, operate with high efficiency and effectiveness, and maintain a total harmonic distortion of 1.73 %. Concurrently, streamlining the Jacobian matrix in the LM algorithm expedites convergence. It enables the system to improve its dynamic response, minimize excess, and quickly return to a stable condition when faced with load variations, a wide range of filter parameter adjustments, and voltage fluctuations. The suggested method's effectiveness and applicability are evaluated by comparing it to the traditional proportional-resonant control, CRNN-BP control, using Matlab/ Simulink and the real-time simulator OPAL-RT5700..",2024
A novel two-stage method for well-diversified portfolio construction based on stock return prediction using machine learning,"The performance of portfolio model can be improved by introducing stock prediction based on machine learning methods. However, the prediction error is inevitable, which may bring losses to investors. To limit the losses, a common strategy is diversification, which involves buying low-correlation stocks and spreading the funds across different assets. In this paper, a diversified portfolio selection method based on stock prediction is proposed, which includes two stages. To be specific, the purpose of the first stage is to select diversified stocks with high predicted returns, where the returns are predicted by machine learning methods, i.e. random forest (RF), support vector regression (SVR), long short-term memory networks (LSTM), extreme learning machine (ELM) and back propagation neural network (BPNN), and the diversification level is measured by Pearson correlation coefficient. In the second stage, the predictive results are incorporated into a modified mean-variance (MMV) model to determine the proportion of each asset. Using China Securities 100 Index component stocks as study sample, the empirical results demonstrate that the RF+MMV model achieves better results than similar counterparts and market index in terms of return and return-risk metrics.",2022
Leveraging BiLSTM-GAT for enhanced stock market prediction: a dual-graph approach to portfolio optimization,"Stock price prediction remains a critical challenge in financial research due to its potential to inform strategic decision-making. Existing approaches predominantly focus on two key tasks: (1) regression, which forecasts future stock prices, and (2) classification, which identifies trading signals such as buy, sell, or hold. However, the inherent limitations of financial data hinder effective model training, often leading to suboptimal performance. To mitigate this issue, prior studies have expanded datasets by aggregating historical data from multiple companies. This strategy, however, fails to account for the unique characteristics and interdependencies among individual stocks, thereby reducing predictive accuracy. To address these limitations, we propose a novel BiLSTM-GAT-AM model that integrates bidirectional long short-term memory (BiLSTM) networks with graph attention networks (GAT) and an attention mechanism (AM). Unlike conventional graph-based models that define edges based solely on technical or fundamental relationships, our approach employs a dual-graph structure: one graph captures technical similarities, while the other encodes fundamental industry relationships. These two representations are aligned through an attention mechanism, enabling the model to exploit both technical and fundamental insights for enhanced stock market predictions. We conduct extensive experiments, including ablation studies and comparative evaluations against baseline models. The results demonstrate that our model achieves superior predictive performance. Furthermore, leveraging the model's forecasts, we construct an optimized portfolio and conduct backtesting on the test dataset. Empirical results indicate that our portfolio consistently outperforms both baseline models and the S&P 500 index, highlighting the effectiveness of our approach in stock market prediction and portfolio optimization.",2025
Deep Reinforcement Learning for Optimizing Finance Portfolio Management,"Deep reinforcement learning (DRL) is an emerging artificial intelligence (AI) research field which combines deep learning (DL) for policy optimization and reinforcement learning (RL) for goal-oriented self-learning without human intervention. We address major research issues of policy optimization for finance portfolio management. First, we explore one of the deep recurrent neural network (RNN) models, GRUs, to decide the influences of earlier states and actions on policy optimization in non-Markov decision processes. Then, we craft for a viable risk-adjusted reward function to evaluate the expected total rewards for policy. Third, we empower the integration of RL and DL to leverage their respective capabilities to discover an optimal policy. Fourth, we investigate each type of RL approaches for integrating with the DL method while solving the policy optimization problem.",2019
Novel online portfolio selection algorithm using deep sequence features and reversal information,"Computational finance combines machine learning with financial needs to provide more efficient solutions for investment analysis and automated trading. In previous studies, traditional online portfolio selection (OLPS) algorithms were found to be overly reliant on artificially designed, subjective financial features. To address this issue, we propose a new predictive price tracking algorithm based on deep sequence features and reversal information (DSF-RI-PPT) for OLPS, extending a hybrid stock prediction algorithm to a multiasset trading algorithm. We respectively employ the complete ensemble empirical mode decomposition with adaptive noise (CEEMDAN), principal component analysis (PCA) algorithms and long short-term memory (LSTM) network to perform decomposition, feature extraction and prediction on financial data. Further, we supplement the reversal information by modifying the predicted prices with a reversal indicator-rate of change (ROC). Finally, we introduce a fast error back-propagation algorithm to integrate the predictive information into the investment ratio using gradient projection. Through empirical comparison and statistic analysis of the DSF-RI-PPT algorithm, price-tracking algorithms with similar prediction models, and nine classic OLPS algorithms in nine portfolio data sets under three financial indexes, it can be found that the DSF-RI-PPT algorithm is profitable and generalizable.",2024
Rapid seismic response prediction of RC frames based on deep learning and limited building information,"Building portfolio is the important urban engineering system, and the seismic resilience assessment of a city needs the quick and accurate prediction of the seismic responses of existed buildings. However, many existed buildings generally possess the problem that the design information materials are incomplete or completely lost. The major challenge in the seismic resilience assessment of building portfolio is how to predict the seismic responses of buildings quickly and accurately just using limited building information. This manuscript aims to develop a method for the seismic response prediction of the existed reinforced concrete (RC) frame buildings just using limited building information. A total of 162 typical RC frame buildings of low to medium rise are designed, and the inter-story drift (IDR) as well as peak floor acceleration (PFA) of each floor in each building are computed for 200 ground motions with nonlinear time history analysis (NLTHA) method. A convolutional neural network (CNN) is developed with ground motion records and five easy-getting building parameters as inputs. The outputs are IDR and PFA of each floor for the given building. Considering the physical means of an input parameter-number of stories, the modified loss function and modified evaluation function are proposed. The developed network is trained with the computed dataset and the modified loss function, and the trained model (referred to StruNet) can take the characteristics of ground motions and structures into consideration together comparing to previous studies. The proposed model is verified through four cases (i.e., 4 actual buildings with different construction time, occupancy types, and plane layouts), which are independent of the deep learning dataset. The results confirm that the proposed method offers prediction results with sufficient accuracy and shows high computational efficiency.",2022
Stock Ranking Prediction Based on an Adversarial Game Neural Network,"With the globalization of the economy and financial markets today, predicting stock rankings and constructing appropriate portfolio strategies have become hot research topics for many scholars. However, because the stock market has different styles in different periods, market-style switching will seriously affect the prediction performance of the model. To eliminate the influence of style exposure and make the stock selection performance of the deep learning model more balanced, we propose an adversarial game neural network model based on LSTM and an attention mechanism for stock ranking prediction. We also combined trading tasks to construct an MS-WRSE loss function that considers stock rankings to optimize the network. Compared with classic time series prediction models, the adversarial game neural network can eliminate the influence of market-style factors on stock ranking predictions through the mutual game between the main neural network and the auxiliary neural network. This can strengthen the stock selection performance of the model.",2022
Two robust long short-term memory frameworks for trading stocks,"This paper aims to find a superior strategy for the daily trading on a portfolio of stocks for which traditional trading strategies perform poorly due to the low frequency of new information. The experimental work is divided into a set of traditional trading strategies and a set of long short-term memory networks. The networks incorporate general and specific trading patterns, where the former takes into account the universal decision factors for trading across many stocks, while the latter takes into account stock-specific decision factors. Our research shows that both long short-term memory networks, regardless of whether they are based on universal or stock-specific decision factors, significantly outperform traditional trading strategies. Interestingly, however, on average neither has the edge compared to the other, thus remaining ambivalent as to whether universality or specificality is to be preferred when it comes to designing long short-term memory networks for optimal trading.",2021
Control of battery charging based on reinforcement learning and long short-term memory networks,"In an electricity market with time-varying pricing, uncontrolled charging of energy storage systems (ESSs) may increase charging costs. A novel battery charging control methodology based on reinforcement-learning (RL) is proposed in this paper to minimize the charging costs. A significant characteristic of this method is that it is model-free, with no need for a high-accuracy battery/ESS model. Therefore, it overcomes the challenges brought by limited types of battery models and non-ignorable parametric uncertainties in reality. Additionally, since an accurate prediction of fluctuating electricity prices can promote the control performance, a long short-term memory (LSTM) network is leveraged to improve the prediction precision. The final control objective is to seek an optimal charging portfolio to minimize charging costs. Moreover, the presented control algorithm provides a basic framework for a more complicated electricity market where various types of ESSs, generators, and loads exist. (C) 2020 Elsevier Ltd. All rights reserved.",2020
Intelligent portfolio asset prediction enabled by hybrid Jaya-based spotted hyena optimization algorithm,"Purpose The purpose of this study is to provide a novel portfolio asset prediction by means of the modified deep learning and hybrid meta-heuristic concept. In the past few years, portfolio optimization has appeared as a demanding and fascinating multi-objective problem, in the area of computational finance. Yet, it is accepting the growing attention of fund management companies, researchers and individual investors. The primary issues in portfolio selection are the choice of a subset of assets and its related optimal weights of every chosen asset. The composition of every asset is chosen in a manner such that the total profit or return of the portfolio is improved thereby reducing the risk at the same time. Design/methodology/approach This paper provides a novel portfolio asset prediction using the modified deep learning concept. For implementing this framework, a set of data involving the portfolio details of different companies for certain duration is selected. The proposed model involves two main phases. One is to predict the future state or profit of every company, and the other is to select the company which is giving maximum profit in the future. In the first phase, a deep learning model called recurrent neural network (RNN) is used for predicting the future condition of the entire companies taken in the data set and thus creates the data library. Once the forecasting of the data is done, the selection of companies for the portfolio is done using a hybrid optimization algorithm by integrating Jaya algorithm (JA) and spotted hyena optimization (SHO) termed as Jaya-based spotted hyena optimization (J-SHO). This optimization model tries to get the optimal solution including which company has to be selected, and optimized RNN helps to predict the future return while using those companies. The main objective model of the J-SHO-based RNN is to maximize the prediction accuracy and J-SHO-based portfolio asset selection is to maximize the profit. Extensive experiments on the benchmark datasets from real-world stock markets with diverse assets in various time periods shows that the developed model outperforms other state-of-the-art strategies proving its efficiency in portfolio optimization. Findings From the analysis, the profit analysis of proposed J-SHO for predicting after 7 days in next month was 46.15% better than particle swarm optimization (PSO), 18.75% better than grey wolf optimization (GWO), 35.71% better than whale optimization algorithm (WOA), 5.56% superior to JA and 35.71% superior to SHO. Therefore, it can be certified that the proposed J-SHO was effective in providing intelligent portfolio asset selection and prediction when compared with the conventional methods. Originality/value This paper presents a technique for providing a novel portfolio asset prediction using J-SHO algorithm. This is the first work uses J-SHO-based optimization for providing a novel portfolio asset prediction using the modified deep learning concept.",2021
LSTM-based Deep Learning Model for Stock Prediction and Predictive Optimization Model,"A new method of predicting time-series-based stock prices and a new model of an investment portfolio based on predictions obtained is proposed here. For this purpose, a new regression scheme is implemented on a long-short-term-memory-based deep neural network. The predictions once obtained are used to construct an investment portfolio or more specifically a predicted portfolio. A large set of experiments have been carried on stock data of NIFTY-50 obtained from the National stock exchange of India. The results confirm that the proposed model outperforms various standard predictive models as well as various standard portfolio optimization models.",2021
Enhancing a Pairs Trading strategy with the application of Machine Learning,"Pairs Trading is one of the most valuable market-neutral strategies used by hedge funds. It is particularly interesting because it overcomes the arduous process of valuing securities by focusing on relative pricing. By buying a relatively undervalued security and selling a relatively overvalued one, a profit can be made upon the pair's price convergence. However, with the growing availability of data, it became increasingly harder to find rewarding pairs. In this work, we address two problems: (i) how to find profitable pairs while constraining the search space and (ii) how to avoid long decline periods due to prolonged divergent pairs. To manage these difficulties, the application of promising Machine Learning techniques is investi-gated in detail. We propose the integration of an Unsupervised Learning algorithm, OPTICS, to handle problem (i). The results obtained demonstrate the suggested technique can outperform the common pairs' search methods, achieving an average portfolio Sharpe ratio of 3.79, in comparison to 3.58 and 2.59 obtained by standard approaches. For problem (ii), we introduce a forecasting-based trading model, capable of reducing the periods of portfolio decline by 75%. Yet, this comes at the expense of decreasing overall profitability. The proposed strategy is tested using an ARMA model, an LSTM and an LSTM Encoder-Decoder. This work's results are simulated during varying periods between January 2009 and December 2018, using 5-min price data from a group of 208 commodity-linked ETFs, and accounting for transaction costs. (c) 2020 Elsevier Ltd. All rights reserved.",2020
A hybrid neurogenetic approach for stock forecasting,"In this paper, we propose a hybrid neurogenetic system for stock trading. A recurrent neural network (NN) having one hidden layer is used for the prediction model. The input features are generated from a number of technical indicators being used by financial experts. The genetic algorithm (GA) optimizes the NN's weights under a 2-D encoding and crossover. We devised a context-based ensemble method of NNs which dynamically changes on the basis of the test day's context. To reduce the time in processing mass data, we parallelized the GA on a Linux cluster system using message passing interface. We tested the proposed method with 36 companies in NYSE and NASDAQ for 13 years from 1992 to 2004. The neurogenetic hybrid showed notable improvement on the average over the buy-and-hold strategy and the context-based ensemble further improved the results. We also observed that some companies were more predictable than others, which implies that the proposed neurogenetic hybrid can be used for financial portfolio construction.",2007
Fractal-Based Robotic Trading Strategies Using Detrended Fluctuation Analysis and Fractional Derivatives: A Case Study in the Energy Market,"This paper presents an integrated robotic trading strategy developed for the day-ahead energy market that includes different methods for time series analysis and forecasting, such as Detrended Fluctuation Analysis (DFA), Rescaled Range Analysis (R/S analysis), fractional derivatives, Long Short-Term Memory (LSTM) Networks, and Seasonal Autoregressive Integrated Moving Average (SARIMA) models. DFA and R/S analysis may capture the long-range dependencies and fractal features inherited by the nature of the electricity price time series and give information about persistence and variability in their behavior. Given this, fractional derivatives can be used to analyze price movements concerning the minor changes in price and time acceleration for that change, which makes the proposed framework more flexible for quickly changing market conditions. LSTM, from their perspective, may capture complex and non-linear dependencies, while SARIMA models may help handle seasonal trends. This integrated approach improves market signal interpretation and optimizes the market risk through adjustable stop-loss and take-profit levels which could lead to better portfolio performance. The proposed integrated strategy is based on actual data from the Bulgarian electricity market for the years 2017-2024. Findings from this research show how the combination of fractals with statistical and machine learning models can improve complex trading strategies implementation for the energy markets.",2025
Do the US president's tweets better predict oil prices? An empirical examination using long short-term memory networks,"The price of oil is highly complex to predict as it is impacted by global demand and supply, geopolitical events, and market sentiment. The accuracy of such predictions, however, has far-reaching implications for supply chain performance, portfolio management, and expected stock market returns. This paper contributes to the oil price prediction literature by evaluating the predictive impact of the US President's communication on Twitter, while benchmarking various Natural Language Processing (NLP) techniques, including Term Frequency-Inverse Document Frequency (TF-IDF), Word2Vec, Doc2Vec, Global Vectors for Word Representation (GloVe), and Bidirectional Encoder Representations from Transformers (BERT). These techniques are combined with a deep neural network Long Short-Term Memory (LSTM) architecture using a five-day lag for both the oil price and the textual Twitter data. The data was collected during the term of US President Donald Trump, resulting in 1449 days of crude oil price prediction and a total of 16,457 tweets. The study is validated for Brent and West Texas Intermediate blends, using the daily price of a barrel of crude oil as the target variable. The results confirm that including the US President's tweets significantly increases the predictive power of oil price prediction models, and that an LSTM architecture with BERT as NLP technique has the best performance.",2024
Deep-Learning-Based Detection of Segregations for Ultrasonic Testing,"Ultrasonic testing (UT) has been used in the industry for many years to successfully detect internal defects in bulk material. This study focuses on the inspection of materials made out of the superalloy IN718 which is often used for manufacturing turbine components. A recent accident in 2016 with a turbine engine failure led to the incorporation of a new type of defect into the portfolio of defect types that UT might be able to detect. This defect called discrete Clean White Spot Segregation poses new challenges to the conventional UT due to its very different material characteristic in comparison to traditional defects such as cracks or voids. Its reliable detection in an industrial setup remains unsolved and requires new nondestructive techniques. To our best knowledge, our work is the first study that uses deep learning techniques in combination with conventional UT for the detection of this kind of defect. For the new approach presented in this article, artificial defects with similar material characteristics as real ones are defined and successfully manufactured. Then a Recurrent Convolutional Neural Network with Attention and Spectral representations (RCAS) is trained and compared with a convolutional neural network and the conventional UT. In the executed experiments, RCAS proves its superior capability of detection with an AUC(ROC)=0.93 in comparison to conventional UT with an AUC(ROC)=0.16 over the course of six measurements with three different types of ultrasonic probes.",2022
Robust mean-risk portfolio optimization using machine learning-based trade-off parameter,"Conservatism is the notorious problem of the worst-case robust portfolio optimization, and this issue has raised broad discussion in academia. To this end, we propose the hybrid robust portfolio models under ellipsoidal uncertainty sets in this paper, where both the best-case and the worst-case counterparts are involved. In the suggested models, we introduce a trade-off parameter to adjust the portfolio optimism level. Machine learning algorithms including Long Short-Term Memory (LSTM) and eXtreme Gradient Boosting (XGBoost) are used to evaluate the potential market movements and provide forecasting information to generate the hyperparameter for modeling. Additionally, we develop a clustering-based algorithm for properly constructing joint ellipsoidal uncertainty sets to reduce conservatism further. In the modeling phase, we design the hybrid portfolios based on variance (HRMV) and value at risk (VaR) and prove the equivalent relationship between the hybrid robust mean-VaR model (HRMVaR) and the hybrid robust mean-CVaR (conditional value at risk) according to the existing research. The US 12 industry portfolio data set retrieved from Kenneth R. French is employed for the in-sample and out-of-sample numerical experiments. The experimental results demonstrate the effectiveness and robustness of the proposed portfolios, where HRMV models have better Sharpe ratios and Calmar ratios than the corresponding nominal mean-variance model, and HRMVaR models outperform the baseline VaR-based portfolios in terms of returns. Sensitivity analysis supports the superiority of the joint ellipsoidal uncertainty set U-delta(2) where the proposed portfolios constrained with U-delta(2) show stable risk characteristics. (C) 2021 Elsevier B.V. All rights reserved.",2021
Which uncertainty measure better predicts gold prices? New evidence from a CNN-LSTM approach,"Quantifying the influence of uncertainty on gold prices is significant for improving related financial decision making. This study proposes a novel CNN-LSTM neural network that can extract potential features from sample data to effectively predict gold prices. Specifically, we demonstrate various uncertainty measures containing market volatility information, such as the economic policy uncertainty index (EPU), epidemic stock market volatility index (IDEMV), and volatility index (VIX), which can contribute to the prediction of gold prices rather than relying solely on the history of tickers, which is conventionally used for prediction. In addition, the proposed model is evaluated against SVR and two different LSTM models. The empirical findings reveal that incorporating additional features, such as uncertainty measures, contributes to improving the predictive accuracy of the model. The CNN-LSTM model, with the inclusion of EPU, IDEMV, and both, achieves a high prediction accuracy. Additionally, the overall prediction accuracy of the CNN-LSTM model outperforms the other proposed methods. The findings provide profound insight into portfolio diversification and risk management practices for governments and businesses.",2025
Credit card fraud detection using a deep learning multistage model,"The banking sector is on the eve of a serious transformation and the thrust behind it is artificial intelligence (AI). Novel AI applications have been already proposed to deal with challenges in the areas of credit scoring, risk assessment, client experience and portfolio management. One of the most critical challenges in the aforementioned sector is fraud detection upon streams of transactions. Recently, deep learning models have been introduced to deal with the specific problem in terms of detecting and forecasting possible fraudulent events. The aim is to estimate the unknown distribution of normal/fraudulent transactions and then to identify deviations that may indicate a potential fraud. In this paper, we elaborate on a novel multistage deep learning model that targets to efficiently manage the incoming streams of transactions and detect the fraudulent ones. We propose the use of two autoencoders to perform feature selection and learn the latent data space representation based on a nonlinear optimization model. On the delivered significant features, we subsequently apply a deep convolutional neural network to detect frauds, thus combining two different processing blocks. The adopted combination has the goal of detecting frauds over the exposed latent data representation and not over the initial data.",2022
Forecasting the volatility of stock price index: A hybrid model integrating LSTM with multiple GARCH-type models,"Volatility plays crucial roles in financial markets, such as in derivative pricing, portfolio risk management, and hedging strategies. Therefore, accurate prediction of volatility is critical. We propose a new hybrid long short-term memory (LSTM) model to forecast stock price volatility that combines the LSTM model with various generalized autoregressive conditional heteroscedasticity (GARCH)-type models. We use KOSPI 200 index data to discover proposed hybrid models that combine an LSTM with one to three GARCH-type models. In addition, we compare their performance with existing methodologies by analyzing single models, such as the GARCH, exponential GARCH, exponentially weighted moving average, a deep feedforward neural network (DFN), and the LSTM, as well as the hybrid DFN models combining a DFN with one GARCH-type model. Their performance is compared with that of the proposed hybrid LSTM models. We discover that GEW-LSTM, a proposed hybrid model combining the LSTM model with three GARCH-type models, has the lowest prediction errors in terms of mean absolute error (MAE), mean squared error (MSE), heteroscedasticity adjusted MAE (HMAE), and heteroscedasticity adjusted MSE (HMSE). The MAE of GEW-ISTM is 0.0107, which is 37.2% less than that of the E-DFN (0.017), the model combining EGARCH and DFN and the best model among those existing. In addition, the GEW-LSTM has 57.3%, 24.7%, and 48% smaller MSE, HMAE, and HMSE, respectively. The first contribution of this study is its hybrid LSTM model that combines excellent sequential pattern learning with improved prediction performance In stock market volatility. Second, our proposed model markedly enhances prediction performance of the existing literature by combining a neural network model with multiple econometric models rather than only a single econometric model. Finally, the proposed methodology can be extended to various fields as an integrated model combining time-series and neural network models as well as forecasting stock market volatility. (C) 2018 Elsevier Ltd. All rights reserved.",2018
An analysis of the applications of neural networks in finance,"Over the last 10 years, neural networks have been increasingly applied to various areas of finance. Neural networks are more often applied on the assets side than on the liabilities side of the balance sheet. Some major characteristics of the areas of these applications are their data intensity, unstructured nature, high degree of uncertainty, and hidden relationships. Most of the applications use the backpropagation model with one hidden layer. In most of these applications, neural networks outperformed traditional statistical models, such as discriminant and regression analysis. Furthermore, these applications have shown significant success in financial practice, for example, in forecasting T-bills, in asset management, in portfolio selection, and in fraud detection.",2001
A R-GCN-Based Correlation Characteristics Extraction Method for Power Grid Infrastructure Planning and Analysis,"For a large number of grid infrastructure projects, various interrelationships may have an impact on portfolio optimization to a certain extent. At present, there are few qualitative analyses considering linkages among massive power grid infrastructure projects. In order to overcome the limitations of the existing studies, this paper proposes a method for extracting the correlation characteristics of massive power grid infrastructure projects based on relational graph convolutional neural network (R-GCN). The correlation characteristics of power grid infrastructure projects with different voltage levels, engineering attributes and project properties are comprehensively considered. R-GCN generalizes the traditional graph convolutional neural network and can process multi-relational data, building an encoder and identifying multiple relations between entities in the project library by accessing different layers to solve corresponding modeling problems, so as to accurately identify the linkages among a large number of power grid infrastructure projects, and further improve the rationality of portfolio optimization.",2022
"A hybrid framework based on extreme learning machine, discrete wavelet transform, and autoencoder with feature penalty for stock prediction","Accurate prediction of the stock market trend can assist efficient portfolio and risk management. In recent years, with the rapid development of deep learning, it can make the classifiers more robust, which can be used for solving nonlinear problems. In our previous research, we proposed a numerical model for predicting the stock market via combination of discrete wavelet transform (DWT) denoising and extreme learning machine (ELM), and promising outcomes are achieved. The current research presents a hybrid framework using DWT, ELM, and autoencoder (AE) with feature penalty. Firstly, the backpropagation of the AE with feature penalty was deduced theoretically. Then, the raw data were denoised by DWT. The denoised data were used to train the AE with feature penalty after feature preprocessing and utilization of the labeling method. Afterward, the encoder part of the well-trained AE was utilized as the feature extraction model to train ELM model, and the hybrid framework named DAELM (DWT-AE-ELM) could be successfully developed. We also carried out experiments on the cor-responding dataset of 400 stocks, and the prediction accuracy of the current study was higher than that of our previous research. According to the predicted labels, we presented an investment strategy, and the yield-to -maturity of 400 stocks was significantly higher than that of the buy-and-hold (BAH) strategy. The results confirmed the superiority of the proposed hybrid framework.",2022
Recurrent Neural Network GO-GARCH Model for Portfolio Selection,We develop a hybrid model of multivariate volatility that uses recurrent neural networks to capture the conditional variances of latent orthogonal factors in a GO-GARCH framework. Our approach seeks to balance model flexibility with ease of estimation and can be used to model conditional covariances of a large number of assets. The model performs favourably in comparison with relevant benchmark models in a minimum variance portfolio (MVP) scenario.,2024
Patent Quality Valuation with Deep Learning Models,"Patenting is of significant importance to protect intellectual properties for individuals, organizations and companies. One of practical demands is to automatically evaluate the quality of new patents, i.e., patent valuation, which can be used for patent indemnification and patent portfolio. However, to solve this problem, most traditional methods just conducted simple statistical analyses based on patent citation networks, while ignoring much crucial information, such as patent text materials and many other useful attributes. To that end, in this paper, we propose a Deep Learning based Patent Quality Valuation (DLPQV) model which can integrate the above information to evaluate the quality of patents. It consists of two parts: Attribute Network Embedding (ANE) and Attention-based Convolutional Neural Network (ACNN). ANE learns the patent embedding from citation networks and attributes, and ACNN extracts the semantic representation from patent text materials. Then their outputs are concatenated to predict the quality of new patents. The experimental results on a real-world patent dataset show our method outperforms baselines significantly with respect to patent valuation.",2018
Fundamental Multi-factor Deep-learning Strategy For Cryptocurrency Trading,"This paper investigates how to use deep learning methods to combine with traditional multi-factor models and construct a quantitative trading model based on an AutoEncoder algorithm (AE) to classify cryptocurrencies since 2009, so as to screen out ones with investment value and then construct an effective investment portfolio. The AE algorithm is capable of handling high-dimensional data and mining interfactor non-linearities. Our empirical results on cryptocurrencies show that the model outperforms single-type factors and benchmark in terms of Cumulative Returns and the Sharpe Ratio.",2022
"Deep Learning Based Hurricane Resilient Coplanning of Transmission Lines, Battery Energy Storages, and Wind Farms","In this article, a multistage model for expansion coplanning of transmission lines, battery energy storages, and wind farms (WFs) is presented considering resilience against extreme weather events. In addition to high-voltage alternating current lines, multiterminal voltage source converter based high-voltage direct current lines are planned to reduce the impact of high-risk events. To evaluate the system resilience against hurricanes, probable hurricane speed scenarios are generated using Monte Carlo simulation. The fragility curve concept is utilized for calculating the failure probability of lines due to extreme hurricanes. Based on each hurricane damage, the probable scenarios are incorporated in the proposed model. Renewable portfolio standard policy is modeled to integrate high penetration of WFs. To deal with the wind power and load demand uncertainties, a chronological time-period clustering algorithm is introduced for extracting representative hours in each planning stage. A deep learning approach based on bidirectional long short-term memory networks is presented to forecast the yearly peak loads. The mixed-integer linear programming formulation of the proposed model is solved using a Benders decomposition algorithm. A modified IEEE RTS test system is used to evaluate the proposed model effectiveness.",2022
Flexibility-based generation maintenance scheduling in presence of uncertain wind power plants forecasted by deep learning considering demand response programs portfolio,"The special characteristics of renewable energy resources, such as non-emission and low operating costs, have increased the penetration rate of renewable energy resources in the power system. However, the variability nature of renewable energy resources has led to some challenges in power system studies. Therefore, system flexibility has been taken into account, which plays a key role in dealing with renewable energy resources uncertainty. On the other hand, generation maintenance scheduling is one of the most important and effective programs for short-term studies of the power system. It seems necessary to implement a flexibility-based generation maintenance scheduling in order to achieve more flexible operation as a consequence of providing flexible resources. Here, a novel framework for flexibility-based multi-objective generation maintenance scheduling associated with a portfolio of demand response programs is introduced. Hence, a system flexibility index has been applied in this paper. Moreover, a portfolio of multifarious demand response programs as a negawatt resource has been applied as a provider of flexibility from demand-side point of view. In this paper, direct load control, real-time pricing, and emergency demand response programs are implemented as flexibility providers through comprehensive modelling of DRPs. Herein, proper modeling and forecasting of renewable energy resources production will increase the scheduling accuracy. Hence, the uncertainty of wind power plants is considered by deep learning methodology in Python. Reducing costs such as operation and maintenance costs, leveling the reserve margin and increasing flexibility index are regarded as multifarious objectives of flexibilitybased generation maintenance scheduling. Due to the good handling of large-scale, non-convex and nonproportional objective functions, the augmented epsilon constraint method is utilized to evaluate flexibilitybased multi-objective generation maintenance scheduling. According to the results, the system flexibility has been improved without increasing costs. Several analyses are carried out on a modified IEEE-RTS 24 bus to trace the capability of the proposed structure.",2022
Predictive Modeling for Identifying Undervalued Stocks Using Machine Learning,"This study investigates the application of Machine Learning (ML) techniques to identify undervalued stocks, addressing the limitations of traditional investment strategies that rely heavily on fundamental analysis. As financial markets become more complex, characterized by volatility and information asymmetry, conventional valuation methods often struggle to capture these dynamics. In contrast, ML offers the ability to analyze large datasets and uncover intricate patterns, presenting a data-driven alternative for stock selection and portfolio optimization. A comprehensive predictive framework was developed, integrating traditional financial ratios with novel features derived from value investing principles and technical analysis. Several ML models - Random Forest, Long Short-Term Memory (LSTM), and Support Vector Machines - were assessed for their ability to predict high-return stocks. Performance metrics, including accuracy, precision, and recall, were used to evaluate model effectiveness. Among the models tested, the LSTM demonstrated the highest accuracy at 0.81, proving its robustness in identifying undervalued stocks. This research contributes to the growing body of literature on ML in finance by offering a practical framework that bridges theoretical concepts with real-world applications. The study also emphasizes the importance of refining ML algorithms to improve model interpretability and transparency, crucial for fostering trust in these systems. Future research should explore the use of ensemble methods and alternative data sources to further enhance prediction accuracy, while addressing challenges related to accountability in ML-driven investment strategies. This work advances the conversation around algorithmic trading and the future of data-driven finance.",2025
Optimisation and economic feasibility of Battery Energy Storage Systems in electricity markets: The Iberian market case study,"This study identifies the optimal operating strategy of storage systems in the electricity markets, from the perspective of a market participant with a renewables' portfolio. The energy storage system provides a balancing service for renewable sources, while also performing energy arbitrage at the considered three short-term markets. A Long Short-Term Memory (LSTM) model is developed to forecast spot price and renewable generation which are used to guide the bidding decision-making process to maximise the agents' economic profit. Additionally, the designed decision support models consider market rules and the technical constraints in the operation of the storage system. The influence of storage systems in the optimal operation, regulation costs and revenues are analysed on a daily and yearly basis. The Iberian electricity market has been utilised as a case study. It was shown that the use of forecasting techniques and battery implementation reduce daily and yearly regulation costs up to 100% and 53%, respectively and that acting in the balancing market increases the expected profit of the storage system between 21% and 36%. Additionally, the economic viability evaluation in 2018 and 2025, for several battery types, shows that only the lithium-ion battery is a profitable investment.",2021
MOBILE U-NET V3 AND BILSTM: PREDICTING STOCK MARKET PRICES BASED ON DEEP LEARNING APPROACHES,"Stock-market prediction is the task of forecasting future movements or trends in stock prices or overall market behavior. Investors can able to locate companies that offer the highest dividend yields and lower their investment risks by using a trading strategy. It's important to note that predicting stock markets accurately is extremely challenging and no approach can guarantee consistent success. Markets are influenced by a multitude of factors and there is inherent uncertainty involved. For instance, predicting stock-market prices is commonly used in financial disciplines, such as trade-execution strategies, portfolio optimization and stock-market forecasting. Therefore, it's crucial to approach stock-market prediction cautionsly and use it as a tool for informed decision making rather than relying solely on predictions. To overcome the challenges, we proposed a new hybrid deep learning technique to forecast future stock prices. Deep learning has recently enjoyed considerable success in some domains due to its exceptional capacity for handling data. In this research, we propose a hybrid technique of Mobile U-Net V3 and BiLSTM (Bi-Long Short-Term Memory) to predict stock prices. Initially, we utilize the min-max normalization method to normalize the input data in the preprocessing stage. After normalizing the data, we utilize hybrid deep learning techniques of Mobile U-Net V3 and BiLSTM to predict the closing price from stock data. To experiment, we collect data from Apple, Inc. and S&P 500 stock. The evaluation metrics Pearson's Correlation (R), Mean Squared Error (MSE), Root Mean Squared Error (RMSE) and Normalization Root Mean Squared Error (NRMSE) were utilized to calculate the outcomes of the DL stock-prediction methods. The Mobile U-Net V3-BiLSTM model outperformed other techniques in forecasting stock-market prices.",2023
Big Data Analysis and Prediction System Based on Improved Convolutional Neural Network,"This paper presents a big data analysis and prediction system based on convolutional neural networks. Continuous template matching technology is used to analyze the distributed data structure of big data, and the information fusion processing of cloud service combination big data is combined with matching related detection methods, frequent item detection, and association rule feature extraction of high-dimensional fusion data. A clustering method is adopted to realize the classification and mining of cloud service portfolio big data. The hardware equipment of the car to detect the surrounding environment is complicated, and the combination of the convolutional neural network and the camera to detect the surrounding environment has become a research hotspot. However, simply using the convolutional neural network to process the camera data to control the turning angle of the car has the problems of long training time and low accuracy. An improved convolutional neural network is proposed. The experimental results show that the accuracy of data mining by this method is 12.43% and 21.76% higher than that of traditional methods, and the number of iteration steps is shorter, indicating that the timeliness of mining is higher. This network structure can effectively improve the training speed of the network and improve the accuracy of the network. It is proven that the convolutional neural network has faster training speed and higher accuracy.",2022
Attention based dynamic graph neural network for asset pricing,"Recent studies suggest that networks among firms (sectors) play a vital role in asset pricing. This paper investigates these implications and develops a novel end-to-end graph neural network model for asset pricing by combining and modifying two state-of-the-art machine learning techniques. First, we apply the graph attention mechanism to learn dynamic network structures of the equity market over time and then use a recurrent convolutional neural network to diffuse and propagate firms' information into the learned networks. This novel approach allows us to model the implications of networks along with the characteristics of the dynamic comovement of asset prices. The results demonstrate the effectiveness of our proposed model in both predicting returns and improving portfolio performance. Our approach demonstrates persistent performance in different sensitivity tests and simulated data. We also show that the dynamic network learned from our proposed model captures major market events over time. Our model is highly effective in recognizing the network structure in the market and predicting equity returns and provides valuable market information to regulators and investors.",2023
Machine Learning for Real Estate Time Series Prediction,"Several researchers have demonstrated that real estate investments have improved the risk-adjusted performance of mixed-asset portfolios belonging to institutional investors. In order for these portfolio strategies to be more effective, one could use price predictions (instead of historical data) to optimize weights. The goal of this paper is to investigate the predictive performance on price time series of REITs (real estate investment trusts), stocks and bonds, of five different machine learning (ML) algorithms. These algorithms are: linear regression; support vector regression; gradient boosting; long short-term memory neural networks; and k-nearest neighbour. We run experiments on 90 datasets and compare the ML results to those of an ARIMA model, which is a popular econometric benchmark used in financial time series predictions. Our results show that machine learning algorithms statistically outperform ARIMA. In addition, we find that all machine learning algorithms are able to produce very low root mean square errors, with linear regression and long short-term memory obtaining the lowest error values.",2024
Augmenting Deep Learned Representation Based Portfolio Selection With Predictive Shallow Networks,"We propose a novel stock portfolio selection strategy based on learned deep representations and shallow neural networks. The performance of many portfolio selection strategies is affected by stock similarity. Many existing methods to measure stock similarity need (a) a long period of data which may not represent current market dynamics, (b) are linear in nature and cannot capture nonlinear relationships between stocks effectively. To solve these problems we transform multi-dimensional time series data into a learned vector space and apply clustering algorithms on these vectors to group similar stocks. We use a deep LSTM Autoencoder to learn the vector representations of the time series. We introduce a novel addition to the stock selection strategy by adding a shallow neural network to predict future price behaviour of a stock which takes the learned representation as input, further leveraging the power of the abstractions learned by the Autoencoder. Results show that the models are able to generate greater than market returns and that the models augmented by the shallow network are able to match the un-augmented models while executing fewer trades, thereby being less risky.",2019
Sequential Machine Learning for Activity Sequence Prediction from Daily Work Report Data,"It is critical for project owners to have a reasonable estimation of project duration before the letting date for contract time determination and project management purposes. To determine the project duration, highway agencies employ scheduling techniques and arrange activities in sequential order. Activity sequencing is a crucial task since a slight change in the sequence of critical activities can significantly influence project duration. Also, the task of activity arrangement is time-consuming for a broad portfolio of projects and requires skillful schedulers. To aid activity sequence determination, prior studies used project drawings, expert knowledge, and historical data to identify sequence rules, logic templates, and sequence prediction models. However, weaknesses and areas of improvement exist, including a lack of adequately leveraging available historical data, the necessity of human input, reliance on human experience rather than data, and poor detection of the overlapping time of activities. This study proposes a novel framework that predicts the sequences of work activities using historical daily work reports to train a long short-term memory recurrent neural network to predict the activity sequence and overlapping in future projects. The daily work reports of 720 highway projects obtained from a highway agency are used as the case study. A novel evaluation technique based on conditional probability is used to assess the model and compare its output sequence to sequences created randomly. The assessment results indicate that the model's output is superior in 94.4% of situations, suggesting a high level of model reliability. The impact of key project characteristics such as project work type and size on activity prediction is examined, indicating a significant impact of project work type and no impact of project size on activity prediction. The results of this study can assist highway project owners in activity sequence and overlap determination by entering a series of activities and receiving the likely next successors.",2023
IntPort: An Intelligent Portfolio Construction Technique Based on Financial Forecasting by Statistical Average Method,"Investors are inclined to predict stock values, and conventional studies indicate that using machine learning (ML) for stock price prediction is the most effective method. This study focuses on ML-based stock price forecasting that aims to assist people with limited investment capabilities by providing a high-quality approach to price prediction. The research utilizes various characteristics of the current stock price, such as 'Open,' 'Low,' 'High, 'Adj Close', and 'Close'. In addition, it incorporates principal component analysis (PCA), linear discriminant analysis (LDA), and a statistical average method (SAM) to create additional features. These features and current stock price attributes are combined to form a feature vector for ML methods. The study also emphasizes building a portfolio that reduces investment risk while capitalizing on the expected upward movement of stock prices. Experimental results indicate that incorporating the SAM-price feature associated with the ML technique, bidirectional long short-term memory (Bi-LSTM), leads to superior forecasting accuracy compared to existing approaches. It is evident from previous literary works that various supervised learning methods have successfully predicted stock prices. Our research is dedicated to producing a novel approach to generate better price accuracy by forecasting and an effective portfolio that can be beneficial to the general public. The investigation reveals an accuracy rate of 98.14% when applied with the SAM-price feature defined by the additional feature dataset (AFD), surpassing the accuracy achieved by traditional pricing features alone. Additionally, as a novel price feature, AFD generates no over-fitting. Furthermore, the portfolio generated using the SAM-price function demonstrates a return on investment of 145.475% and a Sharpe ratio value of 77.62, indicating a favorable risk-return trade-off.",2025
A time-varying stock portfolio selection model based on optimized PSO-BiLSTM and multi-objective mathematical programming under budget constraints,"Choosing the optimal portfolio is an ongoing challenging research area and a complex process involving selecting the best investment plan according to various factors, such as investor preferences for expected return, risk, and duration of investments. Although various methods have been presented so far, they failed to obtain a holistic approach to the existing data, and the need for a comprehensive mechanism based on the investor's time preferences is felt. In this paper, by considering the fundamental characteristics, technical indicators, time-series data, and budget constraints, we developed a comprehensive and time-varying methodology to forecast stock prices and form an optimal portfolio. The proposed method consists of recurrent neural networks and multi-objective mathematical programming (MOMP). In this regard, the bidirectional long short-term memory model is adopted and optimized by the particle swarm optimization (PSO) algorithm, called PSO-BiLSTM. Furthermore, the hybrid MOMP models are developed based on long-, mid-, and short-term strategies to provide the optimal portfolio of the stocks with investment constraints. The main objectives of this research were to address the following issues: (1) developing a precise and efficient model to forecast the stocks prices, taking account of fundamental characteristics, technical indicators, time-series data appropriate to the period considered by the investor, (2) providing an optimized time-varying portfolio through developing the hybrid MOMP models, and generally (3) proposing a holistic step-by-step methodology considering three groups of market data and deep learning to apply investment constraints as well as investor's time preferences in the process of building more realistic portfolios. The results highlight that the tuned PSO-BiLSTM method performs better than the conventional methods in all three constructed models using fundamental characteristics, technical indicators, and time-series data. Compared to the conventional methods, the proposed methodology outperforms in generalization power, is more precise in forecasting prices, and provides portfolios with more profit.",2023
Financial Times Series Forecasting of Clustered Stocks,"Predicting the stock market is a widely studied field, either due to the curiosity in finding an explanation for the behavior of financial assets or for financial purposes. Among these studies the best techniques use neural networks as a prediction technique. More specifically, the best networks for this purpose are called recurrent neural networks (RNN) and provide an extra option when dealing with a sequence of values. However, a great part of the studies is intended to predict the result of few stocks, therefore, this work aims to predict the behavior of a large number of stocks. For this, similar stocks were grouped based on their correlation and later the algorithm K-means was applied so that similar groups were clustered. After this process, the Long Short-Term Memory (LSTM) - a type of RNN - was used in order to predict the price of a certain group of assets. Later, predicted prices are compared to the correct prices in order to analyze prices tendency. Results showed that clustering stocks did not influence the effectiveness of the network, once tendency was predicted correct for an average of 48% of time. Investors and portfolio managers can use proposed techniques to simply their daily tasks.",2021
Surveying the prediction of risks in cryptocurrency investments using recurrent neural networks,"Decentralized cryptocurrencies have received much attention over the last few years. Bitcoin (BTC) has enabled straight online expenditures without the need for centralized financial institutions. Cryptocurrencies are used not only for online payments but are also increasingly used as financial assets. With the rise in the number of cryptocurrencies, including BTC, Ethereum (ETH), and Ripple (XRP), and the millions of daily trades through different exchange services, cryptocurrency trading is prone to challenges similar to those seen in the traditional financial industry, such as price and trend forecasting, volatility forecasting, portfolio building, and fraud detection. This study examines the use of Recurrent neural networks (RNNs) for predicting BTC, ETH, and XRP prices. Accurate price prediction is essential for investors and traders in this volatile market. Machine learning techniques, including RNNs, Long-Short-Term Memory (LSTM), and convolutional neural networks, have been employed to forecast cryptocurrency prices with varying degrees of success. The aim of this study is to evaluate the effectiveness of RNNs in predicting cryptocurrency prices and compare their performance with other established methods. The results indicate that RNNs, particularly LSTMs and Gated Recurrent Units, demonstrate excellent capabilities in accurately predicting currency prices and providing insights to investors and traders in the cryptocurrency market.",2024
Integrating AI and OR for investment decision-making in emerging digital lending businesses: a risk-return multi-objective optimization approach,"This study investigates the application of operational research techniques to optimize investment decisions in peer-to-peer (P2P) lending platforms, focusing on balancing risk and return for investors. The study proposes a multi-objective decision-making model that leverages data from the Lending Club, the largest P2P marketplace in the United States, to minimize risk and maximize returns. To address the data imbalance, the model uses classification techniques including logistic regression, decision trees, random forests, and light gradient boosting machines (LGBM), which are supported by the synthetic minority oversampling technique (SMOTE). While a convolutional neural network (CNN) predicts net present value (NPV), logistic regression is used to assess risk. The nondominated sorting genetic algorithm II (NSGA-II) is then used for portfolio optimization, producing returns of over 7% with risk levels that are comparable with conventional methods. Sensitivity analysis highlights the importance of investment allocation strategies by emphasizing that portfolio returns are more sensitive to changes in investments than risk. This study contributes to the operational research literature on risk management, investment modeling, and practical decision support systems in financial services by integrating advanced AI-based computational methods and optimization tools. HIGHLIGHTSThe multi-objective model seeks to balance risk reduction with return maximization.The LGBM, logistic regression, random forest, and decision tree models are assessed.The NSGA-II algorithm is used to optimize the portfolio model.A sensitivity analysis is used to evaluate the investment amounts.The results provide wisdom on return optimization and risk reduction in P2P lending.",2025
Fuzzy portfolio selection with different risk attitudes based on machine learning,"This paper studies a fuzzy portfolio selection program with different risk attitudes based on Machine Learning to help investors make reasonable investment decisions. Firstly, the asset's return is assumed as a fuzzy variable, which is estimated by the Long-Short Term Memory, Convolutional Neural Networks, Support Vector Regression and Random Forest, respectively. Secondly, the possibilistic mean and possibilistic variance with different risk attitudes are calculated within the framework of possibilistic theory. Thirdly, considering the borrowing constraints, transaction costs, and threshold constraints, a fuzzy portfolio selection model with different risk attitudes based on Machine Learning is proposed. According to the possibilistic measure, the proposed model is transformed into a quadratic programming problem, and the pivoting algorithm is designed to obtain the optimal solution. Finally, the possibility equal-weight portfolio model and possibility mean-variance portfolio model based on history quartile are selected as benchmarks, and a comparing numerical example is provided to demonstrate the effectiveness of the proposed model.",2025
Harnessing Cognitively Inspired Predictive Models to Improve Investment Decision-Making,"In the last years, researchers and practitioners have focused on defining portfolio optimization approaches. This task aims to identify a suitable distribution of assets for maximizing profits and minimizing risks, also offering protection against unexpected market behaviors. Nevertheless, the state-of-the-art approaches encounter significant limitations due to the complex nature of the task: (1) forecasting of non-stationary, non-linearity and volatile stock price; (2) budget allocation over different stocks satisfying multi-objective objective function; (3) risk costs can significantly affect the effectiveness of the designed approaches. In this paper, we propose a cognitively inspired framework for portfolio optimization by integrating deep learning-based stock forecasting for maximizing the revenue and portfolio diversification and Shape Ratio for minimizing the risk. Furthermore, the cognitively inspired forecasting module relies on the LSTM-based approach which combines historical financial data and technical indicators. Hence, this approach addresses the portfolio optimization task with the aim of designing more and more cognitive agents that perform autonomous actions for supporting decision-making. To make these agents cognitive, we further integrate stock forecasting into the portfolio optimization model, also investigating the main factors affecting both stock forecasting and portfolio optimization tasks. The proposed framework has been evaluated in two stages on a real-world dataset, composed of four years of information about stocks from six different areas. Firstly, we compare the proposed forecasting models based on LSTM and GRU, pointing out that the former achieves higher effectiveness results although the latter has a shorter training time. Finally, the proposed framework has been compared with different baselines, obtaining a net difference of $168 at the maximum. Finally, we compare the proposed approach w.r.t. several baselines in terms of total revenue, also providing an ablation analysis to investigate how stock prediction might support investors in dealing with portfolio optimization task.",2024
Deep Learning and Machine Learning Insights Into the Global Economic Drivers of the Bitcoin Price,"This study examines the connection between Bitcoin and global factors, including the VIX, the oil price, the US dollar index, the gold price, and interest rates estimated using the Federal funds rate and treasury securities rate, for forecasting analysis. Deep learning methodologies, including LSTM, GRU, CNN, and TFT, with machine learning algorithms such as XGBoost, LightGBM, and SVR, were employed to identify the optimal prediction model for the Bitcoin price. The findings indicate that the TFT model is the most successful predictive approach, with the gold price identified as the most relevant component in determining the Bitcoin price. After the gold indicator, the US dollar index was a substantial factor in the explanation of the Bitcoin price. The TFT model also included regulatory decisions and global events. It was estimated that the Bitcoin price was significantly influenced by the COVID-19 pandemic. After that, global climate events and China mining ban strongly affected the Bitcoin price. These findings indicate that regulatory decisions and global events determine the Bitcoin price in addition to macroeconomic factors. The VAR analysis was employed as a robustness check. The results indicate that gold and oil prices have a strong negative influence on Bitcoin, particularly in the long term. The paper has significant policy implications for investors, portfolio managers, and scholars.",2025
Reducing infrequent-token perplexity via variational corpora,"Recurrent neural network (RNN) is recognized as a powerful language model (LM). We investigate deeper into its performance portfolio, which performs well on frequent grammatical patterns but much less so on less frequent terms. Such portfolio is expected and desirable in applications like autocomplete, but is less useful in social content analysis where many creative, unexpected usages occur (e.g., URL insertion). We adapt a generic RNN model and show that, with variational training corpora and epoch unfolding, the model improves its performance for the task of URL insertion suggestions.",2015
Index tracking using shapley additive explanations and one-dimensional pointwise convolutional autoencoders,"The aim of index tracking is to mimic the performance of a benchmark index via minimizing the tracking error between the returns of the market index and the tracking portfolio. Lately, various deep learning solutions have been proposed to perform stock prediction or active investment. However, there remains a gap in literature to explore the application of deep learning to index tracking. In this paper, the one-dimensional Pointwise Convolutional Autoencoder is proposed to capture the main market characteristics and the Shapley Additive Explanations feature importance ranking is applied to select stocks to implement the partial replication index tracking with and without Covid-19 data. Moreover, portfolios with different holding periods and with different rebalancing frequency are created on different financial markets to check the effectiveness of the proposed strategy. Compared with different benchmark stock selection strategies, including Pearson correlation, mutual information, and Euclidean distance, the proposed strategy achieves state-of-the-art performance on different financial markets.",2024
WaveCorr: Deep reinforcement learning with permutation invariant convolutional policy networks for portfolio management,"We present a new portfolio policy convolutional neural network architecture, WaveCorr, for deep reinforcement learning applied to portfolio optimization. WaveCorr is the first to treat asset correlation while preserving asset invariance property, a new permutation invariance property that significantly increases the stability of performance in problems where input indexing is done arbitrarily. A general theory is also derived for verifying this property in other fields of application. Our experiments show that WaveCorr consistently outperforms other state-of-the-art convolutional architectures.(c) 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).",2023
Is Image Encoding Beneficial for Deep Learning in Finance?,"In 2012, Securities and Exchange Commission (SEC) mandated all corporate filings for any company doing business in the U.S. be entered into the electronic data gathering, analysis, and retrieval (EDGAR) system. In this work, we are investigating ways to analyze the data available through the EDGAR database. This may serve portfolio managers (pension funds, mutual funds, insurance, and hedge funds) to get automated insights into companies they invest in, to better manage their portfolios. The analysis is based on artificial neural networks applied to the data. In particular, one of the most popular machine learning methods, the convolutional neural network (CNN) architecture, originally developed to interpret and classify images, is now being used to interpret financial data. This work investigates the best way to input data collected from the SEC filings into a CNN architecture. We incorporate accounting principles and mathematical methods into the design of three image encoding methods. Specifically, two methods are derived from accounting principles (sequential arrangement, category chunk arrangement) and one is using a purely mathematical technique [the Hilbert vector arrangement (HVA)]. In this work, we analyze fundamental financial data as well as financial ratio data and study companies from the financial, healthcare, and information technology sectors in the United States. We find that using imaging techniques to input data for CNN works better for financial ratio data but is not significantly better than simply using the 1-D input directly for fundamental data. We do not find the HVA technique to be significantly better than other imaging techniques.",2022
"Forecasting Stock Market Prices Using Machine Learning and Deep Learning Models: A Systematic Review, Performance Analysis and Discussion of Implications","The financial sector has greatly impacted the monetary well-being of consumers, traders, and financial institutions. In the current era, artificial intelligence is redefining the limits of the financial markets based on state-of-the-art machine learning and deep learning algorithms. There is extensive use of these techniques in financial instrument price prediction, market trend analysis, establishing investment opportunities, portfolio optimization, etc. Investors and traders are using machine learning and deep learning models for forecasting financial instrument movements. With the widespread adoption of AI in finance, it is imperative to summarize the recent machine learning and deep learning models, which motivated us to present this comprehensive review of the practical applications of machine learning in the financial industry. This article examines algorithms such as supervised and unsupervised machine learning algorithms, ensemble algorithms, time series analysis algorithms, and deep learning algorithms for stock price prediction and solving classification problems. The contributions of this review article are as follows: (a) it provides a description of machine learning and deep learning models used in the financial sector; (b) it provides a generic framework for stock price prediction and classification; and (c) it implements an ensemble model-Random Forest + XG-Boost + LSTM-for forecasting TAINIWALCHM and AGROPHOS stock prices and performs a comparative analysis with popular machine learning and deep learning models.",2023
Forecasting ESG Stock Indices Using a Machine Learning Approach,"As the demand for investment products tied to environmental, social and governance (ESG) concerns rises, ESG stock indices have been established. These indices aim to aid investors in navigating and assessing the risks associated with firms based on ESG factors and potential investment returns. The objective of the article is to predict ESG stock indices using a machine learning approach. We use daily data of Dow Jones Sustainability Index (DJSI) World, DJSI Asia Pacific and DJSI Emerging Market from 2018 to 2022 as samples. Two-layer ensemble model - combination of support vector machine (SVM), random forest (RF), long short-term memory (LSTM) and gated recurrent unit (GRU) algorithms - is employed to forecast the indices. The results show that the ensemble model accurately forecasts the indices, with the prediction line closely matching the actual values. It gives the implication that investors are able to improve investment decisions, assist in managing investment risk, and optimize their portfolio diversification. Meanwhile, policymakers are able to anticipate economic trends, inflation and interest rates, assisting in the development of successful economic policies.This research article presents a machine learning approach for predicting ESG stock indices. The proposed model combines SVM, RF, LSTM and GRU algorithms to create a powerful two-layer ensemble model that outperforms individual models. The results show that the ensemble model accurately forecasts ESG stock indices, with the prediction line closely matching the actual values. The model offers insights into the behaviour of different algorithms, highlighting their strengths and limitations. The proposed model can guide decision-making processes, support investment strategies, and ultimately contribute to advancing sustainable investment practices.",2024
Mapping stock market dynamics: A tripartite neural network approach using modified grid search for stock market prediction,"The challenge of stock market prediction still persists for investors, researchers, portfolio managers, and a diverse array of stakeholders. This study aims to investigate the effectiveness of artificial neural networks, deep neural networks, and long-term memory models in predicting stock market indices. The study encompasses daily index prices of Nifty 50, S&P 500, and Euronext 100, along with macroeconomic data and technical indicators from January 2015 to September 2023, containing 2201 observations for each market. When evaluated using different metrics, the results indicate better performance of artificial neural network models than deep neural networks and long short-term memory models in most cases. The results from the validation set, test set, and an extra holdout set indicate better performance of artificial neural networks in the context of the Nifty 50 index. In the case of the S&P 500, the deep neural network performed well on validation set results, and artificial neural networks performed better than other models in the test set and holdout set predictions. In the case of Euronext 100, the deep neural network again performed better on the validation set; however, the Long short-term memory model outperformed other models with better predictions on testing and holdout set data. The study also applies a modified grid search approach to find the optimal hyperparameters, where the hyperparameters from the simpler model, i.e., artificial neural network using a conventional grid search approach, were used in more complex models like deep neural network and long short-term memory model.",2025
Asymmetric Graph-Based Deep Reinforcement Learning for Portfolio Optimization,"In recent years, existing studies have sought to enhance the effectiveness of portfolio optimization by modeling asset relations. However, employing conventional graph neural network methodologies for effective aggregation and final representation learning of intricately complex financial information within real-world markets proves challenging. This necessitates the optimization of graph structures to enhance the accuracy of parsing and leveraging financial information. In this paper, we propose an asymmetric graph-based deep reinforcement learning for portfolio optimization. Specifically, leveraging the excellent evaluative capabilities of large language models, we decipher multi-dimensional asymmetric relationships between stocks in multi-dimensional data, constructing asymmetric stock relationship graphs based on news and sectors. We then design a multi-dimensional relationship attention mechanism to jointly represent asymmetric graph information and employ deep reinforcement learning for end-to-end portfolio optimization. Extensive experiments on real datasets from China and the United States have demonstrated the superiority of our method over existing state-of-the-art methods. In the industrial observation conducted at a leading financial technology company, we validated the applicability of our method in real-world market scenarios.",2024
Stock market network based on bi-dimensional histogram and autoencoder,"In this study, we propose a deep learning related framework to analyze S&P500 stocks using bi-dimensional histogram and autoencoder. The bi-dimensional histogram consisting of daily returns of stock price and stock trading volume is plotted for each stock. Autoencoder is applied to the bi-dimensional histogram to reduce data dimension and extract meaningful features of a stock. The histogram distance matrix for stocks are made of the extracted features of stocks, and stock market network is built by applying Planar Maximally Filtered Graph(PMFG) algorithm to the histogram distance matrix. The constructed stock market network represents the latent space of bi-dimensional histogram, and network analysis is performed to investigate the structural properties of the stock market. we discover that the structural properties of stock market network are related to the dispersion of bi-dimensional histogram. Also, we confirm that the autoencoder is effective in extracting the latent feature of the bi-dimensional histogram. Portfolios using the features of bi-dimensional histogram network are constructed and their investment performance is evaluated in comparison with other benchmark portfolios. We observe that the portfolio consisting of stocks corresponding to the peripheral nodes of bi-dimensional histogram network shows better investment performance than other benchmark stock portfolios.",2022
Noxtrader: Lstm-Based Stock Return Momentum Prediction For Quantitative Trading,"We introduce NoxTrader, a sophisticated system designed for portfolio construction and trading execution with the primary objective of achieving profitable outcomes in the stock market, specifically aiming to generate moderate to long-term profits. The underlying learning process of NoxTrader is rooted in the assimilation of valuable insights derived from historical trading data, particularly focusing on time-series analysis due to the nature of the dataset employed. In our approach, we utilize price and volume data of US stock market for feature engineering to generate effective features, including Return Momentum, Week Price Momentum, and Month Price Momentum. We choose the Long Short-Term Memory (LSTM) model to capture continuous price trends and implement dynamic model updates during the trading execution process, enabling the model to continuously adapt to the current market trends. Notably, we have developed a comprehensive trading backtesting system - NoxTrader, which allows us to manage portfolios based on predictive scores and utilize custom evaluation metrics to conduct a thorough assessment of our trading performance. Our rigorous feature engineering and careful selection of prediction targets enable us to generate prediction data with an impressive correlation range between 0.65 and 0.75. Finally, we monitor the dispersion of our prediction data and perform a comparative analysis against actual market data. Through the use of filtering techniques, we improved the initial-60% investment return to 325%.",2023
"Connectedness and portfolio hedging between NFTs segments, American stocks and cryptocurrencies Nexus","The paper examines the dynamic spillover and hedging effectiveness between five main segments of NFTs, which are Collectibles, Art, Game, Metaverse, and Utility, and the other asset classes namely Bitcoin and the American Stocks (S&P500). The study sample covers the period from April 27, 2018 to September 15, 2022. Using a Time Varying connectedness approach through the TVP-VAR model and inspired by the Diebold and Yilmaz spillover index, the results show weak dynamic return spillovers between NFTs and the other assets, indicating that these new digital assets are still relatively decoupled from traditional asset and Bitcoin. We find also that Bitcoin is a major transmitter of spillover whereas Collectibles, Utility and S&P500 are net recipients of spillovers. Using the DCC-GARCH model, we extract the optimal weights, hedge ratios, and hedging effectiveness for the pairwise portfolios composed of S&P500/NFTs and Bitcoin/NFTs. The results indicate that investors and portfolio managers should consider adding NFTs in their portfolios of either S&P500 or Bitcoin to achieve diversification benefits. Finally, for Robustness Checks, we forecast the performance of the hedged versus the unhedged portfolios using the Long Short-Term Memory (LSTM) networks. Our findings confirm almost the results of the hedging effectiveness of NFTs and stem for the superiority of metaverse among these assets to serve as a perfect hedge.",2024
Gated Neural Network-Based Mean-EVaR-Skewness Portfolio Optimization under Uncertain Environment,"Numerous empirical studies show that portfolio returns are generally asymmetric, and investor would prefer a portfolio return with larger degree of asymmetry along with risk and return. In this paper, a concept of skewness is defined as the third central moment and studied its mathematical properties. To predict the stock prices, a novel recurrent neural network with gated recurrent unit (GRU) cell is preferred. Based on these predictions, stock returns, entropic value at risks and skewness are calculated. A mean-EVaR-skewness multi-objective portfolio optimization model is devised to account for market uncertainty. Cardinality, bounding restrictions, and liquidity are considered in addition to risk and return to make the model more effective. Uncertain goal programming is used to solve the proposed model. Finally, an example portfolio is presented to display the efficacy and the feasibility of the model suggested in this paper.",2021
An in-depth investigation of five machine learning algorithms for optimizing mixed-asset REITs,"Real estate is a favored investment option as it allows investors to diversify their portfolios and minimize risk. Investors can invest in real estate directly by purchasing a property, or through real estate investment funds (REITs) where they can purchase shares in companies that own and manage real estate. Investing in REITs has become increasingly popular because it eliminates some of the disadvantages associated with direct real estate investment, such as the need for a large upfront payment. When investing in mixed asset portfolios, it is crucial to predict future prices accurately to ensure profitable and less risky asset allocation. However, literature on price prediction often focuses on only one or two algorithms, and there is no research that explores REITs' price prediction in the context of portfolio optimization. To address this gap, we conducted a thorough evaluation of 5 machine learning algorithms (ML), including Ordinary Least Squares Linear Regression (LR), Support Vector Regression (SVR), k-Nearest Neighbors Regression (KNN), Extreme Gradient Boosting (XGBoost), and Long/Short-Term Memory Neural Networks (LSTM), as well as other financial benchmarks like Holt's Exponential Smoothing (HES), Trigonometric Seasonality, Box-Cox Transformation, ARMA Errors, Trend, and Seasonal Components (TBATS), and Auto-Regression Integrated Moving Average (ARIMA). We applied these algorithms to predict future prices for 30 REITs from the US, UK, and Australia, as well as 30 stocks and 30 bonds. The assets were then used as part of a portfolio, which we optimized using a genetic algorithm. Our results showed that using ML algorithms for price prediction provided at least three times the return over benchmark models and reduced risk by almost two-fold. For REITs, we observed that the use of ML algorithms led to a higher allocation to REITs diversified by country. In particular, our results showed that SVR was the best-performing algorithm in terms of risk-adjusted returns across different time horizons, as confirmed by our Friedman test results (Sharpe ratio). Overall, our study highlights the effectiveness of ML algorithms in predicting asset prices and optimizing portfolio allocation.",2024
"Return, Diversification and Risk in Cryptocurrency Portfolios using Deep Recurrent Neural Networks and Multi-Objective Evolutionary Algorithms","Nowadays the widespread adoption of cryptocurrencies (also referred to as Altcoins) has universalized the access of the society to trading opportunities in alternative markets, thereby laying a rich substrate for the development of new applications and services aimed at easing the management of personal investment portfolios. When selecting how much to invest and in which asset it is often the case that multiple criteria conflict with each other within a single decision making process, which calls for efficient means to optimally balance such contradicting objectives. In this paper we report initial findings around the combination of Deep Learning (DL) models and Multi-Objective Evolutionary Algorithms (MOEAs) for allocating cryptocurrency portfolios. Technical rationale and details are given on the design of a stacked DL recurrent neural network, and how its predictive power can be exploited for yielding accurate ex ante estimates of the return and risk of the portfolio. These two objectives are complemented by a measure of the diversity of the investment. Results are presented and discussed with real cryptocurrency data, showcasing the potential of our technical approach to produce near-optimal portfolios by balancing the aforementioned objectives. Our study stimulates further research towards incorporating other factors in the design of predictive portfolios, such as the confidence of the DL model output.",2019
Neural network with fixed noise for index-tracking portfolio optimization,"Index tracking portfolio optimization is popular form of passive investment strategy, with a steady and profitable performance compared to an active investment strategy. Due to the revival of deep learning in recent years, several studies have been conducted to apply deep learning in the field of finance. However, most studies use deep learning exclusively to predict stock price movement, not to optimize the portfolio directly. We propose a deep learning framework to optimize the index-tracking portfolio and overcome this limitation. We use the output distribution of the softmax layer from the fixed noise as the portfolio weights and verify the tracking performance of the proposed method on the S&P 500 index. Furthermore, by performing the ablation studies on the training-validation dataset split ratio and data normalization, we demonstrate that these are critical parameters for applying deep learning to the portfolio optimization problem. We also verify the generalization performance of the proposed method through additional experiments with another index of a major stock market, the Hang Seng Index (HSI).",2021
DEEP STOCK REPRESENTATION LEARNING: FROM CANDLESTICK CHARTS TO INVESTMENT DECISIONS,"We propose a novel investment decision strategy (IDS) based on deep learning. The performance of many IDSs is affected by stock similarity. Most existing stock similarity measurements have the problems: (a) The linear nature of many measurements cannot capture nonlinear stock dynamics; (b) The estimation of many similarity metrics (e.g. covariance) needs very long period historic data (e.g. 3K days) which cannot represent current market effectively; (c) They cannot capture translation-invariance. To solve these problems, we apply Convolutional AutoEncoder to learn a stock representation, based on which we propose a novel portfolio construction strategy by: (i) using the deeply learned representation and modularity optimisation to cluster stocks and identify diverse sectors, (ii) picking stocks within each cluster according to their Sharpe ratio (Sharpe 1994). Overall this strategy provides low-risk high-return portfolios. We use the Financial Times Stock Exchange 100 Index (FTSE 100) data for evaluation. Results show our portfolio outperforms FTSE 100 index and many well known funds in terms of total return in 2000 trading days.",2018
Deep learning framework for predictive modeling of crude oil price for sustainable management in oil markets,"Crude oil price predictability has continually been considered as a fundamental argument of finance literature, given its critical propositions for risk management, investment decisions, and commercial and financial policymaking. This work presents an innovative learning framework for efficient predictive modeling of daily and weekly crude oil price (COP) information, which aims to enable sustainable management in oil markets. Firstly, an optimized version of variation mode decomposition (OVMD) is proposed to adaptively decompose the original COP time series into multiple modes based on a set of optimized parameters calculated with a Tree-structured Parzen Estimator (TPE) algorithm. Secondly, an AdaBoost algorithm is redesigned using random forest (RF) to model the future price information in the modes with the high frequency. Thirdly, a new deep network is presented to develop automatically learn spatial-temporal representations from decomposed COP data, where a novel Conv-former module is designed to efficiently extract local as well as global spatial representations without incurring extra computational costs. Followingly, Multiple Long short-term Memory (LSTM) networks are stacked to learn temporal representations from input modes. To further empower the representation power of our framework, a new bidirectional learning module is presented to stack the LSTM layer to learn from COP data in the forward and backward directions. To validate the efficiency of the proposed framework, this work performs experimental simulations and analyses based on a case study from Brent crude oil prices at both daily and weekly scales. The experimental findings show up the competent predictive modeling capabilities of the proposed framework over the cutting-edge methods rendering it as a promising solution to enable sustainable management in crude oil markets. The proposed framework can be generalized to different predictive modeling tasks and hence qualified to be used as a valuable tool for oil portfolio creation, property pricing, and risk management in Crude Oil Markets.",2023
Forecasting cryptocurrencies volatility using statistical and machine learning methods: A comparative study,"Forecasting cryptocurrency volatility can help investors make better-informed investment decisions in order to minimize risks and maximize potential profits. Accurate forecasting of cryptocurrency price fluctuations is crucial for effective portfolio management and contributes to the stability of the financial system by identifying potential threats and developing risk management strategies. The objective of this paper is to provide a comprehensive study of statistical and machine learning methods for predicting daily and weekly volatility of the following four cryptocurrencies: Bitcoin, Ethereum, Litecoin, and Monero. Several models and forecasting methods are compared in terms of their forecasting accuracy, i.e., HAR (heterogeneous autoregressive), ARFIMA (autoregressive fractionally integrated moving average), GARCH (generalized autoregressive conditional heteroscedasticity), LASSO (least absolute shrinkage and selection operator), RR (ridge regression), SVR (support vector regression), MLP (multilayer perceptron), FNM (fuzzy neighbourhood model), RF (random forest), and LSTM (long short-term memory). The realized variance calculated from intraday returns is used as the input variable for the models. In order to assess the predictive power of the models considered, the model confidence set (MCS) procedure is applied. Our experimental results demonstrate that there is no single best method for forecasting volatility of each cryptocurrency, and different models may perform better depending on the specific cryptocurrency, choice of the error metric and forecast horizon. For daily forecasts, the method that is always found in a set of best models is linear SVR, while for weekly forecasts, there are two such methods, namely FNM and RR. Furthermore, we show that simple linear models such as HAR and ridge regression, perform not worse than more complex models like LSTM and RF. The research provides a useful reference point for the development of more sophisticated models.",2024
VCONV: A Convolutional Neural Network Accelerator for FPGAs,"Field Programmable Gate Arrays (FPGAs), with their wide portfolio of configurable resources such as Look-Up Tables (LUTs), Block Random Access Memory (BRAM), and Digital Signal Processing (DSP) blocks, are the best option for custom hardware designs. Their low power consumption and cost-effectiveness give them an advantage over Graphics Processing Units (GPUs) and Central Processing Units (CPUs) in providing efficient accelerator solutions for compute-intensive Convolutional Neural Network (CNN) models. CNN accelerators are dedicated hardware modules capable of performing compute operations such as convolution, activation, normalization, and pooling with minimal intervention from a host. Designing accelerators for deeper CNN models requires FPGAs with vast resources, which impact its advantages in terms of power and price. In this paper, we propose the VCONV Intellectual Property (IP), an efficient and scalable CNN accelerator architecture for applications where power and cost are constraints. VCONV, with its configurable design, can be deployed across multiple smaller FPGAs instead of a single large FPGA to provide better control over cost and parallel processing. VCONV can be deployed across heterogeneous FPGAs, depending on the performance requirements of each layer. The IP's performance can be evaluated using embedded monitors to ensure that the accelerator is configured to achieve the best performance. VCONV can be configured for data type format, convolution engine (CE) and convolution unit (CU) configurations, as well as the sequence of operations based on the CNN model and layer. VCONV can be interfaced through the Advanced Peripheral Bus (APB) for configuration and the Advanced eXtensible Interface (AXI) stream for data transfers. The IP was implemented and validated on the Avnet Zedboard and tested on the first layer of AlexNet, VGG16, and ResNet18 with multiple CE configurations, demonstrating 100% performance from MAC units with no idle time. We also synthesized multiple VCONV instances required for AlexNet, achieving the lowest BRAM utilization of just 1.64 Mb and deriving a performance of 56GOPs.",2025
A Novel Implementation of Siamese Type Neural Networks in Predicting Rare Fluctuations in Financial Time Series,"Stock trading has tremendous importance not just as a profession but also as an income source for individuals. Many investment account holders use the appreciation of their portfolio (as a combination of stocks or indexes) as income for their retirement years, mostly betting on stocks or indexes with low risk/low volatility. However, every stock-based investment portfolio has an inherent risk to lose money through negative progression and crash. This study presents a novel technique to predict such rare negative events in financial time series (e.g., a drop in the S&P 500 by a certain percent in a designated period of time). We use a time series of approximately seven years (2517 values) of the S&P 500 index stocks with publicly available features: the high, low and close price (HLC). We utilize a Siamese type neural network for pattern recognition in images followed by a bootstrapped image similarity distribution to predict rare events as they pertain to financial market analysis. Extending on literature about rare event classification and stochastic modeling in financial analytics, the proposed method uses a sliding window to store the input features as tabular data (HLC price), creates an image of the time series window, and then uses the feature vector of a pre-trained convolutional neural network (CNN) to leverage pre-event images and predict rare events. This research does not just indicate that our proposed method is capable of distinguishing event images from non-event images, but more importantly, the method is effective even when only limited and strongly imbalanced data is available.",2022
Portfolio trading system of digital currencies: A deep reinforcement learning with multidimensional attention gating mechanism,"As a hot topic in the financial engineering, the portfolio optimization aims to increase investors' wealth. In this paper, a portfolio management system based on deep-reinforcement learning is proposed. In contrast to inflexible traditional methods, the proposed system achieves a better trading strategy through Reinforcement learning. The reward signal of Reinforcement learning is updated by action weights from Deep learning networks. Low price, high price and close price constitute the inputs, but the importance of these three features is quite different. Traditional methods and the classical CNN can't deal with these three features separately, but in our method, a designed depth convolution is proposed to deal with these three features separately. In a virtual currency market, the price rise only occurs in a flash. Traditional methods and CNN networks can't accurately judge the critical time. In order to solve this problem, a three-dimensional attention gating network is proposed and it gives higher weights on rising moments and assets. Under different market conditions, the proposed system achieves more substantial returns and greatly improves the Sharpe ratios. The short-term risk index of the proposed system is lower than those of the traditional algorithms. Simulation results show that the traditional algorithms (including Best, CRP, PAMR, CWMR and CNN) are unable to perform as well as our approach. (C) 2020 Elsevier B.V. All rights reserved.",2020
Machine-Learning-Based Rotating Detonation Engine Diagnostics: Evaluation for Application in Experimental Facilities,"Real-time monitoring of combustion behavior is a crucial step toward actively controlled rotating detonation engine (RDE) operation in laboratory and industrial environments. Various machine learning methods have been developed to advance diagnostic efficiencies from conventional postprocessing efforts to real-time methods. This work evaluates and compares conventional techniques alongside convolutional neural network (CNN) architectures trained in previous studies, including image classification, object detection, and time series classification, according to metrics affecting diagnostic feasibility, external applicability, and performance. Real-time, capable diagnostics are deployed and evaluated using an altered experimental setup. Image-based CNNs are applied to externally provided images to approximate dataset restrictions. Image classification using high-speed chemiluminescence images and time series classification using high-speed flame ionization and pressure measurements achieve classification speeds enabling real-time diagnostic capabilities, averaging laboratory-deployed diagnostic feedback rates of 4-5 Hz. Object detection achieves the most refined resolution of 20 mu s in postprocessing. Image and time series classification require the additional correlation of sensor data, extending their time-step resolutions to 80 ms. Comparisons show that no single diagnostic approach outperforms its competitors across all metrics. This finding justifies the need for a machine learning portfolio containing a host of networks to address specific needs throughout the RDE research community.",2023
Recurrent neural networks for stochastic control problems with delay,"Stochastic control problems with delay are challenging due to the path-dependent feature of the system and thus its intrinsic high dimensions. In this paper, we propose and systematically study deep neural network-based algorithms to solve stochastic control problems with delay features. Specifically, we employ neural networks for sequence modeling (e.g., recurrent neural networks such as long short-term memory) to parameterize the policy and optimize the objective function. The proposed algorithms are tested on three benchmark examples: a linear-quadratic problem, optimal consumption with fixed finite delay, and portfolio optimization with complete memory. Particularly, we notice that the architecture of recurrent neural networks naturally captures the path-dependent feature with much flexibility and yields better performance with more efficient and stable training of the network compared to feedforward networks. The superiority is even evident in the case of portfolio optimization with complete memory, which features infinite delay.",2021
Cryptocurrency Portfolio Management with Deep Reinforcement Learning,"Portfolio management is the decision-making process of allocating an amount of fund into different financial investment products. Cryptocurrencies are electronic and decentralized alternatives to government-issued money, with Bitcoin as the best-known example of a cryptocurrency. This paper presents a model-less convolutional neural network with historic prices of a set of financial assets as its input, outputting portfolio weights of the set. The network is trained with 0.7 years' price data from a cryptocurrency exchange. The training is done in a reinforcement manner, maximizing the accumulative return, which is regarded as the reward function of the network. Back test trading experiments with trading period of 30 minutes is conducted in the same market, achieving 10-fold returns in 1.8 month's periods. Some recently published portfolio selection strategies are also used to perform the same back tests, whose results are compared with the neural network. The network is not limited to cryptocurrency, but can be applied to any other financial markets.",2017
Explainable deep learning model for stock price forecasting using textual analysis,"Stock price forecasting is a challenging task because financial time series are primarily nonlinear, noisy, and disordered systems that are complicated to forecast. Deep learning models show promise in this domain along with natural language processing, to extract relevant features from text data and map them to numerical representations. This study aims to forecast stock prices using text analysis and deep learning approaches and explain the models using explainable AI. We construct a World Halal Tourism Composite Sentiment Index (WHTCSI) using text analysis to forecast halal tourism stock price. The results suggest that Convolutional Neural Networks (CNN) outperform all other models. The results are robust when considering country-level data. In addition, model explanations show that the index contributes 35.55% to the forecasting model, indicating irrational investment activity and herding behavior in the halal tourism industry. The study's findings have significant implications for investors, analysts, and portfolio managers in making investment decisions.",2024
Forecasting the impact of financial stress on hedging between the oil market and GCC financial markets,"PurposeThis paper investigates the predictive impact of Financial Stress on hedging between the oil market and the GCC stock and bond markets from January 1, 2007, to December 31, 2020. The authors also compare the hedging performance of in-sample and out-of-sample analyses.Design/methodology/approachFor the modeling purpose, the authors combine the GARCH-BEKK model with the machine learning approach to predict the transmission of shocks between the financial markets and the oil market. The authors also examine the hedging performance in order to obtain well-diversified portfolios under both Financial Stress cases, using a One-Dimensional Convolutional Neural Network (1D-CNN) model.FindingsAccording to the results, the in-sample analysis shows that investors can use oil to hedge stock markets under positive Financial Stress. In addition, the authors prove that oil hedging is ineffective in reducing market risks for bond markets. The out-of-sample results demonstrate the ability of hedging effectiveness to minimize portfolio risk during the recent pandemic in both Financial Stress cases. Interestingly, hedgers will have a more efficient hedging performance in the stock and oil market in the case of positive (negative) Financial Stress. The findings seem to be confirmed by the Diebold-Mariano test, suggesting that including the negative (positive) Financial Stress in the hedging strategy displays better out-of-sample performance than the in-sample model.Originality/valueThis study improves the understanding of the whole sample and positive (negative) Financial Stress estimates and forecasts of hedge effectiveness for both the out-of-sample and in-sample estimates. A portfolio strategy based on transmission shock prediction provides diversification benefits.",2024
An Empirical Study on the Effectiveness of Bi-LSTM-Based Industry Rotation Strategies in Thai Equity Portfolios,"Portfolio optimization poses a significant challenge due to asset price volatility caused by various economic factors. Portfolio optimization typically aims to achieve a high risk-adjusted return through asset allocation. However, high-volatility assets such as equities can lead to significant losses in the event of crises, such as trade wars. An industry rotation strategy can reduce portfolio risk by investing in industry indexes. This research aims to develop industry rotation strategies for Thailand by analyzing previous consecutive months of economic variables with the goal of maximizing the portfolio's Sharpe ratio in the following period. Two strategies are proposed in this paper, one with cash and the other without, both of which include eight Thai industry indexes in their portfolios. Both strategies are developed using Bidirectional Long Short-term Memory (BiLSTM) models, which generate the allocation ratio based on historical economic variable data. The models then optimize the allocation ratio by using a modified loss function to maximize the Sharpe ratio. In addition to the Sharpe ratio, the return on investment and the Calmar ratio are used to assess the performance of the strategies. The results showed that our strategies outperformed the baseline buy-and-hold SET50 and equal-weight strategies.",2023
Distributed Generative Adversarial Networks for Fuzzy Portfolio Optimization,"Financial time series is one of the most important data in the field of economics and finance, and it is important to forecast and simulate such data effectively based on historical patterns and trends. Existing forecasting models mainly forecasting one-step ahead, and cannot retain the complex characteristics of financial time series data such as serial correlation and the long-term time-dependent relationship. On the other hand, the large-scale data makes the training of the deep learning models a time-consuming process. Therefore, how to forecast financial time series multi-step ahead efficiently has become a key point to improve the asset management capability. At the same time, constructing a fuzzy portfolio optimization for different distributions is also an important direction to improve the robustness of a portfolio model. This paper proposes a distributed financial time series simulating model AssetGANs that simulating multi-step ahead based on GANs, and apply GANs as a parameter simulation method to fuzzy portfolio optimization to provide users with better strategy choices. The paper carries on numerical experiments on real market stock data, compares the results with LSTM and achieves a training speedup of over 573 with 8 GPUs compared to the CPU version.",2024
Portfolio Optimization Using Novel EW-MV Method in Conjunction with Asset Preselection,"Integration of asset preselection with appropriate portfolio optimization techniques can improve the performance of the portfolio optimization models. This paper morphed the potential asset selection and the optimal portfolio construction rather than focusing on one. A large volume of sample data from 25 stocks is used for the experiment from the National Stock Exchange, India, between January 2005 and December 2021. Initially, a 3-step screening approach, an asset selection method is applied to select potential assets. The 3-steps comprise data choice, fundamental screening, and the Long Short Term Memory model anticipating real-time stock prices to shortlist stocks with higher expected returns. The suggested approach is effective in determining the quality of assets. Further, the optimal asset allocation is done by introducing a novel exponentially weighted-mean-variance model. This exponential weighting scheme outperforms the classical Mean-Variance model when applied to the maximum Sharpe ratio model. The proposed model outperforms the five baseline techniques in terms of the Sharpe ratio and average potential returns and risks. Additionally, the proposed model's resilience across diversified time frames is tested through the incorporation of multiple time windows, demonstrating robustness of the performance.",2024
Can multi-period auto-portfolio systems improve returns? Evidence from Chinese and US stock markets,"Current portfolios often underperform due to limited utilization of stock selection and a lack of attention to multi-period trading. To address this issue, we propose an auto-portfolio system that addresses these problems by integrating multi-class stock selection with portfolio optimization based on technical indicators. For stock selection, we combine Two-dimensional Convolutional Neural Network with Long and Short-term Memory to forecast the future trends of stocks and select potentially profitable stocks for investment. We then develop two portfolio models based on two technical indicators, which automatically perform multi-period investment. We establish a many-objective optimization problem including return, Conditional Value-at-Risk, skewness, kurtosis, and cost. To solve the optimization problem, we employ Non-dominated Sorting Genetic Algorithm III. The data of Chinese and the U.S. stock markets is used for verification, and a comparative analysis is discussed. In the outof-sample period, two proposed multi-period portfolio models outperform the other models in both single and multi period, achieving higher Sharpe ratio of 1.021 and 1.052 in China, and 1.116 and 1.236 in the U.S., respectively.",2024
MDAEN: Multi-Dimensional Attention-based Ensemble Network in Deep Reinforcement Learning Framework for Portfolio Management,"Reinforcement Learning algorithms are widely applied in many diverse fields, including portfolio management. Ensemble of Identical Independent Evaluators (EIIE) framework proposed by Jiang et al. achieved portfolio management based on their deep reinforcement learning algorithm. In the implementation of EIIE framework, a neural network such as the Convolutional Neural Network is applied as the policy network, to uncover more patterns in the data. However, this network typology is inefficient due to its simple structure. To overcome the shortcoming of EIIE framework, this paper introduces a novel algorithm, the Multi-Dimensional Attention-based Ensemble Network (MDAEN) strategy, which consists of a features-attention module and an assets-attention module. The MDAEN applies different types of attention mechanisms to extract information from the assets. Having adopted the reinforcement learning framework fromJiang et al., the agent is able to process transactions through MDAEN in a market. In our portfolio establishment, Bitcoin together with eleven other cryptocurrencies is selected to validate the performance of MDAEN against seven traditional portfolio strategies and EIIE. The experimental result demonstrates the efficacy of our strategy outperforming all other strategies by at least 35% in profitability and at least 30% in Sharpe Ratio.",2022
Artificial Intelligence for ETF Market Prediction and Portfolio Optimization,"In asset allocation and time-series forecasting studies, few have shed light on using the different machine learning and deep learning models to verify the difference in the result of investment returns and optimal asset allocation. To fill this research gap, we develop a robo-advisor with different machine learning and deep learning forecasting methodologies and utilize the forecasting result of the portfolio optimization model to support our investors in making decisions. This research integrated several dimensions of technologies, which contain machine learning, data analytics, and portfolio optimization. We focused on developing robo-advisor framework and utilized algorithms by integrating machine learning and deep learning approaches with the portfolio optimization algorithm by using our predicted trends and results to replace the historical data and investor views. We eliminate the extreme fluctuation to maintain our trading within the acceptable risk coefficient. Accordingly, we can minimize the investment risk and reach a relatively stable return. We compared different algorithms and found that the F1 score of the model prediction significantly affects the result of the optimized portfolio. We used our deep learning model with the highest winning rate and leveraged the prediction result with the portfolio optimization algorithm to reach 12% of annual return, which outperform our benchmark index 0050.TW and the optimized portfolio with the integration of historical data.",2019
False Safe Haven Assets: Evidence From the Target Volatility Strategy Based on Recurrent Neural Network,"This paper examines which safe haven assets should be used when improving out-of-sample portfolio performance. We define a market state with recurrent neural network (RNN) volatility predictions and construct an investment strategy that dynamically combines equity, cash, and safe havens. The equity is allocated by targeting the volatility, and investing in safe havens depends on the predicted market state. We consider the S&P500 index with 13 safe haven assets, such as long-term government bonds, commodities, gold, and other precious metals. Other indices, NIKKEI225, NIFTY50, and STOXX50, are examined for robustness. With analysis conducted over a 20-year sample period, we find that RNN delivers sound predictions to construct the volatility targeting strategy. Among considered assets, only long-term Treasury bonds act as a safe haven and improve the strategy performance. Other considered assets have no such potential. Our findings are relevant to portfolio managers and investors actively managing portfolio risk.",2022
A Deep Reinforcement Learning Model for Portfolio Management Incorporating Historical Stock Prices and Risk Information,"At present, more and more studies have begun to apply deep reinforcement learning (DRL) to portfolio management problems. However, most cutting-edge DRL models have some limitations in processing time series data, while also not considering the extent to which historical risks impact the current market. To solve this problem, this paper proposes a DRL model that takes into account historical stock prices and risk information. Based on the double-delay depth deterministic strategy gradient (TD3) model, this study incorporates a convolutional short term neural network (CNN-LSTM) to enable TD3 to handle time series data and account for the interrelation between multiple features. To consider the degree of influence of historical risk on the current market, a risk assessment unit is introduced, which processes the risk indicators through long and short term neural network (LSTM) and dynamically weights the results. The experiments reveal that the proposed model is capable of attaining higher returns when accounting for risks.",2024
Deep reinforcement learning for stock portfolio optimization by connecting with modern portfolio theory,"With artificial intelligence and data quality development, portfolio optimization has improved rapidly. Traditionally, researchers in the financial market have utilized the modern portfolio theory for portfolio optimization; however, with the recent development of artificial intelligence, attempts to optimize portfolios with reinforcement learning are increasing. Many studies have developed reinforcement learning and deep learning algorithms and conducted portfolio optimization research. However, in reality, thus far, the securities industry thus has used the modern portfolio theory, which is sufficiently valuable. Nevertheless, to the best of our knowledge, there has yet to be an attempt to combine modern portfolio theory and reinforcement learning. To bridge this gap in the literature, we propose a novel deep reinforcement learning approach that combines the modern portfolio theory and a deep learning approach. As far as we know, we are the first to combine recent deep learning technology and traditional financial theory. Specifically, we solved the multimodal problem through the Tucker decomposition of a model with the input of technical analysis and stock return covariates. The results show that the proposed method outperforms state-of-the-art algorithms regarding the Sharpe ratio, annualized return, and maximum drawdown. In addition, the proposed method dynamically changes the weight according to the market trend, unlike other state-of-the-art algorithms.",2023
Portfolio optimization using predictive auxiliary classifier generative adversarial networks,"In financial engineering, portfolio optimization has been of consistent interest. Portfolio optimization is a process of modulating asset distributions to maximize expected returns and minimize risks. Despite numerous studies on shallow learning models, they have shown limited success in analyzing the complex nature of massive stock data, a task where recent deep learning models excel. However, the deterministic nature of conventional deep learning models impedes their consideration of portfolio risk due to an inherent lack of uncertainty quantification in their predictions. This paper proposes a novel portfolio weighting strategy, incorporating both risk and return considerations within a deep learning framework. We propose the Predictive Auxiliary Classifier Generative Adversarial Networks (PredACGAN), a probabilistic deep learning model, to measure prediction uncertainty. The PredACGAN generator leverages latent vectors and historical stock prices to predict future returns. The model synthesizes predictive distributions from various latent vectors and past prices. The associated risk is produced via the entropy of these distributions, facilitating portfolio optimization through both return and risk considerations. The proposed algorithm removes high-risk assets from the investment universe at rebalancing moments, enabling PredACGAN to optimize portfolios considering both return and risk. We evaluated PredACGAN and the accompanying algorithm with S & P 500 stocks from 1990 to 2020, with portfolios rebalanced monthly based on PredACGAN predictions and risk measures. The PredACGAN portfolios yielded 9.123% annual returns and a 1.054 Sharpe ratio, outperforming a risk-agnostic portfolio yielding 1.024% annual returns and a 0.236 Sharpe ratio. The PredACGAN portfolio also exhibited lower maximum drawdowns, highlighting its effectiveness.",2023
"Dynamic interrelationships among crude oil, green bond, and carbon markets: Evidence from fuzzy logic autoencoders","This paper investigates the dynamic interrelationships among various markets covering crude oil, green bonds, and carbon emissions from January 2014 to October 2022, using a Fuzzy Logistic Autoencoder (FLAE) model, which elevates methodological sophistication and helps capturing intricate and complex relationships across the three markets. Different features of FLAE, such as identifying crossed lags and introducing a novel sigmoid-type activation function, enhance structural stability and establish the model as a reference for studying crosstemporal effects across markets. The key findings indicate that green bond returns negatively impact the returns of carbon emission allowances and Brent oil in the short and medium term. The impact of carbon emission allowance returns and oil returns on the forecast of green bond returns is comparatively trivial. Forecasting green bond returns is primarily driven by its short-term lags. These findings should be useful for portfolio managers in energy markets, environmentally conscious investors, and policy-makers concerned with financial sustainability amid the energy transition.",2025
A portfolio construction model based on sector analysis using Dempster-Shafer evidence theory and Granger causal network: An application to National stock exchange of India,"With the emerging areas of economy, the diverse sector-based investment portfolios are considered more significant. This paper presents an integrated approach of portfolio construction based on sector analysis for investment in National Stock Exchange of India. The model is developed in four stages: First, multiple evidences are collected using historical data to analyze the performance of different sectors, and ranked using DempsterShafer evidence theory. The top-ranked sectors are considered as the strong sectors. Second, Granger causality test is employed for determining interdependencies between the strong sectors using the past closing price time series. Then, the strong sectors with no causal relationships are selected to diversify the investment. Third, leading stocks of the selected sectors are picked on the basis on their performance in previous years. Thus, the portfolio of best stocks from strong and diverse sectors is constructed. Fourth, for optimizing of the constructed portfolio or to obtain optimal ratio allocations of stocks in the portfolio, an optimization function is constructed and simulated using a deep recurrent neural network. The results obtained by the proposed portfolio are found very significant which confirms its effectiveness. The applicability of the proposed model is verified by empirical study over the existing models.",2023
Application of Features and Neural Network to Enhance the Performance of Deep Reinforcement Learning in Portfolio Management,"Portfolio management is the decision-making process of allocating a certain amount of funds to multiple financial assets and continuously changing the distribution weights to increase returns and reduce risks. With the advance in artificial intelligence technology, it has become possible to use computers for self-learning and large-scale calculations, and to achieve optimized portfolio management. This paper mainly studies and analyzes the problem of portfolio optimization in the digital currency market, uses Poloniex's historical transaction data of digital currency to conduct experiments, and proposes a strategy based on the framework of deep reinforcement learning algorithms. The investment strategy framework uses Convolutional Neural Network and Visual Geometry Group Network. In addition to the closing price, highest price and lowest price, we also consider other internal or external features such as Network Value to Transaction Volume Ratio, Market Value to Realized Value Ratio, Return on Investment and Volatility. The results show that the return rate of our algorithm based on VGG with NVT as feature is 11.05% better than the work of Jiang et al. and at least 110% better than investment strategies such as Moving Average Reversion and Robust Median Reversion.",2021
COMPUTATION INTELLIGENCE BASED DAILY ALGORITHMIC STRATEGIES FOR TRADING IN THE FOREIGN EXCHANGE MARKET,"Successful trading in financial markets is not possible without a support system that manages the preparation of the data, prediction system, and risk management and evaluates the trading efficiency. Selected orthogonal data was used to predict exchange rates by applying recurrent neural network ( RNN) software based on the open source framework Keras and the graphical processing unit (GPU) NVIDIA GTX1070 to accelerate RNN learning. The newly developed software on the GPU predicted ten high-low distributions in approximately 90 minutes. This paper compares different daily algorithmic trading strategies based on four methods of portfolio creation: split equally, optimisation, orthogonality, and maximal expectations. Each investigated portfolio has opportunities and limitations dependent on market state and behaviour of investors, and the efficiencies of the trading support systems for investors in foreign exchange market were tested in a demo FOREX market in real time and compared with similar results obtained for risk-free rates.",2018
Uncertainty-Aware Reinforcement Learning for Portfolio Optimization,"We explored the use of Reinforcement Learning (RL) combined with risk assessment for optimizing investment portfolios. The dynamic nature of trading, compounded by market frictions, the responses of other market participants, and uncertainties, poses challenges to portfolio optimization. The financial market's intricacies make it difficult to model accurately, compounded by regulatory requirements and internal risk policies mandating risk-averse decisions to avoid catastrophic outcomes. To address this, we proposed risk estimation for investor's risk tolerance threshold. Moreover, modern Deep Learning models are adept at approximating complex relationship between abundant data, however, the main drawback we face now a day is generalization of the relationship to the unseen data. Therefore, the epistemic uncertainty can pose risk to the decision making system. This uncertainty is further addressed using a Variational Autoencoder (VAE) to estimate, and Cost Network to backpropogate riskiness through the model to learn actions with safe results. The actions with stable result or lower reward will be avoided due to reward optimization of RL. Consequently, we successfully managed to reduce the risk and uncertainties in the agent testing process. Our risk-constrained RL algorithm demonstrated zero violation of the constraint in the testing phase. This suggests that adopting a risk-averse RL approach could be beneficial for portfolio optimization, particularly for risk-averse investors.",2024
BP refocuses chemical portfolio,,2003
RETRACTED: Decision support model of e-commerce enterprise investment based on deep learning algorithm (Retracted Article),"According to the current situation and future trend of e-commerce investment market research at home and abroad, combined with the established research objectives, this paper studies and analyzes the existing methods of investment quality evaluation. This paper puts forward the modeling idea of the evaluation index system of investment decision quality, and takes the deep neural network as the modeling tool and python as the simulation tool to complete the establishment of the investment decision support model of e-commerce listed companies and get the experimental results. In this paper, based on the deep learning portfolio replication algorithm, the features of the portfolio model are extracted by the automatic encoder to realize the portfolio replication. First, the definition of deep learning model and the framework of model training will be given. Then, a process of trestle automatic encoder model will be introduced, and then the detailed process of portfolio replication algorithm based on deep learning will be explained in detail. Finally, the trained model is used to evaluate the samples of the test set, and the results are good, which shows that the index evaluation system is feasible and effective.",2023
Modelling shares choice to enter in a portfolio using artificial neural networks (ANN),"Shares choice to enter a portfolio is a good topic in finance and management, as it affects the portfolio performance which is managed by a Fund Manager. In this research, we aim to create an artificial neural network model to choose a share to enter a portfolio based on its financial factors and big data about the financial condition of companies. The artificial neural network model has 15 input nodes of attributes associated with a company's financial situation, 8 hidden layer nodes, and 1 output node. The accuracy of the model is 85.71%, with a learning rate of 0.05 trained over 2000 iterations.",2020
How to fly to safety without overpaying for the ticket,"For most active investors treasury bonds (govs) provide diversification and thus reduce the risk of a portfolio. These features of govs become particularly desirable in times of elevated risk which materialize in the form of the flight-to-safety (FTS) phenomenon. The FTS for govs provides a shelter during market turbulence and is exceptionally beneficial for portfolio drawdown risk reduction. However, what if the unsatisfactory expected return from treasuries discourages higher bonds allocations? This research proposes a solution to this problem with Deep Target Volatility Equity-Bond Allocation (DTVEBA) that dynamically allocate portfolios between equity and treasuries. The strategy is driven by a state-of-the-art recurrent neural network (RNN) that predicts next-day market volatility. An analysis conducted over a twelve year out-of-sample period found that with DTVEBA an investor may reduce treasury allocation by two (three) times to get the same Sharpe (Calmar) ratio and overper-forms the S & P500 index by 43% (115%).",2023
IMPROVING AUTOMOBILE INSURANCE CLAIMS FREQUENCY PREDICTION WITH TELEMATICS CAR DRIVING DATA,"Novel navigation applications provide a driving behavior score for each finished trip to promote safe driving, which is mainly based on experts' domain knowledge. In this paper, with automobile insurance claims data and associated telematics car driving data, we propose a supervised driving risk scoring neural network model. This one-dimensional convolutional neural network takes time series of individual car driving trips as input and returns a risk score in the unit range of (0,1). By incorporating credibility average risk score of each driver, the classical Poisson generalized linear model for automobile insurance claims frequency prediction can be improved significantly. Hence, compared with non-telematics-based insurers, telematics-based insurers can discover more heterogeneity in their portfolio and attract safer drivers with premiums discounts.",2022
Application of Deep Q-Network in Portfolio Management,"Machine Learning algorithms and Neural Networks are widely applied to many different areas such as stock market prediction, facial recognition and automatic machine translation. This paper introduces a novel strategy based on the classic Deep Reinforcement Learning algorithm, Deep Q-Network, for stock market portfolio management. It is a type of deep neural network which is optimized by Q Learning. To adapt the Deep Q-Network for stock market production, we first discretize the action space so that portfolio management becomes a problem that Deep Q-Network can solve. Following this, we combine the Convolutional Neural Network and dueling Q-Net to enhance the recognition ability of the algorithm. We choose five low-relevant American stocks to test our model. It is found that the Deep Q-Network based strategy outperforms the ten other traditional strategies. The profit of Deep Q-Network algorithm is 30% more than the profit of other strategies. Moreover, the Sharpe ratio and Max Drawdown demonstrates that the risk of policy associated with Deep Q-Network is the lowest.",2020
Neural network copula portfolio optimization for exchange traded funds,"This paper attempts to investigate if adopting accurate forecasts from Neural Network (NN) models can lead to statistical and economically significant benefits in portfolio management decisions. In order to achieve that, three NNs, namely the Multi-Layer Perceptron, Recurrent Neural Network and the Psi Sigma Network (PSN), are applied to the task of forecasting the daily returns of three Exchange Traded Funds (ETFs). The statistical and trading performance of the NNs is benchmarked with the traditional Autoregressive Moving Average models. Next, a novel dynamic asymmetric copula model (NNC) is introduced in order to capture the dependence structure across ETF returns. Based on the above, weekly re-balanced portfolios are obtained and compared using the traditional mean-variance and the mean-CVaR portfolio optimization approach. In terms of the results, PSN outperforms all models in statistical and trading terms. Additionally, the asymmetric skewed t copula statistically outperforms symmetric copulas when it comes to modelling ETF returns dependence. The proposed NNC model leads to significant improvements in the portfolio optimization process, while forecasting covariance accounting for asymmetric dependence between the ETFs also improves the performance of obtained portfolios.",2018
Machine Learning-Driven Virtual Bidding With Electricity Market Efficiency Analysis,"This paper develops a machine learning-driven portfolio optimization framework for virtual bidding in electricity markets considering both risk constraint and price sensitivity. The algorithmic trading strategy is developed from the perspective of a proprietary trading firm to maximize profit. A recurrent neural network-based Locational Marginal Price (LMP) spread forecast model is developed by leveraging the inter-hour dependencies of the market clearing algorithm. The LMP spread sensitivity with respect to net virtual bids is modeled as a monotonic function with the proposed constrained gradient boosting tree. We leverage the proposed algorithmic virtual bid trading strategy to evaluate both the profitability of the virtual bid portfolio and the efficiency of U.S. wholesale electricity markets. The comprehensive empirical analysis on PJM, ISO-NE, and CAISO indicates that the proposed virtual bid portfolio optimization strategy considering the price sensitivity explicitly outperforms the one that neglects the price sensitivity. The Sharpe ratio of virtual bid portfolios for all three electricity markets are much higher than that of the S&P 500 index. It was also shown that the efficiency of CAISO's two-settlement system is lower than that of PJM and ISO-NE.",2022
Deep learning price momentum in US equities,"Research into deep learning techniques for stock price trend identification is limited. This can partly be attributed to the aversion of technical analysis within the academic community. One popular investment strategy that has been accepted by both academics and professionals, based purely on historical prices, is price momentum. However, the recent performance of this strategy has been disappointing. In this paper, we construct a new framework integrating state-of-the-art deep learning and machine learning methods to identify price trends of US equities: a deep learning price momentum portfolio. We first replicate the conventional price momentum calculations and compare the results with the market benchmarks and standard implementations of deep learning. We examine the issues of applying standard deep learning techniques to a limited noisy data set. Then we propose a new modular approach, built on deep learning clustering methods and recurrent neural networks that shows significant improvement on conventional price momentum while addressing the deficiencies of conventional deep learning methods. While the best-performing conventional price momentum portfolio yields 12.88% annual return and -0.49% market neutral annual returns for the 15-year period (2003 - 2017), our model improves these to 15.44% and +1.93% respectively with a significantly enhanced Sharpe ratio.",2019
Graph-based stock correlation and prediction for high-frequency trading systems,"In this paper, we have implemented a high-frequency quantitative system that can obtain stable returns for the Chinese A-share market, which has been running for more than 3 months (from March 27, 2020 to June 30, 2020) with the expected results. A number of rules and barriers exist in the Chinese A-share market such as trading restrictions and high fees, as well as scarce and expensive hedging tools. It is difficult to achieve stable absolute returns in such a market. Stock correlation analysis and price prediction play an important role to achieve any profitable trading. The portfolio management and subsequent trading decisions highly depend on the results of stock correlation analysis and price prediction. However, it is nontrivial to analyze and predict any stocks, being time-varying and affected by unlimited factors in a given market. Traditional methods only take some certain factors into consideration but ignore others that may be changed dynamically. In this paper, we propose a novel machine learning model named Graph Attention Long Short-Term Memory (GALSTM) to learn the correlations between stocks and predict their future prices automatically. First, a multi-Hawkes Process is used to initial a correlation graph between stocks. This procedure provides a good training start as the multi-Hawkes Processes will be studied on the most saint feature fluctuations with any correlations being statistically significant. Then an attention based LSTM is built to learn the weighting matrix underlying the dynamic graph. In addition, we also build matching data process plus portfolio management modules to form a complete system. The proposed GALSTM enables us to expand the scope of stock selection under the premise of controlling risks with limited hedging tools in the A-share market, thereby effectively increasing high-frequency excess returns. We then construct a long and short positions combination, select long positions in the A shares of the entire market, and use stock index futures to short. With GALSTM model, the products managed by our fully automatic quantitative trading system achieved an absolute annual return rate of 44.71% and the standard deviation of daily returns is only 0.42% in three months of operation. Only 1 week loss in 13 weeks of running time. (c) 2021 Published by Elsevier Ltd.",2022
A Framework for Market State Prediction with Ontological Asset Selection: A Multimodal Approach,"In this study, we introduce a detailed framework for predicting market conditions and selecting stocks by integrating machine learning techniques with ontological financial analysis. The process starts with ontology-based stock selection, categorizing companies using fundamental financial indicators such as liquidity, profitability, debt ratios, and growth metrics. For instance, firms showcasing favorable debt-to-equity ratios along with robust revenue growth are identified as high-performing entities. This classification facilitates targeted analyses of market dynamics. To predict market states-categorizing them into bull, bear, or neutral phases-the framework utilizes a Non-Stationary Markov Chain (NMC), BERT, to assess sentiment in financial news articles and Long Short-Term Memory (LSTM) networks to identify temporal patterns. Key inputs like the Sentiment Index (SI) and Illiquidity Index (ILLIQ) play essential roles in dynamically influencing regime predictions within the NMC model; these inputs are supplemented by variables including GARCH volatility and VIX to enhance predictive precision further still. Empirical findings demonstrate that our approach achieves an impressive 97.20% accuracy rate for classifying market states, significantly surpassing traditional methods like Naive Bayes, Logistic Regression, KNN, Decision Tree, ANN, Random Forest, and XGBoost. The state-predicted strategy leverages this framework to dynamically adjust portfolio positions based on projected market conditions. It prioritizes growth-oriented assets during bull markets, defensive assets in bear markets, and maintains balanced portfolios in neutral states. Comparative testing showed that this approach achieved an average cumulative return of 13.67%, outperforming the Buy and Hold method's return of 8.62%. Specifically, for the S&P 500 index, returns were recorded at 6.36% compared with just a 1.08% gain from Buy and Hold strategies alone. These results underscore the robustness of our framework and its potential advantages for improving decision-making within quantitative trading environments as well as asset selection processes.",2025
E2EAI: End-to-End Deep Learning Framework for Active Investing,"Active investing aims to construct a portfolio of assets that are expected to be relatively profitable in the markets. A popular strategy involves the use of factor-based methods. Recently, efforts have increased to apply deep learning to identify deep factors that could provide more active returns or promising pipelines for asset trend prediction. However, the question of constructing an active investment portfolio via an end-to-end deep learning framework (E2E) remains largely unexplored in existing research. In this paper, we are the first to propose an E2E approach that encompasses nearly the entire process of factor investing, including factor selection, combination, stock selection, and portfolio construction. A key challenge we address is the potential divergence in the directions of deep factors across different horizon lengths, which can create conflicts in the learning process of our multi-task learning model, E2EAI. To overcome this, we design a directional recovery algorithm that ensures consistent learning across tasks. Extensive experiments on real stock market data demonstrate the effectiveness of our end-to-end deep learning framework in active investing. Our approach not only enhances the potential returns of active investment strategies but also provides a comprehensive solution for managing multi-task learning conflicts in the context of deep learning-based factor investing.",2023
COVID-19 LED TO PRICE SLUMPS IN THE GERMAN STOCK MARKET. IS SENTIMENT APPLICABLE AS AN EXPLANATORY FACTOR?,"Explaining and forecasting returns and other statistical moments of returns in the stock market have always been critical challenges. Recent studies postulate a relation between investor sentiment and future stock market returns. Supported by evidence from other countries, this study explores the statistical moments of stock returns in Germany and analyses to what extent an explanation can be found through investor sentiment. The recent COVID-19 induced market distortions provide an opportunity to investigate the suitability of predictive sentiment-based analyses. These are presented in this study and appear to be meaningful. The main concept behind the sentiment-based return explanation is built on the assumption that stock returns are linked to investor psychology. This theory often serves as an explanation for market movements that cannot be explained by fundamental data which are directly linked to stocks. However, the extraction of various sentiment proxies for further analysis in statistical models remains challenging. Problems occur because sentiment proxies do not have a constant influence and depend greatly on what currently drives the market. Furthermore, the correlation between sentiment indicators varies over time, especially in times of market distress. In this study, 73 sentiment indicators were examined in the aggregate with regard to the explainability of future stock market return distribution moments such as mean, variance, skewness, and kurtosis. This study examines 169 one-month periods from 2006 to 2020 and shows a potential solution to these challenges by applying a neural network based on long short-term memory (LSTM) neurons. The authors were able to identify a good model fit and reasonable forecasting power, which seem to work particularly well in trend forecasting. The results can be valuable in the area of portfolio risk management.",2022
N-BEATS Perceiver: A Novel Approach for Robust Cryptocurrency Portfolio Forecasting,"In this paper, we propose a novel approach for forecasting cryptocurrency portfolios, harnessing modified versions of the N-BEATS deep learning architecture, integrated with convolutional network layers, Transformer mechanisms, and the Mish activation function. Our thorough evaluation, featuring an extensive sample size exceeding 4 million portfolio test samples, shows these variations outperforming traditional and other deep learning forecasting methods across various metrics. Particularly noteworthy is our N-BEATS Perceiver model, a Transformer-based variation, which not only delivers superior forecast accuracy but also exhibits a robust risk profile with less downside. Furthermore, the model performs exceptionally well under the TOPSIS method across a broad spectrum of portfolio evaluation parameters, making it a valuable asset for both portfolio selection and risk management in the dynamic cryptocurrency market.",2024
An empirical evaluation of fuzzy bidirectional long short-term memory with soft computing based decision-making model for predicting volatility of cryptocurrencies,"Cryptocurrencies have received a lot of attention from central banks, investors, and governments worldwide. The insufficiency of any method of political guideline and their market is far from effective, so they want novel regulation methods shortly. From an econometric perspective, the technique underlying the growth of the cryptocurrencies' volatility was observed to demonstrate similarities and differences with other economic time series, e.g., foreign exchange yields. Accurate prediction of cryptocurrency price fluctuations is significant for effectual portfolio management and improves economic models by identifying potential risks and attacks. With the growing use of AI in various fields, its application in financial markets, especially cryptocurrencies and stocks, is an emerging research area. This study presents an Empirical Evaluation of Fuzzy Bidirectional Long Short-Term Memory with a Soft Computing-based Decision-Making Model for Predicting Volatility of Cryptocurrencies (FBLSTMSC-DMPVC) technique. The primary focus of the FBLSTMSC-DMPVC technique is to present a robust and intelligent framework for an advanced decision-making model to predict cryptocurrency volatility. Initially, the presented FBLSTMSC-DMPVC method performs the data preprocessing process using Z-score normalization to ensure all features are standardized and scaled. Furthermore, the fuzzy bidirectional long short-term memory (FBLSTM) method predicts cryptocurrency volatility. To enhance the hyperparameters of the FBLSTM technique, the improved carnivorous plant algorithm (ICPA) is employed. A wide range of simulation is accomplished to ensure the impact of the FBLSTMSC-DMPVC technique. The FBLSTMSC-DMPVC technique portrayed a superior MAPE value of 0.7939 for BTC, 0.8633 for ETH, 0.6187 for LTC, and 0.6667 for XRP, demonstrating its performance across various cryptocurrencies.",2025
EFFECT OF AN E-WORKSHEET MANAGEMENT SYSTEM FOR PROMOTING STUDENT ACTIVE LEARNING,"Students' subjective, interactive, and deep learning (called active learning) is gaining popularity in Japan. E-portfolio system, in which all learning records are electronically collected and accumulated, is attracting attention as a means of supporting these learning processes. However, it is not always clear how to design classes using e-portfolio systems and what kind of e-portfolios should be collected and accumulated. It is also not clear how to utilize the accumulated e-portfolios in learning assessment and class improvement. This study aims to develop an e-portfolio system compatible with active learning. Specifically, we focus on an e-worksheet system which is an e-portfolio system that collects, accumulates, and manages e-portfolios using a worksheet as an interface. We implemented functions to promote active learning with e-worksheet system and tested our system to verify its effect on students. The results suggest that our system promotes students' subjective, interactive, and deep learning.",2018
Portfolio optimization in the stock market under disruptions: Real case studies of COVID-19 pandemic and currency risk,"The connection between risk and return is a critical concept in finance. Investors who take on more risk can earn higher returns. Disruptions are part of market risks, also known as systematic risks. Due to political and macroeconomic risks, their effects on the entire economic market, or a significant portion of its sectors, are not negligible. Among these sectors, the stock market is essential as a basis of the economy. The point is that the consequences of all disruptions are not merely unpleasant for companies. They may affect corporate profitability both negatively and positively. Hence, investors who trace companies' news and fundamental conditions react, and the closing price probably encounters volatility. Therefore, the common trend of several stocks may fluctuate. This research investigates how investors in the stock market should form their investment portfolio to see the minor losses when disruptions occur and take advantage of the potential provided profitability by turning threats into opportunities. A three-step framework is presented to achieve this goal. A prerequisite for this framework is the collection of relevant data. Ten stocks from distinct industries of the Securities and Exchange Organization of Iran are chosen for the examination. In the first step, multi-variate regression analysis categorizes selected stocks into the most and the least affected groups. At the same time, a comprehensive technical analysis is involved in this step. Then, in the second step, three well-known machine learning techniques, namely, stacked long short-term memory (Stacked LSTM), autoregressive integrated moving average (ARIMA), and Prophet, are compared from the point of view of predicting future closed prices of selected stocks. The method with the most minor statistical error in forecasting, i.e., root mean squared error (RMSE) and validation loss, estimates the next month's closed prices. Finally, based on the predicted closed prices, the third step empowers the investor to optimize their portfolio in different scenarios, containing various investment weights on the two obtained groups of the first step, using the Markowitz Modern Portfolio Theory. The COVID-19 pandemic and currency risk are the two examined real case studies to validate the proposed methodology. Numerical results based on the Sharp Ratio show the superiority of investing 75 percent of an asset in the most affected stocks and the rest in the least affected stocks in the case of a pandemic and vice versa for the case of currency risk, which reveals that according to the unique features of disruptions investors can benefit from both categories of stocks.",2024
The Weighted Tardiness as objective function of a RNN model for the Job Scheduling Problem,"This paper proposes a Neural Network approach for the project portfolio management problem. The modern organizations such as the IT firms schedule and perform a set of projects that share common rare resources. Therefore, each IT organization develops a set of IT projects and it has to execute them simultaneously. In this work we reviewed the literature and extended a multi-objective system model based on the job shop scheduling problem modelling and expressed it as recurrent neural network. Moreover, we produced an example within its neural network that is focused on the Weighted Tardiness objective function. In addition, we use an initial solution by amending a greedy algorithm that has been proposed in a previous work for the Makespan objective function.",2012
MAPS: Multi-agent Reinforcement Learning-based Portfolio Management System,"Generating an investment strategy using advanced deep learning methods in stock markets has recently been a topic of interest. Most existing deep learning methods focus on proposing an optimal model or network architecture by maximizing return. However, these models often fail to consider and adapt to the continuously changing market conditions. In this paper, we propose the Multi-Agent reinforcement learning-based Portfolio management System (MAPS). MAPS is a cooperative system in which each agent is an independent investor creating its own portfolio. In the training procedure, each agent is guided to act as diversely as possible while maximizing its own return with a carefully designed loss function. As a result, MAPS as a system ends up with a diversified portfolio. Experiment results with 12 years of US market data show that MAPS outperforms most of the baselines in terms of Sharpe ratio. Furthermore, our results show that adding more agents to our system would allow us to get a higher Sharpe ratio by lowering risk with a more diversified portfolio.",2020
Transmission theory of the risk neural network,"On the basis of general project risk element transmission theory, in order to consider an effective solution of portfolio selection problem. This research proposed a new neural network model: Risk Neural Network model. Based on artificial neural network model analysis, we introduced three computational rules: analysis, weighted and polymerization in Risk Neural Network. By solving the hidden layer of random variables characteristic Junction, a series of definitions were built in Risk Neural Network, including feed-forward risk neural network model and muti-hidden layer risk neural network model. According to the series of definitions, we divided risk elements into discrete model and continuous model to be discussed separately, eventually the analytical model of Risk Neural Network was built. The interactive approach was illustrated with a practical example.",2007
BP adds to solvent portfolio,,1997
An Empirical Study of Stock Return and Investor Sentiment Based on Text Mining and LSTM,"Based on the development of social network and big data, we adopt the unstructured text-based investors' comment data mining from the stock bar forum, and use long short-term memory neural network for text sentiment analysis to build a more accurate investor sentiment indicator. Based on this indicator, an empirical study on the component stocks of the GEM Composite Index is conducted to explore the impact of investor sentiment on stock return. Through a full sample stock selection test, we find that the performance of the portfolio based on investor sentiment indicator performs significantly better than the benchmark. Further more, compared with the basic Fama-French three factor model, the goodness of fit and significance of the asset pricing model with investor sentiment factor added are both improved, indicating that the investor sentiment index we constructed can capture the investors' sentiment in the market well, and has a good explanatory power for stock return.",2019
Forecasting realized volatility using deep learning quantile function,"The accurate prediction of realized volatility is an essential component of effective investment strategies. Existing studies have often focused on modeling selective features of intraday return series, overlooking the comprehensive information embedded within them due to challenges such as microstructure noise and the complexity of handling numerous data points. To address these limitations, this paper proposes a novel deep learning quantile function (DLQF) framework that directly leverages intraday return series to forecast realized volatility. The proposed model integrates a Bi-LSTM network to capture the long memory of realized volatility and a quantile function implemented as a deep neural network to extract rich information from intraday returns. A loss function based on Lp distance measures is defined to estimate the probabilistic distribution of intraday returns, enabling both intraday return prediction and realized volatility estimation. Empirical results demonstrate that DLQF outperforms traditional benchmarks across major ETFs, including SPY, DIA, and QQQ, which represent the S&P 500, Dow Jones Industrial Average, and Nasdaq 100, respectively. This model offers significant potential for applications in portfolio optimization, option pricing, and risk management.",2025
RETRACTED: Construction of business strategic planning structure model based on deep learning algorithm (Retracted Article),"This article analyzes the factors that affect business strategy. Based on the deep learning algorithm, we obtain a three-dimensional analytical framework of business strategy portfolio from the perspective of policy tools, policy objectives, and policy strength. It measures the characteristics of the business strategy portfolio from three aspects of comprehensiveness, consistency, and balance, and an improved deep learning analysis method is used to measure the impact of policy combination characteristics on business strategy effects, and then to clarify the effects of different types of business strategy combinations. The results concluded that there are significant differences in the effects of the business strategy portfolio characteristics. The macroeconomic effects of the combination of policy tools are simulated and analyzed, and the differences in their effects under different policy objectives and policy strengths are compared and analyzed. The prediction accuracy of the model reaches 98.57%.",2023
An improved large-scale sparse multi-objective evolutionary algorithm using unsupervised neural network,"Large-scale sparse multi-objective optimization problems (LSSMOPs) widely exist in the real world, such as portfolio optimization, neural network training problems, and so on. In recent years, a number of multi-objective optimization evolutionary algorithms (MOEAs) have been proposed to deal with LSSMOPs. To improve the search efficiency of the operator, using unsupervised neural networks to reduce the search space is one of the dimensionality reduction methods in sparse MOEAs. However, it is not efficient enough that existing algorithms using neural networks consume much time to train networks in each evolutionary generation. In addition, most sparse MOEAs ignore the relationship between binary vectors and real vectors, which determine the decision variables. Thus, this paper proposes an evolutionary algorithm for solving LSSMOPs. The proposed algorithm adopts an adaptive dimensionality reduction method to achieve a balance between convergence and efficiency. The algorithm groups the binary vectors and adaptively uses a restricted Boltzmann machine to reduce the search space of binary vectors. Then, the generation of real vectors is guided by binary vectors, which enhance the relationship between both parts of the decision variables. According to the experimental results on eight benchmark problems and neural network training problems, the proposed algorithm achieves better performance than existing state-of-the-art evolutionary algorithms for LSSMOPs.",2023
A NOTE ON NUMERICAL METHODS FOR MEAN-VARIANCE PORTFOLIO SELECTION WITH DYNAMIC ATTENTION BEHAVIOR IN A HIDDEN MARKOV MODEL,"In this paper, we present some numerical methods for solving a mean-variance portfolio selection problem. Specifically, we study closed-loop equilibrium strategies for mean-variance portfolio selection problem in a hidden Markov model with the dynamic attention behavior. In addition to the investment strategy, the investor's attention to news is introduced as a control of the accuracy of the news signal process. The main objective of this paper is to find equilibrium strategies by numerically solving an extended HJB equation using the classical Markov chain approximation method, the deep learning method, and the hybrid deep learning Markov chain approximation method. Finally, a numerical example is provided to compare the performance of the proposed three numerical methods.",2025
RNN Modelling for Bi-objective MPM Job Shop Scheduling Problem,"This paper presents a Recurrent Neural Network approach for the multipurpose machines Job Shop Scheduling Problem. This case of JSSP can be utilized for the modelling of project portfolio management besides the well known adoption in factory environment. Therefore, each project oriented organization develops a set of projects and it has to schedule them as a whole. In this work, we extended a bi-objective system model based on the JSSP modelling and formulated it as a combination of two recurrent neural networks. In addition, we designed an example within its neural networks that are focused on the Makespan and the Total Weighted Tardiness objectives. Moreover, we present the findings of our approach using a set of well known benchmark instances and the discussion about them and the singularity that arises.",2013
RETRACTED: Exchange Rate Forecasting Based on Deep Learning and NSGA-II Models (Retracted Article),"Today, the global exchange market has been the world's largest trading market, whose volume could reach nearly 5.345 trillion US dollars, attracting a large number of investors. Based on the perspective of investors and investment institutions, this paper combines theory with practice and creatively puts forward an innovative model of double objective optimization measurement of exchange forecast analysis portfolio. To be more specific, this paper proposes two algorithms to predict the volatility of exchange, which are deep learning and NSGA-II-based dual-objective measurement optimization algorithms for the exchange investment portfolio. Compared with typical traditional exchange rate prediction algorithms, the deep learning model has more accurate results and the NSGA-II-based model further optimizes the selection of investment portfolios and finally gives investors a more reasonable investment portfolio plan. In summary, the proposal of this article can effectively help investors make better investments and decision-making in the exchange market.",2021
A data-centric strategy to improve performance of automatic pavement defects detection,"An integrated data -centric portfolio is presented in this work to tailor the performance of the deep learning method. The proposed portfolio includes attention mechanisms, feature -enabled image augmentation strategy, and orthogonal test -based parameter fine-tuning. It focuses on improving the quality and diversity of the data without changing the architecture of the model. The results show that by embedding attention modules into the deep learning -based model, the mAP50 is increased by 3.1% compared to the benchmark. A Class -Specific Image Augmentation (CSIA) method is proposed to work as an optimism strategy for quantifying the number of generated images for each distress. It outperforms augmenting images for all distresses equally which has been widely used in many studies. An orthogonal test method is introduced to decrease the training time for parameter fine-tuning. With the proposed data -centric portfolio, mAP50 of the YOLOv5s model is significantly improved from 0.594 to 0.818.",2024
Does inclusion of GARCH variance in deep learning models improve financial contagion prediction?,"Financial contagions have traditionally been studied using GARCH models to explain the vola-tility, whereas regression models have been used to predict the stock index values based on different underlying assets. Past research has shown that deep learning regression models have demonstrated superiority over traditional statistical models. This paper creates a hybrid predic-tion model by using the outputs of GARCH models as an input variable in deep learning regression models. It has been observed that hybrid models provide better results as compared to deep learning models. Such improved prediction shall provide portfolio managers an additional tool to determine the investment strategy.",2023
Exploring the Generalizability of Deep Convolutional Neural Networks for Post-Hurricane Damage Assessment,"Research on artificial intelligence (AI) and aerial imaging technologies has led to new opportunities in large-scale damage assessment for disaster management. As in other domains, the quality of AI predictions in disaster damage assessment primarily depends on the size, quality, and heterogeneity of training data. However, each disaster leaves behind a unique visual pattern of destruction that is influenced by both the intrinsic properties of the event (e.g., wind speed of a hurricane, ground acceleration of an earthquake) and the characteristics of the location it is taking place (e.g., building portfolio, terrain, vegetation cover). This makes the development and assessment of AI models for universal damage assessment extremely challenging, as the size and feature space of data collected from each disaster is distinctive. This study aims to evaluate and benchmark the generalizability of a damage assessment AI model across different hurricane events. The model is a stacked convolutional neural network (CNN) that is initially trained on aerial videos from Hurricane Dorian (2019) but is tested without retraining on unseen videos of several hurricanes in the 2017 season, including Harvey, Maria, and Irma. The testing accuracy and the square of Earth Mover's Distance (EMD2) values are used to evaluate the model generalizability. Overall, the model achieves 36.7% precision in detecting buildings and 43.1% accuracy in damage level classification. Additionally, EMD2 is found to be negatively correlated with accuracy. Results also indicate that the model generally has a better performance in predicting extreme ground truth labels (i.e., no damaged or destroyed buildings). This behavior is expected and consistent with how human annotators label buildings for damage since humans find these extreme cases more straightforward to label than cases where buildings have suffered intermediate damage levels.",2022
A Deep Deterministic Policy Gradient-based Strategy for Stocks Portfolio Management,"With the improvement of computer performance and the development of GPU-accelerated technology, trading with machine learning algorithms has attracted the attention of many researchers and practitioners. In this research, we propose a novel portfolio management strategy based on the framework of Deep Deterministic Policy Gradient, a policy-based reinforcement learning framework, and compare its performance to that of other trading strategies. In our framework, two Long Short-Term Memory neural networks and two fully connected neural networks are constructed. We also investigate the performance of our strategy with and without transaction costs. Experimentally, we choose eight US stocks consisting of four low-volatility stocks and four high-volatility stocks. We compare the compound annual return rate of our strategy against seven other strategies, e.g., Uniform Buy and Hold, Exponential Gradient and Universal Portfolios. In our case, the compound annual return rate is 14.12%, outperforming all other strategies. Furthermore, in terms of Sharpe Ratio (0.5988), our strategy is nearly 33% higher than that of the second-best performing strategy.",2021
Generative Meta-Learning Robust Quality-Diversity Portfolio,"This paper proposes a novel meta-learning approach to optimize a robust portfolio ensemble. The method uses a deep generative model to generate diverse and high-quality sub-portfolios combined to form the ensemble portfolio. The generative model consists of a convolutional layer, a stateful LSTM module, and a dense network. During training, the model takes a randomly sampled batch of Gaussian noise and outputs a population of solutions, which are then evaluated using the objective function of the problem. The weights of the model are updated using a gradient-based optimizer. The convolutional layer transforms the noise into a desired distribution in latent space, while the LSTM module adds dependence between generations. The dense network decodes the population of solutions. The proposed method balances maximizing the performance of the sub-portfolios with minimizing their maximum correlation, resulting in a robust ensemble portfolio against systematic shocks. The approach was effective in experiments where stochastic rewards were present. Moreover, the results (Fig. 1) demonstrated that the ensemble portfolio obtained by taking the average of the generated sub-portfolio weights was robust and generalized well. The proposed method can be applied to problems where diversity is desired among co-optimized solutions for a robust ensemble. The source-codes and the dataset are in the supplementary material.",2023
Time-varying minimum-cost portfolio insurance problem via an adaptive fuzzy-power LVI-PDNN,"It is well known that minimum-cost portfolio insurance (MPI) is an essential investment strategy. This article presents a time-varying version of the original static MPI problem, which is thus more realistic. Then, to solve it efficiently, we propose a powerful recurrent neural network called the linear-variational-inequality primal-dual neural network (LVIPDNN). By doing so, we overcome the drawbacks of the static approach and propose an online solution. In order to improve the performance of the standard LVI-PDNN model, an adaptive fuzzy-power LVI-PDNN (F-LVI-PDNN) model is also introduced and studied. This model combines the fuzzy control technique with LVI-PDNN. Numerical experiments and computer simulations confirm the F-LVI-PDNN model's superiority over the LVI-PDNN model and show that our approach is a splendid option to accustomed MATLAB procedures.",2023
Intelligent Asset Allocation via Market Sentiment Views,"The sentiment index of market participants has been extensively used for stock market prediction in recent years. Many financial information vendors also provide it as a service. However, utilizing market sentiment under the asset allocation framework has been rarely discussed. In this article, we investigate the role of market sentiment in an asset allocation problem. We propose to compute sentiment time series from social media with the help of sentiment analysis and text mining techniques. A novel neural network design, built upon an ensemble of evolving clustering and long short-term memory, is used to formalize sentiment information into market views. These views are later integrated into modern portfolio theory through a Bayesian approach. We analyze the performance of this asset allocation model from many aspects, such as stability of portfolios, computing of sentiment time series, and profitability in our simulations. Experimental results show that our model outperforms some of the most successful forecasting techniques. Thanks to the introduction of the evolving clustering method, the estimation accuracy of market views is significantly improved.",2018
Convolutional neural networks automate detection for tracking of submicron-scale particles in 2D and 3D,"Particle tracking is a powerful biophysical tool that requires conversion of large video files into position time series, i.e., traces of the species of interest for data analysis. Current tracking methods, based on a limited set of input parameters to identify bright objects, are ill-equipped to handle the spectrum of spatiotemporal heterogeneity and poor signal-to-noise ratios typically presented by submicron species in complex biological environments. Extensive user involvement is frequently necessary to optimize and execute tracking methods, which is not only inefficient but introduces user bias. To develop a fully automated tracking method, we developed a convolutional neural network for particle localization from image data, comprising over 6,000 parameters, and used machine learning techniques to train the network on a diverse portfolio of video conditions. The neural network tracker provides unprecedented automation and accuracy, with exceptionally low false positive and false negative rates on both 2D and 3D simulated videos and 2D experimental videos of difficult-to-track species.",2018
Automated building classification framework using convolutional neural network,"Despite extensive study, performing Rapid visual screening is still a challenging task for many countries. The challenges include the lack of trained engineers, limited resources, and a large building inventory to detect. One of the most important aspect in rapid visual screening is to establish the building classification based on the guidelines' specific criteria. This study proposes a general framework based on Convolutional Neural Network to perform automated building classification for the rapid visual screening procedure. The method classifies buildings based on the Federal Emergency Management Agency (FEMA)-154 guidelines and uses transfer learning techniques from a pre-trained network. The Indonesian building portfolio is used as a case study and a dataset of building images generated through web-scraping on Google Search (TM) engines and Google StreetView (TM) website is used for the method validation. Results show that the proposed framework has promising potential to automate the building classification based on FEMA-154 guidelines.",2022
WDM equipped universal linear optics for programmable neuromorphic photonic processors,"Non-von-Neumann computing architectures and deep learning training models have sparked a new computational era where neurons are forming the main architectural backbone and vector, matrix and tensor multiplications comprise the basic mathematical toolbox. This paradigm shift has triggered a new race among hardware technology candidates; within this frame, the field of neuromorphic photonics promises to convolve the targeted algebraic portfolio along a computational circuitry with unique speed, parallelization, and energy efficiency advantages. Fueled by the inherent energy efficient analog matrix multiply operations of optics, the staggering advances of photonic integration and the enhanced multiplexing degrees offered by light, neuromorphic photonics has stamped the resurgence of optical computing brining a unique perspective in low-energy and ultra-fast linear algebra functions. However, the field of neuromorphic photonics has relied so far on two basic architectural schemes, i.e., coherent linear optical circuits and incoherent WDM approaches, where wavelengths have still not been exploited as a new mathematical dimension. In this paper, we present a radically new approach for promoting the synergy of WDM with universal linear optics and demonstrate a new, high-fidelity crossbar-based neuromorphic photonic platform, able to support matmul with multidimensional operands. Going a step further, we introduce the concept of programmable input and weight banks, supporting in situ reconfigurability, forming in this way the first WDM-equipped universal linear optical operator and demonstrating different operational modes like matrix-by-matrix and vector-by-tensor multiplication. The benefits of our platform are highlighted in a fully convolutional neural network layout that is responsible for parity identification in the MNIST handwritten digit dataset, with physical layer simulations revealing an accuracy of & SIM;94%, degraded by only 2% compared to respective results obtained when executed entirely by software. Finally, our in-depth analysis provides the guidelines for neuromorphic photonic processor performance improvement, revealing along the way that 4 bit quantization is sufficient for inputs, whereas the weights can be implemented with as low as 2 bits of precision, offering substantial benefits in terms of driving circuitry complexity and energy savings.",2022
Hesitant fuzzy linguistic portfolio model with variable risk appetite and its application in the investment ratio calculation,"Qualitative evaluation information is important for financial decision-making and investment when quantitative data are unavailable. Although an alternative ranking is available, specific portfolio and optimal investment ratios cannot be obtained by using the qualitative decision-making methods. To address this issue, this paper proposes a hesitant fuzzy linguistic portfolio model based on the max-score rule and the hesitant fuzzy linguistic element with variable risk appetite (HFLE-RA). The HFLE-RA is able to express qualitative evaluation information by using the hesitant fuzzy linguistic term set and describe the variable investor risk appetites by introducing the asymmetric sigmoid semantics. Thus, different investors can be distinguished by the risk appetite parameters according to the asymmetric sigmoid semantics, and the optimal investment ratios can be obtained by applying the proposed portfolio model. Moreover, the investment opportunities and efficient frontiers of the hesitant fuzzy linguistic portfolio model are investigated. Also, a value-at-risk fitting approach is introduced to calculate the risk appetite parameters. Based on these works, a qualitative investment ratio calculation process is provided in the HFLE-RA environment. Lastly, a real example of calculating the optimal investment ratios for four newly listed stocks in the Growth Enterprises Market board of the Shenzhen Stock Exchange is provided to demonstrate the proposed approaches. (C) 2019 Elsevier B.V. All rights reserved.",2019
Diffusion Variational Autoencoder for Tackling Stochasticity in Multi-Step Regression Stock Price Prediction,"Multi-step stock price prediction over a long-term horizon is crucial for forecasting its volatility, allowing financial institutions to price and hedge derivatives, and banks to quantify the risk in their trading books. Additionally, most financial regulators also require a liquidity horizon of several days for institutional investors to exit their risky assets, in order to not materially affect market prices. However, the task of multi-step stock price prediction is challenging, given the highly stochastic nature of stock data. Current solutions to tackle this problem are mostly designed for single-step, classification-based predictions, and are limited to low representation expressiveness. The problem also gets progressively harder with the introduction of the target price sequence, which also contains stochastic noise and reduces generalizability at test-time. To tackle these issues, we combine a deep hierarchical variational-autoencoder (VAE) and diffusion probabilistic techniques to do seq2seq stock prediction through a stochastic generative process. The hierarchical VAE allows us to learn the complex and low-level latent variables for stock prediction, while the diffusion probabilistic model trains the predictor to handle stock price stochasticity by progressively adding random noise to the stock data. To deal with the additional stochasticity in the target price sequence, we also augment the target series with noise via a coupled diffusion process. We then perform a denoising process to clean the prediction outputs that were trained on the stochastic target sequence data, which increases the generalizability of the model at test-time. Our Diffusion-VAE (D-Va) model is shown to outperform state-of-the-art solutions in terms of its prediction accuracy and variance. Through an ablation study, we also show how each of the components introduced helps to improve overall prediction accuracy by reducing the data noise. Most importantly, the multi-step outputs can also allow us to form a stock portfolio over the prediction length. We demonstrate the effectiveness of our model outputs in the portfolio investment task through the Sharpe ratio metric and highlight the importance of dealing with different types of prediction uncertainties. Our code can be accessed through https://github.com/koa-fin/dva.",2023
A survey of deep learning applications in cryptocurrency,"This study aims to comprehensively review a recently emerging multidisciplinary area related to the application of deep learning methods in cryptocurrency research. We first review popular deep learning models employed in multiple financial application scenarios, including convolutional neural networks, recurrent neural networks, deep belief networks, and deep reinforcement learning. We also give an overview of cryptocurrencies by outlining the cryptocurrency history and discussing primary representative currencies. Based on the reviewed deep learning methods and cryptocurrencies, we conduct a literature review on deep learning methods in cryptocurrency research across various modeling tasks, including price prediction, portfolio construction, bubble analysis, abnormal trading, trading regulations and initial coin offering in cryptocurrency. Moreover, we discuss and evaluate the reviewed studies from perspectives of modeling approaches, empirical data, experiment results and specific innovations. Finally, we conclude this literature review by informing future research directions and foci for deep learning in cryptocurrency.",2024
Investigation into a University Electronic Portfolio System Using Activity Theory,"The last few years have seen an enormous growth of interest in e-portfolios and the benefits they can bring to learners. While it is generally agreed that e-portfolios have great potential to engage students and promote deep learning, the research that has been conducted to date focuses very little on student perceptions of value of the e-portfolio for their learning. If students do not agree or wish to use the e-portfolio as an integral part of their educational experience, then the potential impact the e-portfolio have on learning will not be realised. This paper describes the development of an e portfolio system to promote reflective skills for engineering students in a university in Malaysia. The Activity Theory is used as a lens to explain the reasons for the failed adoption of the e portfolio system.",2013
RELU special issue: Editorial reflections,"This special issue is special in two major dimensions: the papers range intentionally over a much wider spectrum of social and natural science approaches and disciplines than is normal for the Journal of Agricultural Economics; and, the articles relate to ongoing research rather than completed work. These reflections, perhaps peculiar to a practicing applied economist and policy analyst, concentrate on the lessons to be learned and messages to be heard from the RELU programme, both by those engaged on the programme's research portfolio, and by other researchers.",2006
Text-mining approach with Black-Litterman model: A case study of Armenian pension funds,"Pension fund managers face challenges in acquiring, analysing, and synthesising external information to make informed investment decisions. Text-mining and sentiment analysis can aid fund managers integrate contrasting news, financial data, and market speculation into their decision rubric. Considering Armenia pension funds as the research object, we perform sentiment analysis on Yahoo Finance data, transform the information into numerical data, add confidence weights, and apply the Black-Litterman model using supervised deep learning to predict how information affects portfolio management. Our method using the Black-Litterman model is practical to quantify how external information impacts on fund portfolio management, and using the method leads to an increase in portfolio performance.",2024
Strategies for Integrating Deep Learning Surrogate Models with HPC Simulation Applications,"The emerging trend of the convergence of high performance computing (HPC), machine learning/deep learning (ML/DL), and big data analytics presents a host of challenges for large-scale computing campaigns that seek best practices to interleave traditional scientific simulation-based workloads with ML/DL models. A portfolio of systematic approaches to incorporate deep learning into modeling and simulation serves a vital need when we support AI for science at a computing facility. In this paper, we evaluate several strategies for deploying deep learning surrogate models in a representative physics application on supercomputers at the Oak Ridge Leadership Computing Facility (OLCF). We discuss a set of recommended deployment architectures and implementation approaches. We analyze and evaluate these alternatives and show their performance and scalability up to 1000 GPUs on two mainstream platforms equipped with different deep learning hardware and software stacks.",2022
Robust Portfolio Selection Under Model Ambiguity Using Deep Learning,"In this study, we address the ambiguity in portfolio optimization, particularly focusing on the uncertainty related to the statistical parameters governing asset returns. We propose a novel method that combines robust optimization with artificial neural networks (ANNs). Our approach effectively handles both the randomness inherent in asset prices and the ambiguity in their governing parameters. Through our method, we consider both simulated data, using the Exponential Ornstein-Uhlenbeck process, and real-world stock price data. The results showcase that our ANN-based method outperforms traditional benchmark methods such as equally weighted portfolio and adaptive mean-variance portfolio selection.",2025
Improving REITs Time Series Prediction Using ML and Technical Analysis Indicators,"One of the most popular ways to reduce the risk of an investment portfolio is by holding shares of Real Estate Investment Trusts (REITs), which own and manage real estate. An important aspect of this process is to be able to forecast future REITs prices, as this allows investors to achieve higher returns at lower risk. This paper examines the performance of five different machine learning algorithms in the task of REITs price forecasting: Ordinary Least Squares Linear Regression, Support Vector Regression, k-Nearest Neighbours Regression, Extreme Gradient Boosting, and Long/Short-Term Memory Neural Networks. In addition to past REITs prices, we also use Technical Analysis indicators to assist the algorithms in the task of price prediction. While such indicators are very popular in stocks forecasting, they have never been used to forecast REITs. Our experiments show that (i) all ML algorithms produce low error and standard deviation, and are able to outperform the well-known statistical benchmark of AutoRegressive Integrated Moving Average (ARIMA), and (ii) the introduction of Technical Analysis (TA) indicators into the feature set leads to an error reduction of up to 50%.",2023
STGAT: Spatial-Temporal Graph Attention Neural Network for Stock Prediction,"Stock price prediction and portfolio optimization are critical research areas in financial markets, as they directly impact investment strategies and risk management. Traditional statistical methods and machine learning approaches have been widely applied to these tasks, but they often fail to fully capture the complex dynamics of financial markets. Traditional statistical methods typically rely on unrealistic assumptions or oversimplified models, neglecting the nonlinear and high-dimensional characteristics of market data. Additionally, deep learning methods, especially temporal convolution networks and graph attention networks, have been introduced in this area and have achieved significant improvements in both stock price prediction and portfolio optimization. Therefore, this study proposes a Spatial-Temporal Graph Attention Network (STGAT) that integrates STL decomposition components and graph structures to model both temporal patterns and asset correlations. By combining graph attention mechanisms with temporal convolutional modules, STGAT effectively processes spatiotemporal data, enhancing the accuracy of stock price predictions. Empirical experiments on the CSI 500 and S&P 500 datasets demonstrate that STGAT outperforms other deep learning models in both prediction accuracy and portfolio performance. The investment portfolios constructed based on STGAT's predictions achieve higher returns in real market scenarios, which validates the feasibility of spatiotemporal feature fusion for stock price prediction and highlights the advantages of graph attention networks in capturing complex market characteristics. This study not only provides a robust tool for portfolio optimization but also offers valuable insights for future research in intelligent financial systems.",2025
FINANCIAL TIME SERIES PREDICTION MODEL BASED RECURRENT NEURAL NETWORK,"Financial time series prediction is usually considered as one of the most difficult challenges because of huge external factors, which are usually stochastic and sensitive so that we can hardly recognize the patterns from historical information. Besides, traditional time series prediction models cannot adapt to the changes in financial circumstances. To overcome these problems, we design a prediction model based on recurrent neural network with gating units, which can learn historical information and adapt the market changes through a specific inner structure. Experiments carried on the Shanghai Securities Composite Index show that the prediction results of our model have more competitive performance compared to those of other traditional models. Our model has good interpretability, and the effects of model hyperparameters on prediction accuracy are also analyzed. On the basis, we proceed with the long-term trend analysis and estimate precisely the tipping points of the stock market. These results give application prospects in risk assessment and portfolio management for the finance industry.",2020
An Asynchronous Advantage Actor-Critic Reinforcement Learning Method for Stock Selection and Portfolio Management,"Computation finance has been a classical field that uses computer techniques to handle financial challenges. The most popular domains include financial forecast and portfolio management. They often involve large datasets with complex relations. Due to the special properties of computation finance problems, machine learning techniques, especially deep learning techniques, are widely used as the quantitative analysis tool. In this paper, we try to apply the state-of-art Asynchronous Advantage Actor-Critic algorithm to solve the portfolio management problem and design a standalone deep reinforcement learning model. In the simulated market environment with practical portfolio constrain settings, asset value managed by the proposed machine learning model largely outperforms S&P500 stock index in the test period.",2018
Improving the state-of-the-art in the Traveling Salesman Problem: An Anytime Automatic Algorithm Selection,"This work presents a new metaheuristic for the euclidean Traveling Salesman Problem (TSP) based on an Anytime Automatic Algorithm Selection model using a portfolio of five state-of-the-art solvers. We introduce a new spatial representation of nodes, in the form of a matrix grid, avoiding costly calculation of features. Furthermore, we use a new compact staggered representation for the ranking of algorithms at each time step. Then, we feed inputs (matrix grid) and outputs (staggered representation) into a classifying convolutional neural network to predict the ranking of the solvers at a given time. We use the available datasets for TSP and generate new instances to augment their number, reaching 6,689 instances, distributed into training and test sets. Results show that the time required to predict the best solver is drastically reduced in comparison to previous traditional feature selection and machine learning methods. Furthermore, the prediction can be obtained at any time and, on average, the metasolver is better than running all the solvers separately on all the datasets, obtaining 79.8% accuracy.",2022
Data-driven modelling of fully nonlinear wave loads on offshore wind-turbine monopiles at prototype scale,"Offshore wind energy constitutes a vital component of the renewable energy portfolio, and accurate and efficient prediction of nonlinear wave loads on monopile foundations is critical for ensuring structural integrity and prolonging wind turbines' operational lifespans. Unlike large-volume marine structures, third-order and higher wave loading is important for such slender structures due to ringing response. Traditional approaches, such as the numerical wave tank based on the fully nonlinear potential flow theory and computational fluid dynamics (CFD), are often computationally expensive. This paper proposes data-driven approaches to model nonlinear wave loads using machine learning (ML) techniques. These approaches offer substantial reductions in computational cost while maintaining reasonable predictive accuracy for high-order wave loadings under a range of wave conditions. Two ML-based models are developed and trained based on high-fidelity CFD data to capture linear and nonlinear wave load components, where the CFD data are classified into clusters using the K-means algorithm, an unsupervised clustering technique to optimise the dataset. A representative subset of data is selected from each cluster to construct the training and testing datasets for the ML models, ensuring that sufficient patterns are captured to facilitate model training and generalisation. The first ML model implements a hybrid approach to predicting the nonlinear wave load in the time domain. It combines a physics-based linear predictor for the inline force with a long short-term memory (LSTM) predictor to estimate the residual between the linear model and CFD results. The second model adopts the spirit of reduced-order modelling by predicting the fundamental and higher-order harmonics of the nonlinear wave load in the frequency domain, which are subsequently reconstructed into the time domain. A comparative study of the two models reveals that the second ML-based approach is more robust for the present application, eliminating the trade-off between overfitting and underfitting high-frequency oscillations, an inherent issue in the first model. We also compare the performance of the ML model with the FNV wave load model (Faltinsen et al., 1995; Kristiansen and Faltinsen, 2017). The proposed ML model is applied to predict nonlinear wave loads under various wave conditions, and the variation of maximum force and force nonlinearity is investigated.",2025
BP Amoco adds to US gas portfolio,,1999
BP Amoco begins huge portfolio clear-out,,1999
Bias-regularised Neural-Network Metamodelling of Insurance Portfolio Risk,"Deep learning models have attracted considerable attention in metamodelling of financial risks for large insurance portfolios. Those models, however, are generally trained in disregard of the collective nature of the data in the portfolio under study. Consequently, the training procedure often suffers from slow convergence, and the trained model often has poor accuracy. This is particularly evident in the presence of extreme individual contracts. In this paper, we advocate the view that the training of a meta-model for a portfolio should be guided by portfolio-level metrics. In particular, we propose an intuitive loss regulariser that explicitly accounts for the portfolio-level bias. Further, this training regulariser can be easily implemented with the minibatch stochastic gradient descent commonly used in training deep neural networks. Empirical evaluations on both simulated data and a benchmark dataset show that the regulariser yields more stable training, resulting in faster convergence and more reliable portfolio-level risk estimates.",2020
How to make machine select stocks like fund managers? Use scoring and screening model,"With the development of technology and the abundance of data, many novel methods like artificial intelligence and machine learning have emerged for quantitative finance. This work tries to build a framework with screening function to help investors create a portfolio of stocks based on data from multiple sources, including historical trading data, factor data, financial data and media data. The framework integrates scoring and screening models. The scoring model consists of Seq2Seq model using historical trading data and a factor model using a new bottom-up discretization method while the screening model is composed of a novel discriminative model and a media model based on the weighted stock relation graph. Two types of model are fused to select portfolio with screening ability. This framework has been verified in China's A-share market, and is proved to be effective. We also noticed that the fused model is sensitive to the scale of selected stocks and the length of prediction period, which means it can be quickly adjusted according to our trading strategy.",2022
Portfolio management system in equity market neutral using reinforcement learning,"Portfolio management involves position sizing and resource allocation. Traditional and generic portfolio strategies require forecasting of future stock prices as model inputs, which is not a trivial task since those values are difficult to obtain in the real-world applications. To overcome the above limitations and provide a better solution for portfolio management, we developed a Portfolio Management System (PMS) using reinforcement learning with two neural networks (CNN and RNN). A novel reward function involving Sharpe ratios is also proposed to evaluate the performance of the developed systems. Experimental results indicate that the PMS with the Sharpe ratio reward function exhibits outstanding performance, increasing return by 39.0% and decreasing drawdown by 13.7% on average compared to the reward function of trading return. In addition, the proposed PMS_CNN model is more suitable for the construction of a reinforcement learning portfolio, but has 1.98 times more drawdown risk than the PMS_RNN. Among the conducted datasets, the PMS outperforms the benchmark strategies in TW50 and traditional stocks, but is inferior to a benchmark strategy in the financial dataset. The PMS is profitable, effective, and offers lower investment risk among almost all datasets. The novel reward function involving the Sharpe ratio enhances performance, and well supports resource-allocation for empirical stock trading.",2021
Machine Learning vs. Economic Restrictions: Evidence from Stock Return Predictability,"This paper shows that investments based on deep learning signals extract profitability from difficult-to-arbitrage stocks and during high limits-to-arbitrage market states. In particular, excluding microcaps, distressed stocks, or episodes of high market volatility considerably attenuates profitability. Machine learning-based performance further deteriorates in the presence of reasonable trading costs because of high turnover and extreme positions in the tangency portfolio implied by the pricing kernel. Despite their opaque nature, machine learning methods successfully identify mispriced stocks consistent with most anomalies. Beyond economic restrictions, deep learning signals are profitable in long positions and recent years and command low downside risk.",2023
Reinforcement learning for deep portfolio optimization,"Portfolio optimization is an important financial task that has received widespread attention in the field of artificial intelligence. In this paper, a novel deep portfolio optimization (DPO) framework was proposed, combining deep learning and reinforcement learning with modern portfolio theory. DPO not only has the advantages of machine learning methods in investment decision-making, but also retains the essence of modern portfolio theory in portfolio optimization. Additionaly, it was crucial to simultaneously consider the time series and complex asset correlations of financial market information. Therefore, in order to improve DPO performance, features of assets information were extracted and fused. In addition, a novel risk-cost reward function was proposed, which realized optimal portfolio decision-making considering transaction cost and risk factors through reinforcement learning. Our results showed the superiority and generalization of the DPO framework for portfolio optimization tasks. Experiments conducted on two real-world datasets validated that DPO achieved the highest accumulative portfolio value compared to other strategies, demonstrating strong profitability. Its Sharpe ratio and maximum drawdown also performed excellently, indicating good economic benefits and achieving a trade-off between portfolio returns and risk. Additionally, the extraction and fusion of financial information features can significantly improve the applicability and effectiveness of DPO.",2024
A collective portfolio selection approach for investment clubs,"Recently, with the popularity of social investing platforms, participating in an investment club has become a good choice for investors. Following financial experts in the investment club likely generates more profit as they have higher expertise in planning an investment portfolio. In this study, we propose a portfolio selection mechanism that combines collective intelligence extracted from investors' opinions and LSTM stock price predictions to infer a club's investment preference and predict the profitability of the extracted investment targets. Based on a club's risk tolerance and investment preference, the proposed mechanism can create an appropriate stock portfolio for the investors in the club. Utilizing StockTwits and stock historical data, the experimental results verify that the proposed portfolio selection mechanism performs better than market indices and other benchmark approaches in the market.",2024
Deep reinforcement learning for portfolio management,"Portfolio management facilitates trading off risks against returns for multiple financial assets. Reinforcement Learning (RL) is one of the most promising algorithms for portfolio management. However, these state-of-the-art RL algorithms only complete the task of portfolio management, i.e., acquire the different asset features of portfolio, without considering the global context information from portfolio, which leads to non-optimal portfolio representations; Moreover, the corresponding optimizations are implemented using only the loss function in the viewpoint of RL, without considering the relationships between the local asset information and global context embeddings, which leads to non-optimal portfolio policies. To deal with these issues, this paper proposes a Task-Context Mutual Actor-Critic (TC-MAC) algorithm for portfolio management. Specifically, TC-MAC algorithm is developed based on: (1) representation learning introduces a proposed Task-Context (TC) learning algorithm, which not only encodes the task (i.e., acquire different asset features) of portfolio, but also encodes the global dynamic context of portfolio, thus which helps to learn optimal portfolio embeddings; (2) policy learning introduces a proposed Mutual Actor-Critic (MAC) framework, which can measure the relationships between local embedding of each asset and global context embeddings by maximizing mutual information, the corresponding Mutual-Information loss function combines with RL loss function (i.e., Actor-Critic loss) to collectively optimize the whole algorithm, thus which helps to learn optimal portfolio policies. Experimental results on real-world datasets demonstrate the superior performance of TC-MAC algorithm over the well-known traditional portfolio methods and these state-of-the-art RL algorithms, at the same time, show its advantageous transferability. (c) 2023 Elsevier B.V. All rights reserved.",2023
Improving Real Estate Investment Trusts (REITs) time-series prediction accuracy using machine learning and technical analysis indicators,"The primary goal of investors who include Real Estate Investment Trusts (REITs) in their portfolios is to achieve better returns while reducing the overall risk of their investments. REITs are entities responsible for owning and managing real estate properties. To achieve greater returns while reducing risk, it is essential to accurately predict future REIT prices. This study explores the predictive capability of five different machine learning algorithms used to predict REIT prices. These algorithms include Ordinary Least Squares Linear Regression, Support Vector Regression, k-Nearest Neighbours Regression, Extreme Gradient Boosting, and Long/Short-Term Memory Neural Networks. Additionally, historical REIT prices are supplemented with Technical Analysis indicators (TAIs) to aid in price predictions. While TA indicators are commonly used in stock market forecasting, their application in the context of REITs has remained relatively unexplored. The study applied these algorithms to predict future prices for 30 REITs from the United States, United Kingdom, and Australia, along with 30 stocks and 30 bonds. After obtaining our price predictions, we employ a Genetic Algorithm (GA) to optimise weights of a diversified portfolio. Our results reveal several key findings: (i) all machine learning algorithms demonstrated low average and standard deviation values in the error rate distributions, outperforming commonly used statistical benchmarks such as Holt's Linear Trend Method (HLTM), Trigonometric Box-Cox Autoregressive Time Series (TBATS), and Autoregressive Integrated Moving Average (ARIMA); (ii) incorporating Technical Analysis indicators in the ML algorithms resulted in a significant reduction in prediction errors, up to 60% in some cases; and (iii) a multi-asset portfolio constructed using predictions that incorporated Technical Analysis indicators outperformed a portfolio based solely on predictions derived from past prices. Furthermore, this study employed Shapley Value-based techniques, specifically SHAP and SAGE, to analyse the importance of the features used in the analysis. These techniques provided additional evidence of the value added by Technical Analysis indicators in this context.",2025
Deep learning solution to mean field game of optimal liquidation,"This paper addresses optimal portfolio liquidation using Mean Field Games (MFGs) and presents a solution method to tackle high-dimensional challenges. We develop a deep learning approach that employs two sub-networks to approximate solutions to the relevant partial differential equations. Our method adheres to the requirements of differential operators and satisfies both initial and terminal conditions through simultaneous training. A key advantage of our approach is its mesh-free nature, which mitigates the curse of dimensionality encountered in traditional numerical methods. We validate the effectiveness of our approach through numerical experiments on multi-dimensional portfolio liquidation models.",2025
Portfolio optimization with feedback strategies based on artificial neural networks,"Dynamic portfolio optimization has significantly benefited from a wider adoption of deep learning (DL). While existing research has focused on how DL can applied to solving the Hamilton-Jacobi-Bellman (HJB) equation, some very recent developments propose to forego the derivation of HJB in favor of empirical utility maximization over dynamic allocation strategies expressed through artificial neural networks. In addition to simplicity and transparency, this approach is universally applicable, as it is essentially agnostic about market dynamics. We apply it to optimal portfolio allocation between cash account and risky asset following Heston model. The results appear on par with theoretical ones.",2024
Machine and deep learning-based stock price prediction during the COVID-19 pandemic: the case of CAC 40 index,"PurposeThe goal of this study is to investigate the predictive performance of the machine and deep learning methods in predicting the CAC 40 index and its 40 constituent prices of the French stock market during the COVID-19 pandemic. The study objective in forecasting the CAC 40 index is to analyze if the index and the individual prices will preserve the continuous increase they acquired at the beginning of the administration of vaccination and containment measures or if the negative effect of the pandemic will be reflected in the future.Design/methodology/approachThe authors apply two machine and deep learning methods (KNN and LSTM) and compare their performances to ARIMA time series model. Two scenarios have been considered: optimistic (high values) and pessimistic (low values) and four periods are examined: the period before COVID-19 pandemic, the period during the COVID-19, and the period of vaccination and containment. The last period is divided into two sub-periods: the test period and the prediction period.FindingsThe authors found that the KNN method performed better than LSTM and ARIMA in forecasting the CAC 40 index for both scenarios. The authors also identified that the positive effect of vaccination and containment outweighs the negative effect of the pandemic, and the recovery pattern is not even among major companies in the stock market.Practical implicationsThe study empirical results have valuable practical implications for companies in the stock market to respond to unexpected events such as COVID-19, improve operational efficiency and enhance long-term competitiveness. Companies in the transportation sector should consider additional investment in R&D on communication and information technology, accelerate their digital capabilities, at least in some parts of their businesses, develop plans for lights out factories and supply chains to keep pace with changing times, and even include big data resources. Additionally, they should also use a mix of financing sources and securities in order to diversify their capital structure, and not rely only on equity financing as their share prices are volatile and below the pre-pandemic level. Considering portfolio allocation, the transportation sector was severely affected by the pandemic. This displays that transportation equities fail to be a candidate as a good diversifier during the health crisis. However, the diversification would be worth it while including assets related to the banking and industrial sectors. On another strand, the instability of this period induced an informational asymmetry among investors. This pessimistic mood affected the assets' value and created a state of disequilibrium opening up more opportunities to benefit from potential arbitrage profits.Originality/valueThe impact of COVID-19 on stock markets is significant and affects investor behavior, who suffered amplified losses in a very short period of time. In this regard, correct and well-informed decision-making by investors and other market participants requires careful analysis and accurate prediction of the stock markets during the pandemic. However, few studies have been conducted in this area, and those studies have either concentrated on some specific stock markets or did not apply the powerful machine learning and deep learning techniques such as LSTM and KNN. To the best of our knowledge, no research has been conducted that used these techniques to assess and forecast the CAC 40 French stock market during the pandemic. This study tries to close this gap in the literature.",2024
Deep learning for modeling the collection rate for third-party buyers,"This study evaluates a wide range of machine learning techniques such as deep learning, boosting, and support vector regression to predict the collection rate of more than 65,000 defaulted consumer credits from the telecommunications sector that were bought by a German third-party company. Weighted performance measures were defined based on the value of exposure at default for comparing collection rate models. The approach proposed in this paper is useful for a third-party company in managing the risk of a portfolio of defaulted credit that it purchases. The main finding is that one of the machine learning models we investigate, the deep learning model, performs significantly better out-of-sample than all other methods that can be used by an acquirer of defaulted credits based on weighted-performance measures. By using unweighted performance measures, deep learning and boosting perform similarly. Moreover, we find that using a training set with a larger proportion of the dataset does not improve prediction accuracy significantly when deep learning is used. The general conclusion is that deep learning is a potentially performance-enhancing tool for credit risk management. (c) 2021 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved.",2022
Traditional Prediction Techniques and Machine Learning Approaches for Financial Time Series Analysis,"Accurate financial time series forecasting is critical for effective decision making in areas such as risk management, portfolio optimization, and trading. Given the complexity and volatility of financial markets, traditional forecasting methods often fail to capture the underlying dynamics. Recent advances in artificial neural network (ANN) forecasting research indicate that ANNs present a valuable alternative to traditional linear methods, such as autoregressive integrated moving average (ARIMA). However, time series are typically influenced by a combination of factors which require to consider both linear and non-linear characteristics. This paper proposes a new hybrid model that integrates ARIMA and ANN models such as long short-term memory and gated recurrent unit neural network to leverage the distinct strengths of both linear and non-linear modeling. Moreover, the goodness of the proposed model is evaluated through a comparative analysis of the ARIMA, ANN and Zhang hybrid model, using three financial datasets (i.e., Unicredit SpA stock price, EUR/USD exchange rate and Bitcoin closing price). Various absolute and relative error metrics, computed to evaluate the performance of models, can support the use of the proposed approach. The Diebold-Mariano (DM) test is also implemented to asses the significance of the obtained differences of the hybrid model with respect to the other competing models.",2025
Portfolio assessment: direct from the classroom,"Portfolios have been regarded as a means of personal self-expression. This study reports on student real-life experiences with portfolio assessment. The focus group comprised 150 freshmen (100 females) from a small campus of a tertiary educational institution. For two semesters (approximately 30 weeks), students engaged in numerous activities selected to encourage deep learning and understanding of mathematical concepts. Because students were not involved in the experiment, ecological validity was maximised, and observations may be regarded as fairly authentic and worthy of analysis. Generally, students reported learning much from portfolio assessment and felt an integral part of the assessment process. Portfolio assessment appeared to empower students and provide them with the self-respect they desired. Future research could compare results from everyday observations with those from experiments.",2012
Optimization-based spectral end-to-end deep reinforcement learning for equity portfolio management,"We propose a novel approach to equity portfolio optimization that combines spectral analysis and classical equity portfolio optimization theory with deep reinforcement learning in an end- to-end framework. We introduce the End-to-end Frequency Online Deep Deterministic Policy Gradient (EFO-DDPG) algorithm, which leverages discrete Fourier transform to decompose asset return sequences into frequency components. Unlike traditional methods that treat high-frequency components as noise, EFO-DDPG learns to adjust the influence of different frequency components dynamically. Moreover, the algorithm embeds a mean-variance portfolio optimization problem within a deep learning network, enhancing interpretability compared to black-box approaches. The framework models the investment problem as a Partially Observable Markov Decision Process (POMDP), using a state processing block with transformer encoders to capture complex relationships in the market data. By integrating spectral analysis, portfolio optimization theory, and online deep reinforcement learning, EFO-DDPG aims to adapt to non-stationary financial markets and generate superior investment strategies.",2025
Neural network for nonsmooth pseudoconvex optimization with general convex constraints,"In this paper, a one-layer recurrent neural network is proposed for solving a class of nonsmooth, pseudoconvex optimization problems with general convex constraints. Based on the smoothing method, we construct a new regularization function, which does not depend on any information of the feasible region. Thanks to the special structure of the regularization function, we prove the global existence, uniqueness and slow solution'' character of the state of the proposed neural network. Moreover, the state solution of the proposed network is proved to be convergent to the feasible region in finite time and to the optimal solution set of the related optimization problem subsequently. In particular, the convergence of the state to an exact optimal solution is also considered in this paper. Numerical examples with simulation results are given to show the efficiency and good characteristics of the proposed network. In addition, some preliminary theoretical analysis and application of the proposed network for a wider class of dynamic portfolio optimization are included. (c) 2018 Elsevier Ltd. All rights reserved.",2018
Portfolio use in general practice vocational training: a survey of GP registrars,"Background Portfolios are increasingly advocated in medical education. Qualitative studies have suggested their value in stimulating experiential learning, promoting deep learning and encouraging reflection. This study explored the use of educational portfolios in reflective learning by general practice (GP) registrars in Yorkshire, England. Method A postal questionnaire was sent to the 92 registrars of a deanery in November 2001, after a pilot study with registrars in a single district had been carried out. The questionnaire explored the registrars' use of the portfolio to collect information and for reflection, as well as registrars' attitudes towards the portfolio. It was returned by 71 registrars, representing a 77% response rate. Structured in-depth interviews were used to support the results obtained. Results Of the registrars who responded, 65% recorded information on a regular basis and 42% used the portfolio in reflective learning. Experienced registrars used the portfolio least. Those with supportive trainers used the portfolio more in reflection. Conclusions The study suggests that the role of the trainer/supervisor is vital in portfolio-based learning. It raises questions about the acceptability of portfolio learning. It adds weight to the suggestion that careful introduction of portfolios and training of supervisors is vital. Further work to establish the role of portfolios in reflective learning is recommended.",2004
Improving Knowledge Graph Representation Learning by Structure Contextual Pre-training,"Representation learning models for Knowledge Graphs (KG) have proven to be effective in encoding structural information and performing reasoning over KGs. In this paper, we propose a novel pre-training-then-fine-tuning framework for knowledge graph representation learning, in which a KG model is firstly pre-trained with triple classification task, followed by discriminative fine-tuning on specific downstream tasks such as entity type prediction and entity alignment. Drawing on the general ideas of learning deep contextualized word representations in typical pre-trained language models, we propose SCoP to learn pre-trained KG representations with structural and contextual triples of the target triple encoded. Experimental results demonstrate that fine-tuning SCoP not only outperforms results of baselines on a portfolio of downstream tasks but also avoids tedious task-specific model design and parameter training.",2021
A Distributed Algorithm for the Cooperative Prediction of Power Production in PV Plants,"Forecasting the energy production of photovoltaic plants is today an essential tool for asset owners because it has direct economic implications on the net operating income of the plants whose generated energy is sold in competitive electricity markets. In this paper, we propose an innovative distributed decentralized prediction technique for the forecasting of power generated by several PV plants. The prediction technique is based on the Echo State Networks, which are recurrent neural network models very promising in terms of prediction performance and model accuracy. They will be used in conjunction with a distributed learning algorithm and a distributed consensus protocol that makes unnecessary any central coordinator. The technique has been properly conceived for asset owners that hold a wide portfolio of PV systems that are geographically spread out over large areas. The algorithm reveals very efficient, accurate, and scalable performance to any number of plants and it requires only a simple reliable communication channel. Through a real-world example we assess the applicability of such methodology and show its strength.",2019
Stock Selection with a Novel Sigmoid-Based Mixed Discrete-Continuous Differential Evolution Algorithm,"A stock selection model with both discrete and continuous decision variables is proposed, in which a novel sigmoid-based mixed discrete-continuous differential evolution algorithm is especially developed for model optimization. In particular, a stock scoring mechanism is first designed to evaluate candidate stocks based on their fundamental and technical features, and the top-ranked stocks are selected to formulate an equal-weighted portfolio. Generally, the proposed model makes literature contributions from two main perspectives. First, to determine the optimal solution in terms of feature selections (discrete variables) and the corresponding weights (continuous variables), the original differential evolution algorithm focusing only on continuous problems is extended to a novel mixed discrete-continuous variant based on sigmoid-based conversion for the discrete part. Second, the stock selection model also resolves the gap of the application of differential evolution algorithm to stock selection. Using the Shanghai A share market of China as the study sample, the empirical results show that the novel stock selection model can make a profitable portfolio and significantly outperform its benchmarks (with other model designs and optimization algorithms used in the existing studies) in terms of both investment return and model robustness.",2016
Machine Learning for Earnings Prediction: A Nonlinear Tensor Approach for Data Integration and Completion,"Successful predictive models for financial applications often require harnessing complementary information from multiple datasets. Incorporating data from different sources into a single model can be challenging as they vary in structure, dimensions, quality, and completeness. Simply merging those datasets can cause redundancy, discrepancy, and information loss. This paper proposes a convolutional neural network-based nonlinear tensor coupling and completion framework (NLTCC) to combine heterogeneous datasets without compromising data quality. We demonstrate the effectiveness of NLTCC in solving a specific business problem - predicting firms' earnings from financial analysts' earnings forecast. First, we apply NLTCC to fuse firm characteristics and stock market information into the financial analysts' earnings forecasts data to impute missing values and improve data quality. Subsequently, we predict the next quarter's earnings based on the imputed data. The experiments reveal that the prediction error decreases by 65% compared with the benchmark analysts' consensus forecast. The long-short portfolio returns based on NLTCC outperform analysts' consensus forecast and the S&P-500 index from three-day up to two-month holding period. The prediction accuracy improvement is robust with different performance metrics and various industry sectors. Notably, it is more salient for the sectors with higher heterogeneity.",2022
What is the value of the cross-sectional approach to deep reinforcement learning?,"Reinforcement learning (RL) for dynamic asset allocation is an emerging field of study. Total return, the common performance metric, is useful for comparing algorithms but does not help us determine how close an RL algorithm is to an optimal solution. In real-world financial applications, a bad decision could prove to be fatal. One of the key ideas of our work is to combine the two paradigms of the mean-variance optimization approach (Markowitz criteria) and the optimal capital growth approach (Kelly criteria) via the actor-critic approach. By using an actor-critic approach, we can balance optimization of risk and growth by configuring the actor to optimize the mean-variance while the critic is configured to maximize growth. We propose a Geometric Policy Score used by the critic to assess the quality of the actions taken by the actor. This could allow portfolio manager practitioners to better understand the investment RL policy. We present an extensive and in-depth study of RL algorithms for use in portfolio management (PM). We studied eight published policy-based RL algorithms which are preferred over value-based RL because they are better suited for continuous action spaces and are considered to be state of the art, Deterministic Policy Gradient (DPG), Stochastic Policy Gradients (SPG), Deep Deterministic Policy Gradient (DDPG), Trust Region Policy Optimization (TRPO), Proximal Policy Optimization (PPO), Twin Delayed Deep Deterministic Policy Gradient (TD3), Soft Actor Critic (SAC), and Evolution Strategies (ES) for Policy Optimization. We implemented all eight and we were able to modify all of them for PM but our initial testing determined that their performance was not satisfactory. Most algorithms showed difficulty converging during the training process due to the non-stationary and noisy nature of financial environments, along with other challenges. We selected the four most promising algorithms DPG, SPG, DDPG, PPO for further improvements. The modification of RL algorithms to finance required unconventional changes. We have developed a novel approach for encoding multi-type financial data in a way that is compatible with RL. We use a multi-channel convolutional neural network (CNN-RL) framework, where each channel corresponds to a specific type of data such as high-low-open-close prices and volumes. We also designed a reward function based on concepts such as alpha, beta, and diversification that are financially meaningful while still being learnable by RL. In addition, portfolio managers will typically use a blend of time series analysis and cross-sectional analysis before making a decision. We extend our approach to incorporate, for the first time, cross-sectional deep RL in addition to time series RL. Finally, we demonstrate the performance of the RL agents and benchmark them against commonly used passive and active trading strategies, such as the uniform buy-and-hold (UBAH) index and the dynamical multi-period Mean-Variance-Optimization (MVO) model.",2022
A Fund Selection Robo-Advisor with Deep-learning Driven Market Prediction,"This paper proposes a new investment strategy with deep -learning market prediction for mutual fund portfolio optimization. Our strategy uses the capital asset pricing model (CAPM) that applies macroeconomic factors to predict whether the market is bull or hear. Then, we develop a robo-advisor (RA) to predict future market, optimize portfolio and automate investment. Experiments use 22 years' data of S&P500 and mutual funds of U.S. to validate our strategy. Results show that the accuracy of our market prediction method can reach 84.3% and the rate -of-return of our RA is 13.87%. Our model is more accurate and profitable than other algorithms.",2019
Sample average approximation of CVaR-based hedging problem with a deep-learning solution,"Conditional Value-at-Risk (CVaR) is an extremely popular risk measure in finance and is usually optimized to reduce the risk of large losses. This paper considers the CVaR optimization problem for hedging a portfolio of derivatives with bounded constraints. We focus on minimizing the CVaR of the loss of the hedging portfolio by a deep learning solution because of its promising application to classic portfolio optimization. As the cost objective function in the deep learning framework, the CVaR does not have a closed-form expression, but it can be estimated by using the i.i.d samples average approximation method. While many works have adopted minimizing the estimated CVaR to obtain the optimal solution, they lack theoretical performance guarantees for sample-based solutions. This paper attempts to bridge this gap. On the one hand, we introduce a typical deep neural network architecture for training the optimal hedging strategies, which helps us to analyze the properties of function set for this neural network. On the other hand, we offer a sufficient condition to guarantee that the optimal strategies obtained by using the estimated CVaR can be assured in practical applications. In particular, we prove that the uniform convergence in probability of the estimated CVaR to CVaR over a set of functions, which are generated by the proposed deep neural network. Numerical experiments verify the proposed sufficient condition and demonstrate the feasibility and superiority of this approach.",2021
African buffalo optimized multinomial softmax regression based convolutional deep neural network for software fault prediction,"Software fault prediction is an essential part of the software quality assurance to detect faulty software modules depending on software measurement data. This models area of the research generates software engineers focus to development activities on fault-prone code for increasing the software quality. Many existing designed for improving the software quality by various methods. The software failure cause prediction accuracy and defect detection rate of the conventional techniques were not sufficient. Introduced an African Buffalo Optimized Multinomial Softmax Regression based Convolutional Deep Neural Learning (ABOMSR-CDNL). ABOMSR-CDNL model to enhance the software reliability through predicting root cause of software failure at earlier stage. ABOMSR-CDNL Model comprises four layers, namely input layer, two hidden layers and output layer and software program codes, event log files as an input layer then transmits the software program codes to the hidden layer 1. Construct the projects portfolio with help of optimal parameters selected from event log files then sent to the hidden layer 2. This method reduce the amount of time taken for examining the failure behaviour of system application. ABOMSR-CDNL Model applied multinomial softmax regression analysis in hidden layer 2 this objective of determining the cause of higher accuracy the result is sent to the output layer. Result illustrates ABOMSR-CDNL Model is increasing the accuracy, false positive rate and minimized the software failure identification time. Copyright (c) 2022 Elsevier Ltd. All rights reserved. Selection and peer-review under responsibility of the scientific committee of the International Conference on Recent Advances in Mechanical Engineering and Nanomaterials",2022
Constructing Equity Investment Strategies Using Analyst Reports and Regime Switching Models,"This study demonstrates whether analysts' sentiments toward individual stocks are useful for stock investment strategies. This is achieved by using natural language processing to create a polarity index from textual information in analyst reports. In this study, we performed time series forecasting for the created polarity index using deep learning, and clustered the forecasted values by volatility using a regime switching model. In addition, we constructed a portfolio from stock data and rebalanced it at each change point of the regime. Consequently, the investment strategy proposed in this study outperforms the benchmark portfolio in terms of returns. This suggests that the polarity index is useful for constructing stock investment strategies.",2022
BP adds two discoveries to North Sea portfolio,,2018
"Trading sparse, mean reverting portfolios using VAR(1) and LSTM prediction","We investigated the predictability of mean reverting portfolios and the VAR(1) model in several aspects. First, we checked the dependency of the accuracy of VAR(1) model on different data types including the original data itself, the return of prices, the natural logarithm of stock and on the log return. Then we compared the accuracy of predictions of mean reverting portfolios coming from VAR(1) with different generative models such as VAR(1) and LSTM for both online and offline data. It was eventually shown that the LSTM predicts much better than the VAR(1) model. The conclusion is that the VAR(1) assumption works well in selecting the mean reverting portfolio, however, LSTM is a better choice for prediction. With the combined model a strategy with positive trading mean profit was successfully developed. We found that online LSTM outperforms all VAR(1) predictions and results in a positive expected profit when used in a simple trading algorithm.",2021
A profitable currency portfolio strategy: Learning from connectedness,"This study proposes a profitable currency portfolio strategy integrating dynamic connectedness into machine learning (ML) predictions. The portfolio is constructed using consensus predictions of return levels from LSTM and MLP and return directions from SVM and RF. Our findings reveal that connectedness slightly enhances returns but significantly reduces return volatility, implying its role in risk management. Compared to eight classical currency trading strategies, ML-based portfolios outperform in returns and mitigating extreme losses. Notably, portfolios incorporating RF predictions achieve the highest average return and Sharpe ratio among all strategies. Additionally, ML-based portfolios exhibit significant differences from classical strategies in determining currency positions.",2025
Theoretically Motivated Data Augmentation and Regularization for Portfolio Construction,"The task we consider is portfolio construction in a speculative market, a fundamental problem in modern finance. While various empirical works now exist to explore deep learning in finance, the theory side is almost non-existent. In this work, we focus on developing a theoretical framework for understanding the use of data augmentation for deep-learning-based approaches to quantitative finance. The proposed theory clarifies the role and necessity of data augmentation for finance; moreover, our theory implies that a simple algorithm of injecting a random noise of strength root|r(t) (-) (1)| to the observed return r(t) is better than not injecting any noise and a few other financially irrelevant data augmentation techniques.",2022
AI Robo-Advisor with Big Data Analytics for Financial Services,"Robo-Advisors has been growing attraction from the financial industry for offering financial services by using algorithms and acting as like human advisors to support investors making investment decisions. During the investment planning stage, portfolio optimization plays a crucial role, especially for the medium and long-term investors, in determining the allocation weight of assets to achieve the balance between investors expectation return and risk tolerance. The literature on the topic of portfolio optimization has been offering plenty of theoretical and practical guidance for implementing the theory; however, there is a paucity of studies focusing on the applications which are designed for Robo-Advisors. In this research, we proposed a modular system and focused on integrating big data analysis, deep learning method and the Black-Litterman model to generate asset allocation weight. We developed a portfolio optimization module which takes the information from a variety of sources, such as stocks prices, investor profile and the other alternative data, and used them as input to calculate optimal weights of assets in the portfolio. The module we developed could be used as a sub-system for Robo-Advisors, which offers a customized optimal portfolio based on investors preference.",2018
Improving Pairs Trading Strategies Using Two-Stage Deep Learning Methods and Analyses of Time (In)variant Inputs for Trading Performance,"A pairs trading strategy (PTS) constructs and monitors a stationary portfolio by shorting (longing) when the portfolio is adequately over- (under-)priced measured by a predetermined open threshold. We close this position to earn the price differences when the portfolio's value reverts back to the mean level. When the portfolio is significantly over- (under-)priced measured by another predetermined stop-loss threshold, we close the position to stop loss. This paper develops a two-stage deep learning method to improve the investment performance of a PTS. Note that the literature executes a PTS by selecting the best trigger threshold (a combination of open and stop-loss thresholds) from a restricted, heuristically-determined set of trigger thresholds. Such a design significantly degrades investment performance. However, selecting the best threshold from all possible thresholds yields a non-converged training problem. To resolve this dilemma, we propose in the first stage of our method a representative label mechanism by which to construct a set of candidate trigger thresholds based on all possible thresholds and then train a deep learning (DL) model to select the best from the set. Experiments demonstrate that the proposed first-stage method avoids the non-converged training problem and outperforms most state-of-the-art methods. To further reduce the trading risk, the second stage trains another DL with the profitability of each trade labeled by executing the PTS with trigger thresholds recommended in the first-stage mechanism to remove unprofitable trades. Compared to models that indirectly judge profitability by price movement similarity without considering the quality of the recommended trigger thresholds, our model produces higher win rates and average profits. Furthermore, we find that training with the PTS portfolio value process exhibiting time invariance clearly outperforms training with only time-varying stock/return processes, even though the latter training set contains more information. This is because unpredictable changes in market trends cause the model to learn time-varying patterns from the training set that may not apply to the testing set.",2022
Financial Volatility Forecasting: A Sparse Multi-Head Attention Neural Network,"Accurately predicting the volatility of financial asset prices and exploring its laws of movement have profound theoretical and practical guiding significance for financial market risk early warning, asset pricing, and investment portfolio design. The traditional methods are plagued by the problem of substandard prediction performance or gradient optimization. This paper proposes a novel volatility prediction method based on sparse multi-head attention (SP-M-Attention). This model discards the two-dimensional modeling strategy of time and space of the classic deep learning model. Instead, the solution is to embed a sparse multi-head attention calculation module in the network. The main advantages are that (i) it uses the inherent advantages of the multi-head attention mechanism to achieve parallel computing, (ii) it reduces the computational complexity through sparse measurements and feature compression of volatility, and (iii) it avoids the gradient problems caused by long-range propagation and therefore, is more suitable than traditional methods for the task of analysis of long time series. In the end, the article conducts an empirical study on the effectiveness of the proposed method through real datasets of major financial markets. Experimental results show that the prediction performance of the proposed model on all real datasets surpasses all benchmark models. This discovery will aid financial risk management and the optimization of investment strategies.",2021
Multi-View MOOC Quality Evaluation via Information-Aware Graph Representation Learning,"In this paper, we study the problem of MOOC quality evaluation which is essential for improving the course materials, promoting students' learning efficiency, and benefiting user services. While achieving promising performances, current works still suffer from the complicated interactions and relationships of entities in MOOC platforms. To tackle the challenges, we formulate the problem as a course representation learning task-based and develop an Information-aware Graph Representation Learning(IaGRL) for multi-view MOOC quality evaluation. Specifically, We first build a MOOC Heterogeneous Network (HIN) to represent the interactions and relationships among entities in MOOC plat-forms. And then we decompose the MOOC HIN into multiple single-relation graphs based on meta-paths to depict the multi-view semantics of courses. The course representation learning can be further converted to a multi-view graph representation task. Different from traditional graph representation learning, the learned course representations are expected to match the following three types of validity: (1) the agreement on expressiveness between the raw course portfolio and the learned course representations; (2) the consistency between the representations in each view and the unified representations; (3) the alignment between the course and MOOC platform representations. Therefore, we propose to exploit mutual information for preserving the validity of course representations. We conduct extensive experiments over real-world MOOC datasets to demonstrate the effectiveness of our proposed method.",2023
A clustering-based portfolio strategy incorporating momentum effect and market trend prediction,"The hierarchical clustering algorithm has been proved useful in portfolio investment, which is one of the hottest issues in finance. In our new portfolio strategy, central, peripheral and dispersed portfolios constructed from clusters detected using unweighted and weighted modularity are compared according to their past performances, and the optimal portfolio is used in the investment period only if the market index return predicted by the LR, WMA or BP models is positive to avoid losses when the market drops. Our strategy is tested using the daily data of Chinese A-share market from January 4, 2008 and December 31, 2016, and the average investment return during different moving investment periods and 200 repeated runs is calculated. We find that although incorporating dispersed portfolio into our strategy has no significant effect in raising the investment return, it shows a similar performance as the peripheral portfolio, and the strategy constructed using unweighted modularity generally outperforms its counterpart by using weighted modularity. In addition, the market trend prediction can refine the investment return of our strategy. In brief, the strategy constructed using the BP model and unweighted modularity has the best investment return, which also outperforms the Markowitz portfolio. (C) 2018 Elsevier Ltd. All rights reserved.",2018
Dynamic multi-period sparse portfolio selection model with asymmetric investors' sentiments,"Asymmetric investors' sentiments on returns and risks play an important role in updating the portfolio strategies in multi-period portfolio selection problems. By introducing the Prospect Theory to measure the asymmetric investors' sentiments, a dynamic sentiment-adjusted model (DSAM) is proposed to sparse portfolio selection problem over multiple periods, in which the objective is to minimize the risk of the portfolio. As we focus on the sparse portfolio, a l(0) constraint is added to our model. The l(0) constraint represents that we can only purchase at most k securities from N candidate securities, in which k is a small number compared to N. Since the objective function of the sparse portfolio with l(0) constraint is NP-hard, and could not be solved by the Deep Learning algorithms. The stochastic neural networks algorithm with re-parametrisation trick (SNNrP) is introduced to solve the DSAM. The back-testing framework of our paper includes a multi-period portfolio selection model, in which asymmetric investors' sentiments are modeled to iterate investors' expected return level each period. In the back-testing framework, we conduct the experiments for different investment periods with different investors' sentiments. The experimental results for the Nasdaq and CSI 300 data sets show that, on average, compared with the traditional Mean-variance model, the terminal return and risk obtained by the DSAM model outperforms by 9% and 11.75%.",2021
Portfolio constructions in cryptocurrency market: A CVaR-based deep reinforcement learning approach,"Cryptocurrency markets have much larger tail risk than traditional financial markets, and constructing portfolios with such large tail risk assets would be challenging. Therefore, cryptocurrency funds demand new superior risk management models and Conditional Value at Risk (CVaR) is a prevailing risk measure for constructing portfolios in stock markets with large tail risk. Consequently, our paper contributes to the literature by developing a new cryptocurrency portfolio model framework based on the CVaR risk measure and a deep reinforcement learning optimization framework. We use the data from cryptocurrency market starting 2015 to 2021, unfolding that CVaR measure with deep learning outperforms the traditional portfolio construction technique. Compared with traditional economic parameter-based portfolio models, our model free based approach can capture the nonlinear compounding effect of multiple risk shocks by deep reinforcement learning on the risk distribution with economic structural breakdown. It can guide investments in financial markets with high tail risks.",2023
Intelligent option portfolio model with perspective of shadow price and risk-free profit,"Since Markowitz proposed modern portfolio theory, portfolio optimization has been being a classic topic in financial engineering. Although it is generally accepted that options help to improve the market, there is still an improvement for the portrayal of their unique properties in portfolio problems. In this paper, an intelligent option portfolio model is developed that allows selling options contracts to earn option fees and considers the high leverage of options in the market. Deep learning methods are used to predict the forward price of the underlying asset, making the model smarter. It can find an optimal option portfolio that maximizes the final wealth among the call and put options with multiple strike prices. We use the duality theory to analyze the marginal contribution of initial assets, risk tolerance limit, and portfolio leverage limit for the final wealth. The leverage limit of the option portfolio has a significant impact on the return. To satisfy the investors with different risk preferences, we also give the conditions for the option portfolio to gain a risk-free return and replace the Conditional Value-at-Risk. Numerical experiments demonstrate that the intelligent option portfolio model obtains a satisfactory out-of-sample return, which is significantly positively correlated with the volatility of the underlying asset and negatively correlated with the forecast error of the forward price. The risk- free option model is effective in achieving the goal of no drawdown and gaining satisfactory returns. Investors can adjust the balance point between returns and risks according to their risk preference.",2023
State of the Art in Electric Batteries' State-of-Health (SoH) Estimation with Machine Learning: A Review,"The sustainable reuse of batteries after their first life in electric vehicles requires accurate state-of-health (SoH) estimation to ensure safe and efficient repurposing. This study applies the systematic ProKnow-C methodology to analyze the state of the art in SoH estimation using machine learning (ML). A bibliographic portfolio of 534 papers (from 2018 onward) was constructed, revealing key research trends. Public datasets are increasingly favored, appearing in 60% of the studies and reaching 76% in 2023. Among 12 identified sources covering 20 datasets from different lithium battery technologies, NASA's Prognostics Center of Excellence contributes 51% of them. Deep learning (DL) dominates the field, comprising 57.5% of the implementations, with LSTM networks used in 22% of the cases. This study also explores hybrid models and the emerging role of transfer learning (TL) in improving SoH prediction accuracy. This study also highlights the potential applications of SoH predictions in energy informatics and smart systems, such as smart grids and Internet-of-Things (IoT) devices. By integrating accurate SoH estimates into real-time monitoring systems and wireless sensor networks, it is possible to enhance energy efficiency, optimize battery management, and promote sustainable energy practices. These applications reinforce the relevance of machine-learning-based SoH predictions in improving the resilience and sustainability of energy systems. Finally, an assessment of implemented algorithms and their performances provides a structured overview of the field, identifying opportunities for future advancements.",2025
Results and prospects of development of new polyphenolic drugs for cancer patients,"The conference Results and prospects of development of new polyphenolic drugs for cancer patients took place at the N.N. Petrov National Medical Research Center of Oncology (PNMRCO) on May 31, 2017, and gathered researchers involved in development and evaluation of medicinal products based on the novel lignin-derived soluble polyphenolic polymer BP-Cx-1. BP-Cx-1 is the platform for a portfolio of innovative pharmacological products such as BP-C1, BP-C2 and BP-C3.",2017
Graph Denoising Networks: A Deep Learning Framework for Equity Portfolio Construction,"Graph-based deep learning is a rapidly evolving and practical field due to the ubiquity of graph data and its flexible topology. Although many graph learning frameworks show impressive capabilities, their outputs begin to deteriorate for sufficiently noisy data. In this paper, we look to overcome this shortcoming by introducing the Graph Denoising Network, which combines denoising diffusion methods with graph models in a compounding manner. We prove under certain conditions that this can be construed as an MCMC approach to learning and sampling from the true data distribution. When testing on a graph built from financial returns, we obtain Sharpe Ratios of up to 4.4, and consistently above 2. Compared to a baseline graph convolutional network, we find noticeable improvement and statistical evidence to conclude that graph denoising networks improve performance and attain significant economic benefits. Our findings are applicable to other domains that employ noisy graph-based data, potentially in a time-dependent context.",2023
FreQuant: A Reinforcement-Learning based Adaptive Portfolio Optimization with Multi-frequency Decomposition,"How can we leverage inherent frequency features of stock signals for effective portfolio optimization? Portfolio optimization in the domain of finance revolves around strategically allocating assets to maximize returns. Recent advancements highlight the efficacy of deep learning and reinforcement learning (RL) in capturing temporal asset patterns for portfolio optimization. However, previous methodologies focusing on time-domain often fail to detect sudden market shifts and abrupt events because their models are overly tailored to prevalent patterns, resulting in significant losses. In this paper, we propose FREQUANT (Adaptive Portfolio Optimization via Multi-Frequency Quantitative Analysis), an effective deep RL framework for portfolio optimization that fully operates in the frequency domain, tackling the limitations of time domain-focused models. By bringing the analysis into the frequency domain with the Discrete Fourier Transform, our framework captures both prominent and subtle market frequencies, enhancing its adaptability and stability in response to market shifts. This approach allows FREQUANT to adeptly identify primary asset patterns while also effectively responding to less common and abrupt market events, providing a more accurate and comprehensive asset representation. Empirical validation on diverse real-world trading datasets underscores the remarkable performance of FREQUANT, showing its superiority in terms of profitability. Notably, FREQUANT achieves up to 2.1x higher Annualized Rate of Return and 2.9x higher Portfolio Value than the best-performing competitors.",2024
STOCK MOVEMENT PREDICTION AND PORTFOLIO MANAGEMENT VIA MULTIMODAL LEARNING WITH TRANSFORMER,"This paper introduces a novel high performing multimodal deep learning architecture(Trans-DiCE) for stock movement prediction utilizing financial indicators and news data. Our multimodal architecture uses dilated causal convolutions and Transformer blocks for feature extraction from both data sources. The masked multi-head self-attention layers inside Transformers preserve causality and improve features based on contextual information. To integrate the derived multimodal model representations, we use stacked Transformer blocks. We show empirically that our model performs best compared to state-of-the-art baseline methods for S&P 500 index and individual stock prediction and provides a significant 3.45% improvement from 74.29% to 77.74%. We also demonstrate our model's utility for the Portfolio Management task. We propose a Deep Reinforcement Learning Framework utilizing Trans-DiCE for Portfolio Optimization, providing noticeable gain on Sharpe Ratio and 7.9% increase in Portfolio Value over the existing state of the art Models.",2021
INVESTIGATION OF ALGORITHMIC TRADING MODELS FOR SHARES OF THE DRUG MANUFACTURING INDUSTRY,"Algorithmic trading models are now widely used in investment decision-making. By grounding these models in scientific knowledge, investors can obtain efficient results in financial markets. During the COVID-19 outbreak, the drug manufacturing industry has received substantial attention from investors. The purpose of our research is to form an investment portfolio using an algorithmic trading model in the drug manufacturing industry. The model covers the entire process of portfolio formation: market analysis, selection of industry, selection of particular stocks, data mining, forecasting and investment decision-making. Three portfolios - maximum return, minimum risk and maximum Sharpe ratio - are constructed and compared across two periods. Portfolios formed using deep learning forecasting outperformed the index in more cases than did portfolios created using the Monte Carlo simulation. Portfolio formation using algorithmic trading models is suitable for individual investors, can be easily automated using the computer application and can not only be applied to one industry but diversified across various sectors.",2023
Credit risk evaluation: a review and the application using Backpropagation Neural Networks,"The dramatic increase in the corporate failures over the last decade has led to the increasing interests in failure prediction model. This paper reviews various quantitative methods and adopts one neural network approach, Backpropagation Neural Networks (BPNN), to identify the credit risk. BPNN gives convincing 54.55% bankruptcy and 100% non-bankruptcy out-of-sample prediction accuracies. The promising results validate that the neural network approach is an excellent supplement to the traditional prediction techniques and it provides management tremendous benefits on credit approval, loan securitization and loan portfolio management.",2007
CONSTRUCTION OF ELECTRONIC PROFESSIONAL PORTFOLIO AS INSTRUCTIONAL TECHNO-PEDAGOGICAL DESIGN: AN EXPERIENCE,"The electronic portfolio is agreed with the educative proposal in knowledge society because it shows evidences about process and product of deep learning. Construction of an electronic portfolio promotes reflective though and authentic evaluation of student performance. From a constructivist vision in education, this experience exposes a way to build an electronic professional portfolio with pedagogical and psychology postgraduate students where they put together different concepts and resources about portfolios as educational and technological diffusion tool. The process of electronic portfolios construction was in two steps: a) reading and analyzing of educative literature on the subject of models and conception about portfolios, b) collaborative learning and deliberation in order to define electronic professional portfolio, there were different dimensions as professional identity, educational work lines with portfolio, prospective vision of professional work and personal reflective space. In each dimension, guide questions were in order to support student's reflection process. In addition, students' evidences were selected from their knowledge, teacher work and examples of problems solve in their professional performance. At the same time, students had preparation and help in technology usage of Google Sites. Also student group made a rubric to asses an electronic portfolio. This rubric consists with different dimensions of an electronic professional portfolio. The portfolios construction was co-evaluated through a blog. This paper analyzes collaborative work of some participants in an electronic professional construction process. These analyze show examples of different dimensions and student's co-evaluation expressions. Electronic professional portfolio is a good strategy for helping students to watch their professional work in a critical and significance way.",2011
Deep Risk Model: A Deep Learning Solution for Mining Latent Risk Factors to Improve Covariance Matrix Estimation,"Modeling and managing portfolio risk is perhaps the most important step to achieve growing and preserving investment performance. Within the modern portfolio construction framework that built on Markowitz's theory, the covariance matrix of stock returns is a required input to calculate portfolio risk. Traditional approaches to estimate the covariance matrix are based on human-designed risk factors, which often require tremendous time and effort to design better risk factors to improve the covariance estimation. In this work, we formulate the quest of mining risk factors as a learning problem and propose a deep learning solution to effectively design risk factors with neural networks. The learning objective is also carefully set to ensure the learned risk factors are effective in explaining the variance of stock returns as well as having desired orthogonality and stability. Our experiments on the stock market data demonstrate the effectiveness of the proposed solution: our method can obtain 1.9% higher explained variance measured by R-2 and also reduce the risk of a global minimum variance portfolio. The incremental analysis further supports our design of both the architecture and the learning objective.",2021
High-dimensional multi-period portfolio allocation using deep reinforcement learning,"This paper proposes a novel investment strategy based on deep reinforcement learning (DRL) for long-term portfolio allocation in the presence of transaction costs and risk aversion. We design an advanced portfolio policy framework to model the price dynamic patterns using convolutional neural networks (CNN), capture group-wise asset dependence using WaveNet, and solve the optimal asset allocation problem using DRL. These methods are embedded within a multi-period Bellman equation framework. An additional appealing feature of our investment strategy is its ability to optimize dynamically over a large set of potentially correlated risky assets. The performance of this portfolio is tested empirically over different holding periods, risk aversion levels, transaction cost rates, and financial indices. The results demonstrate the effectiveness and superiority of the proposed long-term portfolio allocation strategy compared to several competitors based on machine learning methods and traditional optimization techniques.",2025
An optimal portfolio method based on real time prediction of gold and bitcoin prices,"Aiming at the portfolio problem of gold and bitcoin with a given linear trading commission, this paper puts forward the stage implementation forecast and optimal portfolio model. In the aspect of data prediction, SMA is used to predict the initial data, LSTM is used to predict the price trend of long-term data, and daily updated real-time price data is predicted. Considering the risk aversion of investors, the heuristic algorithm is used to solve the daily trading strategy of maximizing utility from September 12th, 2016 to September 12th, 2021. The simulation analysis of the sliding window shows that the algorithm can realize reasonable prediction, which verifies the effectiveness of the algorithm.",2022
Graph Representation Learning for Similarity Stocks Analysis,"Listed companies with similar or related fundamentals usually influence each other, and these influences are usually reflected in stock prices. For example, the momentum spillover effect in the behavioral finance theory describes the formation of lead-lag effects between the stock prices of related companies. The relationship between listed companies consists of many types, such as relationships in the industry chain, industry information, transaction information, patent sharing degree, equity, etc. We construct a set of industry chain knowledge graph of listed companies to describe the production and supply relationship between the upstream and downstream of listed companies. Then, graph representation learning method is used to study the relevance between listed company entities in the knowledge graph. It includes dimensions such as industry and transaction information of listed companies as weights to optimize the graph representation learning process, and finally calculates the similarity index between listed companies. To evaluate the effectiveness of the method, we conduct a link prediction experiment and construct a stock quantitative investment portfolio based on the similarity index. The result of the quantitative backtest experiment based on China's stock market data in the last 10 years shows that the graph representation learning method we proposed can be used to study the momentum spillover effect and obtain investment returns.",2022
Factor-GAN: Enhancing stock price prediction and factor investment with Generative Adversarial Networks,"Deep learning, a pivotal branch of artificial intelligence, has increasingly influenced the financial domain with its advanced data processing capabilities. This paper introduces Factor-GAN, an innovative framework that utilizes Generative Adversarial Networks (GAN) technology for factor investing. Leveraging a comprehensive factor database comprising 70 firm characteristics, Factor-GAN integrates deep learning techniques with the multi-factor pricing model, thereby elevating the precision and stability of investment strategies. To explain the economic mechanisms underlying deep learning, we conduct a subsample analysis of the Chinese stock market. The findings reveal that the deep learning-based pricing model significantly enhances return prediction accuracy and factor investment performance in comparison to linear models. Particularly noteworthy is the superior performance of the long-short portfolio under Factor-GAN, demonstrating an annualized return of 23.52% with a Sharpe ratio of 1.29. During the transition from state-owned enterprises (SOEs) to non-SOEs, our study discerns shifts in factor importance, with liquidity and volatility gaining significance while fundamental indicators diminish. Additionally, A-share listed companies display a heightened emphasis on momentum and growth indicators relative to their dual-listed counterparts. This research holds profound implications for the expansion of explainable artificial intelligence research and the exploration of financial technology applications.",2024
Grouping of contracts in insurance using neural networks,"Despite the high importance of grouping in practice, there exists little research on the respective topic. The present work presents a framework for grouping and a novel method to optimize model points in life insurance. We introduce a supervised clustering algorithm using neural networks to form a less complex portfolio, alias grouping. In a two-step approach, we first approximate selected characteristics of a portfolio. Next, we nest this estimator in a neural network, such that cluster representatives, alias model points, are calibrated in accordance with their effect on the characteristics of the portfolio. This approach is similar to the work by Horvath, B., Muguruza, A. & Tomas, M. [(2019). Deep learning volatility. Available on arXiv 1901.09647.], who focus on the calibration of implied volatility models. Our numerical experiments for term life insurance and defined contribution pension plans show significant improvements, in terms of capturing the characteristics of a portfolio, of the neural network approach over K-means clustering, a common baseline algorithm for grouping. These results are further confirmed by a sensitivity analysis of the investment surplus, where we additionally show the flexibility of the model to include common industry practice.",2021
Online Planner Selection with Graph Neural Networks and Adaptive Scheduling,"Automated planning is one of the foundational areas of AI. Since no single planner can work well for all tasks and domains, portfolio-based techniques have become increasingly popular in recent years. In particular, deep learning emerges as a promising methodology for online planner selection. Owing to the recent development of structural graph representations of planning tasks, we propose a graph neural network (GNN) approach to selecting candidate planners. GNNs are advantageous over a straightforward alternative, the convolutional neural networks, in that they are invariant to node permutations and that they incorporate node labels for better inference. Additionally, for cost-optimal planning, we propose a two-stage adaptive scheduling method to further improve the likelihood that a given task is solved in time. The scheduler may switch at halftime to a different planner, conditioned on the observed performance of the first one. Experimental results validate the effectiveness of the proposed method against strong baselines, both deep learning and non-deep learning based. The code is available at https://github.com/matenure/GNN_ planner.",2020
Mixup Gamblers: Learning to Abstain with Auto-Calibrated Reward for Mixed Samples,"Deep learning models have recently been used in a wide range of fields. However, one of the problems with deep learning is the reliability of the inference results. Models that can evaluate the reliability of their inference results are important, and therefore methods such as selective classification have been proposed. Selective classification is classification with a reject option, which reduces false inferences by allowing an inference to be rejected. Inspired by portfolio theory, L. Ziyin et al. proposed a deep gamblers method that learns to reject. Taking this approach a step further, we propose a learning method for selective classification, mixup gamblers, to improve rejection ability. This method exploits data augmentation parameters for rejection learning. The proposed method outperforms existing state-of-the-art methods on a selective classification benchmark.",2021
Towards Data-Driven Volatility Modeling with Variational Autoencoders,"In this study, we show how S&P 500 Index volatility surfaces can be modeled in a purely data-driven way using variational autoencoders. The approach autonomously learns concepts such as the volatility level, smile, and term structure without leaning on hypotheses from traditional volatility modeling techniques. In addition to introducing notable improvements to an existing variational autoencoder approach for the reconstruction of both complete and incomplete volatility surfaces, we showcase three practical use cases to highlight the relevance of this approach to the financial industry. First, we show how the latent space learned by the variational autoencoder can be used to produce synthetic yet realistic volatility surfaces. Second, we demonstrate how entire sequences of synthetic volatility surfaces can be generated to stress test and analyze an options portfolio. Third and last, we detect anomalous surfaces in our options dataset and pinpoint exactly which subareas are divergent.",2023
Efficacy of different dietary patterns on lowering of blood pressure level: an umbrella review,"Background: Many systematic reviews and meta-analyses have assessed the efficacy of dietary patterns on blood pressure (BP) lowering but their findings are largely conflicting. Objective: This umbrella review aims to provide an update on the available evidence for the efficacy of different dietary patterns on BP lowering. Methods: PubMed and Scopus databases were searched to identify relevant studies through to June 2020. Systematic reviews with meta-analyses of randomized controlled trials (RCTs) were eligible if they measured the effect of dietary patterns on systolic (SBP) and/or diastolic blood pressure (DBP) levels. The methodological quality of included systematic reviews was assessed by A Measurement Tool to Assess Systematic Review version 2. The efficacy of each dietary pattern was summarized qualitatively. The confidence of the effect estimates for each dietary pattern was graded using the NutriGrade scoring system. Results: Fifty systematic reviews and meta-analyses of RCTs were eligible for review. Twelve dietary patterns namely the Dietary Approaches to Stop Hypertension (DASH), Mediterranean. Nordic. vegetarian, low-salt, low-carbohydrate, low-fat, high-protein. low glycemic index, portfolio, pulse, and Paleolithic diets were included in this umbrella review. Among these dietary patterns, the DASH diet was associated with the greatest overall reduction in BP with unstandardized mean differences ranging from -3.20 to -7.62 mmHg for SBP and from -2.50 to -4.22 mmHg for DBP. Adherence to Nordic, portfolio, and low-salt diets also significantly decreased SBP and DBP levels. In contrast, evidence for the efficacy of BP lowering using the Mediterranean, vegetarian, Paleolithic, low-carbohydrate, low glycemic index, high-protein, and low-fat diets was inconsistent. Conclusion: Adherence to the DASH, Nordic, and portfolio diets effectively reduced BP. Low-salt diets significantly decreased BP levels in normotensive Afro-Caribbean people and in hypertensive patients of all ethnic origins.",2020
OPEN MARKOV CHAIN SCHEME MODELS FED BY SECOND ORDER STATIONARY AND NON STATIONARY PROCESSES,"We introduce a schematic formalism for the time evolution of a random open population divided into classes. With a Markov chain model, allowing for population entrances, we consider the flow of incoming members modeled by a time series - either ARIMA for the number of new incomings or SARMA for the residuals of a deterministic sigmoid type trend - and we detail the time series structure of the elements in each class. A practical application to real data from a credit portfolio is presented.",2017
A Trading Strategy Based on Analysts' Industry Analyses - Evidence from Textual Analyses of Analyst Reports in Chinese Stock Market,"Applying a deep-learning method that is efficient in differentiating the order of words, we extract the tone of analysts' industry analyses to measure analyst expertise and aggregate it at industry level as OPNI. Based on OPNI, we successfully construct the industry hedging portfolio that longs industries with highest OPNI and shorts industries with lowest OPNI, which generates significant and robust abnormal returns. Furthermore, we find that the industry hedging portfolio based on industry-level numerical forecasts cannot generate significant returns. Additionally, in mechanism analyses, we find that the informativeness of analysts' industry analyses is driven by its predictability on industry-level unexpected revenues and earnings. Our findings suggest that industry analyses in analysts' reports contain incremental value about their industry expertise, which is beyond analysts' quantitative forecasts.",2023
A representation and classification method for collective investor attention in the financial market,"Introduction: It is increasingly becoming integral to analyze the collected information effectively.Methods: We propose a representation and classification method for collective investor attention in the financial market, taking the Chinese stock market as an example. The method includes three key steps: 1) converting the hourly search volume of each stock per week to an image representation for describing the changes of collective investor attention; 2) extracting features of each image by utilizing a self-encoding algorithm in deep learning; and 3) clustering generated images by K-means to arrange stocks into different groups.Results: The empirical results show that the portfolio considering the clustering information outperforms the HS300 index.Discussion: The method may not only use deep learning features for stock similarity measurement, but also shed some light on profoundly understanding the mechanisms of the collective investor attention for the financial market.",2023
A Deep Learning-Aided Approach to Portfolio Design for Financial Index Tracking,"This paper considers the index tracking portfolio (ITP) design problem in financial markets, which aims at reproducing the performance of a financial index by investing in a subset of the assets constituting it. From a regression-based point of view, the ITP design problem is formulated as a mixed-integer programming (MIP). Leveraging the graph convolutional network (GCN), a calibrated GCN is proposed for asset selection followed by a lightweight MIP problem to realize asset allocation. Numerical simulations show that compared to existing methods the proposed learning-aided approach can generate comparable ITP design results and significantly accelerate the computation which is favorable for practical index tracking targets in finance.",2020
Deep Learning for Multi-factor Models in Regional and Global Stock Markets,"Many studies have been undertaken with machine learning techniques to predict stock returns in terms of time-series prediction. However, from the viewpoint of the cross-sectional prediction with machine learning techniques, there are no examples that verify its profitability in regional and global stock markets. This paper implements deep learning for multi-factor models to predict stock returns in the cross-section in these stock markets and investigates the performance of the method. Our results show that deep neural networks generally outperform representative machine learning models all over the world. These results indicate that deep learning shows promise as a skillful machine learning method to predict stock returns in the cross-section. Although deep learning performs quite well, it has significant disadvantages such as a lack of transparency and limitations to the interpretability of the prediction. Then, we present the application of layerwise relevance propagation (LRP) to decompose attributes of the predicted return. By applying LRP to each stock and averaging them in a portfolio, we can determine which factor contributes to prediction. We illustrate which factor contributes to prediction in regional and global stock markets.",2020
Alliance portfolio internationalization and firm performance,"Alliance research has traditionally focused on structural and relational aspects of the networks in which firms are situated, paying less attention to the inherent characteristics of their partners. This study introduces the notion of alliance portfolio internationalization (API), which refers to the degree of foreignness of partners in a firm's collection of immediate alliance relationships. We develop a framework to explain how API impacts firm performance. We suggest that as a firm's API increases, financial performance is expected to initially decline, then improve, and finally decline again. This sigmoid relationship between API and financial performance is ascribed to evolving learning effects that shape the net benefits of API. When the firm's alliance portfolio, on average, consists of proximate foreign partners, the firm may fail to recognize latent national differences, but at moderate levels of API, its absorptive capacity and specialized collaborative routines support the exchange of valuable network resources. Nevertheless, high levels of API undermine firm performance because of the failure of collaborative routines and mounting liabilities of cross-national differences. We test the framework using data on the alliance portfolios of U. S.-based software firms from 1990 to 2001. The results provide support for the sigmoid relationship as well as for our predictions that firms, which have gained experience with foreign partners and maintained wholly owned subsidiaries in their partners' countries of origin, can overcome some of the liabilities of API and better leverage its benefits.",2008
LSTM in Algorithmic Investment Strategies on BTC and S&P500 Index,"We use LSTM networks to forecast the value of the BTC and S&P500 index, using data from 2013 to the end of 2020, with the following frequencies: daily, 1 h, and 15 min data. We introduce our innovative loss function, which improves the usefulness of the forecasting ability of the LSTM model in algorithmic investment strategies. Based on the forecasts from the LSTM model we generate buy and sell investment signals, employ them in algorithmic investment strategies and create equity lines for our investment. For this purpose we use various combinations of LSTM models, optimized on in-sample period and tested on out-of-sample period, using rolling window approach. We pay special attention to data preprocessing in the input layer, to avoid overfitting in the estimation and optimization process, and assure correct selection of hyperparameters at the beginning of our tests. The next stage is devoted to the conjunction of signals from various frequencies into one ensemble model, and the selection of best combinations for the out-of-sample period, through optimization of the given criterion in a similar way as in the portfolio analysis. Finally, we perform a sensitivity analysis of the main parameters and hyperparameters of the model.",2022
RETRACTED: Research on Securities Portfolio Model Based on Genetic Optimization Neural Network (Retracted Article),"Portfolio is an investment management concept different from individual asset management. This consideration leads to an interesting result, that is, investors should buy a variety of securities at the same time instead of one kind of securities for diversified investment. Aiming at the limitations of BPNN (BP neural network) in traditional artificial neural network and its shortcomings such as many iterations, low convergence accuracy, and poor generalization, a portfolio method based on GA_BPNN (Genetic Optimization Neural Network) was proposed. The setting of GA (genetic algorithm) parameters and BPNN parameters are discussed in detail, and the implementation steps of genetic BP algorithm are described. The results show that the evaluation indexes of GA_BPNN prediction model are obviously better than those of the comparison prediction model, with the coincidence rate of 77.96% and the average absolute error of 12.451. The combination of GA and BPNN can effectively solve this problem. The simulation results of optimizing securities portfolio show that its optimization scheme is better than quadratic programming method, and this method is more correct, efficient, and practical.",2022
Stock Index Forecasting Using an Explainable TAFT Model with Online Data-Driven Social Sentiment Index,"Forecasting financial indices presents significant challenges owing to the inherent nonlinearity, noise, and disorder in financial time series data. To address these challenges, this study introduces a novel approach that integrates social sentiment analysis with advanced deep learning models. Specifically, a social sentiment index (SSI) is developed using FinBERT to analyze the sentiment scores of online article data from Investing.com. Additionally, a target-auxiliary fusion transformer (TAFT) is designed to effectively integrate SSI as an auxiliary feature with other indicators. This integration captures long-term dependencies and complex patterns in financial data more effectively than traditional time-series models. By incorporating the SSI, the model can capture the influence of social sentiment on financial markets, thus providing a more comprehensive and accurate prediction framework. Furthermore, TAFT incorporates a dynamic attention mechanism during both training and testing, thereby enhancing the explainability of the relative importance across auxiliary input features. The empirical results indicate that incorporating SSI significantly enhances the predictive accuracy of the financial forecasting model. TAFT achieved a 33.3% improvement in a mean absolute error (MAE) over the best-performing benchmark model for the S&P 500. Additionally, in a classification task, the model outperformed benchmark models with an accuracy of 0.71, a precision of 0.74, a recall of 0.64, and an F1 score of 0.63. This approach provides valuable insights for investors, analysts, and portfolio managers, demonstrating the efficacy of combining sentiment analysis with advanced time series models to improve financial decision-making.",2024
HYPERGRAPH-BASED REINFORCEMENT LEARNING FOR STOCK PORTFOLIO SELECTION,"Stock portfolio selection is an important financial planning task that dynamically re-allocates the investments to stock assets to achieve the goals such as maximal profits and minimal risks. In this paper, we propose a hypergraph-based reinforcement learning method for stock portfolio selection, in which the fundamental issue is to learn a policy function generating appropriate trading actions given the current environments. The historical time-series patterns of stocks are firstly captured. Then, different from prior works ignoring or implicitly modeling stock pairwise correlations, we present a HyperGraph Attention Module (HGAM) in the portfolio policy learning, which utilizes the hypergraph structure to explicitly model the group-wise industry-belonging relationships among stocks. The attention mechanism is also introduced in HGAM that quantifies the importance of different neighbors regarding the target node to aggregate the information on the stock hypergraph adaptively. Extensive experiments on the real-world dataset collected from China's A-share market demonstrate the significant superiority of our method, compared with state-of-the-art methods in portfolio selection, including both online learning-based methods and reinforcement learning-based methods. The data and codes of our work have been released at https://github.com/lixiaojieff/stock-portfolio.",2022
A novel neural network for data mining,"The algorithm proposed here for data mining deals with the standard Multilayer Perceptron using Temporal Backpropagation algorithm with the concept of Bollinger Band Crossover from the concept of Trading Systems added to it, and is referred to as the Bollinger Band Crossover Supervised Network (BBCSN). To visualize the performances of each of this algorithm, a portfolio management scheme was designed and translated into code using Visual C++. This enables a critical analysis of the algorithm, with respect to their financial performances. According to the results obtained in this project, the newly proposed and designed Bollinger Band Crossover gives much better results than generally obtained from a Multilayer Perceptron network.",2001
Using simulated annealing to schedule oil field drilling rigs,"Oil companies often have large backlogs of drilling opportunities. Optimizing this portfolio is critical. I used a simulated annealing algorithm to schedule drilling rigs for BP Exploration by making an analogy to the vehicle-routing problem, and I estimated the value of acquiring additional drilling rigs. By considering the perishability of projects' benefits in optimizing over a multi-period planning horizon, I increased the value of portfolios by deferring attractive projects in favor of less attractive ones. This violates the standard practice of maximizing value by sorting projects by such attractiveness measures as net present value or internal rate of return. My program is BP's primary planning tool in the Prudhoe Bay field. The first year's application improved portfolio net present value by approximately $30 million over traditional planning methods.",1996
GA-BP neural network modeling for project portfolio risk prediction,"PurposeProject portfolio risk (PPR) management plays an important role in promoting the smooth implementation of a project portfolio (PP). Accurate PPR prediction helps managers cope with risks timely in complicated PP environments. However, studies on accurate PPR impact degree prediction, which consists of both risk occurrence probabilities and risk impact consequences considering project interactions, are limited. This study aims to model PPR prediction and expand PPR prediction tools.Design/methodology/approachIn this study, the authors build a PPR prediction model based on a genetic algorithm and back-propagation neural network (GA-BPNN) integrated with entropy-trapezoidal fuzzy numbers. Then, the authors verify the proposed model with real data and obtain PPR impact degrees.FindingsThe test results indicate that the proposed method achieves an average absolute error of 0.002 and an average prediction accuracy rate of 97.8%. The former is reduced by 0.038, while the latter is improved by 32.1% when compared with the results of the original BPNN model. Finally, the authors conduct an index sensitivity analysis for identifying critical risks to effectively control them.Originality/valueThis study develops a hybrid PPR prediction model that integrates a GA-BPNN with entropy-trapezoidal fuzzy numbers. The authors use this model to predict PPR impact degrees, which consist of both risk occurrence probabilities and risk impact consequences considering project interactions. The results provide insights into PPR management.",2024
Styrenics - Lummus adds BP's PS process to licensing portfolio,,1997
Educating capable doctors-A portfolio approach. Linking learning and assessment,"Background: Teachers want students to focus on their learning to become capable doctors; yet, students primarily want to focus on passing their exams. How much of this paradox is explained by learning and assessment being seen as two different entities rather than as the continuum of one and the same process? How may the two areas be more closely and effectively linked? Aim: This article describes and illustrates a conceptual framework for an approach termed capability-based portfolio assessment. Results and conclusions: Thinking about capability, i.e. the ability to perform in the real world, is needed for a contemporary curriculum and assessment design. A capability-focus will help students to integrate the foundations of medical practice with learning how to become a capable, reflective and life-long learner. A well-structured capability portfolio, regularly presented and reviewed, will be a useful tool to guide the journey, and should have the potential to help drive deep learning and allow the assessment of capabilities that are hard to assess using conventional approaches. Assessment based on portfolio approaches should not equate to increasing the overall assessment burden as it will reduce the need for more traditional assessment methods.",2009
Deep learning for 3D imaging and image analysis in biomineralization research,"Biomineralization research examines structure-function relations in all types of exo- and endo-skeletons and other hard tissues of living organisms, and it relies heavily on 3D imaging. Segmentation of 3D renderings of biomineralized structures has long been a bottleneck because of human limitations such as our available time, attention span, eye-hand coordination, cognitive biases, and attainable precision, amongst other limitations. Since recently, some of these routine limitations appear to be surmountable thanks to the development of deeplearning algorithms for biological imagery in general, and for 3D image segmentation in particular. Many components of deep learning often appear too abstract for a life scientist. Despite this, the basic principles underlying deep learning have many easy-to-grasp commonalities with human learning and universal logic. This primer presents these basic principles in what we feel is an intuitive manner, without relying on prerequisite knowledge of informatics and computer science, and with the aim of improving the reader's general literacy in artificial intelligence and deep learning. Here, biomineralization case studies are presented to illustrate the application of deep learning for solving segmentation and analysis problems of 3D images ridden by various artifacts, and/or which are plainly difficult to interpret. The presented portfolio of case studies includes three examples of imaging using micro-computed tomography (mu CT), and three examples using focused-ion beam scanning electron microscopy (FIB-SEM), all on mineralized tissues. We believe this primer will expand the circle of users of deep learning amongst biomineralization researchers and other life scientists involved with 3D imaging, and will encourage incorporation of this powerful tool into their professional skillsets and to explore it further.",2020
The design and implementation of a deep reinforcement learning and quantum finance theory-inspired portfolio investment management system,"Deep Learning (DL) and Reinforcement Learning (RL) are common machine learning techniques used in automatic trading, notwithstanding, RL is deficient in portfolio investment in terms of funds distribution, potential loss control, profit maximization, and examine undetected environment. This paper proposed an intelligent Quantum Finance-based portfolio investment system (QFPIS), which is a combination of Deep Reinforcement Learning (DRL) with Quantum Finance Theory (QFT) to improve these conditions. There are two major agents embodied in the system: 1) a trading agent based on Deep Deterministic Policy Gradient algorithm to determine investment weighting for different financial products by generating continuous actions; 2) an intelligent agent based on Policy Gradient (PG) algorithm to enact risk control and determine whether to hold current orders by producing discrete actions depend on daily Quantum Price Levels (QPLs). The advantages of incorporating a two agents system design are to devise stable and realistic fund allocation for different products in portfolio. Experiment results had shown robustness, flexibility, and profitability on a series of forex products and the U.S. stocks in the back-testing phase as compared to other RL trading systems.",2024
Navigating Inflation Challenges: AI-Based Portfolio Management Insights,"After 2010, the consumer price index fell to a low level in the EU. In the euro area, it remained low between 2010 and 2020. The European Central Bank has even had to take action against the emergence of deflation. The situation changed significantly in 2021. Inflation jumped to levels not seen for 40 years in the EU. Our study aims to use artificial intelligence to forecast inflation. We also use artificial intelligence to forecast stock index changes. Based on the forecasts, we propose portfolio reallocation decisions to protect against inflation. The forecasting literature does not address the importance of structural breaks in the time series, which, among other things, can affect both the pattern recognition and prediction capabilities of various machine learning models. The novelty of our study is that we used the Zivot-Andrews unit root test to determine the breakpoints and partitioned the time series into training and testing datasets along these points. We then examined which database partition gives the most accurate prediction. This information can be used to re-balance the portfolio. Two different AI-based prediction algorithms were used (GRU and LSTM), and a hybrid model (LSTM-GRU) was also included to investigate the predictability of inflation. Our results suggest that the average error of the inflation forecast is a quarter of that of the stock market index forecast. Inflation developments have a fundamental impact on equity and government bond returns. If we obtain a reliable estimate of the inflation forecast, we have time to rebalance the portfolio until the inflation shock is incorporated into government bond returns. Our results not only support investment decisions at the national economy level but are also useful in the process of rebalancing international portfolios.",2024
Portfolio-based learning in surgery Making competencies visible,"Background Due to an increasing competence orientation of medical studies, surgical curricula are being adapted in many places. In addition to surgical knowledge and practical skills, these should also teach competencies in differential diagnostics and treatment. The teaching of surgical knowledge through lectures and seminars and the demonstration of practical skills, e.g., through the use of logbooks in the Bock Practical Surgery (BP), only allows limited active engagement with surgical competencies on differential diagnostics and treatment. A reflection-based portfolio allows, through the independent written elaboration of surgical topics, an active engagement with the competencies and promises a higher learning effect. In the context of the implementation of such a portfolio as part of the proof of activity in BP, the effects on the acquisition of competencies and on the way of learning were investigated. Material and methods Using a mixed methods approach, we compared competence acquisition using a reflection-based portfolio with learning using a logbook. Students conducted a self-assessment of competencies using questionnaire surveys before and after the BP. Through focus group interviews with discussions among students using a guideline, we explored the different ways of acquiring competencies. In addition, the examination and evaluation results of both cohorts were compared. Results and discussion Students' self-assessed competency acquisition and examination and evaluation results showed no differences when comparing the two cohorts. During the focus group interviews, we were able to show that in the perception of the students, surgical competencies can be made more visible and thus more explicit with the help of a reflection-based portfolio. In addition, self-regulated learning was promoted without neglecting practical skills. Students demanded greater supervision and guidance by mentors in both groups.",2023
Machine Learning for Continuous-Time Finance,"We develop an algorithm for solving a large class of nonlinear high-dimensional continuous-time models in finance. We approximate value and policy functions using deep learning and show that a combination of automatic differentiation and Ito's lemma allows for the computation of exact expectations, resulting in a negligible computational cost that is independent of the number of state variables. We illustrate the applicability of our method to problems in asset pricing, corporate finance, and portfolio choice and show that the ability to solve high-dimensional problems allows us to derive new economic insights.",2024
Non-traditional Assessment Methods for Hospitality Educators: The Student Portfolio,"Considering developments such as growing student numbers, increased faculty/student ratios, and increasingly diverse student population, hospitality educational institutions require flexible and alternative approaches to teaching, learning, and assessing their students. This paper promotes the student portfolio as an alternative assessment method of hospitality students, providing them with an approach to learning and development vital for successfully competing in the hospitality industry. Benefits of student portfolios range from resource based to deep learning, greater student motivation, and the provision of key managerial skills in areas such as decision-making, empowerment, self-reflection and self-analysis.",2008
Enhancing Logistic Regression Using Neural Networks for Classification in Actuarial Learning,"We developed a methodology for the neural network boosting of logistic regression aimed at learning an additional model structure from the data. In particular, we constructed two classes of neural network-based models: shallow-dense neural networks with one hidden layer and deep neural networks with multiple hidden layers. Furthermore, several advanced approaches were explored, including the combined actuarial neural network approach, embeddings and transfer learning. The model training was achieved by minimizing either the deviance or the cross-entropy loss functions, leading to fourteen neural network-based models in total. For illustrative purposes, logistic regression and the alternative neural network-based models we propose are employed for a binary classification exercise concerning the occurrence of at least one claim in a French motor third-party insurance portfolio. Finally, the model interpretability issue was addressed via the local interpretable model-agnostic explanations approach.",2023
Portfolio Management System with Reinforcement Learning,"Portfolio management is a critical issue which should be skilled by position sizing and resource allocation. Traditional and generic portfolio strategies require to forecast the future stocks prices as the model inputs, which is not a trivial task in the real-world applications. To solve the above limitations and provide a better solution for the portfolio management to the inventors, we then develop a portfolio management system (PMS) with equity market neutral strategy in reinforcement learning. A novel reward function involving Sharpe ratio is also designed to evaluate the performance of the developed systems. Experimental results indicate that the PMS with Sharpe ratio reward function has the outstanding performance, and increase the return 39.0% and decrease the drawdown of 13.7% on average than that with reward function of trading return. In addition, the developed PMS_CNN model is more suitable and profitable to construct RL portfolio, but has a 1.98 times more drawdown risk than the PMS_RNN. Overall, the proposed PMS outperforms the benchmark strategies in the measurements of total return and Sharpe ratio. The PMS is profitable and effective with lower investment risk, and the novel reward function by involving Sharpe ratio really enhances the performance, and well support the resource-allocation in the empirical stock trading.",2020
An AI-assisted method artefact for investing decision: automatic identification of winning stocks within a value portfolio,"PurposeThis paper combines the key aspects of artefact-based systems. DSS and artificial intelligence in a unified approach to solve a typical financial analysis problem within the design science paradigm.Design/methodology/approachOur proposition is based on the seven design science guidelines. Our proposed method artefact is a financial application catering to the investment domain in particular. We present a detailed analysis of stock data from the Indian market for an extended period of 17 years by deploying state-of-the-art algorithms. The use of computational intelligence involving machine and deep learning helps in automatically identifying winning stocks within a value portfolio, that too, on a forward-looking basis.FindingsOur method artefact depicts superior results by identifying outperforming stocks, differentiated from the weak ones, within the value portfolio.Originality/valueThis has significant implications for the investing community, particularly the Indian investors. Traditional research in value stocks has shown underwhelming performance in differentiating lucrative stocks from the rest.",2025
Neural Network Model for the Multiple Factor Analysis of Economic Efficiency of an Enterprise,"The paper proposes a neural network model for assessing the impact of financial instruments and organizational forms on the growth of efficiency within the industry based on the case study of such a high-technology company as the Rosatom State Atomic Energy Corporation. A large holding that is a monopoly state corporation (Rosatom SC) manages more than 300 large enterprises which it owns (either fully or partially, through joint ventures, such as JSCs), or controls directly, such as FSUEs (Federal state unitary enterprises) and FSBIs (Federal state budgetary institutions). Objective: To explain the degree of impact of financial instruments and their groups on the overall economic efficiency using a non-recurrent neural network-based analysis, and to build a neural network-based profit generation model. The main criterion for the economic efficiency of the head enterprise of Rosatom group is its combined profit for the year. Since 2007, Rosatom group has used EBITDA as the main indicator of the company's performance. The Rosatom's order portfolio exceeds $133 billion, which is 67% of the global nuclear power plant construction market. The present paper suggests a methodology for evaluating the economic efficiency of existing organizational forms, financial instruments and support institutions for Rosatom. The paper proposes an algorithm for building a neural network model for evaluating an enterprise's efficiency.",2021
A Novel Financial Forecasting Approach Using Deep Learning Framework,"Moving averages, which are calculated with statistical approaches, are obtained from the price, but a horizontal market has noise problems and a trending market has lag problems. Since there is an inverse correlation between noise and delay, it is not possible to completely eliminate it with statistical approaches. In the light of the literature, it is common to obtain the classification accuracy or price estimation using regression in studies on financial forecasting. However, a high classification accuracy or a low predicted error cannot guarantee that the portfolio will win. For this reason, a Backtest process that shows the portfolio gain is also needed. This study focused on obtaining moving averages with a deep learning model instead of using statistical approaches. Better results were obtained when the moving averages were obtained with the proposed approach and the statistical approaches used the Backtest for the same periods. Experimental studies have shown that the PF is improved by an average of 9% and the trend forecast accuracy level reaches 82%.",2023
Fund Price Analysis Using Convolutional Neural Networks for Multiple Variables,"Investing in funds has the effect of indirectly employing asset management professionals with specialized knowledge and experience, which can result in a diversified investment through the use of a portfolio. In this study, we focus on learning the patterns of prices rather than time points to predict Korean fund prices. We convert time-series data into 2-dimensional images and analyze them using a convolutional neural network. To improve the fund price forecasting performance, we consider the following aspects. A Korean fund should be recommended according to the level of risk aversion. The risk level of the fund is determined by the proportion of risky assets. Therefore, when estimating the fund price, the risk level of the fund needs to be considered. In this study, we use 15 additional variables, such as foreign stock indexes, foreign exchange rates, and Korean stock indices, in addition to the fund price data. The appropriate filter size, which plays an important role in this process, is proposed. In addition, types of networks and architectures are selected as suitable for forecasting the fund price. We also demonstrate that the number of output classes can be adjusted to increase the future return of the fund. Through this methodology with multiple variables, we can achieve a 25% cumulative profit for 2 years. This means that multi-variable models have a higher cumulative return than the single-variable model and KOSPI and thus a higher average of all funds for active investors.",2019
Factor Integration Based on Neural Networks for Factor Investing,"Factor investing is one kind of quantitative investing methodologies for portfolio construction based on factors. Factors with different style are extracted from multiple sources such as market data, fundamental information from financial statements, sentimental information from the Internet, etc. Numerous style factors are defined by Barra model proposed by Morgan Stanley Capital International(MSCI) to explain the return of a portfolio. Multiple factors are usually integrated linearly when being put to use, which ensures the stability of the process of integration and enhances the effectiveness of integrated factors. In this work, we integrate factors by machine learning and deep learning methodologies to explore deeper information among multiple style factors defined by MSCI Barra model. Multi-factors indexes are compiled using Smart Beta Index methodology proposed by MSCI. The results show non-linear integration by deep neural network can enhance the profitability and stability of the index compiled according to the integrated factor.",2019
Volatility forecasting with hybrid neural networks methods for Risk Parity investment strategies,"We present a hybrid method for computing volatility forecasts that can be used to implement a risk-controlled strategy for a multi-asset portfolio consisting of both US and international equities. Recent years have been characterized by extremely low yields, with 2022 marked by rising interest rates and an increasing inflation rate. These factors produced new challenges for both private and institutional investors, including the need for robust forecast methods for financial assets' volatilities. Addressing such task, our research focuses on a hybrid solution that combines classical statistical models with specific classes of Recurrent Neural Networks (RNNs). In particular, we first use the Generalized Autoregressive Conditional Heteroscedasticity (GARCH) approach within the preprocessing phase to capture volatility clustering, striking an efficient balance between computational effort and accuracy, to then apply RNN architectures, namely GRU, LSTM, and a mixed model with both units, as to maximize performances of volatility forecasts later used as input factors for risk-controlled investment strategies. In terms of portfolio allocation, we focus on a simplified version of the Risk Parity method that was first proposed by the Research division of S&P Global. This version ignores the contribution of cross-correlations among assets, nevertheless providing encouraging results. Indeed, we show the effectiveness of the chosen approach by providing forward-looking risk parity portfolio strategies that outperform standard risk/return portfolio structures.",2023
Hybrid ARMA-GARCH-Neural Networks for intraday strategy exploration in high-frequency trading,"The frequency of armed conflicts increased during the last 20 years. The problems of the emergence of military disputes, not only concern social parameters, but also economic and financial dimensions. This study examines the potential impact of global geopolitical events on the stock market prices of the Dow Jones U.S. Aerospace & Defense Index and Foreign Exchange (FOREX) markets movements. We analyse whether defence stocks and exchange rate perform similarly during military incidents or geopolitical crises. We built an Autoregressive Moving Average Model with a Generalized Autoregressive Conditional Heteroskedasticity process (ARMAGARCH) with the machine learning methods of Neural Networks, Deep Recurrent Convolutional Neural Networks, Deep Neural Decision Trees, Quantum Neural Networks, and Quantum Recurrent Neural Networks, aimed at detecting intraday patterns for forecasting defence stock market and FOREX markets disturbances in a market microstructure framework. The empirical results provide preliminary findings on the foreseeability of market disturbances and small differences are observed before and during geopolitical events. Additionally, we confirm the effectiveness of the hybrid model ARMA-GARCH with the machine learning approaches, being ARMAGARCH-Quantum Recurrent Neural Network the technique that achieves the best accuracy results. Our work has a large potential impact on investment market agents and portfolio managers, as shocks from geopolitical events could provide a new methodology to support the decision-making process for trading in High-Frequency Trading.",2024
Asset correlation based deep reinforcement learning for the portfolio selection,"Portfolio selection is an important application of AI in the financial field, which has attracted considerable attention from academia and industry alike. One of the great challenges in this application is modeling the correlation among assets in the portfolio. However, current studies cannot deal well with this challenge because it is difficult to analyze complex nonlinearity in the correlation. This paper proposes a policy network that models the nonlinear correlation by utilizing the self-attention mechanism to better tackle this issue. In addition, a deterministic policy gradient recurrent reinforcement learning method based on Monte Carlo sampling is constructed with the objective function of cumulative return to train the policy network. In most existing reinforcement learning-based studies, the state transition probability is generally regarded as unknown, so the value function of the policy can only be estimated. Based on financial backtest experiments, we analyze that the state transition probability is known in the portfolio, and value function can be directly obtained by sampling, further theoretically proving the optimality of the proposed reinforcement learning method in the portfolio. Finally, the superiority and generality of our approach are demonstrated through comprehensive experiments on the cryptocurrency dataset, S&P 500 stock dataset, and ETF dataset.",2023
A learning-based strategy for portfolio selection,"Neural networks have shown exceptional performance in targeting different research areas. In this paper, we investigate a learning-based strategy for optimal investment by using neural network. First, an optimization problem for portfolio selection is proposed. Then, a neural network model is used to optimize this problem. The main contribution is that based on this proposed optimization problem and neural network model, we can easily implement the structure and obtain the final results by using deep learning software. Finally, we numerically compare the results obtained from our strategy with those of classic solutions. The comparison demonstrates the effectiveness of the learning-based strategy.",2021
Factors Influencing Student Learning in Portfolio Assessed Introductory Programming,"Constructive alignment combines constructive learning theories with aligned curriculum to promote deep learning. Using an action research methodology, this work reflects upon twelve iterations, over 6-years, of a project that aimed to implement constructive alignment using portfolio assessment for teaching introductory programming. Student results and staff reflections are used to highlight factors and principles that influenced the teaching and learning environment created. The paper advocates for the use of pragmatic constructive learning theories, aligned curriculum, formative feedback, and a positive view of student motivation. These insights can be used to help guide the development of student-centered teaching and learning environments.",2014
A DEEP LEARNING ALGORITHM FOR OPTIMAL INVESTMENT STRATEGIES UNDER MERTON'S FRAMEWORK,"This paper treats Merton's classical portfolio optimization problem for a market participant who invests in safe assets and risky assets to maximize the expected utility. When the state process is a d-dimensional Markov diffusion, this problem is transformed into a problem of solving a Hamilton-Jacobi-Bellman (HJB) equation. The main purpose of this paper is to solve this HJB equation by a deep learning algorithm: the deep Galerkin method, first suggested by J. Sirignano and K. Spiliopoulos. We then apply the algorithm to get the solution to the HJB equation and compare with the result from the finite difference method.",2022
Deep graph convolutional reinforcement learning for financial portfolio management-DeepPocket,"Portfolio management aims at maximizing the return on investment while minimizing risk by continuously reallocating the assets forming the portfolio. These assets are not independent but correlated during a short time period. A graph convolutional reinforcement learning framework called DeepPocket is proposed whose objective is to exploit the time-varying interrelations between financial instruments. These interrelations are represented by a graph whose nodes correspond to the financial instruments while the edges correspond to a pair-wise correlation function in between assets. DeepPocket consists of a restricted, stacked autoencoder for feature extraction, a convolutional network to collect underlying local information shared among financial instruments and an actor-critic reinforcement learning agent. The actor-critic structure contains two convolutional networks in which the actor learns and enforces an investment policy which is, in turn, evaluated by the critic in order to determine the best course of action by constantly reallocating the various portfolio assets to optimize the expected return on investment. The agent is initially trained offline with online stochastic batching on historical data. As new data become available, it is trained online with a passive concept drift approach to handle unexpected changes in their distributions. DeepPocket is evaluated against five real-life datasets over three distinct investment periods, including during the Covid-19 crisis, and clearly outperformed market indexes.",2021
Latent factor model for asset pricing,"One of the fundamental questions in asset pricing is Why different assets earn different average returns?' In this paper, we designed an autoencoder based asset pricing model to explain the return difference among the stocks in an index. The trained autoencoder generates a set of latent representations that constitutes a combined -`communal'- factor to better explains a large portion of the return differences among the stocks in an index. After analyzing all the stocks in S&P-500, Russel-3000, and NASDAQ-100, we found that our proposed latent factor model outperforms many other factor models in predicting the next day's return. Notably, the experiment results show that on average non-communal stocks earn 0.05% over communal stocks. However, the risk associated with this non-communal stock is also 0.8% higher than communal stocks. The experiments confirm that the superior performance comes from the compensation of high risk associated with these non-communal stocks. Investors will benefit from our latent factor model to identify these communal and non-communal stocks for a high return while diversifying their asset portfolio. (C) 2020 Elsevier B.V. All rights reserved.",2020
Automated Algorithm Selection in Single-Objective Continuous Optimization: A Comparative Study of Deep Learning and Landscape Analysis Methods,"In recent years, feature-based automated algorithm selection using exploratory landscape analysis has demonstrated its great potential in single-objective continuous black-box optimization. However, feature computation is problem-specific and can be costly in terms of computational resources. This paper investigates feature-free approaches that rely on state-of-the-art deep learning techniques operating on either images or point clouds. We show that point-cloud-based strategies, in particular, are highly competitive and also substantially reduce the size of the required solver portfolio. Moreover, we highlight the effect and importance of cost-sensitive learning in automated algorithm selection models.",2022
Modeling and Forecasting the Volatility of NIFTY 50 Using GARCH and RNN Models,"The stock market is constantly shifting and full of unknowns. In India in 2000, technological advancements led to significant growth in the Indian stock market, introducing online share trading via the internet and computers. Hence, it has become essential to manage risk in the Indian stock market, and volatility plays a critical part in assessing the risks of different stock market elements such as portfolio risk management, derivative pricing, and hedging techniques. As a result, several scholars have lately been interested in forecasting stock market volatility. This study analyzed India VIX (NIFTY 50 volatility index) to identify the behavior of the Indian stock market in terms of volatility and then evaluated the forecasting ability of GARCH- and RNN-based LSTM models using India VIX out of sample data. The results indicated that the NIFTY 50 index's volatility is asymmetric, and leverage effects are evident in the results of the EGARCH (1, 1) model. Asymmetric GARCH models such as EGARCH (1, 1) and TARCH (1, 1) showed slightly better forecasting accuracy than symmetric GARCH models like GARCH (1, 1). The results also showed that overall GARCH models are slightly better than RNN-based LSTM models in forecasting the volatility of the NIFTY 50 index. Both types of models (GARCH models and RNN based LSTM models) fared equally well in predicting the direction of the NIFTY 50 index volatility. In contrast, GARCH models outperformed the LSTM model in predicting the value of volatility.",2022
Index Tracking Via Learning to Predict Market Sensitivities,"Index funds are substantially preferred by investors nowadays, and market sensitivities are instrumental in managing index funds. An index fund is a mutual fund aiming to track the returns of a pre-defined market index (e.g., the S&P 500). A basic strategy to manage an index fund is replicating the index's constituents and weights identically, which is, however, cost-ineffective and impractical. To address this issue, it is required to replicate the index partially with accurately predicted market sensitivities. Accordingly, we propose a novel partial-replication method via learning to predict market sensitivities. We first examine deep-learning models to predict market sensitivities in a supervised manner with our data-processing methods. Then, we propose a partial-index-tracking optimization model controlling the net predicted market sensitivities of the portfolios and index to be the same. These processes' efficacy is corroborated by our experiments on the Korea Composite Stock Price Index 200. Our experiments show a significant reduction of the prediction errors compared with historical estimations and competitive tracking errors of replicating the index utilizing fewer than half of the entire constituents. Therefore, we show that applying deep learning to predict market sensitivities is promising and that our portfolio construction methods are practically effective. Additionally, to our knowledge, this is the first study addressing market sensitivities focused on deep learning.",2024
Enhancing Predictive Capabilities for Identifying At-Risk Stocks Using Multivariate Time-Series Classification: A Case Study of the Thai Stock Market,"This study proposes a multivariate time-series classification approach using deep learning to predict stocks likely to be flagged by the Market Surveillance Measure List in the Thai stock market. Formulated as a binary classification problem, the model distinguishes At-Risk and Normal stocks based on two primary datasets: End-of-Day stock prices and Market Surveillance Measure List records, incorporating trading volumes and technical indicators. To address data imbalance, concept drift, and long-term dependencies, the framework integrates feature engineering, cost-sensitive learning, and rolling window training. Experimental results show deep learning models significantly outperform traditional baseline methods in capturing financial risk patterns. The study identifies models that effectively balance predictive accuracy with computational efficiency, with performance varying based on forecasting horizons. Despite improvements from specialized techniques, the study identifies challenges in long-term financial risk prediction. These findings support market surveillance, algorithmic trading, and portfolio risk management, with future work exploring explainable AI, adaptive learning, and alternative data sources to enhance interpretability and long-term forecasting.",2025
Efficient risk estimation via nested multilevel quasi-Monte Carlo simulation,"We consider the problem of estimating the probability of a large loss from a financial portfolio, where the future loss is expressed as a conditional expectation. Since the conditional expectation is intractable in most cases, one may resort to nested simulation. To reduce the complexity of nested simulation, we present an improved multilevel Monte Carlo (MLMC) method by using quasi-Monte Carlo (QMC) to estimate the portfolio loss in each financial scenario generated via Monte Carlo. We prove that using QMC can accelerate the convergence rates in both the crude nested simulation and the multilevel nested simulation. Under certain conditions, the complexity of the proposed MLMC method can be reduced to..(epsilon(-2)(log epsilon)(2)). On the other hand, we find that using QMC in MLMC encounters a high-kurtosis phenomenon due to the existence of indicator functions. To remedy this, we propose a smoothed method which uses logistic sigmoid functions to approximate indicator functions. Numerical results show that the optimal MLMC complexity O(epsilon(-2)) is almost attained even in moderate high dimensions.",2024
Evaluation of Deep Learning Algorithms for Quadratic Hedging,"We solve the quadratic hedging problem by deep learning in discrete time. We consider three deep learning algorithms corresponding to three architectures of neural network approximation: approximating controls of different periods by different feedforward neural networks (FNNs) as proposed by Han and Weinan (2016), using a single FNN with decision time as an input to approximate controls of different periods, and using a recursive neural network (RNN) to utilize historical information. We evaluate these algorithms under the discrete-time Black-Scholes model and the DCC-GARCH model for hedging basket options on portfolios of up to 100 assets with time to maturity up to one year. We compare them in terms of their hedging error on the test data, extent of overlearning, learned hedging strategy, training speed, and scalability. Our results favor the single FNN and RNN approximations overall; the multiple FNN approximation can fail for a large portfolio and a long maturity. We also evaluate the performance of the single FNN and RNN algorithms in a data-driven framework, where data is generated by resampling without assuming any parametric model.",2022
PBIL for optimizing inception module in convolutional neural networks,"Inception module is one of the most used variants in convolutional neural networks. It has a large portfolio of success cases in computer vision. In the past years, diverse inception flavours, differing in the number of branches, the size and the number of the kernels, have appeared in the scientific literature. They are proposed based on the expertise of the practitioners without any optimization process. In this work, an implementation of population-based incremental learning is proposed for automatic optimization of the hyperparameters of the inception module. This hyperparameters optimization undertakes classification of the MNIST database of handwritten digit images. This problem is widely used as a benchmark in classification, and therefore, the learned best configurations for the Inception module will be of wide use in the deep learning community. In order to reduce the carbon footprint of the optimization process, policies for reducing the redundant evaluations have been undertaken. As a consequence of this work, an evaluation of configurations of the inception module and a mechanism for optimizing hyperparameters in deep learning architectures are stated.",2023
Tactical asset allocation: An artificial neural network based model,"An artificial neural network was trained to support a tactical asset allocation investment strategy. The allocation strategy considers three asset classes: U.S. stocks, bonds and money market. The neural net-work was trained to forecast the probability that each asset class would outperform the other two by the end of a one-month period. The neural network was trained with the backpropagation algorithm. A tactical asset allocation portfolio was invested in the asset class expected to have the best performance according to the neural network prediction. The strategy was simulated during a one-year period During the simulation period the strategy outperformed the S&P500 Index by 1,792 basis points. The artificial neural network prediction was accurate 92% of the time.",2001
Developing a AI Algorithm for Trading the SiH8 Futures Contract at MoEx on the Basis of Big Data Quantization,"Solving the problem of sustainable regional development by using a neural-network stock trading algorithm is of importance. Analysis has shown many businesses successfully use the stock market mechanisms not only to invest their temporarily disposable assets in securities portfolio, but also for speculation. Research has shown that in the modern world, the ever-larger bulk of stock exchange transactions are done by using mechanical trading systems (trading robots). AI-based systems stand out of mechanical trading systems. Our effort has produced a neural-network trading algorithm for speculative stock transactions with the SiH8 futures contract in USD. The developed neural network is a perception that has an six-parameter input layer, a hidden layer, and a single-parameter output layer that tells the user to either buy (+1) or sell a financial instrument. In the light of transition to digital economy, it is important to use artificial intelligence systems that enable big data processing for pattern-based problem solving.",2018
Probability rough set and portfolio optimization integrated three-way predication decisions approach to stock price,"In the stock market, accurate trend judgment and reasonable asset distribution are effective ways to obtain ideal return. However, the real stock market is affected by the objective economic environment, investors' expected return and other potential factors, which makes the classical portfolio strategy face more challenges and pressures. How to build a reliable portfolio strategy in an uncertain environment will be a scientific problem worthy of in-depth discussion. To address this issue, this paper combines machine learning with rough set to establish a new rough set theory prediction model, quantitatively dividing the stock data into three categories and targetedly predicting the future trend according to the complexity. Based on the proposed prediction model, a new portfolio strategy is proposed by integrating the mean-variance model. Firstly, for reducing the volatility and noise of the original data of stock price, outlier processing (OP) and wavelet denoising (WD) are utilized. Secondly, for the sake of pertinently forecasting the future trend of different characteristic stock price, a three-way prediction (TWP) decisions approach is constructed based on multiscale permutation entropy (MPE), probabilistic rough set (PRS), variational modal decomposition (VMD) and deep learning. Finally, 20 stocks of Shanghai and Shenzhen stock exchanges are taken as research samples to verify the scientificity and rationality of the portfolio strategy. The results show that the proposed approach not only provides scientific support and reference for investors' investment decisions, but also provides a new investment strategy theory and method for the investment decisions of the stock market.",2023
Deep reinforcement learning for multi-agent interaction,"The development of autonomous agents which can interact with other agents to accomplish a given task is a core area of research in artificial intelligence and machine learning. Towards this goal, the Autonomous Agents Research Group develops novel machine learning algorithms for autonomous systems control, with a specific focus on deep reinforcement learning and multi-agent reinforcement learning. Research problems include scalable learning of coordinated agent policies and inter-agent communication; reasoning about the behaviours, goals, and composition of other agents from limited observations; and sample-efficient learning based on intrinsic motivation, curriculum learning, causal inference, and representation learning. This article provides a broad overview of the ongoing research portfolio of the group and discusses open problems for future directions.",2022
Deep Learning in Characteristics-Sorted Factor Models,"This article presents an augmented deep factor model that generates latent factors for cross-sectional asset pricing. The conventional security sorting on firm characteristics for constructing long-short factor portfolio weights is nonlinear modeling, while factors are treated as inputs in linear models. We provide a structural deep-learning framework to generalize the complete mechanism for fitting cross-sectional returns by firm characteristics through generating risk factors (hidden layers). Our model has an economic-guided objective function that minimizes aggregated realized pricing errors. Empirical results on high-dimensional characteristics demonstrate robust asset pricing performance and strong investment improvements by identifying important raw characteristic sources.",2024
Linear-Quadratic Stochastic Delayed Control and Deep Learning Resolution,"We consider a simple class of stochastic control problems with a delayed control, in both the drift and the diffusion part of the state stochastic differential equation. We provide a new characterization of the solution in terms of a set of Riccati partial differential equations. Existence and uniqueness of a solution are obtained under a sufficient condition expressed directly as a relation between the time horizon, the drift, the volatility and the delay. Furthermore, a deep learning scheme (The code is available in a IPython notebook.) is designed and used to illustrate the effect of the delay feature on the Markowitz portfolio allocation problem with execution delay.",2021
"Using fear, greed and machine learning for optimizing global portfolios: A Black-Litterman approach","We introduce a new dimension in constructing relative investor views for the Black-Litterman model by incorporating fear/greed technical indicator predictions as a proxy for investor sentiment in the portfolio construction process. We apply a hybrid CEEMDAN-GRU deep learning model to forecast this indicator and the XGBoost ensemble learning algorithm to forecast returns for ten country ETFs and create relative views for the Black-Litterman model. These models beat several benchmark forecasting models. Our empirical results show that the proposed approach outperforms the Markowitz, minimum-variance, equally-weighted and risk-parity strategies along with four other Black-Litterman approaches from the literature for six investment periods.",2023
Mercury: A Deep Reinforcement Learning-Based Investment Portfolio Strategy for Risk-Return Balance,"Stock portfolio is a hard issue in the Fintech field due to the diversity of data characteristics and the dynamic complexity of the market. Despite advances in deep learning that have made great progress in the complex and highly stochastic portfolio problem, the existing research still faces significant limitations. They either consider only investment returns or simply use some macro-market data to guide their models against risk. The preferred direction of the market greatly affects the choice of stock. And in practice, investors are more inclined to portfolios with low correlation between assets because of the ripple relationships between related things. In this paper, we propose a novel framework, called Mercury, which views stock screening as a reinforcement learning process. In particular, to enhance the ability to perceive changes in the market and generate higher returns, our framework models the sensitivity of the market preferences and learns dynamic temporal and spatial dependency patterns between assets from historical trading data. Additionally, the framework employs reinforcement learning to screen the overall low-correlation portfolio, which can better improve the ability to withstand investment risks while guaranteeing returns. The daily dataset of China's A-share market is used as the research sample to verify the effectiveness and robustness of Mercury, and our framework has strong generalization ability, which can be easily generalized to other trading procedures.",2023
Insights from a Patent Portfolio Analysis on Sensor Technologies for Measuring Fruit Properties,"A patent portfolio focusing on sensors for the measurement of fruit properties was generated and analyzed with the aim of contributing to a better understanding of the trends in the development and application of sensors intended for measuring fruit properties and their changes. A patent portfolio of 189 patents, utility models and patent applications was formed. Three groups of patents were identified: (i) sensor-based measurement of individual parameters, (ii) multisensor solutions for the simultaneous monitoring of multiple relevant aspects and (iii) solutions integrating sensor-derived data with artificial intelligence tools and techniques. The analysis of the patent portfolio pointed out the main driving forces of technology strengthening in the field of fruit property measurement. The development of sensing technologies enables the real-time, rapid and cost-effective determination of ever-increasing and more sophisticated sets of fruit properties and environmental conditions. Solutions integrating different sensing technologies into multisensor systems for monitoring fruit quality, ripening or freshness as holistic concepts opens avenues for the introduction of a new approach to fresh produce management. Increasing numbers of solutions introducing the application of artificial intelligence tools such as computer vision, machine learning and deep learning into the fresh produce supply chain contribute to the possibilities of substituting human decision-making at points of relevance for fresh produce management with optimal evidence-based solutions.",2024
l1-Regularization in Portfolio Selection with Machine Learning,"In this work, we investigate the application of Deep Learning in Portfolio selection in a Markowitz mean-variance framework. We refer to a l(1) regularized multi-period model; the choice of the l(1) norm aims at producing sparse solutions. A crucial issue is the choice of the regularization parameter, which must realize a trade-off between fidelity to data and regularization. We propose an algorithm based on neural networks for the automatic selection of the regularization parameter. Once the neural network training is completed, an estimate of the regularization parameter can be computed via forward propagation. Numerical experiments and comparisons performed on real data validate the approach.",2022
MAPFASTER: A Faster and Simpler take on Multi-Agent Path Finding Algorithm Selection,"Portfolio-based algorithm selection can help in choosing the best suited algorithm for a given task while leveraging the complementary strengths of the candidates. Solving the Multi-Agent Path Finding (MAPF) problem optimally has been proven to be NP-Hard. Furthermore, no single optimal algorithm has been shown to have the fastest runtime for all MAPF problem instances, and there are no proven approaches for when to use each algorithm. To address these challenges, we develop MAPFASTER, a smaller and more accurate deep learning based architecture aiming to be deployed in fleet management systems to select the fastest MAPF solver in a multi-robot setting. MAPF problem instances are encoded as images and passed to the model for classification into one of the portfolio's candidates. We evaluate our model against state-ofthe-art Optimal-MAPF-Algorithm selectors, showing +5.42% improvement in accuracy while being 7.1x faster to train. The dataset, code and analysis used in this research can be found at https://github.com/jeanmarcalkazzi/mapfaster.",2022
Portfolio solver for verifying Binarized Neural Networks,"Although deep learning is a very successful AI technology, many concerns have been raised about to what extent the decisions making process of deep neural networks can be trusted. Verifying of properties of neural networks such as adversarial robustness and network equivalence sheds light on the trustiness of such systems. We focus on an important family of deep neural networks, the Binarized Neural Networks (BNNs) that are useful in resource-constrained environments, like embedded devices. We introduce our portfolio solver that is able to encode BNN properties for SAT, SMT, and MIP solvers and run them in parallel, in a portfolio setting. In the paper we propose all the corresponding encodings of different types of BNN layers as well as BNN properties into SAT, SMT, cardinality constrains, and pseudo-Boolean constraints. Our experimental results demonstrate that our solver is capable of verifying adversarial robustness of medium-sized BNNs in reasonable time and seems to scale for larger BNNs. We also report on experiments on network equivalence with promising results.",2021
Building a Scalable and Interpretable Bayesian Deep Learning Framework for Quality Control of Free Form Surfaces,"Deep learning has demonstrated high accuracy for 3D object shape error modeling necessary to estimate dimensional and geometric quality defects in multi-station assembly systems (MAS). Increasingly, deep learning-driven Root Cause Analysis (RCA) is used for decision-making when planning corrective action of quality defects. However, given the current absence of scalability enabling models, training deep learning models for each individual MAS is exceedingly time-consuming as it requires large amounts of labelled data and multiple computational cycles. Additionally, understanding and interpreting how deep learning produces final predictions while quantifying various uncertainties also remains a fundamental challenge. In an effort to address these gaps, a novel closed-loop in-process (CLIP) diagnostic framework underpinned algorithm portfolio is proposed which simultaneously enhances scalability and interpretability of the current Bayesian deep learning approach, Object Shape Error Response (OSER), to isolate root cause(s) of quality defects in MAS. The OSER-MAS leverages a Bayesian 3D U-Net architecture integrated with Computer-Aided Engineering simulations to estimate root causes. The CLIP diagnostic framework shortens OSER-MAS model training time by developing: (i) closed-loop training to enable faster convergence for a single MAS by leveraging uncertainty estimates of the Bayesian 3D U-net model; and, (ii) transfer/continual learning-based scalability model to transmit meta-knowledge from the trained model to a new MAS resulting in convergence using comparatively less training samples. Additionally, CLIP increases the transparency for quality-related root cause predictions by developing interpretability model which is based on 3D Gradient-based Class Activation Maps (3D Grad-CAMs) and entails: (a) linking elements of MAS model with functional elements of the U-Net architecture; and, (b) relating features extracted by the architecture with elements of the MAS model and further with the object shape error patterns for root cause(s) that occur in MAS. Benchmarking studies are conducted using six automotive-MAS with varying complexities. Results highlight a reduction in training samples of up to 56% with a loss in performance of up to 2.1%.",2021
Carbon risk and return prediction: Evidence from the multi-CNN method,"This paper investigates the carbon risk and its role in stocks' return prediction by identifying the carbon risk information implied in feature engineering. We predict the stock returns with different neural networks, construct the investment portfolio according to the predicted returns and reflect the returns of stocks with different carbon risks through the relevant evaluation of the investment portfolio. Our Multi-CNN method can best collect information on different relationship types and make full use of graph structure data to identify carbon risks. With or without carbon factor, the stock market performance of high-carbon industry is better than that of medium-carbon industry, and the performance of low-carbon industry is the worst. Moreover, our finding is consistent in both Chinese and American markets. Investment should pay attention to carbon risk and requires corresponding carbon risk premium.",2022
Portfolio Optimization for Index Investing Based on Self-organizing Neural Network,"Index investing is an important issue for researchers and practitioners. This paper proposes an index portfolio optimization model for index investing via employing CSI 300 as underlying index. Firstly, a self-organizing neural network clustering model is constructed to complete the stock clustering based on stock trend which regards stock price as input. The index portfolio optimization model is proposed to determine the optimal investment proportion of each cluster sampling and achieve the minimum tracking error. The constraint BP algorithm is improved to benefit the optimization calculation of stock weights. Empirical results show that our approach achieves smaller tracking error and better index tracking effect than the random sampling.",2013
Recommendation system for technology convergence opportunities based on self-supervised representation learning,"We show how a deep neural network can be designed to learn meaningful representations from high-dimensional and heterogeneous categorical features in patent data using self-supervised learning. Based on each firm's technology portfolio and each patent's co-classification information, we propose a novel recommendation system for firms seeking new convergence opportunities through representations of convergence items and firms. The results of this work are expected to recommend convergence opportunities in multiple technology fields by considering the target firm's potential preference. First, we create a technology portfolio consisting of a set of patents owned by each firm. Then, we train a neural network to extract latent representations of firms and technology convergence items. Despite a lack of indicators related to a firm's latent preference for a convergence item, a self-supervised neural network can capture the similarity with semantic information of firm's latent preference that is implicitly present in patent's co-classification information in each firm's technology portfolio. We then calculate the similarity between the vector of a target firm and convergence items for recommendation. The top N similar convergence items that have the highest scores are recommended as the new convergence items for the target firm. We apply our framework to the dataset of patents granted by the United States Patent and Trademark Office between 2011 and 2015. The results indicate that the recent development in theories and empirical studies of deep representation learning can shed new light on extracting valuable information from the structured part of patent data.",2021
Predictive intraday correlations in stable and volatile market environments: Evidence from deep learning,"Standard methods and theories in finance can be ill-equipped to capture highly non-linear interactions in financial prediction problems based on large-scale datasets, with deep learning offering a way to gain insights into correlations in markets as complex systems. In this paper, we apply deep learning to econometrically constructed gradients to learn and exploit lagged correlations among S&P 500 stocks to compare model behaviour in stable and volatile market environments, and under the exclusion of target stock information for predictions. In order to measure the effect of time horizons, we predict intraday and daily stock price movements in varying interval lengths and gauge the complexity of the problem at hand with a modification of our model architecture. Our findings show that accuracies, while remaining significant and demonstrating the exploitability of lagged correlations in stock markets, decrease with shorter prediction horizons. We discuss implications for modern finance theory and our work's applicability as an investigative tool for portfolio managers. Lastly, we show that our model's performance is consistent in volatile markets by exposing it to the environment of the recent financial crisis of 2007/2008. (C) 2020 Elsevier B.V. All rights reserved.",2020
"Deep learning in the stock market-a systematic survey of practice, backtesting, and applications","The widespread usage of machine learning in different mainstream contexts has made deep learning the technique of choice in various domains, including finance. This systematic survey explores various scenarios employing deep learning in financial markets, especially the stock market. A key requirement for our methodology is its focus on research papers involving backtesting. That is, we consider whether the experimentation mode is sufficient for market practitioners to consider the work in a real-world use case. Works meeting this requirement are distributed across seven distinct specializations. Most studies focus on trade strategy, price prediction, and portfolio management, with a limited number considering market simulation, stock selection, hedging strategy, and risk management. We also recognize that domain-specific metrics such as returns and volatility appear most important for accurately representing model performance across specializations. Our study demonstrates that, although there have been some improvements in reproducibility, substantial work remains to be done regarding model explainability. Accordingly, we suggest several future directions, such as improving trust by creating reproducible, explainable, and accountable models and emphasizing prediction of longer-term horizons-potentially via the utilization of supplementary data-which continues to represent a significant unresolved challenge.",2023
DeepScalper: A Risk-Aware Reinforcement Learning Framework to Capture Fleeting Intraday Trading Opportunities,"Reinforcement learning (RL) techniques have shown great success in many challenging quantitative trading tasks, such as portfolio management and algorithmic trading. Especially, intraday trading is one of the most profitable and risky tasks because of the intraday behaviors of the financial market that reflect billions of rapidly fluctuating capitals. However, a vast majority of existing RL methods focus on the relatively low frequency trading scenarios (e.g., day-level) and fail to capture the fleeting intraday investment opportunities due to two major challenges: 1) how to effectively train profitable RL agents for intraday investment decision-making, which involves high-dimensional fine-grained action space; 2) how to learn meaningful multi-modality market representation to understand the intraday behaviors of the financial market at tick-level. Motivated by the efficient workflow of professional human intraday traders, we propose DeepScalper, a deep reinforcement learning framework for intraday trading to tackle the above challenges. Specifically, DeepScalper includes four components: 1) a dueling Q-network with action branching to deal with the large action space of intraday trading for efficient RL optimization; 2) a novel reward function with a hindsight bonus to encourage RL agents making trading decisions with a long-term horizon of the entire trading day; 3) an encoder-decoder architecture to learn multi-modality temporal market embedding, which incorporates both macro-level and micro-level market information; 4) a risk-aware auxiliary task to maintain a striking balance between maximizing profit and minimizing risk. Through extensive experiments on real-world market data spanning over three years on six financial futures (2 stock index and 4 treasury bond), we demonstrate that DeepScalper significantly outperforms many state-of-the-art baselines in terms of four financial criteria. Furthermore, we conduct a series of exploratory and ablative studies to analyze the contributions of each component in DeepScalper.",2022
SDELP-DDPG: Stochastic differential equations with Lévy processes-driven deep deterministic policy gradient for portfolio management,"Portfolio management (PM) involves the ongoing redistribution of funds among various financial products, aiming to seek a balance between returns and risks. In this paper, we propose SDELP-DDPG, a novel approach to portfolio management that combines stochastic differential equations (SDEs) with L & eacute;vy processes and the deep deterministic policy gradient (DDPG) technique. To alleviate the challenges posed by exploration limitations and enhance the stability of DDPG, we employ SDEs driven by L & eacute;vy processes, with drift and diffusion coefficients represented by convolutional neural networks, to generate action policies. Additionally, we devise a reward function, which considers relative entropy, to guide RL agents in learning imitation policies using DDPG. Moreover, we incorporate an attention mechanism and the Ornstein-Uhlenbeck process to choose optimal actions. Our proposed algorithm is evaluated on three real-world datasets: the Dow Jones Industrial Average markets, the Energy markets and the cryptocurrency markets, and the experimental results validate the effectiveness of SDELP-DDPG compared to existing PM approaches.",2025
Deep-Control of Memory via Stochastic Optimal Control and Deep Learning,"In this survey work, we introduce Stochastic Differential Delay Equations and their impacts on Stochastic Optimal Control problems. We observe time delay in the dynamics of a state process that may correspond to inertia or memory in a financial system. For such systems, we demonstrate two special approaches to handle delayed control problems by applying the Dynamic Programming Principle. Moreover, we clarify the technical challenges rising as a consequence of the conflict between the path-dependent, infinite-dimensional nature of the problem and the necessity of the Markov property. Furthermore, we present two different Deep Learning algorithms to solve targeted delayed control tasks and illustrate the results for a complete memory portfolio optimization problem.",2024
Six-factor asset pricing and portfolio investment via deep learning: Evidence from Chinese stock market,"This paper proposes a long short-term memory (LSTM) neural network model to predict daily stock price movements based on asset pricing factors (i.e., the five factors proposed by Fama and French, and the short-term momentum factor). Based on three independent experiments, we systematically evaluate the explanatory power and the predictive power of the LSTM model by employing 3316 A-share listed companies in the Shanghai and Shenzhen stock exchanges from the in-sample period January 1, 2008 to December 31, 2019. Furthermore, we propose a four-step approach to dynamically update the underlying stocks in different portfolios based on the empirical findings. All portfolios are simulated using out-of-sample data (i.e., from January 1, 2020, to May 31, 2021) to avoid look-ahead bias. The trading results suggest that our dynamic investment strategies are superior to the benchmark index and are able to generate significant returns with relatively low risks.",2022
Portfolio optimization through hybrid deep learning and genetic algorithms vine Copula-GARCH-EVT-CVaR model,"This study investigates the potential benefits of using the Conditional Value at Risk (CVaR) portfolio optimization approach with a GARCH model, Extreme Value Theory (EVT), and Vine Copula to obtain the optimal allocation decision for a portfolio consisting of Bitcoin, gold, oil, and stock indices. First, we fit a suitable GARCH model to the return series for each asset, followed by employing the Generalized Pareto Distribution (GPD) to model the innovation tails. Next, we construct a Vine Copula-GARCH-EVT model to capture the interdependence structure between the assets. To refine risk assessment, we combine our model with a Monte Carlo simulation and MeanCVaR model to optimize the portfolio. In addition, we utilize a novel version of deep machine learning's genetic algorithm to address the optimization decision. This research contributes new evidence to the CVaR portfolio optimization approach and provides insights for portfolio managers seeking to optimize multi-asset portfolios.",2023
Deep Learning for Cost-Optimal Planning: Task-Dependent Planner Selection,"As classical planning is known to be computationally hard, no single planner is expected to work well across many planning domains. One solution to this problem is to use online portfolio planners that select a planner for a given task. These portfolios perform a classification task, a well-known and well-researched task in the field of machine learning. The classification is usually performed using a representation of planning tasks with a collection of hand-crafted statistical features. Recent techniques in machine learning that are based on automatic extraction of features have not been employed yet due to the lack of suitable representations of planning tasks. In this work, we alleviate this barrier. We suggest representing planning tasks by images, allowing to exploit arguably one of the most commonly used and best developed techniques in deep learning. We explore some of the questions that inevitably rise when applying such a technique, and present various ways of building practically useful online portfolio-based planners. An evidence of the usefulness of our proposed technique is a planner that won the cost-optimal track of the International Planning Competition 2018.",2019
THE IMPACT OF INNOVATIONS ON THE EVOLUTION OF THE PORT SECTOR: A LITERATURE REVIEW,"The objective of this paper is to analyze the scientific literature to highlight the impacts of innovations throughout the evolution of the port sector and its current innovation trends and processes. For this purpose, a literature review was carried out with the support of the ProKnow-C instrument to select a Bibliographic Portfolio (BP) composed of 44 relevant and representative articles for the research. The BP analysis showed market demand and regulations as the main factors in the selection of innovations; ports '4.0' and 'green' ports as current technological trajectories; and the collaborative trend among the sector's actors.",2022
Deep hedging,"We present a framework for hedging a portfolio of derivatives in the presence of market frictions such as transaction costs, liquidity constraints or risk limits using modern deep reinforcement machine learning methods. We discuss how standard reinforcement learning methods can be applied to non-linear reward structures, i.e.in our case convex risk measures. As a general contribution to the use of deep learning for stochastic processes, we also show in Section4 that the set of constrained trading strategies used by our algorithm is large enough to epsilon-approximate any optimal solution. Our algorithm can be implemented efficiently even in high-dimensional situations using modern machine learning tools. Its structure does not depend on specific market dynamics, and generalizes across hedging instruments including the use of liquid derivatives. Its computational performance is largely invariant in the size of the portfolio as it depends mainly on the number of hedging instruments available. We illustrate our approach by an experiment on the S&P500 index and by showing the effect on hedging under transaction costs in a synthetic market driven by the Heston model, where we outperform the standard complete-market' solution.",2019
Asset Pricing and Portfolio Investment Management Using Machine Learning: Research Trend Analysis Using Scientometrics,"Asset pricing in the context of financial economics pertains to the investigation and formulation of two fundamental pricing ideas and the models that go along with them. Various models exist for different scenarios, but they can be traced back to either general equilibrium asset pricing or rational asset pricing. Asset pricing models, as the name suggests, serve as valuable tools to assess the value of assets. The general equilibrium theory states that supply and demand interact to determine market prices. In this context, asset prices collectively satisfy the market clearing condition, which dictates that the supply and demand for each asset are equal at the prevailing price. Another crucial aspect of financial planning is portfolio management (PM), which aims to maximise investment profits while minimising losses. PM involves implementing effective asset allocation strategies to enhance returns and mitigate risks. Numerous studies have been conducted worldwide on various types of asset pricing models and investment portfolios, with some incorporating machine learning and deep learning techniques. In several models, the predictive accuracy has exceeded 90%. To shed light on the current research landscape in the realm of asset pricing and portfolio investment, we conducted a scientometric analysis.",2024
On the Resiliency of Power and Gas Integration Resources Against Cyber Attacks,"Integration of power and gas systems has been recently proposed as a portfolio solution to deal with the sporadic availability of renewables and enhance the flexibility of power systems. In an integrated system, where critical operating information and control signals of both systems need to be communicated, the risk of cyber attack is intensified. In this article, we present a new model for the integration of power and gas systems using power-to-gas (PtG) and gas-fired generation (GfG) facilities. We demonstrate how the operation of the integrated system can be adversely impacted during cyber attacks that may not be detected using traditional methods. We propose two new detection schemes for false data injection attacks against the input and output signals of the PtG/GfG facility scheduler. In the first scheme, a supervised machine-learning technique, based on the convolutional neural network and wavelet transforms, is adopted to detect attacks on the information received by the facility scheduler. In the second scheme, a hybrid neural network is developed, based on an unsupervised learning technique, that requires no labeled training information to detect attacks on the output control signals issued by the scheduler. In both schemes, information acquired from local sensors and deterministic estimation methods is utilized for signal evaluation. The proposed schemes are incorporated into the facilities' scheduler to create a cyber-attack resilient scheduling model in an integrated power and gas grid. The efficacy and feasibility of the proposed model are evaluated via numerical studies using the IEEE30-bus power system integrated with the Belgian gas grid as the test bed using historical operating parameters.",2021
The materials that make an energy company: BP chief scientist Ellen Williams discusses sustainable energy,"After over three decades in academia, Ellen Williams left her position as a Distinguished University Professor of physics at the University of Maryland to take on the role of Chief Scientist at BP in January 2010. Williams is responsible for keeping a pulse on science and technology developments that could advance BP's energy portfolio and serves as a liaison to the company's university partners. She provides assurance for research and development spending and strategic scientific advice to BP senior executives. She has been instrumental in developing the BP International Center for Advanced Materials (ICAM) that will initially fund research at three UK-based universities and one US university. The center's research foci encompass materials integrity to advance corrosion protection during operations as well as the development of stronger, lighter materials for use in the challenging environments of hydrocarbon production and processing.",2012
A Conceptual Neural Model for Business Selection in Multi Business Unit Firms,"Despite of its importance in the context of corporate portfolio management (CPM), business selection in multi business unit firms is still among ambiguous problems because of its sophisticated nature in which the effective decision rules are different from one firm, industry or country to another. Therefore this article tries to address the business selection problem in corporations by applying a two layer neural networks with sigmoid activation function as a pattern recognition supervised learning algorithm to recognize business selection patterns in different firms and make decision for adding or divesting new business units based on a set of quantitative features. The model trained, validate and tested and results were indicative that the model is relatively reliable for using in action.",2014
Convolutional LSTM Network for forecasting correlations between stocks based on spatiotemporal sequence,"The correlation between stocks is important for investment portfolio pricing and evaluation, risk management, and formulating trading and hedging strategies. The COVID-19 has led to a general increase in the degree of correlation between stocks, the market-wide allocation has lost its meaning, and the hedging strategy has failed. It is more necessary and urgent to predict the correlation between stocks under the influence of the epidemic. However, previous studies mostly focused on traditional financial models. There are problems such as too many assumptions and restrictions, the dimensional disaster of the estimated parameters, and the poor effect of fitting nonlinearity and tail risk, which cannot provide reliable and accurate estimates. In this paper, the covariance matrix for stock return is considered as a sequence with both time and space characteristics, to transform the problem into the study of spatiotemporal sequence prediction. We Innovatively apply the end-to-end Convolutional LSTM (ConvLSTM) to the correlation prediction between stocks and use random matrix theory (RMT) to improve mean squared error (MSE) to eliminate the influence of noise. Experiments show that the performance of ConvLSTM on this problem is better than that of traditional financial model, especially after de-nosing by Random Matrix Theory (RMT). Compared with Fully Connected LSTM (FC-LSTM), ConvLSTM acquired a better out-of-sample MSE and RMT_MSE, which proves the effectiveness of the method. Finally, we repeat experiments with other stock dataset to verify the robustness of the model.",2021
A Robo-Advisor Design using Multiobjective RankNets with Gated Neural Network Structure,"With rapid developments in deep learning and financial technology, a customized robo-advisory service based on novel artificial intelligence techniques has been widely adopted to realize financial inclusion. This study proposes a novel robo-advisor system that integrates trend prediction, portfolio management, and a recommendation mechanism. A gated neural network structure combining three multiobjective RankNet kernels could rank target financial products and recommend the top-n securities to investors. The gated neural network learns to choose or weigh each RankNet for incorporating the most important partial network inputs, such as earnings per share, market index, and hidden information from the time series. Experimental results indicate that the recommendation results of our proposed robo-advisor based on a gated neural network and multiobjective RankNets can outperform existing models.",2019
Dynamic Portfolio Optimization via Augmented DDPG with Quantum Price Levels-Based Trading Strategy,"With the development of deep learning, Dynamic Portfolio Optimization (DPO) problem has received a lot of attention in recent years, not only in the field of finance but also in the field of deep learning. Some advanced research in recent years has proposed the application of Deep Reinforcement Learning (DRL) to the DPO problem, which demonstrated to be more advantageous than supervised learning in solving the DPO problem. However, there are still certain unsolved issues: 1) DRL algorithms usually have the problems of slow learning speed and high sample complexity, which is especially problematic when dealing with complex financial data. 2) researchers use DRL simply for the purpose of obtaining high returns, but pay little attention to the problem of risk control and trading strategy, which will affect the stability of model returns. In order to address these issues, in this study we revamped the intrinsic structure of the model based on the Deep Deterministic Policy Gradient (DDPG) and proposed the Augmented DDPG model. Besides, we also proposed an innovative risk control strategy based on Quantum Price Levels (QPLs) derived from Quantum Finance Theory (QFT). Our experimental results revealed that our model has better profitability as well as risk control ability with less sample complexity in the DPO problem compared to the baseline models.",2023
E2DR: A Deep Learning Ensemble-Based Driver Distraction Detection with Recommendations Model,"The increasing number of car accidents is a significant issue in current transportation systems. According to the World Health Organization (WHO), road accidents are the eighth highest top cause of death around the world. More than 80% of road accidents are caused by distracted driving, such as using a mobile phone, talking to passengers, and smoking. A lot of efforts have been made to tackle the problem of driver distraction; however, no optimal solution is provided. A practical approach to solving this problem is implementing quantitative measures for driver activities and designing a classification system that detects distracting actions. In this paper, we have implemented a portfolio of various ensemble deep learning models that have been proven to efficiently classify driver distracted actions and provide an in-car recommendation to minimize the level of distractions and increase in-car awareness for improved safety. This paper proposes E2DR, a new scalable model that uses stacking ensemble methods to combine two or more deep learning models to improve accuracy, enhance generalization, and reduce overfitting, with real-time recommendations. The highest performing E2DR variant, which included the ResNet50 and VGG16 models, achieved a test accuracy of 92% as applied to state-of-the-art datasets, including the State Farm Distracted Drivers dataset, using novel data splitting strategies.",2022
Investment Behaviors Can Tell What Inside: Exploring Stock Intrinsic Properties for Stock Trend Prediction,"Stock trend prediction, aiming at predicting future price trend of stocks, plays a key role in seeking maximized profit from the stock investment. Recent years have witnessed increasing efforts in applying machine learning techniques, especially deep learning, to pursue more promising stock prediction. While deep learning has given rise to significant improvement, human investors still retain the leading position due to their understanding on stock intrinsic properties, which can imply invaluable principles for stock prediction. In this paper, we propose to extract and explore stock intrinsic properties to enhance stock trend prediction. Fortunately, we discover that the repositories of investment behaviors within mutual fund portfolio data form up a gold mine to extract latent representations of stock properties, since such collective investment behaviors can reflect the professional fund managers' common beliefs on stock intrinsic properties. Powered by extracted stock properties, we further propose to model the dynamic market state and trend using stock representations so as to generate the dynamic correlation between the stock and the market, and then we aggregate such correlation with dynamic stock indicators to achieve more accurate stock prediction. Extensive experiments on real-world stock market data demonstrate the effectiveness of stock properties extracted from collective investment behaviors in the task of stock prediction.",2019
Signatured Deep Fictitious Play for Mean Field Games with Common Noise,"Existing deep learning methods for solving mean-field games (MFGs) with common noise fix the sampling common noise paths and then solve the corresponding MFGs. This leads to a nested-loop structure with millions of simulations of common noise paths in order to produce accurate solutions, which results in prohibitive computational cost and limits the applications to a large extent. In this paper, based on the rough path theory, we propose a novel single-loop algorithm, named signatured deep fictitious play, by which we can work with the unfixed common noise setup to avoid the nested-loop structure and reduce the computational complexity significantly. The proposed algorithm can accurately capture the effect of common uncertainty changes on mean-field equilibria without further training of neural networks, as previously needed in the existing machine learning algorithms. The efficiency is supported by three applications, including linear-quadratic MFGs, mean-field portfolio game, and mean-field game of optimal consumption and investment. Overall, we provide a new point of view from the rough path theory to solve MFGs with common noise with significantly improved efficiency and an extensive range of applications. In addition, we report the first deep learning work to deal with extended MFGs (a mean-field interaction via both the states and controls) with common noise.",2021
A NOVEL STOCK PORTFOLIO MODEL BASED ON DEEP REINFORCEMENT LEARNING,"Deep reinforcement learning is a method to address the problem of achieving maximum return or getting specific goals through learning strategies when interact with environment, which can be used in portfolio investments to achieve more benefits. In this paper, we use two deep reinforcement learning methods, that is, the policy gradient (PG) and the deep deterministic policy gradient (DDPG), to develop models for stock portfolio investments. To determine the weights for a group of stocks, we first process the data using the wavelet transform method; then, we improve the methods by constructing a neural network framework with a convolution neural network (CNN) along with a Squeeze-and-Excitation Block (SE Block); in the model, we employ the average logarithmic cumulative returns and the cumulative Sharpe Ratio as the reward functions. Our experimental results show the improved model is robustness, and perform significantly better over the actual Chinese stocks in risk prevention and returns increment.",2021
BITCOIN: A PONZI SCHEME OR AN EMERGING INFLATION-FIGHTING ASSET?,"Under the dual impact of the COVID-19 pandemic and the Russian-Ukrainian conflict, the excessive stimulation of monetary policy continuously pushes up global inflation (INF). Therefore, this article explores whether Bitcoin can serve as a safe haven for INF. We apply the rolling-window Granger causality test to solve the issue of parameter instability in vector autoregression (VAR) systems and investigate the time-varying interaction between INF and Bitcoin price (BP). The negative influence of INF on BP means a high inflation shock causes BP to decline, indicating that Bitcoin cannot be a safe asset against INF. This is because investors have decreased their willingness to hold Bitcoin under the high INF expectations and cause BP to fall. This finding is not supported by the Intertemporal Capital Asset Pricing Model, emphasising that INF positively impacts BP. Conversely, BP has positive and negative impacts on INF. The positive effect highlights the effectiveness of Bitcoin in predicting INF fluctuations, but economic factors could undermine this effectiveness. In the context of economic stagnation and market turmoil, investors can adjust their portfolio investments based on Bitcoin. The government should utilise the trend of BP to regulate the dynamics of INF to reduce uncertainty in the financial system.",2024
Detecting and adapting to crisis pattern with context based Deep Reinforcement Learning,"Deep reinforcement learning (DRL) has reached super human levels in complex tasks like game solving (Go [1], StarCraft II [2D]), and autonomous driving [3]. However, it remains an open question whether DRL can reach human level in applications to financial problems and in particular in detecting pattern crisis and consequently dis-investing. In this paper, we present an innovative DRL framework consisting in two subnetworks fed respectively with portfolio strategies past performances and standard deviations as well as additional contextual features. The second sub network plays an important role as it captures dependencies with common financial indicators features like risk aversion, economic surprise index and correlations between assets that allows taking into account context based information. We compare different network architectures either using layers of convolutions to reduce network's complexity or LSTM block to capture time dependency and whether previous allocations is important in the modeling. We also use adversarial training to make the final model more robust. Results on test set show this approach substantially over-performs traditional portfolio optimization methods like Markovitz and is able to detect and anticipate crisis like the current Covid one.",2021
Wealth Flow Model: Online Portfolio Selection Based on Learning Wealth Flow Matrices,"This article proposes a deep learning solution to the online portfolio selection problem based on learning a latent structure directly from a price time series. It introduces a novel wealth flow matrix for representing a latent structure that has special regular conditions to encode the knowledge about the relative strengths of assets in portfolios. Therefore, a wealth flow model (WFM) is proposed to learn wealth flow matrices and maximize portfolio wealth simultaneously. Compared with existing approaches, our work has several distinctive benefits: (1) the learning of wealth flow matrices makes our model more generalizable than models that only predict wealth proportion vectors, and (2) the exploitation of wealth flow matrices and the exploration of wealth growth are integrated into our deep reinforcement algorithm for the WFM. These benefits, in combination, lead to a highly-effective approach for generating reasonable investment behavior, including short-term trend following, the following of a few losers, no self-investment, and sparse portfolios. Extensive experiments on five benchmark datasets from real-world stock markets confirm the theoretical advantage of the WFM, which achieves the Pareto improvements in terms of multiple performance indicators and the steady growth of wealth over the state-of-the-art algorithms.",2022
Quantifying credit portfolio sensitivity toasset correlations with interpretablegenerative neural networks,"We propose a novel approach for quantifying the sensitivity of credit portfolio value-at-risk to asset correlations with the use of synthetic financial correlation matrixesgenerated with deep learning models. In previous work, generative adversarial net-works (GANs) were employed to demonstrate the generation of plausible correlationmatrixes that capture the essential characteristics observed in empirical correlationmatrixes estimated on asset returns. Instead of GANs, we employ variational autoen-coders (VAEs) to achieve a more interpretable latent space representation and toobtain a generator of plausible correlation matrixes by sampling the VAE's latentspace. Through our analysis, we reveal that the VAE's latent space can be a use-ful tool to capture the crucial factors impacting portfolio diversification, particularlyin relation to the sensitivity of credit portfolios to changes in asset correlations. AVAE trained on the historical time series of correlation matrixes is used to generatesynthetic correlation matrixes that satisfy a set of expected financial properties. Our analysis provides clear indications that the capacity for realistic data augmentationprovided by VAEs, combined with the ability to obtain model interpretability, canprove useful for risk management, enhancing the resilience and accuracy of modelswhen backtesting, as past data may exhibit biases and might not contain the essentialhigh-stress events required for evaluating diverse risk scenarios.",2024
Planning new developments in an upstream gas business,"BP Trinidad and Tobago LLC has an upstream gas business with large process and export capacity, significant market growth opportunities, and a large portfolio of development and exploration opportunities. With such an asset, there must be a process to facilitate and guide capital-spending decisions that underpin a strategy for delivering a gas growth agenda. The process must accurately identify preinvestment opportunities that can be leveraged toward future growth.",2003
AI Predicted Product Portfolio for Profit Maximization,"Enterprises analyze opportunities and threats in the external environment, measure internal strengths and weaknesses, and formulate strategic objectives to stay ahead of their opponents. Product portfolio management (PPM) is a dynamic process by which an enterprise chooses which products to develop, sell, maintain, and remove to achieve strategic objectives, maximize profit, and balance markets for different capabilities. Most product portfolios involve new products only and exclude existing products. This study proposes a product/market portfolio model that considers both old/new products and old/new markets to maximize overall PPM profit, determine which old products should stay in existing markets, which new markets should be considered, or which markets should be abandoned, and develop new products for old markets or to introduce new products to some new markets. This study uses machine learning and deep learning algorithms to establish prediction models to screen the planned products and markets with a high success rate. Mathematical programming is then used to determine which old products should be sold in which old and new markets and which new products should be launched in which new and old markets to maximize profit. A sensitivity analysis is used to determine the effect of changes in the resource and the risk threshold on profit and product/market selection.",2022
Integrated prediction of green bond return under the dual risks of climate change and energy crisis,"Prediction of bond return is a classic problem in financial area, providing an important basis for portfolio construction and risk management. The sustainable investment attribute of green bonds has been favored by investors, so that green bonds have become an important component for major asset allocation. However, due to the specific investment focus of green bonds, investors' return expectations are influenced not only by traditional corporate bond factors, but also by related factors such as climate change and energy transition. Against the backdrop of increasingly severe climate risks and the global energy crisis, this paper analyses the volatility characteristics of China's green bonds at multiple time scales, and introduces exogenous variables such as returns of the alternative financial assets, climate risks and returns of energy markets for prediction. Based on the LSTM model, the volatility of green bond yield at different time scales is separately predicted using optimal exogenous variable before integration. It is found that the new integrated prediction model can significantly improve the forecasting performance compared to traditional single LSTM models and simple decomposition-integrated models. Further, both climate risks and energy markets variables have a significant improvement effect on predicting green bond in low-frequency item, while energy markets variables also have a better predictive effect on trend items. Building on the use of only LSTM model, it could be further enhanced by integrating more algorithms to select the best single model for each component, further improve the prediction accuracy and provide a more effective quantitative tool for investment decision-making and risk management in related fields.",2023
Ultra long-Term Wind Farm Generation Forecast by Combining Numerical Weather Prediction with Gated Recurrent Units,"Wind energy is an integral resource in the renewable energy portfolio of many utilities across the world. One of the challenges in planning for operations when dealing with wind farms is to account for the fact that wind power is not dispatchable, and forecasting of wind over a typical window of operational planning such as a 7-day long horizon is challenging. While most previous reports on forecasting wind power are focused on short term wind forecast, this study focuses on ultra-long term forecast of generation in wind farms by using physical models in combination with deep learning as a rapidly growing part of machine learning discipline. The proposed approach is compared against a traditional approach of wind power forecast using physical models and provides promising improvement in accuracy.",2021
Machine learning vs deep learning in stock market investment: an international evidence,"Machine learning and deep learning are powerful tools for quantitative investment. To examine the effectiveness of the models in different markets, this paper applies random forest and DNN models to forecast stock prices and construct statistical arbitrage strategies in five stock markets, including mainland China, the United States, the United Kingdom, Canada and Japan. Each model is applied to the price of major stock indices constituting stocks in these markets from 2005 to 2020 to construct a long-short portfolio with 20 selected stocks by the model. The results show that the a particular model obtains significantly different profits in different markets, among which DNN has the best performance, especially in the Chinese stock market. We find that DNN models generally perform better than other machine learning models in all markets.",2023
Deep learning for enhanced index tracking,"We develop a novel deep learning method for the enhanced index tracking problem, which aims to outperform an index while effectively controlling the tracking error. We generate a dynamic trading policy from a neural network that accepts a set of features as inputs. We design four blocks in the neural network architecture to handle different types of features, including regimes of the index and stocks, their short-term characteristics, and the current allocation. Outputs from the blocks are integrated into the final output that changes the portfolio allocation. We test our model on several indexes in empirical studies based on real market data. Out-of-sample results reveal the importance of different features and demonstrate the ability of our method in obtaining excess returns while effectively controlling the tracking error, downside risk, and transaction costs.",2024
Risk Budgeting Allocation for Dynamic Risk Measures,"We define and develop an approach for risk budgeting allocation-a risk diversification portfolio strategy-where risk is measured using a dynamic time-consistent risk measure. For this, we introduce a notion of dynamic risk contributions that generalize the classical Euler contributions, which allows us to obtain dynamic risk contributions in a recursive manner. We prove that for the class of coherent dynamic distortion risk measures, the risk allocation problem may be recast as a sequence of strictly convex optimization problems. Moreover, we show that self-financing dynamic risk budgeting strategies with initial wealth of one are scaled versions of the solution of the sequence of convex optimization problems. Furthermore, we develop an actor-critic approach, leveraging the elicitability of dynamic risk measures, to solve for risk budgeting strategies using deep learning.",2024
Non-Markovian Mean-Variance Portfolio Selection Problems via Closed-Loop Equilibrium Strategies,"In this article, a class of mean-variance portfolio selection problems with constant risk aversion is investigated by means of closed-loop equilibrium strategies. Thanks to the non-Markovian setting, two delicate kinds of equilibrium strategies are introduced and both of them obviously reduce to the existing counterpart in the Markovian case. To explicitly represent the equilibrium strategy, a class of backward stochastic Riccati system is introduced, and its solvability is carefully discussed for the first time in the literature. Different from the current literature, the spectacular role of random interest rates in the model is firstly indicated by several interesting phenomena, and the new deeper relations between closed-loop, open-loop equilibrium strategies are shown as well. Finally, numerical analysis via deep learning method is shown to illustrate the novel theoretical findings.",2024
Enhancing Customer Experience: Exploring Deep Learning Models for Banking Customer Journey Analysis,"Customer journey analytics is the process of monitoring and analyzing how customers use combinations of points of contact, services, or products to interact with an organization. Companies use customer journey analytics because it is one of the most effective ways to increase long-term customer value, improve customer loyalty, and drive revenue growth. Customer journey analysis provides teams with a window on customer behavior that provides valuable information that they can then use to inform their decisions. These points of contact are called events and they define the customer's behavioral model across an organization. In a typical big bank, about 100,000 events are carried out per second. Several dynamic events are associated with a bank such as an ATM withdrawal, a POS transaction, a cash deposit. This series of customer journey events can be used for different use cases such as cross-selling, account reactivation, hard rolling, soft rolling to name a few. This paper uses deep neural network-based, recurrent neural network (RNN) algorithm to capture these customer journey events across a bank and how these events can be used to predict cross-sell propensity for other bank products. We developed various RNN models using both time series and static data layers to estimate the likelihood of cross-selling credit card facility to existing customers on hypothetical dataset. A highly predictable model is developed with an AUC of 0.92 on training and 0.90 on validation sample. This model can capture around 91% of the cross-sell events in first two deciles for training sample, indicating that by targeting a small proportion of the portfolio, a bank can achieve maximum conversions from cross-sell programs.",2024
Comparison of Discrete Choice and Machine Learning Models for Simultaneous Modeling of Mobility Tool Ownership in Agent-Based Travel Demand Models,"Individual travel behavior, such as mode choice, is determined to a distinct degree by the respective portfolio of available mobility tools, such as the number of cars, public transit pass ownership, or a carsharing membership. However, the choice of different mobility tools is interdependent, and individuals weigh alternatives against each other. This process of parallel trade-offs is currently not reflected in typically used sequential logit models of agent-based travel demand models. This study fills this research gap by applying discrete choice and neural network models on a synthetic population to model multiple mobility tool ownership simultaneously. Using data from a national household travel survey, both model types approximated the given target distributions of mobility tools more accurately than the sequence of three corresponding logit models. Owing to its greater flexibility, the tested shallow and deep neural network exhibited higher predictive accuracy than simultaneous discrete choice models. The results indicated that neural networks with only one hidden layer were more robust and easier to formulate and interpret than deep networks with three hidden layers. Finally, the flat neural network was applied to a different synthetic population resulting in equally accurate results.",2024
A Peak Price Tracking-Based Learning System for Portfolio Selection,"We propose a novel linear learning system based on the peak price tracking (PPT) strategy for portfolio selection (PS). Recently, the topic of tracking control attracts intensive attention and some novel models are proposed based on backstepping methods, such that the system output tracks a desired trajectory. The proposed system has a similar evolution with a transform function that aggressively tracks the increasing power of different assets. As a result, the better performing assets will receive more investment. The proposed PPT objective can be formulated as a fast backpropagation algorithm, which is suitable for large-scale and time-limited applications, such as high-frequency trading. Extensive experiments on several benchmark data sets from diverse real financial markets show that PPT outperforms other state-of-the-art systems in computational time, cumulative wealth, and risk-adjusted metrics. It suggests that PPT is effective and even more robust than some defensive systems in PS.",2018
"From the NSF: The National Science Foundation's Investments in Broadening Participation in Science, Technology, Engineering, and Mathematics Education through Research and Capacity Building","The National Science Foundation (NSF) has a long history of investment in broadening participation (BP) in science, technology, engineering, and mathematics (STEM) education. A review of past NSF BP efforts provides insights into how the portfolio of programs and activities has evolved and the broad array of innovative strategies that has been used to increase the participation of groups underrepresented in STEM, including women, minorities, and persons with disabilities. While many are familiar with these long-standing programmatic efforts, BP is also a key component of NSF's strategic plans, has been highlighted in National Science Board reports, and is the focus of ongoing outreach efforts. The majority of familiar BP programs, such as the Louis Stokes Alliances for Minority Participation (now 25 years old), are housed in the Directorate for Education and Human Resources. However, fellowship programs such as the Graduate Research Fellowships and Postdoctoral Research Fellowships under the Directorate for Biological Sciences (and parallel directorates in other STEM disciplines) are frequently used to address underrepresentation in STEM disciplines. The FY2016 and FY2017 budget requests incorporate funding for NSF INCLUDES, a new cross-agency BP initiative that will build on prior successes while addressing national BP challenges. NSF INCLUDES invites the use of innovative approaches for taking evidence-based best practices to scale, ushering in a new era in NSF BP advancement.",2016
Chinese Value Investing Theory and Quantitative Technology,"After nearly three decades of a hard journey, China's capital market has more and more clearly demonstrated the right value of value investing. A-share market participants - retail investors and institutions - are in urgent need of a value investing theory in line with China's national conditions. We realize that China's value investing system must be the joint value investing of China and the world. This paper proposes a value investing theory and quantitative realizing technology system with China as the main body and taking both China and the world conditions into account. The main contents include: 1) under the framework of big data, using the credit risk analysis for filtering out stocks with mediocre or poor credit; 2) multi-factor models of quantitative investment for selection of value and growth stocks; 3) deep learning financial market prediction model for capturing dynamic margin of safety and profit opportunities; 4) deep intelligent portfolio trading technology for implementing value investing into super intelligent systems of quantitative investment. The characteristics and innovations of the theory are: expanding the big data holographic credit risk analysis for Chinese enterprises to value investing analysis; developing comprehensive multi-factor models for selecting value and growth stocks into portfolios; developing big data-driven deep learning financial market prediction models; innovating and developing deep intelligent trading strategies and systems.",2021
What do the AI methods tell us about predicting price volatility of key natural resources: Evidence from hyperparameter tuning,"Volatility plays a significant role in pricing derivatives, managing portfolio risk, and using hedging strategies in the financial markets. As a result, it is imperative to precisely estimate the volatility of key natural resources, including crude oil, gold, copper, natural gas, and silver. The likelihood of some countries' budget deficits exceeding permissible levels increased due to recent uncertainties brought on by geo-political threats. This article employs a hybrid model of LSTM-GJR-GARCH (1,1) with hyperparameter tuning to forecast the volatility of the prices of significant natural resources using daily closing prices for crude oil, natural gas, silver, copper, and gold from January 2012 to July 2022. Our results demonstrate that, compared to utilising standard LSTM-GJR-GARCH, employing hyperparameter adjustment increases volatility predictions by an average of 40%-70%. We also looked at the connection between the geo-political risk index and the overall connectedness of natural resources. Our findings suggest that geo-political risk uncertainty does not account for the overall intercon-nectedness of natural resources' prices. Because they may better understand future volatility and manage their portfolios and budgets by estimating the price volatility of natural resources, our findings are important for politicians, governments, and investors.",2023
Leveraging Weather Dynamics in Insurance Claims Triage Using Deep Learning,"In property insurance claims triage, insurers often use static information to assess the severity of a claim and to identify the subsequent actions. We hypothesize that the pattern of weather conditions throughout the course of a loss event is predictive of the insured losses, and hence appropriate use of weather dynamics improves the operation of insurers' claim management. To test this hypothesis, we propose a deep learning method to incorporate dynamic weather information in the predictive modeling of the insured losses for reported claims. The proposed method features a hierarchical network architecture to address the challenges in claims triage due to the nature of weather dynamics. In the empirical analysis, we examine a portfolio of hail damage property insurance claims obtained from a major U.S. insurance carrier. When supplemented by dynamic weather information, the deep learning method exhibits substantial improvement in the hold-out predictive performance. We further design a cost-conscious decision strategy for triaging claims using the probabilistic forecasts of the insurance claim amounts. We show that leveraging weather dynamics in claims triage leads to a reduction of up to 9% and 6% in operational costs compared to when the triaging decision is based on forecasts without any weather information and with only static weather information, respectively. Supplementary materials for this article are available online.",2024
Machine learning for cryptocurrency market prediction and trading,"We employ and analyze various machine learning models for daily cryptocurrency market prediction and trading. We train the models to predict binary relative daily market movements of the 100 largest cryptocurrencies. Our results show that all employed models make statistically viable predictions, whereby the average accuracy values calculated on all cryptocurrencies range from 52.9% to 54.1%. These accuracy values increase to a range from 57.5% to 59.5% when calculated on the subset of predictions with the 10% highest model confidences per class and day. We find that a long-short portfolio strategy based on the predictions of the employed LSTM and GRU ensemble models yields an annualized out-of-sample Sharpe ratio after transaction costs of 3.23 and 3.12, respectively. In comparison, the buy-and-hold benchmark market portfolio strategy only yields a Sharpe ratio of 1.33. These results indicate a challenge to weak form cryptocurrency market efficiency, albeit the influence of certain limits to arbitrage cannot be entirely ruled out. (c) 2022 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).",2022
Contrastive Learning of Asset Embeddings from Financial Time Series,"Representation learning has emerged as a powerful paradigm for extracting valuable latent features from complex, high-dimensional data. In financial domains, learning informative representations for assets can be used for tasks like sector classification, and risk management. However, the complex and stochastic nature of financial markets poses unique challenges. We propose a novel contrastive learning framework to generate asset embeddings from financial time series data. Our approach leverages the similarity of asset returns over many subwindows to generate informative positive and negative samples, using a statistical sampling strategy based on hypothesis testing to address the noisy nature of financial data. We explore various contrastive loss functions that capture the relationships between assets in different ways to learn a discriminative representation space. Experiments on real-world datasets demonstrate the effectiveness of the learned asset embeddings on benchmark industry classification and portfolio optimization tasks. In each case our novel approaches significantly outperform existing baselines highlighting the potential for contrastive learning to capture meaningful and actionable relationships in financial data.",2024
Company2Vec-German Company Embeddings Based on Corporate Websites,"With Company2Vec, the paper proposes a novel application in representation learning. The model analyzes business activities from unstructured company website data using Word2Vec and dimensionality reduction. Company2Vec maintains semantic language structures and thus creates efficient company embeddings in fine-granular industries. These semantic embeddings can be used for various applications in banking.Direct relations between companies and words allow semantic business analytics (e.g., top-n words for a company). Furthermore, industry prediction is presented as a supervised learning application and evaluation method. The vectorized structure of the embeddings allows measuring companies' similarities with the cosine distance. Company2Vec hence offers a more fine-grained comparison of companies than the standard industry labels (NACE). This property is relevant for unsupervised learning tasks, such as clustering. An alternative industry segmentation is shown with k-means clustering on the company embeddings. Finally, this paper proposes three algorithms for (1) firm-centric, (2) industry-centric and (3) portfolio-centric peer-firm identification.",2024
Service Retrieval for Service-Oriented Business Process Modeling,"Many enterprises are not able to adapt to changing business requirements. One of the solutions to this agility problem is the usage of service-oriented BP modeling. Meanwhile, their existing BP modeling does not consider the potential services in Legacy IS ( LIS) or from partners, in order to have a service-oriented BP modeling that promotes agility. This requires a complete reengineering of the LIS and the BPs into services realized by business objects. In this modeling paradigm, BPs are represented by specialized services, having separated concerns such as controller service, state service, and worker services. This paper provides guidance, by using techniques to retrieve business knowledge embedded in LIS and transform it into services towards moving from as-is to to-be BPs. These techniques are: (i) reverse engineering LIS, by extracting services from traces of BPs, and (ii) reverse engineering from the enterprise service portfolio or reusing partner and provider services.",2013
Financial applications of machine learning: A literature review,"This systematic literature review analyses the recent advances of machine learning and deep learning in finance. The study considers six financial domains: stock markets, portfolio management, cryptocurrency, forex markets, financial crisis, bankruptcy and insolvency. We provide an overview of previously proposed techniques in these areas by examining 126 selected articles across 44 reputed journals. The main contributions of this review include an extensive examination of data characteristics and features used for model training, evaluation of validation approaches, and model performance addressing each financial problem. A systematic literature review methodology, PRISMA, is used to carry out this comprehensive review. The study also analyses bibliometric information to understand the current status of research focused on machine learning in finance. The study finally points out possible research directions which might lead to new inquiries in machine learning and finance.",2023
TaskMet: Task-Driven Metric Learning for Model Learning,"Deep learning models are often used with some downstream task. Models solely trained to achieve accurate predictions may struggle to perform well on the desired downstream tasks. We propose using the task loss to learn a metric which parameterizes a loss to train the model. This approach does not alter the optimal prediction model itself, but rather changes the model learning to emphasize the information important for the downstream task. This enables us to achieve the best of both worlds: a prediction model trained in the original prediction space while also being valuable for the desired downstream task. We validate our approach through experiments conducted in two main settings: 1) decision-focused model learning scenarios involving portfolio optimization and budget allocation, and 2) reinforcement learning in noisy environments with distracting states. The source code to reproduce our experiments is available here.",2023
Does reinforcement learning outperform deep learning and traditional portfolio optimization models in frontier and developed financial markets?,"Advancements in machine learning have opened up a wide range of new possibilities for using advanced computer algorithms, such as reinforcement learning in portfolio risk management. However, very little evidence has been provided on the superior performance of reinforcement learning models over traditional optimization models following the mean-variance framework in different financial market settings. This study uses two experiments with data from the Viet-namese and U.S. securities markets to justify whether advanced machine learning models could outperform traditional portfolios' cumulative returns while optimizing the Sharpe ratio. The re-sults suggest that reinforcement learning consistently outperforms the established methods and benchmarks in both experiments, even when using a very similar degree of diversification in portfolio construction and the same input data. This study confirms the ability of reinforcement learning to provide dynamic responses to market conditions and redefine the risk-return standard in the financial system.",2023
Optimizing portfolio selection through stock ranking and matching: A reinforcement learning approach,"Predicting asset movements with machine learning (ML) algorithms remains a complex challenge, particularly in selecting optimal models or designing effective ensemble strategies. This study presents a novel methodology that synergizes reinforcement learning (RL) with advanced ML algorithms-LSTM, XGBoost, and Deep RankNet-to improve prediction accuracy and portfolio construction. The approach incorporates hyperparameter optimization, innovative feature engineering, and a comprehensive comparison of algorithmic performance. RL serves a dual role as both an ensemble strategy and a dynamic learning layer, enabling a 15% increase in cumulative returns compared to traditional ensemble techniques. This advancement highlights RL's capacity to refine predictions and enhance risk assessment by adaptively integrating outputs from diverse algorithms. Beyond demonstrating superior performance, the study provides actionable insights for practitioners seeking to construct effective, risk-sensitive trading portfolios.",2025
Estimating the Value-at-Risk by Temporal VAE,"Estimation of the value-at-risk (VaR) of a large portfolio of assets is an important task for financial institutions. As the joint log-returns of asset prices can often be projected to a latent space of a much smaller dimension, the use of a variational autoencoder (VAE) for estimating the VaR is a natural suggestion. To ensure the bottleneck structure of autoencoders when learning sequential data, we use a temporal VAE (TempVAE) that avoids the use of an autoregressive structure for the observation variables. However, the low signal-to-noise ratio of financial data in combination with the auto-pruning property of a VAE typically makes use of a VAE prone to posterior collapse. Therefore, we use annealing of the regularization to mitigate this effect. As a result, the auto-pruning of the TempVAE works properly, which also leads to excellent estimation results for the VaR that beat classical GARCH-type, multivariate versions of GARCH and historical simulation approaches when applied to real data.",2023
Bibliometric and systemic analysis of the relationship between management and carbon,"This paper aims to present a bibliometric and systemic analysis of the Bibliographic Portfolio (BP) jointly exam-ining the literature related to topics like Greenhouse gas, mainly carbon, and Management, as published in databases data such as Web of Science and Scopus in the field of economic and social sciences. The Knowledge and Constructivist Development Process methodology -Proknow-C- was used to establish the final portfolio and through the VosViewer program were mapped the various groups or relationships between the studied literature. The paper presents the theoretical and methodological aspects focusing on the areas and countries of study and highlighting the most relevant authors to have researched this particular topic. We use this constructivist model to describe the measurement variables and synthesize the concepts most used in these studies in order to propose new focal points and thematic approaches that could be developed further in the future.",2022
Using GAN-generated market simulations to guide genetic algorithms in index tracking optimization,"Index tracking is the problem of building a portfolio that replicates the performance of a market index. The recent applications involving deep learning in index tracking are more focused on the learned information rather than on the framework that consumes this information. The problem is that, until now, a way to enable the extension of the index tracking models that adopt machine learning was not yet proposed. Nowadays, the mathematical programming framework is more flexible when considering model extensions to build realistic portfolios. Thus, this study presents ways to combine generative adversarial networks (GANs) within this framework to generate market simulations incorporated into a base index tracking model. It was verified how the simulations generated by GANs can impact the out-of-sample performance of the portfolio and how to deal with their instability, by using real data from the Brazilian market. To achieve this, two evolutionary metaheuristics were proposed to solve the multiple scenario index tracking problem. The proposed evolutionary algorithms minimize the tracking errors of a portfolio in multiple market simulations generated by GANs. The performance of the proposed algorithms was compared against another evolutionary metaheuristic that solves the index tracking problem using historical data. It was possible to observe that the scenario-based dominance genetic algorithm (SDM-SBDGA-GAN) was able to perform better than the real data genetic algorithm (RDM-GA) and the sample average approximation genetic algorithm (SDM-SAAGA-GAN). These results open doors for new applications of synthetic data in the construction of portfolios using more realistic constraints and other tracking objectives. This work also brings discussions about problems related to the application of GANs in this context.& COPY; 2023 Elsevier B.V. All rights reserved.",2023
Towards efficient similarity embedded temporal Transformers via extended timeframe analysis,"Price prediction remains a crucial aspect of financial market research as it forms the basis for various trading strategies and portfolio management techniques. However, traditional models such as ARIMA are not effective for multi-horizon forecasting, and current deep learning approaches do not take into account the conditional heteroscedasticity of financial market time series. In this work, we introduce the similarity embedded temporal Transformer (SeTT) algorithms, which extend the state-of-the-art temporal Transformer architecture. These algorithms utilise historical trends in financial time series, as well as statistical principles, to enhance forecasting performance. We conducted a thorough analysis of various hyperparameters including learning rate, local window size, and the choice of similarity function in this extension of the study in a bid to get optimal model performance. We also experimented over an extended timeframe, which allowed us to more accurately assess the performance of the models in different market conditions and across different lengths of time. Overall, our results show that SeTT provides improved performance for financial market prediction, as it outperforms both classical financial models and state-of-the-art deep learning methods, across volatile and non-volatile extrapolation periods, with varying effects of historical volatility on the extrapolation. Despite the availability of a substantial amount of data spanning up to 13 years, optimal results were primarily attained through a historical window of 1-3 years for the extrapolation period under examination.",2024
Applicability of genetic algorithms for stock market prediction: A systematic survey of the last decade,"Stock market is one of the attractive domains for researchers as well as academicians. It represents highly complex non-linear fluctuating market behaviours where traders, investors, and organizers look forward to reliable future predictions of the market indices. Such prediction problems can be computationally addressed using various machine learning, deep learning, sentiment analysis, as well as mining approaches. However, the internal parameters configuration can play an important role in the prediction performance; also, feature selection is a crucial task. Therefore, to optimize such approaches, the evolutionary computation-based algorithms can be integrated in several ways. In this article, we systematically conduct a focused survey on genetic algorithm (GA) and its applications for stock market prediction; GAs are known for their parallel search mechanism to solve complex real-world problems; various genetic perspectives are also integrated with machine learning and deep learning methods to address financial forecasting. Thus, we aim to analyse the potential extensibility and adaptability of GAs for stock market prediction. We review stock price and stock trend prediction, as well as portfolio optimization, approaches over the recent years (2013-2022) to signify the state-of-the-art of GA-based optimization in financial markets. We broaden our discussion by briefly reviewing other genetic perspectives and their applications for stock market forecasting. We balance our survey with the consideration of competitiveness and complementation of GAs, followed by highlighting the challenges and potential future research directions of applying GAs for stock market prediction.",2024
Support System for Trading in Exchange Market by Distributional Forecasting Model,"Integration of algorithms of investment theory and artificial intelligence allows one to create a support system for investors in exchange markets based on the ensemble of long-short-termmemory (LSTM) based recurrent neural networks (RNN). The proposed support system contains five stages: preparation of historical data, prediction by an ensemble of LSTM RNNs, assessment of prediction distributions, investment portfolio formation and verification. The prediction process outputs a multi-modal distribution, which provides useful information for investors. The research compares four different strategies based on a combination of distribution forecasting models. The high-low strategy helps decision-makers in exchange markets to recognize signals of transactions and fix limits for expectations. A combination of high-low-daily-weekly predictions helps investors to make daily transactions with knowing distribution of exchange rates during the week. The shift in time of five hours between London and New York inspired us to create a UK-NY strategy, which allows investors to recognize the signals of the market in a very short time. The joined high-low-UK-NY strategy increases the possibility of recognizing the signals of transactions in a very short time and of fixing the limits for day trading. So, this support system for investors is verified as a profitable tool for speculators in the relatively risky currency market.",2019
Multi-Sensor Temporal Fusion Transformer for Stock Performance Prediction: An Adaptive Sharpe Ratio Approach,"Accurate prediction of the Sharpe ratio, a key metric for risk-adjusted returns in financial markets, remains a significant challenge due to the complex and stochastic nature of stock price movements. This paper introduces a novel deep learning model, the Temporal Fusion Transformer with Adaptive Sharpe Ratio Optimization (TFT-ASRO), designed to address this challenge. The model incorporates real-time market sensor data and financial indicators as input signals, leveraging multiple data streams including price sensors, volume sensors, and market sentiment sensors to capture the complete market state. Using a comprehensive dataset of US historical stock prices and earnings data, we demonstrate that TFT-ASRO outperforms traditional methods and existing deep learning models in predicting Sharpe ratios across various time horizons. The model's multi-task learning framework, which simultaneously predicts returns and volatility, provides a more nuanced understanding of risk-adjusted performance. Furthermore, our adaptive optimization approach effectively balances the trade-off between return maximization and risk minimization, leading to more robust predictions. Empirical results show that TFT-ASRO achieves a 18% improvement in Sharpe ratio prediction accuracy compared to state-of-the-art baselines, with particularly strong performance in volatile market conditions. The model also demonstrates superior uncertainty quantification, providing reliable confidence intervals for its predictions. These findings have significant implications for portfolio management and investment strategy optimization, offering a powerful tool for financial decision-makers in the era of data-driven investing.",2025
An Ensemble System Based on Hybrid EGARCH-ANN with Different Distributional Assumptions to Predict S&P 500 Intraday Volatility,"Accurate forecasting of stock market volatility is an important issue in portfolio risk management. In this paper, an ensemble system for stock market volatility is presented. It is composed of three different models that hybridize the exponential generalized autoregressive conditional heteroscedasticity (GARCH) process and the artificial neural network trained with the backpropagation algorithm (BPNN) to forecast stock market volatility under normal, t-Student, and generalized error distribution (GED) assumption separately. The goal is to design an ensemble system where each single hybrid model is capable to capture normality, excess skewness, or excess kurtosis in the data to achieve complementarity. The performance of each EGARCH-BPNN and the ensemble system is evaluated by the closeness of the volatility forecasts to realized volatility. Based on mean absolute error and mean of squared errors, the experimental results show that proposed ensemble model used to capture normality, skewness, and kurtosis in data is more accurate than the individual EGARCH-BPNN models in forecasting the S&P 500 intra-day volatility based on one and five-minute time horizons data.",2015
Evolving Hybrid Neural Fuzzy Network for Realized Volatility Forecasting with Jumps,"Equity assets volatility modeling and forecasting are fundamental in risk management, portfolio construction, financial decision making and derivative pricing. The use of realized volatility models outperforms GARCH and related stochastic volatility models in out-of-sample forecasting. Gains in performance can be achieved by separately considering volatility jump components. This paper suggests an evolving hybrid neural fuzzy network (eHFN) modeling approach for realized volatility forecasting with jumps. The eHFN model is nonlinear, timeraying, and uses neurons based on uninorms and sigmoidal activation functions in a feedforward network topology. The approach simultaneously chooses the number of hidden layer neurons and corresponding neural networks weights. This is of outmost importance in dynamic environments such as in volatility forecasting using data streams. Computational experiments were performed to evaluate and to compare the performance of eHFN with multilayer feedforward neural network, linear regression, and evolving fuzzy models representative of the current state of the art. The experiments use actual data from the main equity market indexes in global markets, namely, S&P 500 and Nasdaq (United States), FTSE (United Kingdom), DAX (Germany), IBEX (Spain) and Ibovespa (Brazil). The results show that the evolving hybrid neural fuzzy network is highly capable to model timevarying realized volatility with jumps.",2014
Auto-Pytorch: Multi-Fidelity MetaLearning for Efficient and Robust AutoDL,"While early AutoML frameworks focused on optimizing traditional ML pipelines and their hyperparameters, a recent trend in AutoML is to focus on neural architecture search. In this paper, we introduce Auto-PyTorch, which brings together the best of these two worlds by jointly and robustly optimizing the network architecture and the training hyperparameters to enable fully automated deep learning (AutoDL). Auto-PyTorch achieves state-of-the-art performance on several tabular benchmarks by combining multi-fidelity optimization with portfolio construction for warmstarting and ensembling of deep neural networks (DNNs) and common baselines for tabular data. To thoroughly study our assumptions on how to design such an AutoDL system, we additionally introduce a new benchmark on learning curves for DNNs, dubbed LCBench, and run extensive ablation studies of the full Auto-PyTorch on typical AutoML benchmarks, eventually showing that Auto-PyTorch performs better than several state-of-the-art competitors.",2021
XVA analysis from the balance sheet,"XVAs denote various counterparty risk related valuation adjustments that are applied to financial derivatives since the 2007-2009 crisis. We root a cost-of-capital XVA strategy in a balance sheet perspective which is key to identifying the economic meaning of the XVA terms. Our approach is first detailed in a static setup that is solved explicitly. It is then plugged into the dynamic and trade incremental context of a real derivative banking portfolio. The corresponding cost-of-capital XVA strategy ensures for bank shareholders a submartingale equity process corresponding to a target hurdle rate on their capital at risk, consistently between and throughout deals. Set on a forward/backward SDE formulation, this strategy can be solved efficiently using GPU computing combined with deep learning regression methods in a whole bank balance sheet context. A numerical case study emphasizes the workability and added value of the ensuing pathwise XVA computations.",2021
Code-labelling: A Teaching Activity Encouraging Deep Learning in a non-STEM Introductory Programming Course,"The code-labelling exercise is an attempt to apply natural language education techniques for solving the challenge of teaching introductory programming to non-STEM novices in higher education. This paper presents findings from a study exploring the use of natural language teaching techniques in programming education collected in an Action Research cycle. The results support the use of a structural approach to teaching programming to this target audience; particularly, the translation-grammar method seems to integrate well with programming education. The paper also explores the potential underlying reasons. It seems the exercise invokes an assimilation of student's existing cognitive schemata and supports a deep-learning experience. The exercise is an invitation to other teachers to create further iterations to improve their own teaching. It also seeks to enrich the portfolio of teaching activities for solving the challenge of teaching introductory programming to non-STEM novices.",2017
Overview of the use of quantitative methods in research on corporate university and organizational learning,"This article provides an overview of the quantitative methods used in research on Corporate Universities and Organizational Learning. The analysis was based on a bibliographic portfolio consisting of 20 articles published in the Scopus and Web of Science databases, selected using the Knowledge Development Process -Constructivist (Proknow-C) methodology. The results of the analysis revealed that: i) descriptive statistics were the most commonly used quantitative method; ii) Likert scales were the most frequently used measurement format; iii) questionnaires were the most commonly used data collection instrument; iv) there was a considerable variation in sample sizes across the publications, with judgment sampling being the most prevalent; and v) in terms of literature and prominent authors, no significant bibliography support was found in the sample. The study found that many of the articles in the Bibliographic Portfolio (BP) lacked detailed description of the adopted methodological procedures, which could potentially contribute to a broader analysis and replication of the studies.",2023
An Open Markov Chain Scheme Model for a Credit Consumption Portfolio fed by ARIMA and SARMA Processes,We introduce a schematic formalism for the time evolution of a random population entering some set of classes and such that each member of the population evolves among these classes according to a scheme based on a Markov chain model. We consider that the flow of incoming members is modeled by a time series and we detail the time series structure of the elements in each of the classes. We present a practical application to data from a credit portfolio of a Cape Verdian bank; after modeling the entering population in two different ways - namely as an ARIMA process and as a deterministic sigmoid type trend plus a SARMA process for the residues - we simulate the behavior of the population and compare the results. We get that the second method is more accurate in describing the behavior of the populations when compared to the observed values in a direct simulation of the Markov chain.,2016
A representation-learning approach for insurance pricing with images,"Unstructured data are a promising new source of information that insurance companies may use to understand their risk portfolio better and improve the customer experience. However, these novel data sources are difficult to incorporate into existing ratemaking frameworks due to the size and format of the unstructured data. This paper proposes a framework to use street view imagery within a generalized linear model. To do so, we use representation learning to extract an embedding vector containing useful information from the image. This embedding is dense and low dimensional, making it appropriate to use within existing ratemaking models. We find that there is useful information included in street view imagery to predict the frequency of claims for certain types of perils. This model can be used as in a ratemaking framework but also opens the door to future empirical research on attempting to extract which characteristics within the image leads to increased or decreased predicted claim frequencies. Throughout, we discuss the practical difficulties (technical and social) of using this type of data for insurance pricing.",2024
Conspiracy spillovers and geoengineering,"Geoengineering techniques such as solar radiation management (SRM) could be part of a future technology portfolio to limit global temperature change. How-ever, there is public opposition to research and deployment of SRM technologies. We use 814,924 English-language tweets containing #geoengineering globally over 13 years (2009-2021) to explore public emotions, perceptions, and attitudes toward SRM using natural language processing, deep learning, and network anal-ysis. We find that specific conspiracy theories influence public reactions toward geoengineering, especially regarding chemtrails(whereby airplanes allegedly spray poison or modify weather through contrails). Furthermore, conspiracies tend to spillover, shaping regional debates in the UK, USA, India, and Sweden and connecting with broader political considerations. We also find that positive emotions rise on both the global and country scales following events related to SRM governance, and negative and neutral emotions increase following SRM projects and announcements of experiments. Finally, we also find that online toxicity shapes the breadth of spillover effects, further influencing anti-SRM views.",2023
Predicting macro-financial instability-How relevant is sentiment? Evidence from long short-term memory networks,"This paper examines the relevance of sentiment in predicting overall financial system instability using long-run short-term memory networks. Weekly data on the US financial system, consumer sentiment, producer sentiment, and investor sentiment is collected from 21 January 1994 to 27 December 2019, and different models are developed to predict the one-week-ahead levels of financial stress in the US financial system. We find that models using sentiment indices outper-form those relying solely on historical financial stress and risk data. This result is robust to comparisons with an alternative deep learning method and out-of-sample predictions. It consti-tutes an argument in favor of behavioral finance and Minsky's (Knell, 2015) financial instability hypothesis against the Efficient Market Hypothesis. As it concretely identifies the main indicators for predicting US financial stress one week in advance, the study provides relevant recommen-dations for policymakers and investors in terms of macroprudential policies and portfolio management.",2023
Machine Trading by Time Series Models and Portfolio Optimization,"Machine learning algorithms such as Support Vector Machine (SVM) and Artificial Neural Network (ANN) are used for machine trading. The problem with SVM and ANN is that it is difficult to determine appropriated features for both models; moreover, it is also time consuming to perform backpropagation for ANN when a number of both features and data increase. However, machine trading is not confined only these two algorithms, but also time series models. In this study, we will employ time series models namely Autoregressive Integrated Moving Average (ARIMA) and Holt - Winters' Exponential Smoothing (HW) as the guidance for trading since time series models only require time series as an input. We will perform time series analysis to snatch the trading opportunity in the Stock Exchange of Thailand (SET). There are fifty companies on the list of SET50 index; we will choose five amongst them to invest measured by Sharpe Ratio; the top five from this measurement will be selected as invested assets in simulated portfolio. Furthermore, the well-known portfolio optimization framework by Harry Markowitz will be used to ensure that the combination of the invested assets is located on the efficient frontier; the result from this study is favorable as the return generated by these activities outperforms market return; furthermore, manipulating time series into different time lags yields higher return and as well as combining both ARIMA and HW models to help predict stock prices also improves power of prediction of time series models. This study will help retail investor who has limited resource overthrow bias and intuition throughout investment decision process ranging from finding the stocks for investment to capturing market movement for trading opportunity.",2019
Lossless Transformations and Excess Risk Bounds in Statistical Inference,"We study the excess minimum risk in statistical inference, defined as the difference between the minimum expected loss when estimating a random variable from an observed feature vector and the minimum expected loss when estimating the same random variable from a transformation (statistic) of the feature vector. After characterizing lossless transformations, i.e., transformations for which the excess risk is zero for all loss functions, we construct a partitioning test statistic for the hypothesis that a given transformation is lossless, and we show that for i.i.d. data the test is strongly consistent. More generally, we develop information-theoretic upper bounds on the excess risk that uniformly hold over fairly general classes of loss functions. Based on these bounds, we introduce the notion of a delta-lossless transformation and give sufficient conditions for a given transformation to be universally delta-lossless. Applications to classification, nonparametric regression, portfolio strategies, information bottlenecks, and deep learning are also surveyed.",2023
Designing and deploying insurance recommender systems using machine learning,"Recommender systems have become extremely important to various types of industries where customer interaction and feedback is paramount to the success of the business. For companies that face changes that arise with ever-growing markets, providing product recommendations to new and existing customers is a challenge. Our goal is to give our customers personalized recommendations based on what other similar people with similar portfolios have, in order to make sure they are adequately covered for their needs. Our system uses customer characteristics in addition to customer portfolio data. Since the number of possible recommendable products is relatively small, compared to other recommender domains, and missing data is relatively frequent, we chose to use Bayesian Networks for modeling our systems. We also present a deep-learning-based approach to provide recommendations to prospects (potential customers) where only external marketing data is available at the time of prediction. This article is categorized under: Application Areas > Industry Specific Applications Algorithmic Development > Structure Discovery Algorithmic Development > Bayesian Models Technologies > Machine Learning",2020
Ensemble of temporal Transformers for financial time series,"The accuracy of price forecasts is important for financial market trading strategies and portfolio management. Compared to traditional models such as ARIMA and other state-of-the-art deep learning techniques, temporal Transformers with similarity embedding perform better for multi-horizon forecasts in financial time series, as they account for the conditional heteroscedasticity inherent in financial data. Despite this, the methods employed in generating these forecasts must be optimized to achieve the highest possible level of precision. One approach that has been shown to improve the accuracy of machine learning models is ensemble techniques. To this end, we present an ensemble approach that efficiently utilizes the available data over an extended timeframe. Our ensemble combines multiple temporal Transformer models learned within sliding windows, thereby making optimal use of the data. As combination methods, along with an averaging approach, we also introduced a stacking meta-learner that leverages a quantile estimator to determine the optimal weights for combining the base models of smaller windows. By decomposing the constituent time series of an extended timeframe, we optimize the utilization of the series for financial deep learning. This simplifies the training process of a temporal Transformer model over an extended time series while achieving better performance, particularly when accounting for the non-constant variance of financial time series. Our experiments, conducted across volatile and non-volatile extrapolation periods, using 20 companies from the Dow Jones Industrial Average show more than 40% and 60% improvement in predictive performance compared to the baseline temporal Transformer.",2024
"Artificial intelligence in clinical and translational science: Successes, challenges and opportunities","Artificial intelligence (AI) is transforming many domains, including finance, agriculture, defense, and biomedicine. In this paper, we focus on the role of AI in clinical and translational research (CTR), including preclinical research (T1), clinical research (T2), clinical implementation (T3), and public (or population) health (T4). Given the rapid evolution of AI in CTR, we present three complementary perspectives: (1) scoping literature review, (2) survey, and (3) analysis of federally funded projects. For each CTR phase, we addressed challenges, successes, failures, and opportunities for AI. We surveyed Clinical and Translational Science Award (CTSA) hubs regarding AI projects at their institutions. Nineteen of 63 CTSA hubs (30%) responded to the survey. The most common funding source (48.5%) was the federal government. The most common translational phase was T2 (clinical research, 40.2%). Clinicians were the intended users in 44.6% of projects and researchers in 32.3% of projects. The most common computational approaches were supervised machine learning (38.6%) and deep learning (34.2%). The number of projects steadily increased from 2012 to 2020. Finally, we analyzed 2604 AI projects at CTSA hubs using the National Institutes of Health Research Portfolio Online Reporting Tools (RePORTER) database for 2011-2019. We mapped available abstracts to medical subject headings and found that nervous system (16.3%) and mental disorders (16.2) were the most common topics addressed. From a computational perspective, big data (32.3%) and deep learning (30.0%) were most common. This work represents a snapshot in time of the role of AI in the CTSA program.",2022
Innovation in public administration: bibliometric analysis from the mapping of international literature,"The objective of this study is to present the characteristics of international scientific publications related to the adoption of innovations in public administration through electronic systems. The Proknow-C was used as a research instrument. After applying filters for title, abstract, full-text reading, and scientific recognition, a Final Bibliographic Portfolio (BP) of 30 articles was obtained. The results highlighted the authors and journals that have published the most on the subject, the most referenced scientific articles, the most frequently used keywords, the strongest co-authorship networks, the countries that stand out the most in publications on the subject, and characteristics of the co-citation network. Thus, this study contributes to the proposal of a BP aligned with the topic, whose analysis of the characteristics provides information for public administrators to support their practices and decisions based on literature backed by international scientific recognition.",2024
Asymmetric Autoencoders for Factor-Based Covariance Matrix Estimation,"Estimating high dimensional covariance matrices for portfolio optimization is challenging because the number of parameters to be estimated grows quadratically in the number of assets. When the matrix dimension exceeds the sample size, the sample covariance matrix becomes singular. A possible solution is to impose a (latent) factor structure for the cross-section of asset returns as in the popular capital asset pricing model. Recent research suggests dimension reduction techniques to estimate the factors in a data-driven fashion. We present an asymmetric autoencoder neural network-based estimator that incorporates the factor structure in its architecture and jointly estimates the factors and their loadings. We test our method against well established dimension reduction techniques from the literature and compare them to observable factors as benchmark in an empirical experiment using stock returns of the past five decades. Results show that the proposed estimator is very competitive, as it significantly outperforms the benchmark across most scenarios. Analyzing the loadings, we find that the constructed factors are related to the stocks' sector classification.",2022
Evaluation of port performance: Research opportunities from the systemic analysis of international literature,"This article aims to analyze the research opportunities on the topic of port industry performance evaluation, through the investigation of a Bibliographic Portfolio (BP) of international literature articles with relevance and scientific recognition. To achieve this goal, ProKnow-C (Knowledge Development Process-Constructivist) intervention instrument was used. The systemic analysis consists of a structured process of critical analysis of BP articles, based on a set of assumptions defined by the researcher informed by the theoretical affiliation adopted, in order to highlight gaps and research opportunities. It is an exploratory study, with a qualitative approach, involving the collection of primary and secondary data. Thus, it is possible to conclude that port performance evaluation studies, for the most part, apply standardized models, methods, tools and techniques, without taking into account the context specific needs, aiming particularly to measure the productivity and operational efficiency of the ports.",2018
Emerging and Potential Opportunities for 2D Flexible Nanoelectronics,"The last 10 years have seen the emergence of two-dimensional (2D) nanomaterials such as graphene, transition metal dichalcogenides (TMDs), and black phosphorus (BP) among the growing portfolio of layered van der Waals thin films. Graphene, the prototypical 2D material has advanced rapidly in device, circuit and system studies that has resulted in commercial large-area applications. In this work, we provide a perspective of the emerging and potential translational applications of 2D materials including semiconductors, semimetals, and insulators that comprise the basic material set for diverse nanosystems. Applications include RF transceivers, smart systems, the so-called internet of things, and neurotechnology. We will review the DC and RF electronic performance of graphene and BP thin film transistors. 2D materials at sub-um channel length have so far enabled cut-off frequencies from baseband to 100GHz suitable for low-power RF and sub-THz concepts.",2016
COMPARATIVE ANALYSIS OF THE COMPLETE CHLOROPLAST GENOME OF THREE PROSOPIS SPECIES IN JORDAN,"Worldwide, Prosopis Genus is widely spread and well known to be of high tolerance to harsh conditions. The P. juliflora and P. cineraria species were introduced to the Mediterranean, while P. farcta is a native one. The genomic structure of the chloroplast of P. juliflora, P. cineraria and P. farcta were targeted in this study. The chloroplast DNA samples were sequenced by genetic analyzer sequencer Ion S5TM System. The results indicated the size of the genome to be ranged between 162900 bp in P. farcta and 163667 bp in P. cineraria . The full chloroplast of P. juliflora and P. cineraria genome were reported for the first time nationally in Jordan, while globally P. farcta was the first to be analyzed genetically. The present study offers an important portfolio of Prosopis species chloroplast genome analyses, this could help with identification of species and speed up biological and genetic diversity researches.",2024
On Bounding Credit-Event Risk Premia,"Reduced-form models of default that attribute a large fraction of credit spreads to compensation for credit-event risk typically preclude the most plausible economic justification for such risk to be priced, namely, a contemporaneous drop in the market portfolio. When this contagion channel is introduced within a general equilibrium framework for an economy comprising a large number of firms, credit-event risk premia have an upper bound of a few basis points, and are dwarfed by the contagion premium. We provide empirical evidence that indicates credit-event risk premia are less than 1 bp, but contagion risk premia are significant.",2015
BPM governance: a literature analysis of performance evaluation,"Purpose - The purpose of this paper is to collect data and select a bibliographic portfolio (BP) of the literature on the performance evaluation of business process management (BPM) governance, in order to highlight studies aligned with business process governance, and with scientific recognition and its bibliometric parameters. Design/methodology/approach - The research method is qualitative and the process of identification, selection, and analysis of the articles in the BP took place through evaluation and interpretation by the authors of this research. Regarding data collection, this research used primary data in the selection of the BP, and secondary data when the authors analyzed the articles. Findings - The paper selects a set of 19 articles with scientific recognition and aligned with the research topic, which refers to the performance evaluation of BPM governance. This set is called the BP, and highlights and contains the most often present journals, articles, authors, and keywords found in the search performed by the authors. Originality/value - This research uses thorough procedures for the selection process that differ from traditional procedures: the selection process is structured in a way that allows checking of each research stage; the research topic is fragmented into many areas of study and the search is carried out simultaneously in all these areas; and the researchers interact with the search process and as they expand their learning they adjust the search direction.",2017
An online portfolio strategy based on trend promote price tracing ensemble learning algorithm,"How to carry out an investment portfolio efficiently and reasonably has become a hot issue. This study mainly addresses the problem of the instability of forecasting stock price investment and the difficulty in determining investment proportion by proposing the trend peak price tracing (TPPT). First of all, because of the influence of stock price anomaly, TPPT strategy sets adjustable historical window width. It uses slope value to judge prediction direction to track price change, which uses exponential moving average and peak equal weight slope value three-state price prediction method. Secondly, the accumulated wealth target is refined, and the fast error Back Propagation based on gradient projection algorithm (BP) is added. The algorithm solves investment proportion and feedbacks the increasing ability of assets to the investment proportion in order to maximize the accumulated wealth. Finally, comparison of eight empirical strategies in five typical data and statistical tests show that TPPT strategy has great advantages in balancing risk and return, and it is a robust and effective online portfolio strategy. (c) 2021 Elsevier B.V. All rights reserved.",2022
Financial implications of fourth industrial revolution: Can bitcoin improve prospects of energy investment?,"Bitcoin and the blockchain technology on which it is based are the key drivers behind the accelerated pace of Fourth Industrial Revolution in the domain of Finance. The offshoots of this technology however are not limited and are rapidly spreading in other domains such as oil market. This paper investigates the causally or influences that both markets, Bitcoin price (BP) and oil price (OP) have on each other by applying the bootstrap Granger causal relationship tests considering full as well as sub-samples. Our analysis reveals that shocks originated in OP and transmitted towards BP can be both positive or negative. The positive impact indicates that Bitcoin can be viewed as an asset helpful in avoiding the risks of the high OP, which also indicates that Bitcoin and oil are in the same boat, however, the negative effects cannot support this view. The negative influence of OP on BP can be explained by the burst of the Bitcoin bubble which has weakened its hedging ability. In turn, there is also a negative influence or reverse causally running from BP to OP, highlighting that the demand for oil by investors can be threatened by the increasing BP. Keeping in view the more integrated and complexed financial dynamics which are the results of Fourth Industrial Revolution, investors can benefit from this interrelationship to diversify the risks and optimize their investment by building a more balanced portfolio. Also, governments could promote and protect the healthy development of the Bitcoin and energy market by preventing the Bitcoin bubbles and understanding the reasons of oil price volatility.",2020
Design Comorbidity Portfolios to Improve Treatment Cost Prediction of Asthma Using Machine Learning,"Comorbidity is an important factor to consider when trying to predict the cost of treating asthma patients. When an asthmatic patient suffered from comorbidity, the cost of treating such a patient becomes dependent on the nature of the comorbidity. Therefore, lack of recognition of comorbidity on asthmatic patient poses a challenge in predicting the cost of treatment. In this study, we proposed a comorbidity portfolio design that improves the prediction cost of treating asthmatic patients by regrouping frequently occurred comorbidities in different cost groups. In the experiment, predictive models, including logistic regression, random forest, support vector machine, classification regression tree, and backpropagation neural network were trained with real-world data of asthmatic patients from 2012 to 2014 in a large city of China. The 10-fold cross validation and random search algorithm were employed to optimize the hyper-parameters. We recorded significant improvements using our model, which are attributed to comorbidity portfolios in area under curve (AUC) and sensitivity increase of 46.89% (standard deviation: 4.45%) and 101.07% (standard deviation: 44.94%), respectively. In risk analysis of comorbidity on cost, respiratory diseases with a cumulative proportion in the adjusted odds ratio of 36.38% (95%CI: 27.61%, 47.86%) and circulatory diseases with a cumulative proportion in the adjusted odds ratio of 23.83% (95%CI: 15.95%, 35.22%) are the dominant risks of asthmatic patients that affects the treatment cost. It is found that the comorbidity portfolio is robust, and provides a better prediction of the high-cost of treating asthmatic patients. The preliminary characterization of the joint risk of multiple comorbidities posed on cost are also reported. This study will be of great help in improving cost prediction and comorbidity management.",2021
Stock market movement forecast: A Systematic review,"Achieving accurate stock market models can provide investors with tools for making better data-based decisions. These models can help traders to reduce investment risk and select the most profitable stocks. Furthermore, creating advanced models enable the usage of non-traditional data like historical stock prices and news. There are several review articles about financial problems, including stock market analysis and forecast, currency exchange forecast, optimal portfolio selection, among others. However, the recent advances in machine learning techniques, like Deep Learning, Text Mining Techniques, and Ensemble Techniques, raises the need to perform an updated review. This study aims to fill this gap by providing an updated systematic review of the forecasting techniques used in the stock market, including their classification, characterization and comparison. The review is focused on studies on stock market movement prediction from 2014 to 2018, obtained from the scientific databases Scopus and Web of Science. Besides, it analyzes surveys and other reviews of recent studies published in the same time frame and the same databases. (C) 2020 Elsevier Ltd. All rights reserved.",2020
Where to go? Visualization of cryptocurrency research trends based on scientometrics,"This study presents an in-depth analysis of the progression, focal points, and emerging areas in cryptocurrency research spanning from 2014 to 2022. By utilizing the JCR-based classification map within CiteSpace software, we charted the evolutionary trajectory of knowledge in the realm of cryptocurrency research. The nucleus of fundamental knowledge emerged predominantly within the domains of mathematics and economics. To further discern the prevailing research trends, we conducted a comprehensive analysis of keyword co-occurrences utilizing the same software. This analysis spotlighted six key research hotspots: safe haven, blockchain, market efficiency, deep learning, portfolio management, and financial regulation. Additionally, to gauge the research frontiers, we scrutinized the strength of keyword bursts. This exploration identified 23 evolving keywords, segregated into two distinct phases: the initial phase (2014-2017) characterized by keywords tied to Bitcoin, followed by the subsequent phase (2017-2022) marked by keywords linked to blockchain technology and financial regulation. In sum, this investigation furnishes invaluable insights into the trajectories and trajectories of cryptocurrency research, thereby serving as a compass to steer future explorations in this dynamic field.",2023
"Bayesian machine learning framework for characterizing structural dependency, dynamics, and volatility of cryptocurrency market using potential field theory","Identifying the structural dependence between the cryptocurrencies and predicting market trend are fundamental for effective portfolio management in cryptocurrency trading. In this paper, we present a unified Bayesian machine learning framework based on potential field theory and Gaussian Process to characterize the structural dependency of various cryptocurrencies, using historic price information. The following are our significant contributions: (i) Proposed a novel model for cryptocurrency price movements as a trajectory of a dynamical system governed by a time-varying non-linear potential field. (ii) Developed a Bayesian machine learning framework for inferring the non-linear potential function from observed cryptocurrency prices. (iii) Proposed that attractors and repellers inferred from the potential field are reliable cryptocurrency market indicators, surpassing existing attributes in the literature. (iv) Analysis of cryptocurrency market during various Bitcoin crash durations shows that attractors captured the market trend, volatility, and correlation. In addition, attractors aids explainability and visualization. (v) The proposed cryptocurrency market indicators (attractors and repellers) was used to improve the prediction performance of state-of-art deep learning price prediction models.",2025
Financial Time Series Forecasting: A Comprehensive Review of Signal Processing and Optimization-Driven Intelligent Models,"Financial time series forecasting is pivotal in various sectors such as portfolio management investment allocation and risk assessment. However, traditional methods are not suitable to provide acceptable forecasting attributes of financial data. In response, intelligent algorithms like artificial neural networks, fuzzy logic, machine and deep learning techniques have emerged as promising tools for improving forecasting accuracy. This article provides a comprehensive review of different intelligent forecasting models, highlighting their advantages and limitations. Directly feeding historical data into these models is not reliable due to the volatile, nonlinear, and non-stationary nature of financial information, along with uncertainties in numerous independent parameters. Therefore, additional feature engineering and optimal parameter selection techniques are necessary. Integrating signal processing techniques enables the extraction of useful features from noisy financial data, while optimization algorithms aid in model refinement and parameter tuning. The article also discusses performance indicators, which are crucial for identifying optimal features and parameters in forecasting models. These integrated approaches not only enhances forecasting accuracy but also provides new possibilities in decision-making processes across various sectors.",2025
"Stock Embeddings Acquired from News Articles and Price History, and an Application to Portfolio Optimization","Previous works that integrated news articles to better process stock prices used a variety of neural networks to predict price movements. The textual and price information were both encoded in the neural network, and it is therefore difficult to apply this approach in situations other than the original framework of the notoriously hard problem of price prediction. In contrast, this paper presents a method to encode the influence of news articles through a vector representation of stocks called a stock embedding. The stock embedding is acquired with a deep learning framework using both news articles and price history. Because the embedding takes the operational form of a vector, it is applicable to other financial problems besides price prediction. As one example application, we show the results of portfolio optimization using Reuters & Bloomberg headlines, producing a capital gain 2.8 times larger than that obtained with a baseline method using only stock price data. This suggests that the proposed stock embedding can leverage textual financial semantics to solve financial prediction problems.",2020
"Lower Risks, Beter Choices: Stock Correlation Based Portfolio Selection in Stock Markets","Over the past few years, we've seen a huge interest in applying AI techniques to develop investment strategies both in academia and the finance industry. However, we note that generating returns is not always the sole investment objective. Take large pension funds for example, they are considerably more risk-averse as opposed to profit-seeking. With this observation, we propose a Risk-balanced Deep Portfolio Constructor (RDPC) that takes risk into explicit consideration. RDPC is an end-to-end reinforcement learning-based transformer trained to optimize both returns and risk, with a hard attention mechanism that learns the relationship between asset pairs, imitating the powerful pairs trading strategy widely adopted by many investors. Experiments on real-world data show that RDPC achieves state-of-the-art performance not just on risk metrics such as maximum drawdown, but also on risk-adjusted returns metrics including Sharpe ratio and Calmar ratio.",2023
Pedagogic and assessment innovative practices in higher education: the use of portfolio in economics,"PurposeThe purpose of this paper is to describe this new evaluation experience with portfolio in economics, not only from the teacher's point of view but from the student perspective, and all the learning from its implementation; to provide ideas of evaluation practices in virtual and face-to-face modality in international business education; to motivate the rethinking of assessment practices in higher education to combine the best of each modality in the future.Design/methodology/approachThe present work is a case study based on a qualitative description of the implementation of a portfolio as an assessment practice, supported by a reflection questionnaire with students' perceptions and some elements of metacognition. The first section summarizes the literature used as a theoretical framework of this work. The second section describes the portfolio implementation by analyzing teachers and students reflections with a qualitative approach. The third section presents the findings. The fourth section is a discussion of findings, practical implications, limitations and future research directions. Finally, the conclusions of the work are shared.FindingsBecause the portfolio has had overwhelming results to assess what students have learned during the pandemic, it has become the learning and assessment tool after the pandemic, as it transforms the classes experience by shifting the focus from traditional examinations to more comprehensive, personalized and reflective ones. It also empowers students to take ownership of their learning, develop essential skills and cultivate a deeper understanding. Among other benefits, the portfolio means the creation of a safe and supportive environment for honest reflection, the development and design of strategic directions to improve learning and lead students toward metacognitive autonomy. Reflection pieces, a critical component of the portfolio, are a vital tool in the proactive learning process, as through reflection students learn to examine their own performance and discuss strategies to enhance their success in future work.Research limitations/implicationsThis work began as an educational experience per se, not for research purposes, which caused it to be systematized and reconstructed in a descriptive way, not to measure quantitative results. In this way, the present work describes that the portfolio helps to achieve better results on students' learning than traditional examinations but, as another limitation, it does not measure them nor the process. One more limitation of this work is that it was written in a postpandemic context but was implemented during the pandemic; therefore, the circumstances of writing are not the same as those of implementation, and this could also entail a certain margin of decontextualization. At the same time, this is an experience that is still in process and continually being adapted to this changed and changing educational postpandemic context.Practical implicationsOne of the main implications of the portfolio experience, transferable to all educational contexts, is that it transforms the final exam into a metacognitive one, letting students be aware of their own process of learning and results - objectives and competences - acquired. In this way, it lets teachers witness a part of the learning process that is not so evident in the traditional assessment practices - focused on some aspect of the learning - as it makes visible the way in which students receive, process and apply content, that is to say, how they make it their own. Social implicationsThe portfolio promotes reflective learning and metacognition, vital skills that benefit students beyond the classroom. This can have a positive impact on societal attitudes toward education and the quality of learning. Of the students, 82% felt the portfolio creation was helpful in their personal and professional lives, suggesting a broader societal impact. The paper's findings contribute to the body of knowledge about the effectiveness of portfolio-based assessment in higher education, especially in the worldwide transition from online education to postpandemic education. This could guide future studies in similar educational contexts or with different pedagogical innovative tools.Originality/valueIn light of the 2020 pandemic lockdown, this work delves into the pressing need for educators to adapt and modify their teaching approaches. The relevance of this study is accentuated by the worldwide transition from online education to postpandemic education. This paper bridges the gap between theory and practice because the research can be applied to the educational practice of any international business education context, as well as lay the foundations for future research in the field that contributes to increasing evidence of the effectiveness of the use of the portfolio to achieve significant and deep learning in higher education.",2024
A Stock Decision Model Based on Optimized Neural Network Algorithm,The stock comprehensive decision indexes are extracted by kernel principal component (KPC) analysis method. An effective stock decision model based on optimized neural network algorithm is presented. The weight and threshold value of the proposed BP neural network with KPC input and stock return output are adjusted and optimized by genetic algorithm. The empirical test results of CSI 300 stock sample show that the proposed stock decision model improves the operational efficiency and possesses strong learning ability with high prediction accuracy. This paper develops a bottom-up stock decision model to conduct data mining in stock returns and risks in order to select stock portfolio from individual companies with high quality.,2019
Exchange Rate Transaction of International Trade Goods Based on Fuzzy Granulation and Deep Learning,"The change of international trade goods exchange rate transaction has an impact on economic operations and economic stability. Therefore, an international trade goods exchange rate transaction based on fuzzy granulation and in-depth learning is proposed. Based on fuzzy information granulation and BP neural network, this paper analyzes the interest rate evaluation theory. For the future expectation of currency exchange rate, portfolio equilibrium determines the proportional relationship of each component in the portfolio and analyzes the impact of asset price and exchange rate change according to this relationship. Then, it points out the risk evaluation index system, calculates the risk degree of exchange rate transaction of international trade goods, and then evaluates the risk of exchange rate transaction of international trade goods. It completes the research on exchange rate transactions of international trade goods based on fuzzy granulation and in-depth learning. The experimental results show that excessive exchange rate fluctuation will bring the same proportion fluctuation to the asset price in the financial market, and the coordination between exchange rates and the coordination of exchange rate and asset price can promote the steady growth of national economy.",2021
"RETRACTION: Quantitative analysis of portfolio based on optimized BP neural network (Retraction of Vol 52, Pg 709, 2018)",,2019
"RETRACTION: LSTM-Based Deep Model for Investment Portfolio Assessment and Analysis (Retraction of Vol 2022, art no 1852138, 2022)",,2023
Genomic structural variation in Barramundi Perch Lates calcarifer and potential roles in speciation and adaptation,"Advancements in genome sequencing and assembly techniques have increased the documentation of structural variants in wild organisms. Of these variants, chromosomal inversions are especially prominent due to their large size and active recombination suppression between alternative homokaryotypes. This suppression enables the 2 forms of the inversion to be maintained and allows the preservation of locally adapted alleles. The Barramundi Perch (BP; Lates calcarifer) is a widespread species complex with 3 main genetic lineages located in the biogeographic regions of Australia and New Guinea (AUS + NG), Southeast Asia (SEA), and the Indian Subcontinent (IND). BP are typically considered to be a protandrous sequential hermaphrodite species that exhibits catadromy. Freshwater occupancy and intraspecific variation in life history (e.g. partially migratory populations) exist and provide opportunities for strongly divergent selection associated with, for example, salinity tolerance, swimming ability, and marine dispersal. Herein, we utilize genomic data generated from all 3 genetic lineages to identify and describe 3 polymorphic candidate chromosomal inversions. These candidate chromosomal inversions appear to be fixed for ancestral variants in the IND lineage and for inverted versions in the AUS + NG lineage and exhibit variation in all 3 inversions in the SEA lineage. BP have a diverse portfolio of life history options that includes migratory strategy as well as sexual system (i.e. hermaphroditism and gonochorism). We propose that the some of the life history variabilities observed in BP may be linked to inversions and, in doing so, we present genetic data that might be useful in enhancing aquaculture production and population management.",2024
Application of life cycle assessment as a tool for evaluating the sustainability of contaminated sites remediation: A systematic and bibliographic analysis,"As the discussion surrounding sustainable remediation has advanced, numerous tools have been developed to evaluate the sustainability of remediation technologies, including life cycle assessment (LCA). In the present study, a systematic and bibliometric analysis of scientific articles indexed in the databases of Scopus and the Web of Science in the field of LCA was performed, particularly studies relating to the remediation of contaminated sites from a sustainability perspective. We selected a bibliographic portfolio (BP) of papers related to sustainable remediation using LCA. Then, we performed a bibliometric analysis of the selected BP, presenting theoretical development, highlighting the authors, journals, and countries associated with these publications. Finally, we conducted a thematic synthesis and reviewed the prospects for future research. The BP was composed of 44 papers from 2007 to 2018. In 2018 there was the highest number of publications, corresponding to 27% of the total BP. The results showed that developed countries have generated the largest number of publications, whereas developing countries had lower representation in the BP. However, China stands out as the second country with the highest number of publications. The thematic analysis showed that most articles have aimed to assess the environmental impacts of remediation techniques. However, several publications have performed a broader analysis considering the economic and social pillars of sustainability through using LCA in conjunction with other tools. The study also highlights the main application of LCA in decision-making on the remediation processes in the context of sustainable remediation. The present research study makes several new contributions, providing academics and practitioners with an overview of the implementation of LCA in the field of sustainable remediation of contaminated sites through sorting published data according to scientific indexes and bibliometric, describing the main research approaches, and highlighting prospects for new research. (C) 2019 Elsevier B.V. All rights reserved.",2019
Stock market prediction with time series data and news headlines: a stacking ensemble approach,"Time series forecasting models are gaining traction in many real-world domains as valuable decision support tools. Stock market analysis is a challenging domain, characterized by a complex multi-variate and time-evolving nature, with high volatility, and multiple correlations with exogenous factors. Autoregressive, machine learning, and deep learning models for temporal data have been adopted thus far to solve this task. However, they are usually limited to the analysis of a single data source or modality, and do not collectively deal with all the inherent challenges and complexities presented by stock market data. In this paper, inspired by the promising learning capabilities of hybrid ensemble methods, we propose a novel stacking ensemble approach for stock market prediction that jointly considers news headlines, multi-variate time series data, and multiple base models as predictors. By taking multiple factors into consideration, our model is able to learn historical patterns leveraging multiple data sources and models. Our experiments showcase the ability of our model to outperform popular baselines on next-day stock market trend prediction. A portfolio analysis reveals that our method is also able to yield potential gains or capital preservation capabilities when its predictions are exploited for trading decisions.",2024
Deep differentiable reinforcement learning and optimal trading,"In many reinforcement learning applications, the underlying environment reward and transition functions are explicitly known differentiable functions. This enables us to use recent research which applies machine learning tools to stochastic control to find optimal action functions. In this paper, we define differentiable reinforcement learning as a particular case of this research. We find that incorporating deep learning in this framework leads to more accurate and stable solutions than those obtained from more generic actor critic algorithms. We apply this deep differentiable reinforcement learning (DDRL) algorithm to the problem of one asset optimal trading strategies in various environments where the market dynamics are known. Thanks to the stability of this method, we are able to efficiently find optimal strategies for complex multi-scale market models. We also extend these methods to simultaneously find optimal action functions for a wide range of environment parameters. This makes it applicable to real life financial signals and portfolio optimization where the expected return has multiple time scales. In the case of a slow and a fast alpha signal, we find that the optimal trading strategy consists in using the fast signal to time the trades associated to the slow signal.",2022
Effects of Temperature Rise on Clean Energy-Based Capital Market Investments: Neural Network-Based Granger Causality Analysis,"During the past 20 years, due to climate change, the government and the private sector have significantly focused on relying on non-fossil fuel-based methods for their energy needs. Climate change-related events, such as unusual weather conditions, abnormal temperature spikes, etc., have an adverse influence on clean energy-based investments. In the given study, we intend to focus on how an incremental temperature rise could affect investors' perceptions of clean energy assets. To understand the investor-based sentiment on climate change, we utilize prominent clean energy ETFs (exchange traded funds) and consider the temperature's effect on them. The daily average temperatures of the three most dynamic international financial centers: New York, London and Tokyo, are taken as predictors. Deep learning-based neural networks are applied to understand both the linear and non-linear relationships between the desired variables and identify the causal effects. The results indicate that in almost all the cases with desired lags, there is some sort of non-linear causality, irrespective of linear causality effects. We hope this occurrence can help portfolio managers and environmental professionals in identifying novel climate change-related factors when considering the temperature-related risks.",2022
Digitalization Canvas - Towards Identifying Digitalization Use Cases and Projects,"Nowadays, many companies are running digitalization initiatives or are planning to do so. There exist various models to evaluate the digitalization potential of a company and to define the maturity level of a company in exploiting digitalization technologies summarized under buzzwords such as Big Data, Artificial Intelligence (AI), Deep Learning, and the Industrial Internet of Things (IIoT). While platforms, protocols, patterns, technical implementations, and standards are in place to adopt these technologies, small-to mediumsized enterprises (SME) still struggle with digitalization. This is because it is hard to identify the most beneficial projects with manageable cost, limited resources and restricted know-how. In the present paper, we describe a real-life project where digitalization use cases have been identified, evaluated, and prioritized with respect to benefits and costs. This effort led to a portfolio of projects, some with quick and easy wins and some others with mid-to long-term benefits. From our experiences, we extracted a general approach that could be useful for other SMEs to identify concrete digitalization activities and to define projects implementing their digital transformation. The results are summarized in a Digitalization Canvas.",2017
Current advances in the use of bioluminescence assays for drug discovery: an update of the last ten years,"IntroductionBioluminescence is a well-established optical detection technique widely used in several bioanalytical applications, including high-throughput and high-content screenings. Thanks to advances in synthetic biology techniques and deep learning, a wide portfolio of luciferases is now available with tuned emission wavelengths, kinetics, and high stability. These luciferases can be implemented in the drug discovery and development pipeline, allowing high sensitivity and multiplexing capability.Areas coveredThis review summarizes the latest advancements of bioluminescent systems as toolsets in drug discovery programs for in vitro applications. Particular attention is paid to the most advanced bioluminescence-based technologies for drug screening over the past 10 years (from 2013 to 2023) such as cell-free assays, cell-based assays based on genetically modified cells, bioluminescence resonance energy transfer, and protein complementation assays in 2D and 3D cell models.Expert opinionThe availability of tuned bioluminescent proteins with improved emission and stability properties is vital for the development of bioluminescence assays for drug discovery, spanning from reporter gene technology to protein-protein techniques. Further studies, combining machine learning with synthetic biology, will be necessary to obtain new tools for sustainable and highly predictive bioluminescent drug discovery platforms.",2024
A Deep Reinforcement Learning Heuristic for SAT based on Antagonist Graph Neural Networks,"Heuristics are one of the most important tools to guide search to solve combinatorial problems. They are often specifically designed for one single problem and require both expertise and implementation work. Generic frameworks like SAT or CSP have developed heuristics that obey general principles like first fail or are able to learn and adapt from the exploration of the search tree like Dom/wDeg. In SAT, the classic VSIDS heuristic falls into both categories. The question of whether it is possible to learn from solving existing problems has been addressed for a long time by portfolio solvers where the best heuristic is chosen by Machine Learning from hand-crafted features, and more recently with Deep Learning by embedding this knowledge into a Graph Neural Network (GNN). In this paper, we build upon the latter category by proposing a new heuristic based on Deep Reinforcement Learning using two GNNs with adversarial rewards. We show that our method reduces the number of fails to get the first solution by more than 50% compared to MiniSat. This work shows the advantages of this type of techniques to extract structural and contextual knowledge from past solving experience.",2022
Similarity Embedded Temporal Transformers: Enhancing Stock Predictions with Historically Similar Trends,"Price prediction is essential in financial market research, as it is often used as a primary component for trading strategy or portfolio management specialisations. As these strategies rely on more than one future prediction point, the accuracy of a multi-horizon forecast is very important. Classical models, such as autoregressive integrated moving average (ARIMA), are not very good at multi-horizon forecasting. Also, current approaches employing deep learning do not usually factor in the heteroscedasticity of financial market time series. We introduce the similarity embedded temporal transformer (SeTT) algorithm by extending the state-of-the-art temporal transformer architecture with time series forecasting and statistical principles. We employ similarity vectors generated from historical trends across different financial instruments that are used to adjust the weight of the temporal transformer model during the training process. We conducted independent experiments across two time frames with volatile extrapolation periods using 20 companies from the Dow Jones Industrial Average. By focusing on the historical windows that are most similar to the current window in the self-attention tuning process, SeTT outperformed both the classical financial models and the baseline temporal transformer model in terms of predictive performance.",2022
Deep Portfolio Optimization via Distributional Prediction of Residual Factors,"Recent developments in deep learning techniques have motivated intensive research in machine learning-aided stock trading strategies. However, since the financial market has a highly non-stationary nature hindering the application of typical data-hungry machine learning methods, leveraging financial inductive biases is important to ensure better sample efficiency and robustness. In this study, we propose a novel method of constructing a portfolio based on predicting the distribution of a financial quantity called residual factors, which is known to be generally useful for hedging the risk exposure to common market factors. The key technical ingredients are twofold. First, we introduce a computationally efficient extraction method for the residual information, which can be easily combined with various prediction algorithms. Second, we propose a novel neural network architecture that allows us to incorporate widely acknowledged financial inductive biases such as amplitude invariance and time-scale invariance. We demonstrate the efficacy of our method on U.S. and Japanese stock market data. Through ablation experiments, we also verify that each individual technique contributes to improving the performance of trading strategies. We anticipate our techniques may have wide applications in various financial problems.",2021
UNLOCKING THE POWER OF VOICE FOR FINANCIAL RISK PREDICTION: A THEORY-DRIVEN DEEP LEARNING DESIGN APPROACH,"Unstructured multimedia data (text and audio) provides unprecedented opportunities to derive actionable decision-making in the financial industry, in areas such as portfolio and risk management. However, due to formidable methodological challenges, the promise of business value from unstructured multimedia data has not materialized. In this study, we use a design science approach to develop DeepVoice, a novel nonverbal predictive analysis system for financial risk prediction, in the setting of quarterly earnings conference calls. DeepVoice forecasts financial risk by leveraging not only what managers say (verbal linguistic cues) but also how managers say it (vocal cues) during the earnings conference calls. The design of DeepVoice addresses several challenges associated with the analysis of nonverbal communication. We also propose a two-stage deep learning model to effectively integrate managers' sequential vocal and verbal cues. Using a unique dataset of 6,047 earnings call samples (audio recordings and textual transcripts) of S&P 500 firms across four years, we show that DeepVoice yields remarkably lower risk forecast errors than that achieved by previous efforts. The improvement can also translate into nontrivial economic gains in options trading. The theoretical and practical implications of analyzing vocal cues are discussed.",2023
Performance Evaluation of Reverse Logistics: Opportunities for Future Research,"This study aimed to analyze the characteristics of the scientific research that approaches Reverse Logistics (RL) from the perspective of Performance Evaluation (PE). For this purpose, ProKnow-C was used to select 21 articles to compose a Bibliographical Portfolio (BP). Among the results, we mention Govindan, Sarkis, Zhu and Lai as prominent authors. By analyzing the articles, it was perceived that most of them perform the RL and PE fields separately and present tools that consider the alignment of the indicators with the strategy. Also, the articles lack of a structured PE process that could serve as a subsidy to the practice of logistics management. The results present that there is a theoretical gap in the literature of a PE model of RL.",2019
"A Systematic Approach to Portfolio Optimization: A Comparative Study of Reinforcement Learning Agents, Market Signals, and Investment Horizons","This paper presents a systematic exploration of deep reinforcement learning (RL) for portfolio optimization and compares various agent architectures, such as the DQN, DDPG, PPO, and SAC. We evaluate these agents' performance across multiple market signals, including OHLC price data and technical indicators, while incorporating different rebalancing frequencies and historical window lengths. This study uses six major financial indices and a risk-free asset as the core instruments. Our results show that CNN-based feature extractors, particularly with longer lookback periods, significantly outperform MLP models, providing superior risk-adjusted returns. DQN and DDPG agents consistently surpass market benchmarks, such as the S&P 500, in annualized returns. However, continuous rebalancing leads to higher transaction costs and slippage, making periodic rebalancing a more efficient approach to managing risk. This research offers valuable insights into the adaptability of RL agents to dynamic market conditions, proposing a robust framework for future advancements in financial machine learning.",2024
"RETRACTED: Quantitative analysis of portfolio based on optimized BP neural network (Retracted article. See vol. 56, pg. 264, 2019)","The securities market is a high risk and high return investment market. Investors are pursuing the goal of getting higher returns and reducing risks. This involves two basic issues: one is to choose which securities (to predict the stock price); and the two is how to allocate the portfolio to reduce the risk (prediction accuracy). On the basis of the traditional and innovation theory, the advanced technical methods have been fully realized on the basis of the traditional and innovation theory, based on the two problems mentioned above. Cluster. Traditional statistical techniques have great limitations in dealing with nonlinear data, and stock market data are nonlinear. Artificial neural network has proved its ability to analyze nonlinear time series data. Stock price forecasting is an important field in today's research. Different types of models have been implemented in this field. The two technologies include the ARMA model and the neural network. In this work, the ARMA model, together with two types of neural networks (back propagation) and multilayer perceptron (MLP), has been used. In addition, the two neural networks are combined with the ARMA model (alone) to produce the best prediction price. The two indicators used for forecasting are Dow Jones Jones Industrial Average Index (DJI) and Saudi stock exchange TATA-WUL (TASI). The 800 values are used to predict the next 200 values. It is found that for such a large number of forecasts, MLP produces the best results, and the results are significantly improved when combined with ARMA prediction. (C) 2018 Elsevier B.V. All rights reserved.",2018
Systematic Review of Lithium-Ion Battery Recycling Literature Using ProKnow-C and Methodi Ordinatio,"Recycling lithium-ion batteries (LIBs) plays an important role in environmental preservation since it prevents heavy metals from polluting the soil and underground water through the recovering of valuable metals. The interest in LIB recycling has grown in recent years due to the environmental and economic gains which can be seen by increasing number of articles and publications. This review uses two methodologies: ProKnow-C and Methodi Ordinatio to create a bibliographic portfolio (BP) that defines the state-of-the-start literature in LIB recycling. This review is vital because it proposes a database of a finite number of publications of relevant authors and articles to service new research on the LIB recycling theme. The research started off with 2515 articles related to the search query which were later filtered and treated to be systematically analyzed. After filtering, 591 articles were left in the filtered raw article database (FRA-database). The efficiency and parameters of ProKnow-C and Methodi Ordinatio were counter-compared forming two databases. These databases were analyzed systematically and it was found that in the initial stages there were no differences between them. Nevertheless, in the final phases, a difference in the ranking was established when compiling the final BP of the 23 best ranked articles and authors. By using ProKnow-C and Methodi Ordinatio, this review sets out to establish a concise BP of paramount importance to the LIB recycling theme.",2022
Data management within new product development and collaborative engineering: a bibliometric and systemic analysis,"Purpose Although organizations have more data than ever at their disposal, actually deriving meaningful insights and actions from them is easier said than done. In this concern, the main objective of this study is to identify trends and research opportunities regarding data management within new product development (NPD) and collaborative engineering. Design/methodology/approach Bibliometric and systemic analyses have been carried out using the methodological procedure ProKnow-C, which provides a structured framework for the literature review. A bibliographic portfolio (BP) was consolidated with 33 papers that represent the state of art in the subject. Findings Most recent researches within the BP indicate new trends and paradigm shifts in this area of research, tackling subjects such as the internet of things, cloud computing, big data analytics and digital twin. Research gaps include the lack of data automation and the absence of a common architecture for systems integration. However, from a general perspective of the BP, the management of experimental data is suggested as a research opportunity for future works. Although many studies have tackled data and collaboration based on computer-aided technologies environments, no study examined the management of the measured data collected during the verification and validation stages of a product. Originality/value This work provides a fresh and relevant source of authors, journals and studies for researchers and practitioners interested in the domain of data management applied to NPD and collaborative engineering.",2022
Revisiting time-varying dynamics in stock market forecasting: A multi-source sentiment analysis approach with large language model,"This paper presents the Heterogeneous Dynamic Seemingly Unrelated Regression with Dynamic Linear Models (HD-SURDLM), an innovative framework for stock return prediction that combines cutting-edge sentiment analysis with dynamic financial modeling. The model integrates sentiment data from 2.5 million Twitter posts and various news sources, utilizing state-of-the-art sentiment analysis tools such as VADER, TextBlob, and RoBERTa. HD-SURDLM refines Gibbs sampling for enhanced numerical stability and efficiency while capturing cross-sectional dependencies across multiple assets such as a portfolio. The model consistently outperforms traditional methods like LSTM, Random Forest, and RNN in forecasting accuracy. Empirical results show a 1.02% improvement in 1-day horizon forecasts, a 0.42% gain for 20-day predictions, and a 0.36% increase for 50-day forecasts. By effectively merging public sentiment with dynamic asset modeling, HD-SURDLM offers substantial improvements in short- and long-term prediction accuracy. Its capacity to capture both crosssectional insights and temporal dynamics makes it an invaluable tool for investors, traders, and financial institutions navigating sentiment-driven markets. HD-SURDLM not only enhances predictive accuracy but also provides a robust decision-support system for financial stakeholders.",2025
MF-Informer for long-term QoS prediction in edge-cloud collaboration environments,"In Service-Oriented Architecture (SOA) systems, continuously stabilizing web services' quality of service (QoS) is critical to maintaining system performance. Dynamic changes in edge-cloud collaborative computing environments lead to fluctuations in QoS values, and the original service portfolio design will no longer fulfill the Service Level Agreement (SLA), resulting in performance degradation of SOA systems. To ensure the efficiency of SOA systems, long time-series prediction of services' QoS is an effective method, which can warn of SLA violations and recommend optimal candidate services. In this paper, we propose a prediction algorithm, MF-Informer, which combines matrix factorization and the Informer model to solve the sparsity problem of QoS historical data, and the self-attention mechanism of the Informer model realizes the prediction of service QoS over N steps ahead. In this paper, experiments are conducted based on real-world web service QoS datasets, and the results show that this paper's method improves the efficiency and accuracy of service QoS long-term prediction, which is significantly better than existing methods in several evaluation metrics.",2024
The Network of Mutual Funds: A Dynamic Heterogeneous Graph Neural Network for Estimating Mutual Funds Performance,"Mutual funds are interconnected to each other through multiple types of links, including but not limited to co-investment, advisors, firms, and managers. These connections enable information flow among network entities, influence investment decisions, and ultimately impact mutual fund managers' performance. In this paper, we propose a dynamic graph neural network approach to model these heterogeneous relationships and their contributions to mutual fund performance. Using the graph attention mechanism, our model learns latent embedding for mutual funds and their invested assets dynamically in each month and then uses the embedding to estimate future returns. Empirical analysis confirms that the proposed method outperforms the state-of-the-art DeepWalk model by 10%. Furthermore, this study also reveals the importance of networks in mutual fund performance. The inclusion of network connections in a feedforward machine learning model significantly increases the performance of the model by 118%. Finally, portfolio analysis and regression estimation on next month's excess return show that the proposed approach has a significant economic contribution over current benchmark approaches.",2023
A Real-Time Framework for Matching Prosumers With Minimum Risk in the Cluster of Microgrids,"Microgrids provide an economical solution to exploit increasing distributed energy sources by locally consuming generated power. The key to the reliable operation of microgrids is how to cope with the uncertainty of renewables when selling and buying power. Although the surplus power of each microgrid can fluctuate significantly, aggregating the contributions from multiple microgrids may produce a smoothed supply. We study the matching problem in the cluster of cooperative microgrids where surplus power from some microgrids (called sellers) can be consumed by other microgrids (called buyers) in need of more power. We develop a framework for predicting sellers and buyers for every time interval, and matching them based on the prediction. We first formulate the problem of matching sellers and buyers. This problem finds a portfolio of sellers contributions to every buyer with minimum risk of mismatch between supply from sellers and demand from buyers. We characterize the optimal matching and give some insight on how surplus power should be distributed to buyers. The formulation involves several statistical parameters of microgrids. We present a LSTM based method for predicting these parameters. Using surplus power data of real microgrids, we demonstrate that our framework can reduce the risk of mismatch.",2020
Catastrophic Oil Spills and the Problem of Insurance,"The BP oil spill of 2010 focused considerable attention on the operating conduct of BP, on the potential liability of BP and other entities associated with the spill, and on the fund that BP established to provide compensation to victims of the spill. Much less attention has been paid, however, to the nature and scope of insurance covering losses caused by catastrophic environmental disasters such as oil spills. BP's establishment of the Gulf Coast Claims Facility, and the compensation that will be paid by that facility, will likely dampen awareness of the mismatches between the resulting losses and the insurance available to cover such losses. What might otherwise have been a very dramatic demonstration of the ways in which our insurance and liability systems fall short in such situations will probably be much more muted. Future spills, however, may not follow this pattern. Understanding the structure of insurance and liability that are and are not available when spills occur is therefore critical to developing satisfactory approaches to dealing with the consequences of spills. This Article identifies the matches, and mismatches, between the losses resulting from oil spills, the insurance available to the victims of spills, the liability of the parties responsible for losses caused by spills, and the insurance available to the parties who face such liability. The Article then attempts to make sense of the situation it has identified, considering three explanations for the mismatches: difficulties associated with proving the cause of pure economic loss, traditional challenges to the insurance of pollution loss and liability, and preexisting portfolio diversification by potential spill defendants that discourages the purchase of large amounts of insurance. Finally, the Article critically analyzes two proposals that have been made for remedying the insurance mismatches in this field: the imposition of an ex ante drillers' tax on the amount of their potential liability in excess of their combined assets and liability insurance and the imposition of mandatory liability insurance requirements far in excess of the amounts of insurance that are currently available or purchased.",2011
Optimal techno-economic assessment of isolated microgrid integrated with fast charging stations using radial basis deep learning,"The global transportation electrification commerce sector is now booming. Stakeholders are paying an increased attention to the integration of electric vehicles and electric buses into the transportation networks. As a result, there is an urgent need to invest in public charging infrastructure, particularly for fast charging facilities. Consequently, and to complete the portfolio of the green environment, these fast-charging stations (FCSs) are designed using 100% of renewable energy sources (RESs). Thus, this paper proposes an optimization model for the techno-economic assessment of FCSs comprising photovoltaic and wind turbines with various energy storage devices (ESDs). In this regard, the FCS performance is evaluated using flywheels and super capacitors due to their high-power density and charging/discharging cycles and rates. Then, optimal sizing of these distributed generators is attained considering diverse technical and economical key performance indicators. Afterwards, the problem gets more sophisticated by investigating the effect of RES's uncertainties on the selection criterion of the FCS's components, design and capacity. Eventually, as an effort dedicated to an online energy management approach, a deep learning methodology based on radial basis network (RBN) is implemented, validated, and carried out. In stark contrast to conventional optimization approaches, RBN demonstrates its superiority by obtaining the optimum solutions in a relatively short amount of time.",2024
Exploring The Efficient Market Hypothesis for Accurate Stock Movement Prediction via Feature-Axis Transformer,"Stock movement forecasting is a significant challenge in financial machine-learning application fields due to its profound impact on financial markets. While the Efficient Market Hypothesis (EMH) [10] postulates that predicting stock movement is nearly impossible, recent studies using deep learning methodologies exhibit promising results. The EMH is based on the assumption that stock prices immediately incorporate all available information, such as financial statements, earnings announcements, and macroeconomic news. Input features used by the prior studies commonly include Open, High, Low, Close, and Adjusted Close (OHLCA), which potentially contain salient information for forecasting movements. However, most have yet to extract the information implicit in each price separately and utilize it to make predictions. This paper proposes FATE: Feature-Axis Transformer based on EMHdesigned to leverage each OHLCA component to facilitate stock movement prediction. FATE consists of three modules: 1) capturing each feature's temporal correlation between various stocks; 2) generating global market context data; and 3) constructing a contextual vector through correlating to other prices around the closing price. Experimental results show that FATE demonstrates better predictive results than state-of-the-art baselines on six real-world datasets. FATE also yields profitable portfolio trading gains compared to the baselines. Furthermore, it offers interpretable visualized results during its stock movement forecasting operations.",2024
SELF-FTS: A SELF-SUPERVISED LEARNING METHOD FOR FINANCIAL TIME SERIES REPRESENTATION IN STOCK INTRADAY TRADING,"The stock price's highly unstable fluctuation pattern makes learning efficient representation challenging to model the stock movement. The common deep learning often overfits after a few epochs of training and performs poorly in the validation set because the optimization objective is insufficient to characterize the stock adequately. In this paper, we propose Self-FTS, a self-supervised learning framework for financial time series representation, to learn the underlying representation and use in stock trading, affected by the fact that self-supervised learning is a promising technique for learning representation for extracting high dimensional features from unlabeled financial data to overcome the bias caused by handcrafted features. Specifically, we design several auxiliary tasks to generate samples with pseudo labels from the A-share stock price data sets and build a weight-sharing feature extraction backbone combined with a classification head to learn the pseudo labels based on the samples. Finally, We evaluate the learned representations extracted from the backbone by fine-tuning data sets labelled with stock returns to build an investment portfolio. Experimental analysis results on the Chinese stock market data show that our method significantly improves the stock trend forecasting performances and the actual investment income through backtesting compared to the current SOTA method, which strongly demonstrates our effective approach.",2022
Deep Learning-Based Imbalance Market Price Range Predictions in the Day-Ahead Horizon,"Variable Renewable Energy (VRE) sources are characterized by production uncertainty that is largely due to weather forecast errors. This leads to greater volumes in the real-time balancing markets that drive Imbalance Market (IM) price higher, creating economic opportunities for flexibility providers. However, lack of information on foreseen IM prices and regulation states at the time of day-ahead market closure, reduces the flexibility providers' opportunity of optimizing their portfolio. The objective of this paper is to investigate to which extent there is a correlation between the IM prices and weather parameters in the Dutch Imbalance Market. A Deep Learning (DL) model based on Feed-Forward Deep Neural Network (FFDNN) is developed with the aim to support VRE asset owners and flexibility providers to predict IM price ranges and regulation states in the day-ahead horizon. The parameters considered are temperature, solar radiation, wind speed, relative humidity, and cloud cover. A benchmark model using Support Vector Machine (SVM) is used to compare with the DL's model performance. Both models are trained and tested using data from the weather prediction model provided by Royal Netherlands Meteorological Institute (KNMI), and historical IM prices from the Dutch Transmission System Operator (TenneT), for the years 2018-2020.",2023
Stock Trend Prediction Using Candlestick Charting and Ensemble Machine Learning Techniques With a Novelty Feature Engineering Scheme,"Stock market forecasting is a knotty challenging task due to the highly noisy, nonparametric, complex and chaotic nature of the stock price time series. With a simple eight-trigram feature engineering scheme of the inter-day candlestick patterns, we construct a novel ensemble machine learning framework for daily stock pattern prediction, combining traditional candlestick charting with the latest artificial intelligence methods. Several machine learning techniques, including deep learning methods, are applied to stock data to predict the direction of the closing price. This framework can give a suitable machine learning prediction method for each pattern based on the trained results. The investment strategy is constructed according to the ensemble machine learning techniques. Empirical results from 2000 to 2017 of China's stock market confirm that our feature engineering has effective predictive power, with a prediction accuracy of more than 60% for some trend patterns. Various measures such as big data, feature standardization, and elimination of abnormal data can effectively solve data noise. An investment strategy based on our forecasting framework excels in both individual stock and portfolio performance theoretically. However, transaction costs have a significant impact on investment. Additional technical indicators can improve the forecast accuracy to varying degrees. Technical indicators, especially momentum indicators, can improve forecasting accuracy in most cases.",2021
Urban-scale power decarbonization using a modified power purchase agreements framework based on Markowitz mean-variance theory,"Urban power decarbonization is essential in the fight against climate change, yet current research often neglects the financial risks faced by investors and the shifting demands of consumers in liberalized electricity markets. This study addresses these gaps by proposing a modified Markowitz Mean-Variance Portfolio (MVP) theory, integrated with the Low Emissions Analysis Platform (LEAP), and a deep learning model. On this basis, an urban energy transition framework centered on Power Purchase Agreements (PPAs) is proposed and developed. The framework is validated considering a case study in Kitakyushu, Japan, highlighting its potential in accelerating power sector decarbonization and achieving net-zero emissions by 2038. Additionally, the internal rate of return (IRR) remains stable between 14.5 % and 19.6 % across seven other cities. While the framework reduces longterm cash flow volatility, its effectiveness hinges on industrial electrification efficiency and regional energy selfsufficiency. The findings indicate that relying solely on renewable energy for low-carbon transitions is unrealistic. Furthermore, green hydrogen could emerge as a viable alternative to fossil fuels, potentially replacing batteries for long-term energy storage. Future research should explore cross-regional energy trade and establish legal frameworks for long-term energy transactions to bolster urban energy transition resilience across diverse geographic and economic contexts.",2024
Performance Evaluation in the University Context: an investigation of literature from the Constructivist perspective,"The objective of the article is to know and investigate the characteristics of Performance Evaluation in the University Context, from a Constructivist perspective. The intervention instrument used was the ProKnow-C which originated a Bibliographic Portfolio (BP) composed of 67 articles. The analysis and discussion of results made use of these stages: Literature Map, Bibliometric Analysis and Systemic Analysis. The Literature Map shows the predominance of studies addressing measurement elements and Performance Evaluation ( PE) models. The Bibliometric Analysis showed that most of the articles did not make use of the theoretical contribution of Organizational Performance Evaluation (OPE) regarding metrics. Systemic Analysis points out the misalignment between the evaluation made in the BP studies and the defined OPE concept. The contributions of the study refer to the verification of the paths taken by the literature and the analysis of PE instruments/models, helping to understand the possibilities of future research that seek to improve models and the participation of managers in this process. The originality lies in the knowledge generated by the mapping of aspects involving the field, enabling the identification of research gaps that point to the desire for future research that deepens the themes Intellectual Capital, Knowledge Management, HRM Practices and Performance Evaluation System.",2022
Domain Adaptive Multi-Modality Neural Attention Network for Financial Forecasting,"Financial time series analysis plays a central role in optimizing in- vestment decision and hedging market risks. This is a challenging task as the problems are always accompanied by dual-level (i.e,data-level and task-level) heterogeneity. For instance, in stock price forecasting, a successful portfolio with bounded risks usually consists of a large number of stocks from diverse domains (e.g, utility, information technology, healthcare, etc.), and forecasting stocks in each domain can be treated as one task; within a portfolio, each stock is characterized by temporal data collected from multiple modalities (e.g, finance, weather, and news), which corresponds to the data-level heterogeneity. Furthermore, the finance industry follows highly regulated processes, which require prediction models to be interpretable, and the output results to meet compliance. Therefore, a natural research question is how to build a model that can achieve satisfactory performance on such multi-modality multi- task learning problems, while being able to provide comprehensive explanations for the end users. To answer this question, in this paper, we propose a generic time series forecasting framework named Dandelion, which leverages the consistency of multiple modalities and explores the relatedness of multiple tasks using a deep neural network. In addition, to en- sure the interpretability of the framework, we integrate a novel trinity attention mechanism, which allows the end users to investigate the variable importance over three dimensions (i.e, tasks, modality and time). Extensive empirical results demonstrate that Dandelion achieves superior performance for financial market prediction across 396 stocks from 4 different domains over the past 15 years. In particular, two interesting case studies show the efficacy of Dandelion in terms of its profitability performance, and the interpretability of output results to end users.",2020
Predicting the Product Life Cycle of Songs on the Radio How Record Labels can Manage Product Portfolios and Prioritise Artists by Using Machine Learning Techniques,"In terms of determining the success of a musical artist's song, there is a positive correlation of radio play success and music sales success. Therefore, being able to forecast the future plays of a song on the radio can serve as powerful risk management and product portfolio management tools for record labels and other stakeholders of a song. This research strives to predict the remaining product life cycle of a song on the radio after it has been played for one or two months. The best results were achieved using a k-d tree to calculate the songs the most similar to the test songs and use a Random Forest model to forecast radio plays. Accuracy of 82.78% and 83.44% was achieved for the two time periods, respectively. This explorative research leads to over 4500 test metrics to find the best combination of models and pre-processing techniques. Other algorithms tested were KNN, MLP, and CNN. The features only consist of daily radio plays and use no musical features.",2021
University rankings disclosure and efficiency in higher education: A bibliometric and systematic analysis,"Whereas new public management models urge universities to manage available resources more efficiently and effectively, the pressure exerted by the phenomenon of university rankings - referents of the quality and excellence of higher education institutions-has driven universities to strive for better positions in these rankings with the aim of maximizing their reputation. While the effects of the disclosure of university rankings on the one hand and the measurement of efficiency in universities on the other have been widely analysed, little is known about the variables involved in university rankings and their relationship with the efficiency levels of higher education institutions. Therefore, this study aims to identify evidence and/or disagreements within the relevant scientific literature regarding universities' efficiency levels and their position in the rankings as a causal relationship between efficiency, reputation and market perception. Given this approach, the present study has the objective of exploring what the scientific literature offers regarding these two areas, with the aim of increasing our knowledge on the topic and presenting research opportunities. To this end, a structured intervention process known as the Knowledge Development Process - Constructivist (Proknow-c) is used. As a result, an BP Bibliographic Portfolio is obtained from the most relevant scientific publications, composed of 77 items covering the period of 1995-2016. This portfolio is achieved through a bibliometric and systematic analysis that presents gaps and research opportunities relevant to the proposed subject of interest.",2019
Towards sustainable development through the perspective of eco-efficiency - A systematic literature review,"Sustainability concerns have increasingly gained importance among organizations and their stakeholders around the world. In this context, eco-efficiency has become a consistent tool towards the transition to sustainable development and the efforts of eco-efficiency indicators have been used for comparative studies and decision-making tasks, providing better financial, environmental, and social performance. The aim of this paper is to provide a systematic literature review on the theme of sustainable development from the perspective of eco-efficiency, with the adaptation of the Knowledge Development Process intervention instrument - constructivist (ProKnow-C). The paper identifies and structures the state-of-the-art between Eco-Efficiency and Sustainable Development with a view to: (i) selecting a Bibliographic Portfolio (BP) that is aligned with the perception of the researchers on the theme; (ii) performing a bibliometric analysis of the selected BP; (iii) performing a thematic synthesis; (iv) finding the integration of eco-efficiency and sustainable development with other approaches; (v) proposing an innovative framework to achieve sustainable development through eco-efficiency indicators; and (vi) finding paths for further research. This research makes multiple new contributions, providing both academics and practitioners a better panorama to achieve sustainable development through eco-efficiency by expanding the literature review, highlighting the synergies and barriers between eco-efficiency and sustainable development and by comparing and analysing them, showing its relevant features. In addition, we synthesized the contributions of the BP according to the BASF indicators, sustainable dimensions and four measurement levels: industry, organization, project and process to better describe the current academic scenario on the subject. (C) 2017 Elsevier Ltd. All rights reserved.",2017
Cryptocurrency returns prediction using candlestick patterns analysis and multi-layer deep LSTM neural networks,"Financial markets are characterised by their dynamic, non-linear, and fluctuating nature. Analysing financial time series in these contexts is a complex and challenging task. Candlestick patterns are recognised as among the most widely used financial tools and offer invaluable insights into market sentiment and psychology. However, manual analysis of these patterns presents significant challenges. Therefore, leveraging machine learning methods becomes a necessity for overcoming these challenges. In this study, a four-step framework was introduced in which the data preparation process is executed on the price data of the 20 cryptocurrencies. Forty-eight candlestick patterns were extracted alongside returns. Employing the long shortterm memory (LSTM) neural network, structured with multiple layers, each specialising in a specific cryptocurrency, enables individualised prediction of market returns. Evaluation of model accuracy and sensitivity is conducted via the confusion matrix, and two distinct trading strategies assess the capital portfolio. The research findings underscore the profitability of the proposed model across all scenarios. Candlestick patterns serve as powerful tools for understanding market sentiments and identifying shifts in market trends. However, their standalone efficacy is limited. Integrating them with other technical analysis tools facilitates more informed decision-making and fosters a deeper understanding of market dynamics.",2024
"A Data-Driven, Farmer-Oriented Agricultural Crop Recommendation Engine (ACRE)","Agriculture has a significant role to play in any emerging economy and provides the source of income and employment for a large portion of the population. A key challenge faced by small and marginal farmers is to determine which crops to grow to maximize their utililty. With a wrong choice of crops, farmers could end up with sub-optimal yields and low, and possibly even loss of revenue. This work seeks to design and develop ACRE (Agricultural Crop Recommendation Engine), a tool that provides a scientific method to choose a crop or a portfolio of crops, to maximize the utility to the farmer. ACRE uses available data such as soil characteristics, weather conditions, and historical yield data, and uses state-of-the-art machine learning/deep learning models to compute an estimated utility to the farmer. The main idea of ACRE is to generate several recommendations of portfolios of crops, with a ranking of portfolios based on the Sharpe ratio, a popular risk metric in financial investments. We use publicly available data from agmarknet portal in India to perform several thought experiments with ACRE. ACRE provides a rigorous, data-driven backend for designing farmer-friendly mobile apps for assisting farmers in choosing crops (This work was supported by the National Bank for Agriculture and Rural Development (NABARD), Government of India, through a research grant).",2022
Learning to Optimize Contextually Constrained Problems for Real-Time Decision Generation,"The topic of learning to solve optimization problems has received interest from both the operations research and machine learning communities. In this paper, we combine ideas from both fields to address the problem of learning to generate decisions to instances of optimization problems with potentially nonlinear or nonconvex constraints where the feasible set varies with contextual features. We propose a novel framework for training a generative model to produce provably optimal decisions by combining interior point methods and adversarial learning, which we further embed within an iterative data generation algorithm. To this end, we first train a classifier to learn feasibility and then train the generative model to produce optimal decisions to an optimization problem using the classifier as a regularizer. We prove that decisions generated by our model satisfy in -sample and out -of -sample optimality guarantees. Furthermore, the learning models are embedded in an active learning loop in which synthetic instances are iteratively added to the training data; this allows us to progressively generate provably tighter optimal decisions. We investigate case studies in portfolio optimization and personalized treatment design, demonstrating that our approach yields advantages over predict -then -optimize and supervised deep learning techniques, respectively. In particular, our framework is more robust to parameter estimation error compared with the predict -then -optimize paradigm and can better adapt to domain shift as compared with supervised learning models.",2025
Quality-Oriented Classification of Aircraft Material Based on SVM,"The existing material classification is proposed to improve the inventory management. However, different materials have the different quality-related attributes, especially in the aircraft industry. In order to reduce the cost without sacrificing the quality, we propose a quality-oriented material classification system considering the material quality character, Quality cost, and Quality influence. Analytic Hierarchy Process helps to make feature selection and classification decision. We use the improved Kraljic Portfolio Matrix to establish the three-dimensional classification model. The aircraft materials can be divided into eight types, including general type, key type, risk type, and leveraged type. Aiming to improve the classification accuracy of various materials, the algorithm of Support Vector Machine is introduced. Finally, we compare the SVM and BP neural network in the application. The results prove that the SVM algorithm is more efficient and accurate and the quality-oriented material classification is valuable.",2014
Temporal and Heterogeneous Graph Neural Network for Financial Time Series Prediction,"The price movement prediction of stock market has been a classical yet challenging problem, with the attention of both economists and computer scientists. In recent years, graph neural network has significantly improved the prediction performance by employing deep learning on company relations. However, existing relation graphs are usually constructed by handcraft human labeling or nature language processing, which are suffering from heavy resource requirement and low accuracy. Besides, they cannot effectively response to the dynamic changes in relation graphs. Therefore, in this paper, we propose a temporal and heterogeneous graph neural network-based (THGNN) approach to learn the dynamic relations among price movements in financial time series. In particular, we first generate the company relation graph for each trading day according to their historic price. Then we leverage a transformer encoder to encode the price movement information into temporal representations. Afterward, we propose a heterogeneous graph attention network to jointly optimize the embeddings of the financial time series data by transformer encoder and infer the probability of target movements. Finally, we conduct extensive experiments on the stock market in the United States and China. The results demonstrate the effectiveness and superior performance of our proposed methods compared with state-of-the-art baselines. Moreover, we also deploy the proposed THGNN in a real-world quantitative algorithm trading system, the accumulated portfolio return obtained by our method significantly outperforms other baselines.",2022
Modelling the economic value of credit rating systems,"In this paper we develop a model of the economic value of credit rating systems. Increasing international competition and changes in the regulatory framework driven by the Basel Committee on Banking Supervision (Basel II) called forth incentives for banks to improve their credit rating systems. An improvement of the statistical power of a rating system decreases the potential effects of adverse selection, and, combined with meeting several qualitative standards, decreases the amount of regulatory capital requirements. As a consequence, many banks have to make investment decisions where they have to consider the costs and the potential benefits of improving their rating systems. In our model the quality of a rating system depends on several parameters such as the accuracy of forecasting individual default probabilities and the rating class structure. We measure effects of adverse selection in a competitive one-period framework by parameterizing customer elasticity. Capital requirements are obtained by applying the current framework released by the Basel Committee on Banking Supervision. Results of a numerical analysis indicate that improving a rating system with low accuracy to medium accuracy can increase the annual rate of return on a portfolio by 30-40 bp. This effect is even stronger for banks operating in markets with high customer elasticity and high loss rates. Compared to the estimated implementation costs banks could have a strong incentive to invest in their rating systems. The potential of reduced capital requirements on the portfolio return is rather weak compared to the effect of adverse selection. (c) 2006 Elsevier B.V. All rights reserved.",2007
Assessing project portfolio risk via an enhanced GA-BPNN combined with PCA,"Assessing project portfolio risk (PPR) is essential for organizations to grasp the overall risk levels of project portfolios (PPs) and realize PPR mitigation. However, current research is inadequate to effectively assess PPR, which brings challenges to managing PPR. In this context, the purpose of this study is to develop a PPR assessment model via an enhanced backpropagation neural network (BPNN). First, PPR assessment criteria considering project interdependencies are determined. Second, fuzzy logic is used to obtain original data for assessment criteria. Principal component analysis (PCA) is then employed to reduce the dimensionality of assessment criteria and derive the input and output of BPNN. Third, an improved genetic algorithm (IGA) is designed to optimize the initial weights and thresholds of BPNN. On this basis, the PCA-IGA-BPNN assessment model is constructed, followed by training and testing, possessing a test accuracy of 98.6%. Finally, comparison experiments are conducted from both internal and external perspectives. For internal comparison, the proposed model yields less mean absolute percentage error (MAPE), mean square error (MSE), and root mean square error (RMSE) than PCA-GA-BPNN, IGA-BPNN, PCA-BPNN and BPNN and offers the largest convergence speed (). As for external comparison, the presented model produces lower MAPE, MSE, and RMSE than Decision Tree (DT), Support Vector Machine (SVM), Random Forest (RF), and K-Nearest Neighbor (KNN) and has the largest coefficient of determination (R2). Results indicate that the established model performs more satisfactorily in assessing PPR. This research enriches PPR assessment methods and provides managers with a useful tool to evaluate PPR.",2023
Design and progress of a factorial trial testing the effect of spironolactone and inorganic nitrate on arterial function in people at risk of or with type 2 diabetes,"Background: Arterial stiffness (AS), as pulse wave velocity (PWV), is a powerful independent predictor of cardiovascular events and commonly complicates type 2 diabetes (T2D). This trial aims to test if AS, measured by the VaSera machine as cardio-ankle vascular index (CAVI) and by Arteriograph measuring central PWV, can be reduced by spironolactone and/or inorganic nitrate from beetroot juice independently of blood pressure (BP) in those with or at risk of T2D. Methods: A factorial design, double blind, randomised controlled trial in 18-80 year old men and women clinically diagnosed with T2D or at risk of it (body mass index (BMI) >= 27 kg m(-2), positive family history or glucose intolerance). The study lasts up to 36 weeks with daily intervention of either <= 50 mg spironolactone (intervention) or <= 16 mg doxazosin (control), and beetroot juice with <= 400 mg (9 mmol) inorganic nitrate (intervention) or placebo beetroot juice, 0 mg nitrate (control). Non-invasive AS measurements are carried out at baseline and then at 12-week intervals thereafter. Results: To date, 95 participants have been consented and screened, 19 of these were not suitable or not willing to participate so that 73 have been randomised with 9 participants screened as eligible and awaiting randomisation. 53 participants have completed the study. Mean baseline and follow up measures of cardiac-ankle and cardiac-aortic bifurcation PWV and BP have been straightforward. Conclusion: This is a proof-of-principle trial to alter AS independent of BP in a patient sample at high cardiovascular risk. Clinical trial registration information: UK Clinical Research Network Portfolio Database: 25003627. (C) 2015 Association for Research into Arterial Structure and Physiology. Published by Elsevier B.V. All rights reserved.",2015
Modeling hydraulic fracture fluid efficiency in tight gas reservoirs using non-linear regression and a back-propagation neural network,"This study introduces a back-propagation (BP) neural network model and a regression model for estimating the fracture fluid efficiency based on a data set consisting of 1261 staged and ramped simulation runs of tight gas reservoirs subjected to hydraulic fracturing treatment. Data were generated using a 3-D commercial simulator which is a versatile software portfolio that models many well configurations, proppant placement, and fracture geometries. The BP network inputs consist of shear rate/fracture conductivity ratio, the injection rate, reservoir permeability, formation closure stress, reservoir thickness, effective viscosity, and fracture height. The neural network model was able to generate satisfactory estimates of the fracture fluid efficiency for the training dataset, and for the blind testing data. An average error of approximately 2.5% was obtained for the training set, and an average error of 3% was obtained for the testing set. An empirical non-linear regression model has been constructed based on dimensionless groups derived by applying dimensional analysis to a set of variables consisting of the maximum fracture width, fracture length, fracture height, effective viscosity, shear rate/fracture conductivity ratio, reservoir thickness, injection rate, reservoir permeability, and formation closure stress. The average error for estimating the fluid efficiency using the non-linear regression empirical model was approximately 6.17%. Since the non-linear regression model has an explicit formulation, it is easier to apply than the neural network model. The empirical regression model estimates of the fluid efficiency appeared to be unbiased and were more precise than those estimates obtained using either the KGD or the PKN 2-D models. The introduced BP model and the non-linear regression model offer fast and inexpensive alternatives to the application of three-dimensional simulators for estimating the fluid efficiency.",2023
Methodology for integration of wind resource forecasts based on artificial neural networks,"An adaptation of the portfolio theory (PT) is proposed in this article, denoted as PrevPT, Previsao (in Portuguese) by PT, to integrate the three artificial neural networks, namely multilayer perceptron (MLP) backpropagation, radial basis function (RBF), and self-organizing map (SOM), based forecasting techniques, aiming to analyze the impact of wind speed forecasting errors and achieve more accurate results. In its first use, the PT goal was to maximize a financial return, at any risk, through the diversification of securities or investments that are not positively correlated. Based on the development of PrevPT, which was used until this work only for solar forecasting, the proposed technique is applied in this paper to integrate and improve the results of individual wind forecasts. Four-year wind speed data (January 2007 to December 2010) from two different locations (Algeciras, Spain and Petrolina, Brazil) were used. Our methodology develops a topology that integrates the forecasts obtained by MLP, RBF, and SOM aiming to obtain smaller forecast errors. By diversifying the forecasted asset, when one of the assets has negative prediction errors, another compensates for them and, thus, the total or partial cancellation of the errors occurs. PrevPT obtains a mean absolute percentage error of 1.13% for Spain and 2.35% for Brazil. PrevPT surpassed the results obtained by the three techniques applied individually in the two locations. The main innovations of the methodology are the significant reduction of errors and optimization of resource planning, and the beneficial features compared to other predictor integration techniques.",2022
Machine Learning in Futures Markets,"In this paper, we demonstrate how a well-established machine learning-based statistical arbitrage strategy can be successfully transferred from equity to futures markets. First, we preprocess futures time series comprised of front months to render them suitable for our returns-based trading framework and compile a data set comprised of 60 futures covering nearly 10 trading years. Next, we train several machine learning models to predict whether the h-day-ahead return of each future out- or underperforms the corresponding cross-sectional median return. Finally, we enter long/short positions for the top/flop-k futures for a duration of h days and assess the financial performance of the resulting portfolio in an out-of-sample testing period. Thereby, we find the machine learning models to yield statistically significant out-of-sample break-even transaction costs of 6.3 bp-a clear challenge to the semi-strong form of market efficiency. Finally, we discuss sources of profitability and the robustness of our findings.",2021
Performance evaluation of state-owned enterprises based on fuzzy neural network combination model,"Fuzzy neural networks have seen an increasing presence in state-owned enterprise performance evaluation. Fuzzy-based financial and non-financial indicators are combined to evaluate state-owned enterprise performance. In this paper, a combination model is proposed for enterprise performance evaluation. This model is built using fuzzy neural network and uses the fuzzy method along with the neural network's self-learning ability to reduce the impact of subjective factors on the evaluation results while realizing intelligent enterprise performance evaluation. First, this paper proposes construction ideas and principles for the state-owned enterprise' performance evaluation index system and then examines its efficiency. There are two types of indicators in the system: financial and non-financial. The Takagi-Sugeno fuzzy neural network is used to build a financial indicator model. The BP neural network is used to construct a non-financial indicator model for a state-owned enterprise performance evaluation portfolio model based on fuzzy neural networks. Both these networks use a decision support system during the process of building the model. Finally, a comparison is made between the results from Takagi-Sugeno fuzzy neural network and those from the BP neural network performance evaluation model after sample data have been selected, standardization processing has been applied, and a simulation of the network model has been trained. The experiments show that the combined model can be used to evaluate the performance of state-owned enterprises which opens a new direction for evaluating enterprise performance.",2022
Forest types outpaced tree species in centroid-based range shifts under global change,"Introduction Mounting evidence suggests that geographic ranges of tree species worldwide are shifting under global environmental changes. Little is known, however, about if and how these species' range shifts may trigger the range shifts of various types of forests. Markowitz's portfolio theory of investment and its broad application in ecology suggest that the range shift of a forest type could differ substantially from the range shifts of its constituent tree species.Methods Here, we tested this hypothesis by comparing the range shifts of forest types and the mean of their constituent species between 1970-1999 and 2000-2019 across Alaska, Canada, and the contiguous United States using continent-wide forest inventory data. We first identified forest types in each period using autoencoder neural networks and K-means cluster analysis. For each of the 43 forest types that were identified in both periods, we systematically compared historical range shifts of the forest type and the mean of its constituent tree species based on the geographic centroids of interpolated distribution maps.Results We found that forest types shifted at 86.5 km center dot decade-1 on average, more than three times as fast as the average of constituent tree species (28.8 km center dot decade-1). We showed that a predominantly positive covariance of the species range and the change of species relative abundance triggers this marked difference.Discussion Our findings provide an important scientific basis for adaptive forest management and conservation, which primarily depend on individual species assessment, in mitigating the impacts of rapid forest transformation under climate change.",2024
Stable Multilevel Deep Neural Networks for Option Pricing and xVAs Using Forward-Backward Stochastic Differential Equations,"Deep learning techniques have significantly impacted fields such as image processing, computer vision, and natural language processing. However, their influence on quantitative finance, particularly in option pricing, hedging, and portfolio management, has been limited. Traditional financial applications rely on rigorous mathematical models and established numerical methods like Monte Carlo and finite difference methods. However, these methods struggle with high-dimensional problems. Recent works propose using Deep Neural Networks (DNNs) to solve high-dimensional Partial Differential Equations (PDEs) in finance, potentially overcoming the limitations of conventional techniques. Despite the recent progress, DNN methods face high computational costs, stability issues, and generally fail to meet the high accuracy requirements of the financial industry. This paper addresses these challenges. To address the high computational cost of training deep neural networks for financial applications, we propose a multilevel architecture inspired by multilevel Monte Carlo methods. To enhance stability, we adopt a dynamical systems perspective and utilize the NAIS-Net architecture, which ensures global asymptotic stability. For improving accuracy, we leverage the forward and backward systems of stochastic differential equations (FBSDEs) for option pricing problems. We also provide a theoretical argument that suggests that the proposed approach is superior to Physics Informed Neural Networks. Finally, the proposed methodology is implemented on several option pricing and xVA problems and is shown to achieve higher efficiency and accuracy, notably improving the pricing of options and xVAs by an order of magnitude over state-of-the-art methods.",2024
Artificial Intelligence for Personalised Ophthalmology Residency Training,"Residency training in medicine lays the foundation for future medical doctors. In real-world settings, training centers face challenges in trying to create balanced residency programs, with cases encountered by residents not always being fairly distributed among them. In recent years, there has been a tremendous advancement in developing artificial intelligence (AI)-based algorithms with human expert guidance for medical imaging segmentation, classification, and prediction. In this paper, we turned our attention from training machines to letting them train us and developed an AI framework for personalised case-based ophthalmology residency training. The framework is built on two components: (1) a deep learning (DL) model and (2) an expert-system-powered case allocation algorithm. The DL model is trained on publicly available datasets by means of contrastive learning and can classify retinal diseases from color fundus photographs (CFPs). Patients visiting the retina clinic will have a CFP performed and afterward, the image will be interpreted by the DL model, which will give a presumptive diagnosis. This diagnosis is then passed to a case allocation algorithm which selects the resident who would most benefit from the specific case, based on their case history and performance. At the end of each case, the attending expert physician assesses the resident's performance based on standardised examination files, and the results are immediately updated in their portfolio. Our approach provides a structure for future precision medical education in ophthalmology.",2023
Reinforcement Learning-Based Multimodal Model for the Stock Investment Portfolio Management Task,"Machine learning has been applied by more and more scholars in the field of quantitative investment, but traditional machine learning methods cannot provide high returns and strong stability at the same time. In this paper, a multimodal model based on reinforcement learning (RL) is constructed for the stock investment portfolio management task. Most of the previous methods based on RL have chosen the value-based RL methods. Policy gradient-based RL methods have been proven to be superior to value-based RL methods by a growing number of research. Commonly used policy gradient-based reinforcement learning methods are DDPG, TD3, SAC, and PPO. We conducted comparative experiments to select the most suitable method for the dataset in this paper. The final choice was DDPG. Furthermore, there will rarely be a way to refine the raw data before training the agent. The stock market has a large amount of data, and the data are complex. If the raw stock market data are fed directly to the agent, the agent cannot learn the information in the data efficiently and quickly. We use state representation learning (SRL) to process the raw stock data and then feed the processed data to the agent. It is not enough to train the agent using only stock data; we also added comment text data and image data. The comment text data comes from investors' comments on stock bars. Image data are derived from pictures that can represent the overall direction of the market. We conducted experiments on three datasets and compared our proposed model with 11 other methods. We set up three evaluation indicators in the paper. Taken together, our proposed model works best.",2024
Applying Machine Learning Techniques for Forecasting Flexibility of Virtual Power Plants,"Previous and existing evaluations of available flexibility using small device demand response have typically been done with detailed information of end-user systems. With these large numbers, having lower level information has both privacy and computational limitations. We propose a black box approach to investigating the longevity of aggregated response of a virtual power plant using historic bidding and aggregated behaviour with machine learning techniques. The two supervised machine learning techniques investigated and compared in this paper are, multivariate linear regression and single hidden layer artificial neural network (ANN). Both techniques are used to model a relationship between the aggregator portfolio state and requested ramp power to the longevity of the delivered flexibility. Using validated individual household models, a smart controlled aggregated virtual power plant is simulated. A hierarchical market-based supply-demand matching control mechanism is used to steer the heating devices in the virtual power plant. For both the training and validation set of clusters, a random number of households, between 200 and 2000, is generated with day ahead profile scaled accordingly. Further, a ramp power (power deviation) is assigned at various hours of the day and requested to hold for the remainder of the day. Using only the bidding functions and the requested ramp powers, the ramp longevity is estimated for a number of different cluster setups for both the artificial neural network as well as the multi-variant linear regression. It is found that it is possible to estimate the longevity of flexibility with machine learning. The linear regression algorithm is, on average, able to estimate the longevity with a 15% error. However, there was a significant improvement with the ANN algorithm achieving, on average, a 5.3% error. This is lowered 2.4% when learning for the same virtual power plant. With this information it would be possible to accurately offer residential VPP flexibility for market operations to safely avoid causing further imbalances and financial penalties.",2016
Offline Reinforcement Learning for Automated Stock Trading,"Recently, with the increasing interest in investments in financial stock markets, several methods have been proposed to automatically trade stocks and/or predict future stock prices using machine learning techniques, such as reinforcement learning (RL), LSTM, and transformers. Among them, RL has been applied to manage portfolio assets with a sequence of optimal actions. The most important factor in investing in stocks is the utilization of past stock price data. However, existing RL algorithms applied to stock markets do not consider past stock data when taking optimal actions, as RL is formulated based on the Markov property. In other words, it means that the existing RL algorithm infers action based on the current state only. To resolve this limitation, we propose Transformer Actor-Critic with Regularization (TACR) using decision transformer to train the model with the correlation of past MDP (Markov Decision Process) elements using an attention network. In addition, a critic network is added to improve the performance by updating the parameters based on the evaluation of an action. For an efficient learning method, we train our model using an offline RL algorithm through suboptimal trajectories. To prevent overestimating the value of actions and reduce learning time, we train TACR through a regularization technique with an added behavior cloning. The experimental results using various stock market datasets show that TACR performs better than other state-of-the-art methods in terms of the Sharpe ratio and profit.",2023
New tool for stock investment risk management Trend forecasting based on individual investor behavior,"Purpose The purpose of this paper is to propose a new tool for stock investment risk management through studying stocks with what kind of characteristics can be predicted by individual investor behavior. Design/methodology/approach Based on comment data of individual stock from the Snowball, a thermal optimal path method is employed to analyze the lead-lag relationship between investor attention (IA) and the stock price. And machine learning algorithms, including SVM and BP neural network, are used to predict the prices of certain kind of stock. Findings It turns out that the lead-lag relationships between IA and the stock price change dynamically. Forecasting based on investor behavior is more accurate only when the IA of the stock is stably leading its price change most of the time. Originality/value This paper is one of the first few research works that introduce individual investor data into portfolio risk management. The new tool put forward in this study can capture the dynamic interplay between IA and stock price change, which help investors identify and control the risk of their portfolios.",2020
Study of Solar Photovoltaic Potential and Carbon Mitigation in University Buildings,"Capturing solar radiation through photovoltaic deployment on the rooftop of buildings not only produces clean energy but also plays an important role in mitigating carbon dioxide emissions. Semarang State University in Indonesia expanding solar energy until 2021 has installed 260 kWp rooftop solar photovoltaic in 8 buildings. Gradually, the rooftop photovoltaic portfolio is being improved to realize the vision of the green campus. It is important to conduct a quantitative assessment of the power generation potential of rooftop photovoltaics to formulate a policy on effective electricity production integration. The objective of this study is to predict the potential for rooftop solar photovoltaic exploration and the potential for mitigating carbon dioxide emissions. The method used was the combination of a deep learning approach and aerial photography of an unmanned aerial vehicle. It was found that of the 40 tallest building units, the available roof area was approximately 26,645 m(2). The average monthly irradiation was 5.63 kWh/m(2)/day. Energy potential per year: 8,671.1 GWh (m-Si); 7,234.4 GWh (p-Si); 4,427 GWh (a-Si); and 7,414.3 GWh (CdTe). Based on local emission factors, the mitigation potential per year was: 7,199,468.9 tons of CO2 (m-Si); 6,000,536.3 tons of CO2 (p-Si); 3,674,417.7 tons of CO2 (a-Si), and 6,153,902.9 tons of CO2 (CdTe). The findings of the study are dedicated to university management to design and manage roof photovoltaic systems reliably and economically.",2022
Quantifying the Impact of Memory Errors in Deep Learning,"The use of deep learning (DL) on HPC resources has become common as scientists explore and exploit DL methods to solve domain problems. On the other hand, in the coming exascale computing era, a high error rate is expected to be problematic for most HPC applications. The impact of errors on DL applications, especially DL training, remains unclear given their stochastic nature. In this paper, we focus on understanding DL training applications on HPC in the presence of silent data corruption. Specifically, we design and perform a quantification study with three representative applications by manually injecting silent data corruption errors (SDCs) across the design space and compare training results with the error-free baseline. The results show only 0.61-1.76% of SDCs cause training failures, and taking the SDC rate in modern hardware into account, the actual chance of a failure is one in thousands to millions of executions. With this quantitatively measured impact, computing centers can make rational design decisions based on their application portfolio, the acceptable failure rate, and financial constraints; for example, they might determine their confidence in the correctness of training results performed on processors without error correction code (ECC) RAM. We also discover that over 75-90% of the SDCs that cause catastrophic errors can be easily detected by a training loss in the next iteration. Thus we propose this error-aware software solution to correct catastrophic errors, as it has significantly lower time and space overhead compared to algorithm-based fault-tolerance (ABFT) and ECC.",2019
AI-driven valuation: a new era for real estate appraisal,"PurposeThis paper explores the emergence of artificial intelligence (AI) in real estate valuation, analysing its potential to enhance accuracy, efficiency and transparency in the appraisal process and examines the implications of this technological shift for various stakeholders.Design/methodology/approachThis research adopts a comprehensive literature review approach, drawing upon existing research in real estate, computer science and related fields. A systematic analysis of scholarly publications and industry trends was conducted to examine the underlying technologies, diverse applications, potential benefits, inherent limitations and future trends associated with AI-driven valuation models, including machine learning and deep learning methods.FindingsThe study reveals that AI-powered valuation models offer significant advantages over traditional appraisal methods, including enhanced accuracy, increased efficiency, reduced costs and improved risk management. However, critical challenges related to data bias, algorithmic transparency (the black box problem), and the need for human oversight must be addressed to ensure responsible and effective AI implementation.Originality/valueThis paper provides insights into the transformative potential of AI in real estate valuation for a wide range of stakeholders. Real estate professionals can gain a better understanding of how AI can enhance their decision-making processes, improve efficiency and mitigate risk. Appraisers will benefit from the paper's analysis of evolving skillsets required in the AI era, while lenders and investors will gain a clearer understanding of how AI-driven valuation can strengthen risk assessment and portfolio management. Policymakers can utilize this research to inform the development of ethical guidelines and regulations for AI adoption in real estate appraisal.",2025
Mastering Stock Markets with Efficient Mixture of Diversified Trading Experts,"Quantitative stock investment is a fundamental financial task that highly relies on accurate prediction of market status and profitable investment decision making. Despite recent advances in deep learning (DL) have shown stellar performance on capturing trading opportunities in the stochastic stock market, the performance of existing DL methods is unstable with sensitivity to network initialization and hyperparameter selection. One major limitation of existing works is that investment decisions are made based on one individual neural network predictor with high uncertainty, which is inconsistent with the workflow in real-world trading firms. To tackle this limitation, we propose AlphaMix, a novel three-stage mixture-of-experts (MoE) framework for quantitative investment to mimic the efficient bottom-up hierarchical trading strategy design workflow of successful trading companies. In Stage one, we introduce an efficient ensemble learning method, whose computational and memory costs are significantly lower comparing to traditional ensemble methods, to train multiple groups of trading experts with personalised market understanding and trading styles. In Stage two, we collect diversified investment suggestions through building a pool of trading experts utilizing hyperparameter level and initialization level diversity of neural networks for post hoc ensemble construction. In Stage three, we design three different mechanisms, namely as-needed router, with-replacement selection and integrated expert soup, to dynamically pick experts from the expert pool, which takes the responsibility of a portfolio manager. Through extensive experiments on US and Chinese stock markets, we demonstrate that AlphaMix significantly outperforms many state-of-the-art baselines in terms of 7 popular financial criteria.",2023
Using OneNote as an ePortfolio: Promoting Experiential Learning and Self-Regulation,"The pedagogical role of ePortfolios has been established in numerous studies. It has been suggested that ePortfolios facilitate deep learning, as they allow students to achieve a contextual understanding of their own learning. Other pedagogical advantages of ePortfolios are: enabling students to build a more holistic sense of their learning journey, enhancing learning outcomes and making learning visible. This study draws on previous research and develops the pedagogical potential of ePortfolios further. It presents a learning ePortfolio based on OneNote, the Self-Regulatory ePortfolio, where the pedagogical functions are embedded. The OneNote ePortfolio has been designed around a learning cycle based on experiential and self-regulation learning consisting of the functions: identify /plan/ action / record / review. This design of ePortfolio is much more than a tool to allow or catalyse a learning process, it is directly guiding students through the learning process and training them in self-regulative learning. This paper reports on this new model of Self-Regulatory ePortfolio and explains its structure and features within OneNote. It presents how it has been used at the Open University to work in languages and education modules in relation to Personal Development Planning (PDP) and as a Languages Portfolio in the context of the ECML (European Centre for Modern Languages). It reports on the promising results of pilot studies and scholarship projects carried out to evaluate this Self-Regulatory ePortfolio. It discusses the main findings of the studies and in particular the relation to students' experiences using it. This paper concludes by suggesting further ways to implement this learning ePortfolio in other contexts and platforms.",2019
Relational Stock Selection via Probabilistic State Space Learning,"Optimizing stock selection through stock ranking is one of the critical but intricate tasks in quantitative trading areas because of the non-stationary dynamics and complicated interdependencies behind stock markets. Recent studies have made efforts to model historical market movements to enhance stock selection. However, they primarily borrowed the spirit of time series modeling and sought to build a deterministic paradigm without considering the uncertain fluctuations. In addition, some of these studies tailor to explore stock correlations from a predefined (e.g., binary) graph structure and use explicitly simple relations (such as first-order relations) to guide evolving interactions. Nevertheless, aggregating predefined but shallow relationships to collaborate with stock movements may affect selection generalizability and increase the risk of portfolio failure. This study introduces a novel Relational stock selection framework via probabilistic State Space Learning (or RSSL) for stock selection. Specifically, RSSL first attempts to build a tree-based structure to explicitly expose higher-order relations in the stock market, primarily by discovering a hierarchical delineation of ties between stocks. Whereafter, it couples with time-varying movements via an attention mechanism to smoothly explore the interactive correlations among different stocks. Inspired by recent state space models (SSM) in probabilistic Bayesian learning, we devise a Probabilistic Kalman Network (PKNet) with uncertainty estimates to recursively simulate ever-changing stock volatility, enabling more promising return-risk trade-offs. The experimental results on several real-world stock market datasets demonstrate that RSSL outperforms several representative baseline methods by a significant margin.",2025
LSR-IGRU: Stock Trend Prediction Based on Long Short-Term Relationships and Improved GRU,"Stock price prediction is a challenging problem in the field of finance and receives widespread attention. In recent years, with the rapid development of technologies such as deep learning and graph neural networks, more research methods have begun to focus on exploring the interrelationships between stocks. However, existing methods mostly focus on the short-term dynamic relationships of stocks and directly integrating relationship information with temporal information. They often overlook the complex nonlinear dynamic characteristics and potential higher-order interaction relationships among stocks in the stock market. Therefore, we propose a stock price trend prediction model named LSR-IGRU in this paper, which is based on long short-term stock relationships and an improved GRU input. Firstly, we construct a long short-term relationship matrix between stocks, where secondary industry information is employed for the first time to capture long-term relationships of stocks, and overnight price information is utilized to establish short-term relationships. Next, we improve the inputs of the GRU model at each step, enabling the model to more effectively integrate temporal information and long short-term relationship information, thereby significantly improving the accuracy of predicting stock trend changes. Finally, through extensive experiments on multiple datasets from stock markets in China and the United States, we validate the superiority of the proposed LSR-IGRU model over the current state-of-the-art baseline models. We also apply the proposed model to the algorithmic trading system of a financial company, achieving significantly higher cumulative portfolio returns compared to other baseline methods. Our sources are released at https://github.com/ZP1481616577/Baselines_LSR-IGRU.",2024
Deep Multilayer Perceptron Neural Network for the Prediction of Iranian Dam Project Delay Risks,"Construction delays are among the industry's most significant challenges, especially in the infrastructure sector, where delays can have serious socio-economic consequences. Recently, advances in deep learning (DL) have opened up new possibilities for tackling complex issues more efficiently. This study aims to evaluate the potential of deep neural networks in predicting the level of delay in Iranian dam construction projects. As the first step, 65 delay risk factors were identified through a comprehensive literature review and interviews. Then risk scores for 53 completed dam projects in Iran were determined through a questionnaire survey. Subsequently, the most significant latent features were extracted using principal component analysis (PCA). The resultant variables were combined with two project characteristics to develop the input dataset. Finally, the resulting dataset was used to develop a deep multilayer perceptron neural network (MLP-NN) model to predict project delays. The prediction performance of the deep-MLP model was then evaluated and compared to that of the best delay prediction models found in previous studies. The three-times repeated stratified five-fold cross-validation results demonstrated that the proposed deep-NN model outperformed all previous approaches for delay prediction on all performance metrics. This study also explores the effectiveness of combining delay risk factors with project characteristics to train the predictive model. According to the results, adding project characteristic factors to the training dataset significantly improved the prediction performance of deep-MLP. The work presented here can assist managers of future dam constructions in the early stages of the project in selecting and prioritizing projects within a portfolio and allocating a sufficient buffer to ensure the project's timely completion.",2023
A machine-learning digital-twin for rapid large-scale solar-thermal energy system design,"In many industrialized regions of the world, large-scale photovoltaic systems now contribute a significant part to the energy portfolio during daylight operation. However, as energy demands peak shortly before sunset and persist for several hours afterwards, the integration of solar-thermal systems is extremely advantageous as a green bridge energy source. Accordingly, this work develops a digital-twin model to track and optimize the flow of incoming solar power through a complex solar -thermal storage system, consisting of a large array of adaptable mirrors, an optical-receiver and a power distribution system for customers to extract energy. Specifically, the solar power flow is rapidly computed with a reduced order model of Maxwell's equations, based on a high-frequency decomposition of the irradiance into multiple rays that experience mirror reflections, losses and ultimately receiver absorption and customer delivery. The method allows for rapid testing (in microseconds) of the performance of large numbers of mirror-receiver layout configurations in design space, over extremely long time periods, such as weeks, months and years, using a genetic-based machine-learning digital-twin framework, which integrates submodels for: & BULL; optics and tracking of the Fresnel multi-mirror system, & BULL; thermal absorption of the optical energy by the receiver and & BULL; optimal operating temperatures balancing radiative losses with heat storage. The overall machine-learning digital-twin optimizes the configuration layout to balance meeting customer demands and operational efficiency. Numerical examples are provided to illustrate the approach. Finally, a deep-learning algorithm is developed and applied to the create an Artificial Neural-Net representation, which allows for even further simulation speedup. & COPY; 2023 Published by Elsevier B.V.",2023
The Stock Index Prediction Based on SVR Model with Bat Optimization Algorithm,"Accurate stock market prediction models can provide investors with convenient tools to make better data-based decisions and judgments. Moreover, retail investors and institutional investors could reduce their investment risk by selecting the optimal stock index with the help of these models. Predicting stock index price is one of the most effective tools for risk management and portfolio diversification. The continuous improvement of the accuracy of stock index price forecasts can promote the improvement and maturity of China's capital market supervision and investment. It is also an important guarantee for China to further accelerate structural reforms and manufacturing transformation and upgrading. In response to this problem, this paper introduces the bat algorithm to optimize the three free parameters of the SVR machine learning model, constructs the BA-SVR hybrid model, and forecasts the closing prices of 18 stock indexes in Chinese stock market. The total sample comes from 15 January 2016 (the 10th trading day in 2016) to 31 December 2020. We select the last 20, 60, and 250 days of whole sample data as test sets for short-term, mid-term, and long-term forecast, respectively. The empirical results show that the BA-SVR model outperforms the polynomial kernel SVR model and sigmoid kernel SVR model without optimized initial parameters. In the robustness test part, we use the stationary time series data after the first-order difference of six selected characteristics to re-predict. Compared with the random forest model and ANN model, the prediction performance of the BA-SVR model is still significant. This paper also provides a new perspective on the methods of stock index forecasting and the application of bat algorithms in the financial field.",2021
Seek Common While Shelving Differences: Orchestrating Deep Neural Networks for Edge Service Provisioning,"Edge computing (EC) platforms, which enable Application Service Providers (ASPs) to deploy applications in close proximity to users, are providing ultra-low latency and location-awareness to a rich portfolio of services. As monetary costs are incurred for renting computing resources on edge servers to enable service provisioning, ASP has to cautiously decide where to deploy the application and how much resources would be needed to deliver satisfactory performance. However, the service provisioning problem exhibits complex correlations with multifarious factors in EC systems, ranging from user behavior to computation offloading, which are difficult to be fully captured by mathematical modeling and also put off traditional machine learning techniques due to the induction of high-dimension state space. The recent success of deep learning (DL) underpins new tools for addressing our problem. While previous works provide valuable insights on applying DL techniques, e.g., distributed DL, deep reinforcement learning (DRL), and multi-agent DL, in EC systems, these techniques cannot solely handle the distributed and heterogeneous nature of EC systems. To address these limitations, we propose a novel framework based on multi-agent DRL, distributed neural network orchestration (N2O), and knowledge distilling. The multi-agent DRL enables edge servers to learn deep neural networks that shelve distinct features learned from local edge sites and hence caters to the heterogeneity of EC systems. N2O coordinates edge servers in a fully distributed manner toward a common goal of maximizing ASP's reward. It requires only local communications during execution and provides provable performance guarantees. The knowledge distilling is further utilized to distill the N2O policy for reducing the communication overhead and stabilizing the decision-making. We also carry out systematic experiments to show the advantages of our method over state-of-the-art alternatives.",2021
Multi-model transfer function approach tuned by PSO for predicting stock market implied volatility explained by uncertainty indexes,"This paper studies the forecasting power of uncertainty emanating from the commodities market, energy market, economic policy, and geopolitical threats to the CBOE Volatility Index (VIX). In this study, the relationship between the various uncertainty metrics throughout the period 2012-2022, using a multi-model transfer function technique optimized by particle swarm optimization (PSO) is estimated. Furthermore, we utilize PSO for parameter optimization within the multi-model framework, improving model performance and convergence speed. According to empirical findings, the CBOE Volatility Index reacts nonlinearly to the uncertainty indices. Specifically, the conclusions of the performance metrics show that the OVX index (MAPE: 4.1559%; RMSE: 1.0476% and W: 96.74%) outperforms the geopolitical risk index, the Bloomberg energy index, and the economic policy uncertainty index in predicting the volatility of the US equities market. Although individual models have generated respectful performance, results from the aggregate simulation show that when all predictors are combined, they simultaneously provide better performance indicators (MAVE: 2.7511 %; RMSE: 0.7361%; R2: 98.93%) than when they are estimated separately. In addition, results provide evidence that, when considering non-linear patterns in the data, the multi-model transfer function technique calibrated using PSO demonstrates its outperformance over autoregressive baseline models, traditional econometric models, and deep learning techniques. The effectiveness and accuracy of the multi-model transfer function method tuned by PSO as a forecasting tool are confirmed by the convergence analysis of the cost function. Our methodology innovates by employing a multi-model transfer function technique, which captures the complex and nonlinear relationships between uncertainty indicators and the VIX more comprehensively than traditional single-model approaches. These results are important for traders in terms of hedging as well as portfolio diversification by investing in defensive equities and for policymakers in terms of reliability and preciseness of volatility forecasts.",2024
"Oil volatility, oil and gas firms and portfolio diversification","This paper investigates the volatility spillovers and co-movements among oil prices and stock prices of major oil and gas corporations over the period between 18th June 2001 and 1st February 2016. To do so, we use the spillover index approach by Diebold and Yilmaz (2009, 2012, 2014, 2015) and the dynamic correlation coefficient model of Engle (2002) so as to identify the transmission mechanisms of volatility shocks and the contagion of volatility among oil prices and stock prices of oil and gas companies, respectively. Given that volatility transmission across oil and major oil and gas corporations is important for portfolio diversification and risk management, we also examine optimal weights and hedge ratios among the aforementioned series. Our results point to the existence of significant volatility spillover effects among oil and oil and gas companies' stock volatility. However, the spillover is usually unidirectional from oil and gas companies' stock volatility to oil volatility, with BP, CHEVRON, EXXON, SHELL and TOTAL being the major net transmitters of volatility to oil markets. Conditional correlations are positive and time-varying, with those between each of the aforementioned companies and oil being the highest. Finally, the diversification benefits and hedging effectiveness based on our results are discussed. (C) 2018 Elsevier B.V. All rights reserved.",2018
An investigational analysis on forecasting intraday values,"Purpose The algorithmic trading has advanced exponentially and necessitates the evaluation of intraday stock market forecasting on the grounds that any stock market series are foreseen to follow the random walk hypothesis. The purpose of this paper is to forecast the intraday values of stock indices using data mining techniques and compare the techniques' performance in different markets to accomplish the best results. Design/methodology/approach This study investigates the intraday values (every 60th-minute closing value) of four different markets (namely, UK, Australia, India and China) spanning from April 1, 2017 to March 31, 2018. The forecasting performance of multivariate adaptive regression spline (MARSplines), support vector regression (SVR), backpropagation neural network (BPNN) and autoregression (1) are compared using statistical measures. Robustness evaluation is done to check the performance of the models on the relative ratios of the data. Findings MARSplines produces better results than the compared models in forecasting every 60th minute of selected stocks and stock indices. Next to MARSplines, SVR outperforms neural network and autoregression (1) models. The MARSplines proved to be more robust than the other models. Practical implications - Forecasting provides a substantial benchmark for companies, which entails long-run operations. Significant profit can be earned by successfully predicting the stock's future price. The traders have to outperform the market using techniques. Policy makers need to estimate the future prices/trends in the stock market to identify the link between the financial instruments and monetary policy which gives higher insights about the mechanism of existing policy and to know the role of financial assets in many channels. Thus, this study expects that the proposed model can create significant profits for traders by more precisely forecasting the stock market. Originality/value This study contributes to the high-frequency forecasting literature using MARSplines, SVR and BPNN. Finding the most effective way of forecasting the stock market is imperative for traders and portfolio managers for investment decisions. This study reveals the changing levels of trends in investing and expectation of significant gains in a short time through intraday trading.",2020
"A pedo-geomorphological view on land use and its potential in the surroundings of the ancient Hispano-Roman city Munigua (Seville, SW Spain)","This study investigates the surroundings of Munigua (municipium Flavium Muniguense), a small Roman town in the ancient province of Hispania Baetica (SW Spain). The city's economy was based primarily on copper and iron mining, which brought financial prosperity to its citizens. Local production of agricultural goods is thought to have been of little importance, as the regional soil conditions do not seem to be suitable for extensive agriculture. To evaluate the recent soil agro-potential and to find evidence for prehistoric and historic land use in the surroundings of Munigua, we applied a pedo-geomorphological approach based on the physicochemical analysis of 14 representative soil and sediment exposures. Selected samples were analyzed for bulk chemistry, texture and phytoliths. The chronostratigraphy of the sequences was based on radiocarbon dating of charcoal samples. The site evaluation of the present-day soil agro-potential was carried out according to standard procedures and included evaluation of potential rootability, available water-storage capacity and nutrient budget within the uppermost 1 m. The results show that moderate to very good soil agro-potential prevails in the granitic and floodplain areas surrounding Munigua. Clearly, recent soil agro-potential in these areas allows the production of basic agricultural goods, and similar limited agricultural use should also have been possible in ancient times. In contrast, weak to very weak present-day soil agro-potential prevails in the metamorphic landscape due to the occurrence of shallow and sandy to stony soils. In addition, the study provides pedo-geomorphological evidence for prehistoric and historic land use in pre-Roman, Roman and post-Roman times. Catenary soil mapping in the vicinity of a Roman house complex reveals multi-layered colluvial deposits. They document phases of hillslope erosion mainly triggered by human land use between 4063 +/- 82 and 3796 +/- 76 cal BP, around 2601 +/- 115 cal BP, and between 1424 +/- 96 and 421 +/- 88 cal BP. Moreover, geochemical and phytolith analyses of a Roman hortic Anthrosol indicate the local cultivation of agricultural products that contributed to the food supply of Munigua. Overall, the evidence of Roman agricultural use in the Munigua area indicates that the city's economy was by no means focused solely on mining. The production of basic agricultural products was also part of Munigua's economic portfolio. Our geoarcheological study thus supports the archeological concept of economically diversified Roman cities in the province of Baetica and in Hispania.",2022
Controlling Shareholder Characteristics and Corporate Debt Default Risk: Evidence Based on Machine Learning,"The influence of controlling shareholder characteristics on corporate risk has been a popular topic for discussion in academic and theoretical circles. However, current research lacks systematic and quantitative conclusions based on predictive ability, as it only focuses on the causal relationship between a single characteristic of the controlling shareholder and corporate risk. This paper utilizes the back propagation neural network based on gray wolf algorithm (GWO-BP) method in the machine learning algorithm for the first time and takes the listed companies that publicly issue bonds in the Chinese bond market as a research sample. It summarizes the qualities of controlling shareholders from the perspective of controlling shareholders' risk-taking and benefits expropriation and examines multi-dimensional controlling shareholder characteristics for predicting the debt default risk of companies. This research established that: (1) Overall, the characteristics of controlling shareholders can improve the ability to predict the debt default of a company; (2) The features of the investment portfolio of the controlling shareholder have a higher degree of predicting the debt default risk of a company,while the properties of equity structure and related transactions have a lower degree of predicting the risk of corporate debt default.This research not only uses machine learning methods to study controlling shareholders in China from a more comprehensive perspective but also provides a useful incentive for bondholders to protect their interests.",2022
Digital health technologies for high-risk pregnancy management: three case studies using Digilego framework,"Objective: High-risk pregnancy (HRP) conditions such as gestational diabetes mellitus (GDM), hypertension (HTN), and peripartum depression (PPD) affect maternal and neonatal health. Patient engagement is critical for effective HRP management (HRPM). While digital technologies and analytics hold promise, emerging research indicates limited and suboptimal support offered by the highly prevalent pregnancy digital solutions within the commercial marketplace. In this article, we describe our efforts to develop a portfolio of digital products leveraging advances in social computing, data science, and digital health. Methods: We describe three studies that leverage core methods from Digilego digital health development framework to (1) conduct large-scale social media analysis (n = 55 301 posts) to understand population-level patterns in women's needs, (2) architect a digital repository to enable women curate HRP related information, and (3) develop a digital platform to support PPD prevention. We applied a combination of qualitative coding, machine learning, theory-mapping, and programmatic implementation of theory-linked digital features. Further, we conducted preliminary testing of the resulting products for acceptance with sample of pregnant women for GDM/HTN information management (n = 10) and PPD prevention (n = 30). Results: Scalable social computing models using deep learning classifiers with reasonable accuracy have allowed us to capture and examine psychosociobehavioral drivers associated with HRPM. Our work resulted in two digital health solutions, MyPregnancyChart and MomMind are developed. Initial evaluation of both tools indicates positive acceptance from potential end users. Further evaluation with MomMind revealed statistically significant improvements (P < .05) in PPD recognition and knowledge on how to seek PPD information. Discussion: Digilego framework provides an integrative methodological lens to gain micro-macro perspective on women's needs, theory integration, engagement optimization, as well as subsequent feature and content engineering, which can be organized into core and specialized digital pathways for women engagement in disease management. Conclusion: Future works should focus on implementation and testing of digital solutions that facilitate women to capture, aggregate, preserve, and utilize, otherwise siloed, prenatal information artifacts for enhanced self-management of their high-risk conditions, ultimately leading to improved health outcomes.",2024
Bitcoin Price Forecasting and Trading: Data Analytics Approaches,"Currently, the most popular cryptocurrency is bitcoin. Predicting the future value of bitcoin can help investors to make more educated decisions and to provide authorities with a point of reference for evaluating cryptocurrency. The novelty of the proposed prediction models lies in the use of artificial intelligence to identify movement cryptocurrency prices, particularly bitcoin prices. A forecasting model that can accurately and reliably predict the market's volatility and price variations is necessary for portfolio management and optimization in this continually expanding financial market. In this paper, we investigate a time series analysis that makes use of deep learning to investigate volatility and provide an explanation for this behavior. Our findings have managerial ramifications, such as the potential for developing a product for investors. This can help to expand upon our model by adjusting various hyperparameters to produce a more accurate model for predicting the price of cryptocurrencies. Another possible managerial implication of our findings is the potential for developing a product for investors, as it can predict the price of cryptocurrencies more accurately. The proposed models were evaluated by collecting historical bitcoin prices from 1 January 2021 to 16 June 2022. The results analysis of the GRU and MLP models revealed that the MLP model achieved highly efficient regression, at R = 99.15% during the training phase and R = 98.90% during the testing phase. These findings have the potential to significantly influence the appropriateness of asset pricing, considering the uncertainties caused by digital currencies. In addition, these findings provide instruments that contribute to establishing stability in cryptocurrency markets. By assisting asset assessments of cryptocurrencies, such as bitcoin, our models deliver high and steady success outcomes over a future prediction horizon. In general, the models described in this article offer approximately accurate estimations of the real value of the bitcoin market. Because the models enable users to assess the timing of bitcoin sales and purchases more accurately, they have the potential to influence the economy significantly when put to use by investors and traders.",2022
"Machine Learning-Based Approach for Predicting the Altcoins Price Direction Change from a High-Frequency Data of Seven Years Based on Socio-Economic Factors, Bitcoin Prices, Twitter and News Sentiments","Altcoins are alternative types of coins under cryptocurrency, apart from traditional Bitcoins, for which predicting the price movement presents a multifaceted challenge deeply rooted in the volatile nature of the cryptocurrency market. This study compares and analyzes different Machine Learning (ML) and Deep Learning (DL) models for price movement prediction through diverse data sources like Bitcoin prices, social media sentiments, and news sentiments, apart from different socio-economic factors specific to USA geography due to its maturity on use of Altcoins, with temporal scope spanning from 2016 to 2022 collating over 77 M tweets and news items. Ethereum, Binance, XRP, Cardano, Monero, Tron, Stellar, and Litecoin, were considered for experimentation across widely used algorithms like Gradient Boosting, Naive Bayes, Decision Trees, Neural Networks, and the like, with different day-length lags ranging up to 4 days. Highly relevant features were selected using Random Forest selection method and highly correlated features have been removed before the modeling. Accuracy for price movement prediction models varied from 71.03% for Ethereum to 66.14% for Stellar, which were better by 15-20% as compared to percentage benchmarking done by literature to be ranging around 50 s and 60 s. For the model validation, sensitivity analysis involving day-wise lag analysis, and different data splits (based on size and months) were considered, which was stable for the high performing models. Further, an interesting result was observed during the study. In order of priority, Bitcoin prices, social media sentiments, and news sentiments significantly impact altcoin price movement. This implies that by studying the Bitcoin price movement and market sentiments, investors can make wise decisions towards altcoin investments. This study holds significance for researchers and practitioners to understand the impact in the trading market of cryptocurrency and help an investor diversify their portfolio. The findings will be helpful for Algo Trading Platforms, Financial Advisors, Trading Experts, Industry Experts, Researchers, and Scholars.",2024
Cross-modal scenario generation for stock price forecasting using Wasserstein GAN and GCN,"The forecasting of stock price has always been a difficult problem, as the various inputs like company performance, technical innovation, political factors are intricate and often assessed with uncertainty. While most of the existing studies belong to deterministic forecast that focused on either the trend or exact value of future stock price, the forecasted results contain little uncertain information, thus bringing certain risks to investors. In this study, an effective scenario generation method based on wasserstein generative adversarial network (WGAN) is proposed for stock price forecasting, which can characterize the temporally and spatially correlations among different stocks, so as to help investors make proper investment strategies in complicated market environments. To the best of our knowledge, the scenario generation of stock price has been rarely studied by existing publications. Specifically, considering the inherent correlation among stocks, graph convolutional network (GCN) is used to capture the features of related stocks, whereafter the features of target stocks and related stocks are combined. In terms of feature fusion, this paper further uses a pre- trained model to obtain the key information of news headlines as text features, and fully integrates them with historical data through the attention mechanism, thus improving the overall performance of scenario generation. In summary, the proposed model can generate promising scenarios for future stock prices over time based on cross-modal information like historical data and news headlines. Numerical experiments show that our method outperforms other baseline methods in terms of root-mean-square error and average absolute percentage error (the average of several scenarios). For each part of the method, stock correlation is the most helpful for the results, followed by cross-modal information, with scenario generation contributing less to the results. Besides, experiments on a real-life portfolio selection problem also demonstrate that our method brings the highest returns, which proves its effectiveness in practical application.",2024
Interaction of momentum returns in stock and bond markets in Korea,"This study examines the profitability of momentum strategies in stock and bond markets in Korea and tests for a momentum spillover between stocks and bonds. Using weekly data on corporate bonds and common stocks of investment grade firms listed at the KSE from 2001 to 2004, we find significant abnormal returns to momentum strategies by 4bp per week (106 bp cumulative abnormal returns over 25 weeks) from the sample of corporate bonds, but not from the sample of common stocks which turns out to exhibit insignificant reversals over a couple of weeks. This result strikingly contrasts to the well-known evidence observed in the U.S., where common stocks exhibit significant momentum and corporate bonds exhibit significant reversals. Given that stocks and bonds are different claims to the same underlying operating cash flows and are affected by the same firm fundamentals, it is intriguing to observe such different results between stocks and bonds as observed in this study in response to the momentum strategies. The result indicates that the momentum is not a general property of asset returns and might be security-specific in both U.S. and Korea. In order to answer the question of which security returns are a better proxy for firm fundamental news, we examine the lead-lag relationship, between stocks and bonds by looking at whether the bond momentum predicts stock returns over 25 weeks, and vice versa. The answer is in the negative for both directions, indicating that the information linkage between stocks and bonds is fairly weak in Korea. In order to see whether the bond momentum discovered in this study is robust to various liquidity and risk adjustments, we first look at the profitability of bond momentum strategies within liquidity-based subsamples of firms based on the total face value of outstanding debt, the average daily won trading volume of the bonds over the prior 4 weeks, and the average daily turnover ratio of the equity over the prior 4 weeks. The profitability remains significant within the subsamples, indicating that the bond momentum cannot be attributable to illiquidity factors. Similarly, we adjust for risks based on default and maturity risks by matching every firm in the bond momentum portfolio with a benchmark portfolio with roughly the same bond ratings and similar time-to-maturity. The risk-adjusted bond return for each firm is then computed as the difference between the firm's raw bond return and the corresponding benchmark return. The bond momentum strategies applied to these risk-adjusted returns produce far smaller returns than those before adjusted for risk, although they are still significant with 27bp cumulative abnormal returns over 25 weeks and thus cannot be completely explainable by these two risk factors. Additional risk factors are then considered in the Fama-MacBeth's cross-sectional regression framework, which shows that the bond momentum returns are closely related to time-varying risk factors such as the contemporaneous maturity-matched Treasury bond returns and the change in the bond rating scores. Finally, in order to see whether the bond momentum is caused by sluggish responses to future rating revisions of winner and loser portfolios, we look at the change in the average bond ratings of winner and loser portfolios over the next 52 weeks, and the percentage of firms that experience upgrades and downgrades in winner and loser portfolios. Because the rating revisions are likely to be accompanied by corresponding changes in bond prices around the announcement date, we expect to observe positive returns to the bond momentum if losers (winners) subsequently experience more downgrades (upgrades) and decreasing (increasing) prices after portfolio formation. The results show that losers experience significantly more downgrades as well as significantly more upgrades than do winners over the first year after portfolio formation. This observation seems to indicate that the bond momentum cannot be attributable to sluggish responses to future rating revisions.",2006
Performance Appraisal from the Perspective of Organizational Justice: Review and Research Agenda,"Objective: Explore the literature on Performance Appraisal (PA) from the perspective of Organizational Justice, to collaborate with the construction of knowledge and with the identification of research gaps. Theoretical approach: The Knowledge Development Process-Constructivist instrument was used to select and analyze, in a systematic and reflective way, the Bibliographic Portfolio (BP) representative of the theme. Results: It was found the existence of: a literature focused on consequences for people, involving variables such as satisfaction and commitment; preponderance of studies that address PA at the individual level; and, lack of investigations into perceptions of interpersonal and informational justice. The articles mainly analyzed the antecedents and consequences of PA justice perceptions. Among the gaps there is the need to develop models customized to the context that integrate the perceptions of the four factors of justice and of each unit or organization; and the development of studies involving interpersonal and informational justice and perceptions at the organizational level. Originality/Relevance: The study presents aspects of PA justice perceptions as a relevant factor that influences employee behavior and points out research gaps for the evolution of the theme. Theoretical/methodological contributions: This study contributes scientifically as it compiles recognized articles and proposes a research agenda with topics for future investigation. Social contributions/to management: The findings contribute to managers throughout the life cycle of a PAS, by showing how the perception of justice impacts the behavior of employees in achieving organizational goals.",2021
Integrate where it matters,"Many studies have shown that the most treacherous time in the failure-strewn business of mergers comes when companies attempt to combine operations. Surprisingly, however, they often destroy value not as a result of inattention to cle ail but through excessive zeal in their integration efforts.That's because acquirers, recognizing the many potential dangers inherent in the merger process, often attempt to immunize themselves by painstakingly mapping out comprehensive, detailed plans for blending every aspect of operations. What they don't realize is that too much integration can block companies from realizing the benefits of a merger just as easily as too little can. And, in some cases, overintegrating can do far more damage. The authors posit that M&A activity is typically based on one of three types of investment theses . active investing, growing scope and growing scale and that each requires different degrees of merger integration. If an acquired company is the first plank of a new platform in a venture-capitalist firm's portfolio, for example, it will probably require the bare minimum of integration. But deals that enhance scope or scale require executives to pay much more attention to integration. The authors explain how Illinois Too] Works, Sears, Roebuck and Co., BP, Philips Medical Systems and Keppel Offshore & Marine have all benefited from integrating selectively, comprehensively or with a mix of the two, according to whether they were seeking economics of scale or scope.",2004
Ancient DNA reveals phenological diversity of Coast Salish herring harvests over multiple centuries,"Phenological diversity in food resources prolongs foraging opportunities for consumers and buffers them against environmental disturbances. Such diversity is particularly important in forage fish such as Pacific herring (Clupea pallasii), which are foundational to coastal food webs and fisheries. While the importance of phenological diversity is well-known from contemporary studies, the extent to which different populations contribute to fisheries over long time scales is mostly unknown. In this study, we investigated the relative contributions of genetically and phenologically distinct herring populations to Indigenous Peoples' food systems over multiple centuries, using ancient DNA extracted from archaeological herring bones. These bones were excavated from two Coast Salish archaeological sites (Burton Acres Shell Midden and Bay Street Shell Midden) in the Puget Sound region, USA. Using genetic stock identification from seven nuclear DNA markers, we showed that catches at the two sites in central Puget Sound were dominated by January-February and March-April spawners, which are the contemporary spawning groups in the vicinity of the sites. However, May spawners were detected in the older Burton Acres assemblage (dated to 910-685 cal BP), and a mixed stock analysis indicated that catches at this site consisted of multiple populations. These results suggest that Coast Salish ancestors used a portfolio of herring populations and benefited from the ecological resource wave created by different spawning groups of herring. This study of ancient DNA allowed us to glimpse into Indigenous traditional food and management systems, and it enabled us to investigate long-term patterns of biodiversity in an ecologically important forage fish species.",2022
Breeding evaluations in aquaculture using neural networks,"Deep learning comes with a portfolio of highly flexible models, known as neural networks (NNs), capable of solving various problems and setting new high standards for prediction accuracy. Nevertheless, whether NNs could be of value in aquaculture selective breeding settings is unclear as the whole topic is underexplored. Furthermore, fine-tuning a plethora of hyperparameters before fitting a neural network is a daunting task. Using simulated and a publicly available dataset on genetic resistance in carp against koi herpes virus (KHV), various neural network architectures were benchmarked against commonly used animal breeding models. More specifically, the simulated datasets comprised 36000 phenotyped animals genotyped for 54000 single nucleotide polymorphisms (SNPs). In contrast, the carp dataset included 1255 carp juveniles with survival recordings for KHV that were genotyped for 15615 SNPs. The assessed NN architectures included multilayer perceptrons (MLPs), convolution neural networks (CNNs) and local convolution neural networks (LCNNs). In addition, the effect of various hyperparameters of neural networks, such as the number of hidden layers, neurons per layer, activation function, learning rate, batch size, and regularisation techniques like dropout, were examined. In the simulated datasets, fully connected models with 5 hidden layers and 100 neurons per layer performed slightly better (1 - 4 %) than ridge-regression best linear unbiased prediction (rrBLUP), while the CNNs gave the lowest prediction accuracies (similar to 14 % lower than MLPs) and the ones from LCNN in between the above (similar to 8 lower than MLPs). Nevertheless, the estimated breeding values from NNs appeared more biased than rrBLUP (mean regression slope of 1.2 for the NN with the highest prediction accuracy vs 1.08). A reverse picture was observed in the case of the carp dataset, where following the application of receiver operating characteristic (ROC) curves, the animal breeding models outperformed neural networks by more than 2 % (based on the area under the curve index). In this case the LCNN had the highest area under the curve index from all NNs. Overall, NNs could be valuable tools in aquaculture breeding programs, though large training datasets of tens of thousands or more of phenotyped and genotyped animals seem to be required.",2024
Machine learning and deep learning for mineralogy interpretation and CO2 saturation estimation in geological carbon Storage: A case study in the Illinois Basin,"Carbon capture and storage (CCS) is a promising approach to simultaneously maintaining energy security and reducing carbon dioxide (CO2) emissions under the current energy portfolio that is dominated by fossil fuel energy. Pre-injection formation characterization and post-injection CO2 monitoring are two critical tasks to guarantee storage efficiency in CCS. The CCS projects in the Illinois Basin, the first large-scale CO2 injection into saline aquifers in the United States, employed conventional and the latest pulsed neutron logging (PNL) tools for mineralogy interpretation and CO2 saturation estimation, which provide valuable references for future CCS projects. Because of the inherent fuzziness of petrophysical measurements and complex subsurface heterogeneity, interpreting well-logging data is time-consuming, and its accuracy can be user-biased. In recent years, data-driven methods have been widely used to capture the non-linear patterns between input features and interpretation results. This work applied and evaluated four commonly used machine learning (ML) models, including ridge regression (RR), random forest (RF), gradient boosting regression (GBR), support vector regression (SVR), and one deep learning (DL) model, the artificial neural network (ANN). We optimized the hyperparameters of the four ML models and the DL model using the simulated annealing algorithm and the grid search strategy, respectively. The input features of the mineralogy interpretation models were eleven conventional well-logging parameters, and the label data (i.e., ground truth) were the porosity and volumetric fractions of six minerals, including quartz, feldspar, dolomite, calcite, clay, and iron minerals. The results demonstrated that the GBR and RF models were superior in predicting volumetric fractions of minerals and porosity; label data with low coefficient of variation (CV) values tended to yield better performance. For CO2 saturation estimation, the RF was the best-performing model, followed by SVR, ANN, GBR, and RR. Furthermore, we conducted feature importance ranking using the permutation importance algorithm and found that the formation sigma and well pressure were the most important features in this study. The study of CCS projects in the Illinois Basin bridges the gap between the limited knowledge and understanding of geological carbon storage and the increasing demand for reliable, cost-effective, and sustainable energy solutions.",2024
Temporal Contrastive and Spatial Enhancement Coarse Grained Network for Weakly Supervised Group Activity Recognition,"Group activity recognition (GAR) is an increasingly popular topic in the field of computer vision. Numerous researchers have proposed a range of methods to achieve outstanding recognition performance. However, these methods invariably require fine-grained personal feature extraction and a large network architecture to aggregate individual features or reason person relationships. To mitigate the need for a bloated portfolio of annotations and high training costs, weak supervision has emerged as a promising approach. Under the weak supervision paradigm, only coarse -grained labels are used during network training. Nevertheless, this method poses two key challenges. Firstly, it is limited in its ability to model temporal relationships among individual persons, and secondly, it tends to focus on less relevant information, thereby leading to suboptimal network parameter optimization. Both of these challenges result in erroneous temporal information judgment and training inefficiencies. To address these challenges within the weak supervision paradigm, we propose a novel Temporal Contrastive and Spatial Enhancement Coarse -Grained Network (TCSE-CGN) to solve the GAR problem. TCSE-CGN comprises two simple yet effective streams, namely the Spatial Enhancement Stream and the Temporal Contrastive Stream. After extracting features using only several RGB frames, half of the extracted feature is sent to the Spatial Enhancement Stream for enhancement using an attention mechanism. Consequently, the network automatically learns more representative information. The remaining feature is sent to the Temporal Contrastive Stream, which uses contrastive learning to model temporal relationships among all RGB frame -level features. Specifically, the network is guided to learn the hidden semantic temporal information about inter -frame sequences. Network parameters are optimized using a combination of universe cross -entropy loss and a novel temporal contrastive loss. Comprehensive experiments are conducted on two widely used datasets, namely the Volleyball dataset and the Collective dataset, to demonstrate the effectiveness of TCSECGN. Results show that TCSE-CGN performs competitively with other works that require more supervision and a larger architecture.",2024
Learning just got easier,"The future looks bright for e-learning according to NOP research commissioned by training film outfit Video Arts 87% of manufacturing and engineering companies say they are likely to use e-learning to train employees, and 39% claim to be doing so already. Research firm IDC forecasts that the European market for e-learning will be worth $4 billion by 2004. While the US currently leads the way, Europe is catching up rapidly, the IT industry having taken online training onboard rather faster than more traditional engineering sectors. E-learning no longer simply means putting a CD-Rom course on the internet. The internet, say companies promoting e-learning, offers a rich, collaborative learning environment, available anytime and anywhere. Web-based training can be tailored to meet the objectives of companies and the pace of employees. Smartforce is one of the largest suppliers of e-learning packages, with 2,500 corporate users including BP and British Gas. The company has 5,000 hours of content covering IT and e-business programmes, business and interpersonal skills. We offer virtual classrooms where students can experience workshops or online training connected to the web, role play simulations, or access a live mentor at any time around the clock, says global programmes manager Laura Overton. BP has a powerful e-learning facility which allows employees to learn at their own pace, at home or in the office. Many oil majors and power companies use the Oxford Princeton Programme, which offers web-based training for upstream and downstream operations. These online courses combine programmes from Energy Studies in Oxford and the Princeton Energy Programme in the US, which merged last July. But some companies are doing their own thing. BAE Systems launched a Virtual University (W) in 1998. Delivering e-learning is a key aspect of BAE's strategy, targeted at 130,000 employees nationwide, says Dr Andrew Pember, VU head of new programmes. The VU offers a learning and development guide on around 300 courses that can be delivered to employees. These focus on IT and business skills and use commercial, off-the-shelf material - such as psychometric tools - to help people identify their learning styles. We aim to build up a more focused engineering course portfolio eventually, but there is a lack of online teaching resources for engineers, says Pember.",2001
Knowledge building about performance evaluation in lean production An investigation on international scientific research,"Purpose The purpose of this paper is to focus on the analysis of the characteristics and gaps of a literature fragment from the international scientific publications on performance evaluation in lean production, aiming to generate new knowledge and suggestions for future scientific research. Design/methodology/approach The authors have adopted ProKnow-C methodology, a qualitative research approach that is used for literature selection, identification, analysis and reflection on the established characteristics. Findings From a bibliographic portfolio of 67 research works, 91 per cent of the works have individual metrics and 84 per cent have sets of metrics. Evaluating the focus of the performance measurement system, 34 per cent of works measure performance, 43 per cent compare performance and only 18 per cent assist in strategic planning. Evaluating the phases of the PMS life cycle, 87 per cent attend to the design, and 66 per cent attend to the activities of data collection, allow diagnosis, evaluate performance and communicate results. However, only 3 per cent of the studies analysed the use of PMS after its implementation and no research evidenced the review of metrics and objectives based on strategic planning. Originality/value This research adds value because its results allow researchers and practitioners to visualise the boundaries of the knowledge from the BP, about performance management in lean production, and what their gaps are in relation to the reference model of performance evaluation. This research is original because it was not observed in the literature review, a research that used the ProKnow-C methodology for analysis of the alignment and gaps between lean production and performance evaluation.",2019
DeepPricing: pricing convertible bonds based on financial time-series generative adversarial networks,"Convertible bonds are an important segment of the corporate bond market, however, as hybrid instruments, convertible bonds are difficult to value because they depend on variables related to the underlying stock, the fixed-income part, and the interaction between these components. Besides, embedded options, such as conversion, call, and put provisions are often restricted to certain periods, may vary over time, and are subject to additional path-dependent features of the state variables. Moreover, the most challenging problem in convertible bond valuation is the underlying stock return process modeling as it retains various complex statistical properties. In this paper, we propose DeepPricing, a novel data-driven convertible bonds pricing model, which is inspired by the recent success of generative adversarial networks (GAN), to address the above challenges. The method introduces a new financial time-series generative adversarial networks (FinGAN), which is able to reproduce risk-neutral stock return process that retains the unique statistical properties such as the fat-tailed distributions, the long-range dependence, and the asymmetry structure etc., and then transit to its risk-neutral distribution. Thus it is more flexible and accurate to capture the dynamics of the underlying stock return process and keep the rich set of real-world convertible bond specifications compared with previous model-driven models. The experiments on the Chinese convertible bond market demonstrate the effectiveness of DeepPricing model. Compared with the convertible bond market prices, our model has a better convertible bonds pricing performance than both model-driven models, i.e. Black-Scholes, the constant elasticity of variance, GARCH, and the state-of-the-art GAN-based models, i.e. FinGAN-MLP, FinGAN-LSTM. Moreover, our model has a better fitting capacity for higher-volatility convertible bonds and the overall convertible bond market implied volatility smirk, especially for equity-liked convertible bonds, convertible bonds trading in the bull market, and out-of-the-money convertible bonds. Furthermore, the Long-Short and Long-Only investment strategies based on our model earn a significant annualized return with 41.16% and 31.06%, respectively, for the equally-weighted portfolio during the sample period.",2022
Survey of Machine Learning-Based Rotating Detonation Engine Diagnostics: Evaluation for Broad Application in Experimental Facilities,"Laboratory rotating detonation engine (RDE) operations have become increasingly reliable in recent years, giving strong indication that industrial applications are becoming more plausible. Real-time monitoring of combustion behavior within the RDE is a crucial step towards actively controlled RDE operation in the laboratory environment and eventual turbine integration. For these reasons, various machine learning methods have been developed to advance the efficiency of RDE diagnostic techniques from conventional post-processing efforts to lab-deployed real-time methods. This work evaluates and compares various convolutional neural networks (CNNs) trained in previous NETL studies according to metrics effecting diagnostic feasibility, external applicability, and performance. Each CNN surveyed, including image classification, object detection, and time series classification, is used to develop total RDE diagnostics and evaluated alongside conventional techniques with respect to real-time capabilities. Real-time capable diagnostics are deployed and evaluated in the laboratory environment using an altered experimental setup, which is outlined herein for possible adaptations in external experimental facilities. Of particular interest, image-based CNNs are applied to externally provided images to approximate dataset restrictions. Conventional methods and object detection are found to offer diagnostic feedback rates of 0.017 and 9.50 Hz currently limited to post-processing, respectively. Image classification using high-speed chemiluminescence images, and time series classification using high-speed flame ionization and pressure measurements, achieve classification speeds enabling real-time diagnostic capabilities, averaging lab-deployed diagnostic feedback rates of 4 and 5 Hz, respectively. Object detection, while currently limited to post-processing usage, achieves the most refined diagnostic time-step resolution of 20 mu sec. Image and time series classification require the additional correlation of sensor data, extending their time-step resolutions to 80 msec. Comparisons show that no single diagnostic approach outperforms its competitors across all metrics. Instead, each diagnostic is uniquely suited for a set of primary objectives and constraints. This finding justifies the need for a machine learning portfolio containing a host of networks selected and modified to address specific needs throughout the RDE research community.",2023
Technologies and Designs for Small Optical Missions,"The worldwide growing interest in small payloads and platforms require the use of solutions that are compact, cost effective and simple to align and test. In particular, the possibility to use constellations of small satellites require the payloads to be easily built in a relatively large number compared to typical space missions where only the flight model and possibly few flight spares need to be procured. This clearly drives the payload architecture towards solutions that can be easily manufactured, and in large quantities. The recent progress of manufacturing techniques favours this rapid change. For instance, for some applications the possibility to use a spectrometer with a magnification different from one is a key factor to enable instrument designs that are compact, cost effective and with high performance. This can be for instance achieved by using freeform or aspheric mirrors and freeform or spherical gratings. Other compact designs use instead linearly variable filters as dispersive devices, pointing to a different set of applications and performance. The progress on small satellites and payloads, especially in the vision of large constellations, also benefits from the rapid development of imaging processing and deep learning machines, for instance equipping the payloads with powerful on-board data processor for real time generation of Level 2 data to face the challenge of handling the huge amount of data that is produced on-board. By combining all these developments, it is possible to produce a portfolio of innovative multi/hyperspectral payloads covering a broad range of applications, spanning from high spatial resolution to large swath width, from minisatellite to cubesat format. Exploiting the flexibility and interoperability of these payloads, the users will be provided with turnkey solutions and real time response to their specific needs. The European Space Agency is leading several R&D activities in the field of compact multispectral and hyperspectral payloads, fit for small platforms. These activities encompass technology development of novel optical designs, materials and processes, including also engineering of detectors, EEE components and dedicated data processing to achieve innovative and cost-effective solutions. The paper provides an overview of the technology developments, the status of the instruments manufactured so far and those in operation, their performance and their expected applications. An example of an imaging spectrometer design that is extremely compact, realized with only two spherical optical elements and with a magnification different from one (1:3) is also addressed.",2018
The four principles of enduring success,"When your company is doing well, and money is pouring in, how do you know if it could be doing better? How can you tell which management practices are making the difference -and which are merely not doing obvious harm? To find out, Professor Stadler and a team at Innsbruck University's business school conducted a massive benchmarking study comparing nine pairs of European companies over 50 years. Each pair was from the same industry (and, preferably, the same country) and included one exceptional performer and one less impressive, but solid performer. The project yielded four main findings, which Stadler calls the four principles of enduring success: Exploit before you explore. Great companies don't innovate their way to growth-they grow by efficiently exploiting the fullest potential of existing innovations. Diversify your business portfolio. Good companies, conscious of the dangers of irrational conglomeration, tend to stick to their knitting. But the great companies know when to diversify, and they remain resilient by maintaining a wide range of suppliers and a broad base of customers. Remember your mistakes. Good companies tell stories of success, but great companies also tell stories of past failures to avoid repeating them. Be conservative about change. Great companies very seldom make radical changes-and take great care in their planning and implementation. How much difference do these principles make? An investment of $1 in 1953 in the group of companies in the study that consistently applied them-insurers Allianz, Legal & General, and Munich Re; financial services firm HSBC; building materials maker Lafarge; high-tech firms Nokia and Siemens; oil giant Shell; and pharmaceutical firm GlaxoSmithKline-would be worth $4,077 today. A $1 investment in the comparison companies-Aachener und Munchener, Prudential Limited, and Cologne Re; Standard Chartered; Ciments Frangais; Ericsson and AEG; BP; and Wellcome-would have yielded $713.",2007
Learning to hit the Ground Running - The Online Way,"On the road of transition, many people in South Affica still lack the skills needed to participate in society. The South African Government committed itself to empower its citizens with the skills and competencies required to function optimally in the world of work. To ensure that people hit the ground running when they enter the labour market, the National Qualifications Framework (NQF) stipulates critical, cross-field learning outcomes as exit requirements at all levels of education and training. In adherence to this framework, a major curriculum review in the School of Medicine, University of the Free State, was introduced in 2000. An increased focus on helping students develop not only subject-specific and professional skills, but also lifelong learning skills, and a commitment to achieve a synergistic relationship between learning and technology, were among the goals of the review. In 2000-2006, a face-to-face instructional approach was used in a module on generic skills for first-year medical students. Task-oriented activities were used to develop proficiency in skills such as communication, collaboration and the use of computers. However, challenging logistics and cumbersome paper-based portfolio assessment prompted the relocation of this module to an online environment. Since constructivist learning theories claim that generic skills development is encouraged in environments conducive to deep learning, authentic content, social negotiation, reflexivity and tasks requiring active involvement of students, were emphasised. No consensus exists in the literature regarding the benefits of computer-assisted learning. Online learning could even be dangerous in the hands of students who struggle with self-regulatory tasks. This study aimed to evaluate the acceptability and effectiveness of the new approach to skills development. A snapshot descriptive study investigated whether students could identify with the technology-based approach and whether the delivery process permitted deep, constructivist learning. The questionnaire survey and nominal group discussion used to capture student feedback, form part of a more comprehensive action research project aimed at internal quality assurance and on-going improvement of generic skills development. The results indicate that online learning not necessarily leads to enhanced critical outcomes, thus highlighting the vital role of methodology in skills development. The study further confirms that technology is only a tool and not an end in itself in addressing the skills needs of a diverse student population. Ultimately, the how-to knowledge gained by relocating paper-based learning content to an online environment, may be applicable to other similar contexts.",2008
"Patterns of spread and adoption of millet agriculture along the eastern rim of the Tibetan Plateau: Archaeobotanical evidence from Houzidong, Southwest China (4200-4000 cal. BP)","The spread of domesticated crops has commonly occurred alongside broad patterns of long-and short-distance human movements and culture contact across regions. While exchange across Eurasia along the so-called Silk Road has been much discussed, recent work has revealed increasingly more evidence for early north-south contact along the eastern rim of the Tibetan Plateau. Main points of debate concern the timing and direction of the spread of agriculture and domesticated crops. This paper contributes to these discussions by presenting new data from macrobotanical remains and phytoliths from Houzidong in southwest Sichuan, a Neolithic site on the eastern rim of the Tibetan Plateau. The results show that the main crops during the late Neolithic (4200-4000 cal. BP) were foxtail millet (Setaria italica) and broomcorn millet (Panicum miliaceum), with a small amount of rice (Oryza sativa), but that agriculture was overall not a major focus. Rather, the subsistence at Houzidong like at other sites in the region was highly diverse, relying on gathering, hunting, and small-scale cultivation with considerable crop diversity aimed at minimizing the impact of potential crop failure. This paper shows that subsistence practices differed markedly between sites, local populations exploiting the rich natural resources in the respective ecological niches in various ways. We argue that the wide variety of food sources available in southwest China allowed people to mitigate risk but also made them more receptive to new food sources such as plant crops, experimenting with them and adding them to their portfolio. Similar patterns can be seen in the adoption and adaptation of other outside influences with each community picking and choosing what suited them best, thus creating the rich and varied patchwork of highly localized cultural phe-nomena that came to characterize southwest China.",2023
Organizational Performance Management and the 'Sustainability' of the Performance Evaluation System: A View Guided by the Integrative Review Perspective,"Objective: This paper aims to explore the scientific literature in order to show how the process of institutionalizing (incorporating) the 'sustainability' of the performance evaluation system (PES) contributes to organizational performance management (OPM). Methodology: An integrative review was carried out with the support of the ProKnow-C intervention instrument to select 39 articles that formed part of the bibliographic portfolio (BP). The PB analysis was conducted through the evolution of the performance evaluation (PE) area; the elaboration of the concept of OPM, which guided this research; and the development of a 'lens' using the concept of the 'sustainability' of the PES, from which it was possible to identify its essential aspects and use them as a basis for exploration. With this, it was feasible to demonstrate the relationship of the 'lens' with the guiding concept that allowed the elaboration of a taxonomy. Findings: In terms of the results, the evolution of a mature theme in the literature (PE) from a new perspective and with an emphasis on the integration of elements related to management is presented, allowing for the identification that the management elements are incipient and little developed in the literature. The elaboration of a taxonomy made it possible to verify that 'learning' is the aspect of sustainability that most contributes to OPM, that the 'holistic/integrated vision' element encompasses all aspects that determine the sustainability of the PES, and that the 'use of information' is the common component and link between the sustainability of PES and OPM in promoting organizational learning, supporting communication and providing it with a foundation for decision-making. Originality: Gaps were identified in the literature that led to the elaboration of a future research agenda for questions related to the importance of culture in encouraging the continuous process of performance management, the relationship of organizational learning with the context and strategic alignment, and the contribution of the human factor and culture to the continuous improvement of organizational performance. Thus, this research offers a new guiding perspective for OPM.",2022
Solar Photovoltaic Modules' Performance Reliability and Degradation Analysis-A Review,"The current geometric increase in the global deployment of solar photovoltaic (PV) modules, both at utility-scale and residential roof-top systems, is majorly attributed to its affordability, scalability, long-term warranty and, most importantly, the continuous reduction in the levelized cost of electricity (LCOE) of solar PV in numerous countries. In addition, PV deployment is expected to continue this growth trend as energy portfolio globally shifts towards cleaner energy technologies. However, irrespective of the PV module type/material and component technology, the modules are exposed to a wide range of environmental conditions during outdoor deployment. Oftentimes, these environmental conditions are extreme for the modules and subject them to harsh chemical, photo-chemical and thermo-mechanical stress. Asides from manufacturing defects, these conditions contribute immensely to PV module's aging rate, defects and degradation. Therefore, in recent times, there has been various investigations into PV reliability and degradation mechanisms. These studies do not only provide insight on how PV module's performance degrades over time, but more importantly, they serve as meaningful input information for future developments in PV technologies, as well as performance prediction for better financial modelling. In view of this, prompt and efficient detection and classification of degradation modes and mechanisms due to manufacturing imperfections and field conditions are of great importance towards minimizing potential failure and associated risks. In the literature, several methods, ranging from visual inspection, electrical parameter measurements (EPM), imaging methods, and most recently data-driven techniques have been proposed and utilized to measure or characterize PV module degradation signatures and mechanisms/pathways. In this paper, we present a critical review of recent studies whereby solar PV systems performance reliability and degradation were analyzed. The aim is to make cogent contributions to the state-of-the-art, identify various critical issues and propose thoughtful ideas for future studies particularly in the area of data-driven analytics. In contrast with statistical and visual inspection approaches that tend to be time consuming and require huge human expertise, data-driven analytic methods including machine learning (ML) and deep learning (DL) models have impressive computational capacities to process voluminous data, with vast features, with reduced computation time. Thus, they can be deployed for assessing module performance in laboratories, manufacturing, and field deployments. With the huge size of PV modules' installations especially in utility scale systems, coupled with the voluminous datasets generated in terms of EPM and imaging data features, ML and DL can learn irregular patterns and make conclusions in the prediction, diagnosis and classification of PV degradation signatures, with reduced computation time. Analysis and comparison of different models proposed for solar PV degradation are critically reviewed, in terms of the methodologies, characterization techniques, datasets, feature extraction mechanisms, accelerated testing procedures and classification procedures. Finally, we briefly highlight research gaps and summarize some recommendations for the future studies.",2022
PERSPECTIVES ON DESIGN THINKING IN BUSINESS AND INNOVATION MANAGEMENT,"The business world has never been more erratic or unpredictable. Competition comes not only for product, services and technology, but also for sales channels, policies, people and brand. In order to survive in today's unpredictable world, organizations must actively create, embrace and implement new ideas. This requires the creative thinking of the entire team. The concept of design thinking allows to realize such requirements. At-present design thinking is considered as a way to solve problems of a business or organization by empathy, deep understanding of the client, the user, the consumer of goods and services. This approach to decision making helps the reduction of the risks of wasted resources and time by introducing new design thinking methods based on key aspects. First, design thinking is human-centered, it emphasizes the importance of deep learning people's needs and lives while creating value before starting to develop solutions. Second, design thinking is a method based on the ability to create new ideas and innovate. Third, design thinking in business allows you to develop multiple options so you don't risk everything and consider the desires of all stakeholders while still in the search phase, which means being able to manage a portfolio of new ideas. Finally, the process is iterative. It involves doing experimental research in the real world instead of doing analysis using historical data. It is a process of constantly shaping and testing prototypes and changing perceptions of current tools in the business. These and other aspects are discussed in more detail in the article and underline the relevance of the research topic. Among other issues, the article considers the concept of design thinking, justified the history of development, the popularity of this new type of management tool in the economic space, highlighted the main features of design thinking, the stages of implementation, the basic tools and their capabilities. The author offered to consider design thinking as a way of the decision of a certain question in other way with use of completely different approach. It is another way of thinking or product mapping, which relies on the concept of design. This can include convergent and divergent thinking, testing and phasing, examining customers' opinions, views and tastes, and doing ethnographic research. And if all abovementioned factors are combined, this process is called design thinking. And if we add design thinking to management, we can get a number of quantitative and balanced methods of solving individual business-issues. That's why the article reveals the specifics of using design thinking on the example of certain companies, such as RealtimeBoard, Netflix, Airbnb, and presents the results of empirical research of French companies on the scope of design thinking. Focuses on selected areas of design thinking application in different business areas (business design, human resource management, etc.). In this article is presented a vision for future trends in design thinking.",2022
A Review of Degradation and Reliability Analysis of a Solar PV Module,"Affordability, Long-term warranty, scalability, as well as continuous decline in the LCOE (levelized cost of electricity) of PV (Photovoltaic) in many nations, are largely responsible for the current enormous up thrust in global installation of solar PV modules, at residential roof-top as well as utility-scale systems. Also, as the world's energy portfolio evolves toward cleaner energy sources, PV deployment is anticipated to maintain this increasing trend. Despite this, these PV modules are subjected to a broad range of climatic conditions in outdoor application, regardless of the PV module material/type and technology used. These modules are frequently subjected to high chemical, photochemical, and thermomechanical stress because of the reason that these PV modules are exposed to extreme environmental conditions. In addition to manufacturing flaws, these circumstances have a greater impact on the aging rate, flaws, and degradation of PV modules. As a result, different investigations on PV dependability and degradation mechanisms have been conducted recently. These studies not only shed light on how the performance of PV modules deteriorates with time, but most importantly, they provide useful input for future advancements in PV technology and performance forecasting for more accurate financial modeling. Due to this, it is crucial to quickly and accurately identify and classify the degradation modes and mechanisms caused by manufacturing flaws and environmental factors in order to reduce the likelihood of failure and the risks that go along with it. Visual examination, EPM (Electrical-Parameter-Measurements), imaging techniques, and latest data-driven techniques have all been suggested and used in the literature to assess or describe the deterioration signatures and mechanisms/pathways of PV modules. This report offers a critical analysis of recent research that examined the performance reliability and deterioration of solar PV systems. The objective is to identify important topics, advance the state of the art, and offer well-considered suggestions for upcoming research, especially in the field of data-driven analytics. Data-driven analytical methods, such as DL (Deep Learning) ML (Machine Learning) models, have astounding computational abilities to process large amounts of data, with diverse features, and with minimal computation time. This contrasts with visual inspection and statistical approaches, which are more time-intensive and require significant human experience. They can therefore be used to evaluate the performance of a module in manufacturing, field deployments, and lab settings. DL and ML can observe erratic patterns and draw useful conclusions in the classification, diagnosis, and prediction of PV performance degradation signatures thanks to the enormous size of PV module installations, particularly in systems for utility scales, and the large datasets produced in terms of features from imaging and EPM data. In terms of methodology, datasets, characterization techniques, accelerated testing procedures, feature extraction mechanisms, classification procedures, analysis and comparison and critical analysis of solar PV deterioration models. Lastly, we briefly describe any potential research gaps and briefly list some suggestions for additional research.",2024
An automated treatment planning portfolio for whole breast radiotherapy,"BackgroundAutomation in radiotherapy presents a promising solution to the increasing cancer burden and workforce shortages. However, existing automated methods for breast radiotherapy lack a comprehensive, end-to-end solution that meets varying standards of care.PurposeThis study aims to develop a complete portfolio of automated radiotherapy treatment planning for intact breasts, tailored to individual patient factors, clinical approaches, and available resources.MethodsWe developed five automated conventional treatment approaches and utilized an established RapidPlan model for volumetric arc therapy. These approaches include conventional tangents for whole breast treatment, two variants for supraclavicular nodes (SCLV) treatment with/without axillary nodes, and two options for comprehensive regional lymph nodes treatment. The latter consists of wide tangents photon fields with a SCLV field, and a photon tangents field with a matched electron field to treat the internal mammary nodes (IMNs), and a SCLV field. Each approach offers the choice of a single or two isocenter setup (with couch rotation) to accommodate a wide range of patient sizes. All algorithms start by automatically generating contours for breast clinical target volume, regional lymph nodes, and organs at risk using an in-house nnU-net deep learning models. Gantry angles and field shapes are then automatically generated and optimized to ensure target coverage while limiting the dose to nearby organs. The dose is optimized using field weighting for the lymph nodes fields and an automated field-in-field approach for the tangents. These algorithms were integrated into the RayStation treatment planning system and tested for clinical acceptability on 15 internal whole breast patients (150 plans) and 40 external patients from four different institutions in Switzerland, Argentina, Iran, and the USA (360 plans). Evaluation criteria included ensuring adequate coverage of targets and adherence to dose constraints for normal structures. A breast radiation oncologist reviewed the single institution dataset for clinical acceptability (5-point scale) and a physicist evaluated the multi-institutional dataset (use as is or edit).ResultsThe dosimetric evaluation across all datasets (510 plans) showed that 100% of the automated plans met the dose coverage requirements for the breast, 99% for the SCLV, 98% for the axillary nodes, and 91% for the IMN. As expected, hot spots were more prevalent when multiple fields were combined. For the heart, ipsilateral lung, and contralateral breast, automated plans met constraints for 95%, 92%, and 95% of the plans, respectively. Physician evaluation of the 15 internal patients indicated that all automated plans were clinically acceptable with minor edits. Notably, the use of automated contours with the RapidPlan model resulted in plans that were immediately ready for use in 73% of cases (95% confidence interval, 95% CI [51- 96]) of patients, with the remaining cases requiring minor stylistic edits. Similarly, the physicist's review of the 40 multi-institution patients showed that the auto-plans were ready for use 79% (95% CI [73,85]) of the time (95% CI [73,85]), with edits needed for the remaining cases.ConclusionThis study demonstrates the feasibility of a comprehensive automated treatment planning model for whole breast radiotherapy, effectively accommodating diverse treatment paradigms.",2025
Prediction of cryptocurrency's price using ensemble machine learning algorithms,"Purpose - Cryptocurrency markets are gaining popularity, with over 23,000 cryptocurrencies in 2023 and a total market valuation of 870.81 billion USD in 2023. With its increasing popularity, cryptocurrencies are also susceptible to volatility. Predicting the price with the least fallacy or more accuracy has become the need of the hour as it significantly influences investment decisions. Design/methodology/approach - This study aims to create a dynamic forecasting model using the ensemble method and test the forecasting accuracy of top 15 cryptocurrencies' prices. Statistical and econometric model prediction accuracy is examined after hyper tuning the parameters. Drawing inferences from the statistical model, an ensemble model using machine learning (ML) algorithms is developed using gradient-boosted regressor (GBR), random forest regressor (RFR), support vector regression (SVR) and multi-layer perceptron (MLP). Validation curves are utilized to optimize model parameters and boost prediction accuracy. Findings - It is found that when the price movement exhibits autocorrelation, the autoregressive integrated moving average (ARIMA) model and the ensemble model performed better. ARIMA, simple linear regression (SLR), random forest (RF), decision tree (DT), gradient boosting (GB) and multi-model regression (MLR) ensemble models performed well with coins, showing that trends, seasonality and historical price patterns are prominent. Furthermore, the MLR approach produces more accurate predictions for coins with higher volatility and irregular price patterns. Research limitations/implications - Although the dataset includes crisis period data, anomalies or outliers are yet to be explicitly excluded from the analysis. The models employed in this study still demonstrate high accuracy in predicting cryptocurrency prices despite these outliers, suggesting that the models are robust enough to handle unexpected fluctuations or extreme events in the market. However, the lack of specific analysis on the impact of outliers on model performance is a limitation of the study, as it needs to fully explore the resilience of the forecasting models under adverse market conditions. Practical implications - The present study contributes to the body of literature on ensemble methods in forecasting crypto price in general, potentially influencing future studies on price forecasting. The study motivates the researchers on empirical testing of our framework on various asset classes. As a result, on the prediction ability of ensemble model, the study will significantly influence the decision-making process of traders and investors. The research benefits the traders and investors to effectively develop a model to forecast cryptocurrency price. The findings highlight the potential of ensemble model in predicting high volatile cryptocurrencies and other financial assets. Investors can design the investment strategies and asset allocation decisions by understanding the relationship between market trends and consumer behavior. Investors can enhance portfolio performance and mitigate risk by incorporating these insights into their decision-making processes. Policymakers can use this information to design more effective regulations and policies promoting economic stability and consumer welfare. The study emphasizes the need for using diversified model to understand the market dynamics and improving trading strategies. Originality/value - This research, to the best of our knowledge, is the first to use the above models to develop an ensemble model on the data for which the outliers have not been adjusted, and the model still outperformed the other statistical, econometric, ML and deep learning (DL) models.",2025
